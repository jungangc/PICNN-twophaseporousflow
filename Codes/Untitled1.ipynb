{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22a6de-cdc2-4c34-b68b-5008c80a6f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/user/jungangc/PICNN-2phase/PICNN-2phaseflow-constBHP-64by64-homo-Progressive-10steps-homo/Codes\n",
      "0.01\n",
      "[timestep: 1] [epoch: 1] loss: 3013.3381347656\n",
      "[timestep: 1] [epoch: 31] loss: 10.2591228485\n",
      "[timestep: 1] [epoch: 61] loss: 2.5205993652\n",
      "[timestep: 1] [epoch: 91] loss: 1.0430585146\n",
      "[timestep: 1] [epoch: 121] loss: 1.2984540462\n",
      "[timestep: 1] [epoch: 151] loss: 1.3295247555\n",
      "[timestep: 1] [epoch: 181] loss: 0.7873214483\n",
      "[timestep: 1] [epoch: 211] loss: 0.7326619625\n",
      "[timestep: 1] [epoch: 241] loss: 0.7441860437\n",
      "[timestep: 1] [epoch: 271] loss: 0.7061132193\n",
      "[timestep: 1] [epoch: 301] loss: 0.9713774920\n",
      "[timestep: 1] [epoch: 331] loss: 0.8289812803\n",
      "[timestep: 1] [epoch: 361] loss: 0.6741989851\n",
      "[timestep: 1] [epoch: 391] loss: 0.6701477170\n",
      "[timestep: 1] [epoch: 421] loss: 0.9813027382\n",
      "[timestep: 1] [epoch: 451] loss: 0.9239687920\n",
      "[timestep: 1] [epoch: 481] loss: 0.6565639973\n",
      "[timestep: 1] [epoch: 511] loss: 0.7557948828\n",
      "[timestep: 1] [epoch: 541] loss: 0.7563557029\n",
      "[timestep: 1] [epoch: 571] loss: 0.6638236642\n",
      "[timestep: 1] [epoch: 601] loss: 0.6390359402\n",
      "[timestep: 1] [epoch: 631] loss: 0.7299363613\n",
      "[timestep: 1] [epoch: 661] loss: 0.6505890489\n",
      "[timestep: 1] [epoch: 691] loss: 0.6585382223\n",
      "[timestep: 1] [epoch: 721] loss: 0.6234669685\n",
      "[timestep: 1] [epoch: 751] loss: 0.6317614317\n",
      "[timestep: 1] [epoch: 781] loss: 0.5890872478\n",
      "[timestep: 1] [epoch: 811] loss: 0.7502019405\n",
      "[timestep: 1] [epoch: 841] loss: 0.7962525487\n",
      "[timestep: 1] [epoch: 871] loss: 0.7155321240\n",
      "[timestep: 1] [epoch: 901] loss: 1.0444533825\n",
      "[timestep: 1] [epoch: 931] loss: 0.7231728435\n",
      "[timestep: 1] [epoch: 961] loss: 0.7371566296\n",
      "[timestep: 1] [epoch: 991] loss: 0.8294245601\n",
      "[timestep: 1] [epoch: 1021] loss: 0.5846045017\n",
      "[timestep: 1] [epoch: 1051] loss: 0.6512111425\n",
      "[timestep: 1] [epoch: 1081] loss: 0.6168295145\n",
      "[timestep: 1] [epoch: 1111] loss: 0.6045294404\n",
      "[timestep: 1] [epoch: 1141] loss: 0.8521385789\n",
      "[timestep: 1] [epoch: 1171] loss: 0.6940225959\n",
      "[timestep: 1] [epoch: 1201] loss: 0.6230907440\n",
      "[timestep: 1] [epoch: 1231] loss: 0.6089544296\n",
      "[timestep: 1] [epoch: 1261] loss: 0.6246842146\n",
      "[timestep: 1] [epoch: 1291] loss: 0.8897368312\n",
      "[timestep: 1] [epoch: 1321] loss: 0.7166457176\n",
      "[timestep: 1] [epoch: 1351] loss: 0.6797465086\n",
      "[timestep: 1] [epoch: 1381] loss: 0.6491721869\n",
      "[timestep: 1] [epoch: 1411] loss: 0.6554626226\n",
      "[timestep: 1] [epoch: 1441] loss: 0.5456229448\n",
      "[timestep: 1] [epoch: 1471] loss: 0.6275573373\n",
      "[timestep: 1] [epoch: 1501] loss: 0.5741279125\n",
      "[timestep: 1] [epoch: 1531] loss: 0.6194967628\n",
      "[timestep: 1] [epoch: 1561] loss: 0.5536555052\n",
      "[timestep: 1] [epoch: 1591] loss: 0.6019708514\n",
      "[timestep: 1] [epoch: 1621] loss: 0.6386437416\n",
      "[timestep: 1] [epoch: 1651] loss: 0.5865235925\n",
      "[timestep: 1] [epoch: 1681] loss: 0.6120339632\n",
      "[timestep: 1] [epoch: 1711] loss: 0.6434938312\n",
      "[timestep: 1] [epoch: 1741] loss: 0.5652517080\n",
      "[timestep: 1] [epoch: 1771] loss: 0.5454686880\n",
      "[timestep: 1] [epoch: 1801] loss: 0.5392066836\n",
      "[timestep: 1] [epoch: 1831] loss: 0.5534251928\n",
      "[timestep: 1] [epoch: 1861] loss: 0.5607219934\n",
      "[timestep: 1] [epoch: 1891] loss: 0.5379899740\n",
      "[timestep: 1] [epoch: 1921] loss: 0.6489725113\n",
      "[timestep: 1] [epoch: 1951] loss: 0.5200821161\n",
      "[timestep: 1] [epoch: 1981] loss: 0.5895511508\n",
      "[timestep: 1] [epoch: 2011] loss: 0.5803782940\n",
      "[timestep: 1] [epoch: 2041] loss: 0.5437904000\n",
      "[timestep: 1] [epoch: 2071] loss: 0.5597409606\n",
      "[timestep: 1] [epoch: 2101] loss: 0.5363261700\n",
      "[timestep: 1] [epoch: 2131] loss: 0.6057074070\n",
      "[timestep: 1] [epoch: 2161] loss: 0.5972620249\n",
      "[timestep: 1] [epoch: 2191] loss: 0.5169579983\n",
      "[timestep: 1] [epoch: 2221] loss: 0.5845952034\n",
      "[timestep: 1] [epoch: 2251] loss: 0.6051824689\n",
      "[timestep: 1] [epoch: 2281] loss: 0.5349520445\n",
      "[timestep: 1] [epoch: 2311] loss: 0.6731019616\n",
      "[timestep: 1] [epoch: 2341] loss: 0.5819356441\n",
      "[timestep: 1] [epoch: 2371] loss: 0.5453146696\n",
      "[timestep: 1] [epoch: 2401] loss: 0.5998460650\n",
      "[timestep: 1] [epoch: 2431] loss: 0.5364152193\n",
      "[timestep: 1] [epoch: 2461] loss: 0.5401353240\n",
      "[timestep: 1] [epoch: 2491] loss: 0.5409196019\n",
      "[timestep: 1] [epoch: 2521] loss: 0.5370046496\n",
      "[timestep: 1] [epoch: 2551] loss: 0.5563288927\n",
      "[timestep: 1] [epoch: 2581] loss: 0.5297542810\n",
      "[timestep: 1] [epoch: 2611] loss: 0.5460753441\n",
      "[timestep: 1] [epoch: 2641] loss: 0.6051253080\n",
      "[timestep: 1] [epoch: 2671] loss: 0.6053706408\n",
      "[timestep: 1] [epoch: 2701] loss: 0.5367478728\n",
      "[timestep: 1] [epoch: 2731] loss: 0.5499705672\n",
      "[timestep: 1] [epoch: 2761] loss: 0.5567482710\n",
      "[timestep: 1] [epoch: 2791] loss: 0.6023445129\n",
      "[timestep: 1] [epoch: 2821] loss: 0.5733793378\n",
      "[timestep: 1] [epoch: 2851] loss: 0.5781753659\n",
      "[timestep: 1] [epoch: 2881] loss: 0.5748441219\n",
      "[timestep: 1] [epoch: 2911] loss: 0.5182945132\n",
      "[timestep: 1] [epoch: 2941] loss: 0.5620411634\n",
      "[timestep: 1] [epoch: 2971] loss: 0.5262762308\n",
      "[timestep: 1] [epoch: 3001] loss: 0.5500373840\n",
      "[timestep: 1] [epoch: 3031] loss: 0.5350517035\n",
      "[timestep: 1] [epoch: 3061] loss: 0.5374715924\n",
      "[timestep: 1] [epoch: 3091] loss: 0.5245263577\n",
      "[timestep: 1] [epoch: 3121] loss: 0.5264450312\n",
      "[timestep: 1] [epoch: 3151] loss: 0.5400607586\n",
      "[timestep: 1] [epoch: 3181] loss: 0.5470838547\n",
      "[timestep: 1] [epoch: 3211] loss: 0.5174495578\n",
      "[timestep: 1] [epoch: 3241] loss: 0.5826302171\n",
      "[timestep: 1] [epoch: 3271] loss: 0.5589557886\n",
      "[timestep: 1] [epoch: 3301] loss: 0.5301356316\n",
      "[timestep: 1] [epoch: 3331] loss: 0.4581730366\n",
      "[timestep: 1] [epoch: 3361] loss: 0.3083813190\n",
      "[timestep: 1] [epoch: 3391] loss: 0.2299953699\n",
      "[timestep: 1] [epoch: 3421] loss: 0.1622455716\n",
      "[timestep: 1] [epoch: 3451] loss: 0.1250688881\n",
      "[timestep: 1] [epoch: 3481] loss: 0.1853734851\n",
      "[timestep: 1] [epoch: 3511] loss: 0.1906750500\n",
      "[timestep: 1] [epoch: 3541] loss: 0.1757735014\n",
      "[timestep: 1] [epoch: 3571] loss: 0.1051938981\n",
      "[timestep: 1] [epoch: 3601] loss: 0.1858594716\n",
      "[timestep: 1] [epoch: 3631] loss: 0.1119271964\n",
      "[timestep: 1] [epoch: 3661] loss: 0.1708997488\n",
      "[timestep: 1] [epoch: 3691] loss: 0.2082526386\n",
      "[timestep: 1] [epoch: 3721] loss: 0.1402542144\n",
      "[timestep: 1] [epoch: 3751] loss: 0.1272719204\n",
      "[timestep: 1] [epoch: 3781] loss: 0.0927940011\n",
      "[timestep: 1] [epoch: 3811] loss: 0.1018633842\n",
      "[timestep: 1] [epoch: 3841] loss: 0.0791371763\n",
      "[timestep: 1] [epoch: 3871] loss: 0.0726539195\n",
      "[timestep: 1] [epoch: 3901] loss: 0.1572612524\n",
      "[timestep: 1] [epoch: 3931] loss: 0.1433727443\n",
      "[timestep: 1] [epoch: 3961] loss: 0.1231782287\n",
      "[timestep: 1] [epoch: 3991] loss: 0.0982380509\n",
      "[timestep: 1] [epoch: 4021] loss: 0.0788426921\n",
      "[timestep: 1] [epoch: 4051] loss: 0.1090348512\n",
      "[timestep: 1] [epoch: 4081] loss: 0.1716138721\n",
      "[timestep: 1] [epoch: 4111] loss: 0.1041346043\n",
      "[timestep: 1] [epoch: 4141] loss: 0.0770591050\n",
      "[timestep: 1] [epoch: 4171] loss: 0.0527572408\n",
      "[timestep: 1] [epoch: 4201] loss: 0.0524690934\n",
      "[timestep: 1] [epoch: 4231] loss: 0.0577268191\n",
      "[timestep: 1] [epoch: 4261] loss: 0.1043888479\n",
      "[timestep: 1] [epoch: 4291] loss: 0.0554217286\n",
      "[timestep: 1] [epoch: 4321] loss: 0.0908443630\n",
      "[timestep: 1] [epoch: 4351] loss: 0.1312590241\n",
      "[timestep: 1] [epoch: 4381] loss: 0.0389196686\n",
      "[timestep: 1] [epoch: 4411] loss: 0.0669508874\n",
      "[timestep: 1] [epoch: 4441] loss: 0.0548799597\n",
      "[timestep: 1] [epoch: 4471] loss: 0.0491419174\n",
      "[timestep: 1] [epoch: 4501] loss: 0.0709807873\n",
      "[timestep: 1] [epoch: 4531] loss: 0.0695356354\n",
      "[timestep: 1] [epoch: 4561] loss: 0.0820640475\n",
      "[timestep: 1] [epoch: 4591] loss: 0.0671552569\n",
      "[timestep: 1] [epoch: 4621] loss: 0.0527942143\n",
      "[timestep: 1] [epoch: 4651] loss: 0.0610854998\n",
      "[timestep: 1] [epoch: 4681] loss: 0.0786792561\n",
      "[timestep: 1] [epoch: 4711] loss: 0.0305280425\n",
      "[timestep: 1] [epoch: 4741] loss: 0.1151409894\n",
      "[timestep: 1] [epoch: 4771] loss: 0.1026844978\n",
      "[timestep: 1] [epoch: 4801] loss: 0.0727426335\n",
      "[timestep: 1] [epoch: 4831] loss: 0.1250432134\n",
      "[timestep: 1] [epoch: 4861] loss: 0.0491823927\n",
      "[timestep: 1] [epoch: 4891] loss: 0.0700006634\n",
      "[timestep: 1] [epoch: 4921] loss: 0.0287434980\n",
      "[timestep: 1] [epoch: 4951] loss: 0.0682560131\n",
      "[timestep: 1] [epoch: 4981] loss: 0.0426626354\n",
      "[timestep: 1] [epoch: 5011] loss: 0.0569521636\n",
      "[timestep: 1] [epoch: 5041] loss: 0.0648146942\n",
      "[timestep: 1] [epoch: 5071] loss: 0.0583851226\n",
      "[timestep: 1] [epoch: 5101] loss: 0.0626975894\n",
      "[timestep: 1] [epoch: 5131] loss: 0.0707254708\n",
      "[timestep: 1] [epoch: 5161] loss: 0.0718375519\n",
      "[timestep: 1] [epoch: 5191] loss: 0.0359395444\n",
      "[timestep: 1] [epoch: 5221] loss: 0.0481703691\n",
      "[timestep: 1] [epoch: 5251] loss: 0.0290947147\n",
      "[timestep: 1] [epoch: 5281] loss: 0.0936052576\n",
      "[timestep: 1] [epoch: 5311] loss: 0.0557356142\n",
      "[timestep: 1] [epoch: 5341] loss: 0.0386256203\n",
      "[timestep: 1] [epoch: 5371] loss: 0.0251685083\n",
      "[timestep: 1] [epoch: 5401] loss: 0.0407702774\n",
      "[timestep: 1] [epoch: 5431] loss: 0.0374618173\n",
      "[timestep: 1] [epoch: 5461] loss: 0.0641622618\n",
      "[timestep: 1] [epoch: 5491] loss: 0.0380715206\n",
      "[timestep: 1] [epoch: 5521] loss: 0.0286360383\n",
      "[timestep: 1] [epoch: 5551] loss: 0.0873930901\n",
      "[timestep: 1] [epoch: 5581] loss: 0.0499737561\n",
      "[timestep: 1] [epoch: 5611] loss: 0.0568779856\n",
      "[timestep: 1] [epoch: 5641] loss: 0.0426275134\n",
      "[timestep: 1] [epoch: 5671] loss: 0.0568543077\n",
      "[timestep: 1] [epoch: 5701] loss: 0.0347005129\n",
      "[timestep: 1] [epoch: 5731] loss: 0.0449221209\n",
      "[timestep: 1] [epoch: 5761] loss: 0.0407017954\n",
      "[timestep: 1] [epoch: 5791] loss: 0.0386933424\n",
      "[timestep: 1] [epoch: 5821] loss: 0.0401020199\n",
      "[timestep: 1] [epoch: 5851] loss: 0.0385382622\n",
      "[timestep: 1] [epoch: 5881] loss: 0.0697910637\n",
      "[timestep: 1] [epoch: 5911] loss: 0.0475182943\n",
      "[timestep: 1] [epoch: 5941] loss: 0.0521635935\n",
      "[timestep: 1] [epoch: 5971] loss: 0.0757929385\n",
      "[timestep: 1] [epoch: 6001] loss: 0.0285067800\n",
      "[timestep: 1] [epoch: 6031] loss: 0.0347476378\n",
      "[timestep: 1] [epoch: 6061] loss: 0.0543513894\n",
      "[timestep: 1] [epoch: 6091] loss: 0.0764164701\n",
      "[timestep: 1] [epoch: 6121] loss: 0.0509713329\n",
      "[timestep: 1] [epoch: 6151] loss: 0.0345279053\n",
      "[timestep: 1] [epoch: 6181] loss: 0.0593355186\n",
      "[timestep: 1] [epoch: 6211] loss: 0.0267943665\n",
      "[timestep: 1] [epoch: 6241] loss: 0.0381760746\n",
      "[timestep: 1] [epoch: 6271] loss: 0.0424831882\n",
      "[timestep: 1] [epoch: 6301] loss: 0.0461812504\n",
      "[timestep: 1] [epoch: 6331] loss: 0.0356057659\n",
      "[timestep: 1] [epoch: 6361] loss: 0.0539583266\n",
      "[timestep: 1] [epoch: 6391] loss: 0.0485545509\n",
      "[timestep: 1] [epoch: 6421] loss: 0.0422136374\n",
      "[timestep: 1] [epoch: 6451] loss: 0.0303210821\n",
      "[timestep: 1] [epoch: 6481] loss: 0.0462798849\n",
      "[timestep: 1] [epoch: 6511] loss: 0.0188070461\n",
      "[timestep: 1] [epoch: 6541] loss: 0.0271667168\n",
      "[timestep: 1] [epoch: 6571] loss: 0.0535179488\n",
      "[timestep: 1] [epoch: 6601] loss: 0.0333812051\n",
      "[timestep: 1] [epoch: 6631] loss: 0.0644047409\n",
      "[timestep: 1] [epoch: 6661] loss: 0.0315422826\n",
      "[timestep: 1] [epoch: 6691] loss: 0.0273756459\n",
      "[timestep: 1] [epoch: 6721] loss: 0.0636678785\n",
      "[timestep: 1] [epoch: 6751] loss: 0.0265830234\n",
      "[timestep: 1] [epoch: 6781] loss: 0.0617011748\n",
      "[timestep: 1] [epoch: 6811] loss: 0.0347862393\n",
      "[timestep: 1] [epoch: 6841] loss: 0.0336394981\n",
      "[timestep: 1] [epoch: 6871] loss: 0.0418212973\n",
      "[timestep: 1] [epoch: 6901] loss: 0.0275179353\n",
      "[timestep: 1] [epoch: 6931] loss: 0.0408857577\n",
      "[timestep: 1] [epoch: 6961] loss: 0.0317995921\n",
      "[timestep: 1] [epoch: 6991] loss: 0.0208730958\n",
      "[timestep: 1] [epoch: 7021] loss: 0.0431774668\n",
      "[timestep: 1] [epoch: 7051] loss: 0.0315582529\n",
      "[timestep: 1] [epoch: 7081] loss: 0.0183031037\n",
      "[timestep: 1] [epoch: 7111] loss: 0.0254212730\n",
      "[timestep: 1] [epoch: 7141] loss: 0.0456915945\n",
      "[timestep: 1] [epoch: 7171] loss: 0.0327731073\n",
      "[timestep: 1] [epoch: 7201] loss: 0.0573508814\n",
      "[timestep: 1] [epoch: 7231] loss: 0.0388746783\n",
      "[timestep: 1] [epoch: 7261] loss: 0.0335148722\n",
      "[timestep: 1] [epoch: 7291] loss: 0.0227575097\n",
      "[timestep: 1] [epoch: 7321] loss: 0.0369444676\n",
      "[timestep: 1] [epoch: 7351] loss: 0.0201528613\n",
      "[timestep: 1] [epoch: 7381] loss: 0.0434159935\n",
      "[timestep: 1] [epoch: 7411] loss: 0.0219938979\n",
      "[timestep: 1] [epoch: 7441] loss: 0.0235849805\n",
      "[timestep: 1] [epoch: 7471] loss: 0.0200835578\n",
      "[timestep: 1] [epoch: 7501] loss: 0.0248996243\n",
      "[timestep: 1] [epoch: 7531] loss: 0.0346669219\n",
      "[timestep: 1] [epoch: 7561] loss: 0.0205244198\n",
      "[timestep: 1] [epoch: 7591] loss: 0.0249839574\n",
      "[timestep: 1] [epoch: 7621] loss: 0.0199225061\n",
      "[timestep: 1] [epoch: 7651] loss: 0.0151134757\n",
      "[timestep: 1] [epoch: 7681] loss: 0.0544857159\n",
      "[timestep: 1] [epoch: 7711] loss: 0.0278372262\n",
      "[timestep: 1] [epoch: 7741] loss: 0.0310003366\n",
      "[timestep: 1] [epoch: 7771] loss: 0.0297810473\n",
      "[timestep: 1] [epoch: 7801] loss: 0.0164017640\n",
      "[timestep: 1] [epoch: 7831] loss: 0.0229386557\n",
      "[timestep: 1] [epoch: 7861] loss: 0.0214375369\n",
      "[timestep: 1] [epoch: 7891] loss: 0.0120188277\n",
      "[timestep: 1] [epoch: 7921] loss: 0.0386208482\n",
      "[timestep: 1] [epoch: 7951] loss: 0.0412106924\n",
      "[timestep: 1] [epoch: 7981] loss: 0.0327260382\n",
      "[timestep: 1] [epoch: 8011] loss: 0.0176797137\n",
      "[timestep: 1] [epoch: 8041] loss: 0.0277107805\n",
      "[timestep: 1] [epoch: 8071] loss: 0.0092519196\n",
      "[timestep: 1] [epoch: 8101] loss: 0.0103134317\n",
      "[timestep: 1] [epoch: 8131] loss: 0.0303694289\n",
      "[timestep: 1] [epoch: 8161] loss: 0.0317249894\n",
      "[timestep: 1] [epoch: 8191] loss: 0.0306223240\n",
      "[timestep: 1] [epoch: 8221] loss: 0.0388165861\n",
      "[timestep: 1] [epoch: 8251] loss: 0.0173517205\n",
      "[timestep: 1] [epoch: 8281] loss: 0.0260915235\n",
      "[timestep: 1] [epoch: 8311] loss: 0.0158368871\n",
      "[timestep: 1] [epoch: 8341] loss: 0.0377215594\n",
      "[timestep: 1] [epoch: 8371] loss: 0.0225284100\n",
      "[timestep: 1] [epoch: 8401] loss: 0.0209985636\n",
      "[timestep: 1] [epoch: 8431] loss: 0.0307301264\n",
      "[timestep: 1] [epoch: 8461] loss: 0.0328133851\n",
      "[timestep: 1] [epoch: 8491] loss: 0.0192930140\n",
      "[timestep: 1] [epoch: 8521] loss: 0.0180262569\n",
      "[timestep: 1] [epoch: 8551] loss: 0.0248855688\n",
      "[timestep: 1] [epoch: 8581] loss: 0.0174521413\n",
      "[timestep: 1] [epoch: 8611] loss: 0.0376792178\n",
      "[timestep: 1] [epoch: 8641] loss: 0.0321251862\n",
      "[timestep: 1] [epoch: 8671] loss: 0.0356604941\n",
      "[timestep: 1] [epoch: 8701] loss: 0.0246333778\n",
      "[timestep: 1] [epoch: 8731] loss: 0.0232196860\n",
      "[timestep: 1] [epoch: 8761] loss: 0.0248728525\n",
      "[timestep: 1] [epoch: 8791] loss: 0.0260144453\n",
      "[timestep: 1] [epoch: 8821] loss: 0.0133046424\n",
      "[timestep: 1] [epoch: 8851] loss: 0.0328385830\n",
      "[timestep: 1] [epoch: 8881] loss: 0.0150910895\n",
      "[timestep: 1] [epoch: 8911] loss: 0.0166588128\n",
      "[timestep: 1] [epoch: 8941] loss: 0.0229999572\n",
      "[timestep: 1] [epoch: 8971] loss: 0.0246362276\n",
      "[timestep: 1] [epoch: 9001] loss: 0.0375458896\n",
      "[timestep: 1] [epoch: 9031] loss: 0.0231654923\n",
      "[timestep: 1] [epoch: 9061] loss: 0.0121777393\n",
      "[timestep: 1] [epoch: 9091] loss: 0.0161082316\n",
      "[timestep: 1] [epoch: 9121] loss: 0.0177511182\n",
      "[timestep: 1] [epoch: 9151] loss: 0.0161821526\n",
      "[timestep: 1] [epoch: 9181] loss: 0.0099307466\n",
      "[timestep: 1] [epoch: 9211] loss: 0.0101861879\n",
      "[timestep: 1] [epoch: 9241] loss: 0.0082193688\n",
      "[timestep: 1] [epoch: 9271] loss: 0.0141772628\n",
      "[timestep: 1] [epoch: 9301] loss: 0.0280460455\n",
      "[timestep: 1] [epoch: 9331] loss: 0.0276539959\n",
      "[timestep: 1] [epoch: 9361] loss: 0.0234246105\n",
      "[timestep: 1] [epoch: 9391] loss: 0.0459226891\n",
      "[timestep: 1] [epoch: 9421] loss: 0.0206763688\n",
      "[timestep: 1] [epoch: 9451] loss: 0.0160304494\n",
      "[timestep: 1] [epoch: 9481] loss: 0.0176430084\n",
      "[timestep: 1] [epoch: 9511] loss: 0.0187405124\n",
      "[timestep: 1] [epoch: 9541] loss: 0.0104508009\n",
      "[timestep: 1] [epoch: 9571] loss: 0.0073623359\n",
      "[timestep: 1] [epoch: 9601] loss: 0.0116183348\n",
      "[timestep: 1] [epoch: 9631] loss: 0.0231510997\n",
      "[timestep: 1] [epoch: 9661] loss: 0.0183051042\n",
      "[timestep: 1] [epoch: 9691] loss: 0.0114932992\n",
      "[timestep: 1] [epoch: 9721] loss: 0.0232208651\n",
      "[timestep: 1] [epoch: 9751] loss: 0.0254264548\n",
      "[timestep: 1] [epoch: 9781] loss: 0.0187110566\n",
      "[timestep: 1] [epoch: 9811] loss: 0.0205820501\n",
      "[timestep: 1] [epoch: 9841] loss: 0.0105246892\n",
      "[timestep: 1] [epoch: 9871] loss: 0.0200050324\n",
      "[timestep: 1] [epoch: 9901] loss: 0.0235320553\n",
      "[timestep: 1] [epoch: 9931] loss: 0.0158268176\n",
      "[timestep: 1] [epoch: 9961] loss: 0.0130896699\n",
      "[timestep: 1] [epoch: 9991] loss: 0.0122125577\n",
      "[timestep: 1] [epoch: 10021] loss: 0.0085305404\n",
      "[timestep: 1] [epoch: 10051] loss: 0.0125791244\n",
      "[timestep: 1] [epoch: 10081] loss: 0.0056766402\n",
      "[timestep: 1] [epoch: 10111] loss: 0.0131437462\n",
      "[timestep: 1] [epoch: 10141] loss: 0.0115944156\n",
      "[timestep: 1] [epoch: 10171] loss: 0.0083421022\n",
      "[timestep: 1] [epoch: 10201] loss: 0.0262662396\n",
      "[timestep: 1] [epoch: 10231] loss: 0.0169961862\n",
      "[timestep: 1] [epoch: 10261] loss: 0.0110460669\n",
      "[timestep: 1] [epoch: 10291] loss: 0.0089136269\n",
      "[timestep: 1] [epoch: 10321] loss: 0.0091963466\n",
      "[timestep: 1] [epoch: 10351] loss: 0.0088618537\n",
      "[timestep: 1] [epoch: 10381] loss: 0.0201717019\n",
      "[timestep: 1] [epoch: 10411] loss: 0.0094897281\n",
      "[timestep: 1] [epoch: 10441] loss: 0.0088353828\n",
      "[timestep: 1] [epoch: 10471] loss: 0.0134512009\n",
      "[timestep: 1] [epoch: 10501] loss: 0.0243517272\n",
      "[timestep: 1] [epoch: 10531] loss: 0.0119640734\n",
      "[timestep: 1] [epoch: 10561] loss: 0.0208632834\n",
      "[timestep: 1] [epoch: 10591] loss: 0.0251020491\n",
      "[timestep: 1] [epoch: 10621] loss: 0.0135998512\n",
      "[timestep: 1] [epoch: 10651] loss: 0.0205249339\n",
      "[timestep: 1] [epoch: 10681] loss: 0.0158372018\n",
      "[timestep: 1] [epoch: 10711] loss: 0.0171596706\n",
      "[timestep: 1] [epoch: 10741] loss: 0.0116643105\n",
      "[timestep: 1] [epoch: 10771] loss: 0.0091886790\n",
      "[timestep: 1] [epoch: 10801] loss: 0.0092964787\n",
      "[timestep: 1] [epoch: 10831] loss: 0.0081167212\n",
      "[timestep: 1] [epoch: 10861] loss: 0.0086844601\n",
      "[timestep: 1] [epoch: 10891] loss: 0.0100275334\n",
      "[timestep: 1] [epoch: 10921] loss: 0.0044153840\n",
      "[timestep: 1] [epoch: 10951] loss: 0.0084841773\n",
      "[timestep: 1] [epoch: 10981] loss: 0.0078445040\n",
      "[timestep: 1] [epoch: 11011] loss: 0.0089824721\n",
      "[timestep: 1] [epoch: 11041] loss: 0.0075985147\n",
      "[timestep: 1] [epoch: 11071] loss: 0.0108060986\n",
      "[timestep: 1] [epoch: 11101] loss: 0.0065015373\n",
      "[timestep: 1] [epoch: 11131] loss: 0.0083197718\n",
      "[timestep: 1] [epoch: 11161] loss: 0.0062352000\n",
      "[timestep: 1] [epoch: 11191] loss: 0.0079702074\n",
      "[timestep: 1] [epoch: 11221] loss: 0.0070780655\n",
      "[timestep: 1] [epoch: 11251] loss: 0.0113082100\n",
      "[timestep: 1] [epoch: 11281] loss: 0.0062660780\n",
      "[timestep: 1] [epoch: 11311] loss: 0.0133807026\n",
      "[timestep: 1] [epoch: 11341] loss: 0.0138970241\n",
      "[timestep: 1] [epoch: 11371] loss: 0.0098144766\n",
      "[timestep: 1] [epoch: 11401] loss: 0.0129205678\n",
      "[timestep: 1] [epoch: 11431] loss: 0.0106153209\n",
      "[timestep: 1] [epoch: 11461] loss: 0.0117998431\n",
      "[timestep: 1] [epoch: 11491] loss: 0.0108114965\n",
      "[timestep: 1] [epoch: 11521] loss: 0.0090494128\n",
      "[timestep: 1] [epoch: 11551] loss: 0.0196580756\n",
      "[timestep: 1] [epoch: 11581] loss: 0.0152123682\n",
      "[timestep: 1] [epoch: 11611] loss: 0.0085869264\n",
      "[timestep: 1] [epoch: 11641] loss: 0.0101375133\n",
      "[timestep: 1] [epoch: 11671] loss: 0.0162198767\n",
      "[timestep: 1] [epoch: 11701] loss: 0.0159368701\n",
      "[timestep: 1] [epoch: 11731] loss: 0.0171260592\n",
      "[timestep: 1] [epoch: 11761] loss: 0.0206468441\n",
      "[timestep: 1] [epoch: 11791] loss: 0.0176558122\n",
      "[timestep: 1] [epoch: 11821] loss: 0.0197817739\n",
      "[timestep: 1] [epoch: 11851] loss: 0.0186661296\n",
      "[timestep: 1] [epoch: 11881] loss: 0.0123195238\n",
      "[timestep: 1] [epoch: 11911] loss: 0.0161871407\n",
      "[timestep: 1] [epoch: 11941] loss: 0.0248666257\n",
      "[timestep: 1] [epoch: 11971] loss: 0.0087572355\n",
      "[timestep: 1] [epoch: 12001] loss: 0.0131866913\n",
      "[timestep: 1] [epoch: 12031] loss: 0.0116821583\n",
      "[timestep: 1] [epoch: 12061] loss: 0.0062002507\n",
      "[timestep: 1] [epoch: 12091] loss: 0.0056859935\n",
      "[timestep: 1] [epoch: 12121] loss: 0.0055963099\n",
      "[timestep: 1] [epoch: 12151] loss: 0.0043153316\n",
      "[timestep: 1] [epoch: 12181] loss: 0.0041235872\n",
      "[timestep: 1] [epoch: 12211] loss: 0.0047160462\n",
      "[timestep: 1] [epoch: 12241] loss: 0.0058211721\n",
      "[timestep: 1] [epoch: 12271] loss: 0.0037303832\n",
      "[timestep: 1] [epoch: 12301] loss: 0.0100572649\n",
      "[timestep: 1] [epoch: 12331] loss: 0.0075669745\n",
      "[timestep: 1] [epoch: 12361] loss: 0.0078200139\n",
      "[timestep: 1] [epoch: 12391] loss: 0.0072873225\n",
      "[timestep: 1] [epoch: 12421] loss: 0.0118390471\n",
      "[timestep: 1] [epoch: 12451] loss: 0.0092742536\n",
      "[timestep: 1] [epoch: 12481] loss: 0.0070178872\n",
      "[timestep: 1] [epoch: 12511] loss: 0.0154413795\n",
      "[timestep: 1] [epoch: 12541] loss: 0.0105951456\n",
      "[timestep: 1] [epoch: 12571] loss: 0.0087957513\n",
      "[timestep: 1] [epoch: 12601] loss: 0.0062211570\n",
      "[timestep: 1] [epoch: 12631] loss: 0.0075094691\n",
      "[timestep: 1] [epoch: 12661] loss: 0.0047935108\n",
      "[timestep: 1] [epoch: 12691] loss: 0.0084464056\n",
      "[timestep: 1] [epoch: 12721] loss: 0.0076867728\n",
      "[timestep: 1] [epoch: 12751] loss: 0.0040847668\n",
      "[timestep: 1] [epoch: 12781] loss: 0.0059843124\n",
      "[timestep: 1] [epoch: 12811] loss: 0.0032376046\n",
      "[timestep: 1] [epoch: 12841] loss: 0.0051323324\n",
      "[timestep: 1] [epoch: 12871] loss: 0.0083142295\n",
      "[timestep: 1] [epoch: 12901] loss: 0.0087855961\n",
      "[timestep: 1] [epoch: 12931] loss: 0.0172315240\n",
      "[timestep: 1] [epoch: 12961] loss: 0.0091131236\n",
      "[timestep: 1] [epoch: 12991] loss: 0.0055168411\n",
      "[timestep: 1] [epoch: 13021] loss: 0.0058967257\n",
      "[timestep: 1] [epoch: 13051] loss: 0.0066696815\n",
      "[timestep: 1] [epoch: 13081] loss: 0.0049273432\n",
      "[timestep: 1] [epoch: 13111] loss: 0.0087097604\n",
      "[timestep: 1] [epoch: 13141] loss: 0.0051983036\n",
      "[timestep: 1] [epoch: 13171] loss: 0.0061421380\n",
      "[timestep: 1] [epoch: 13201] loss: 0.0081879497\n",
      "[timestep: 1] [epoch: 13231] loss: 0.0045306366\n",
      "[timestep: 1] [epoch: 13261] loss: 0.0108951647\n",
      "[timestep: 1] [epoch: 13291] loss: 0.0050169234\n",
      "[timestep: 1] [epoch: 13321] loss: 0.0032248336\n",
      "[timestep: 1] [epoch: 13351] loss: 0.0041709486\n",
      "[timestep: 1] [epoch: 13381] loss: 0.0051277922\n",
      "[timestep: 1] [epoch: 13411] loss: 0.0034082411\n",
      "[timestep: 1] [epoch: 13441] loss: 0.0053128288\n",
      "[timestep: 1] [epoch: 13471] loss: 0.0031894238\n",
      "[timestep: 1] [epoch: 13501] loss: 0.0042473050\n",
      "[timestep: 1] [epoch: 13531] loss: 0.0035948730\n",
      "[timestep: 1] [epoch: 13561] loss: 0.0034141704\n",
      "[timestep: 1] [epoch: 13591] loss: 0.0044198390\n",
      "[timestep: 1] [epoch: 13621] loss: 0.0045634136\n",
      "[timestep: 1] [epoch: 13651] loss: 0.0033713514\n",
      "[timestep: 1] [epoch: 13681] loss: 0.0044814628\n",
      "[timestep: 1] [epoch: 13711] loss: 0.0046650749\n",
      "[timestep: 1] [epoch: 13741] loss: 0.0089202877\n",
      "[timestep: 1] [epoch: 13771] loss: 0.0040907469\n",
      "[timestep: 1] [epoch: 13801] loss: 0.0041172858\n",
      "[timestep: 1] [epoch: 13831] loss: 0.0030890310\n",
      "[timestep: 1] [epoch: 13861] loss: 0.0036534653\n",
      "[timestep: 1] [epoch: 13891] loss: 0.0058264546\n",
      "[timestep: 1] [epoch: 13921] loss: 0.0088085495\n",
      "[timestep: 1] [epoch: 13951] loss: 0.0037216574\n",
      "[timestep: 1] [epoch: 13981] loss: 0.0034047980\n",
      "[timestep: 1] [epoch: 14011] loss: 0.0036567219\n",
      "[timestep: 1] [epoch: 14041] loss: 0.0028788191\n",
      "[timestep: 1] [epoch: 14071] loss: 0.0031792109\n",
      "[timestep: 1] [epoch: 14101] loss: 0.0050863726\n",
      "[timestep: 1] [epoch: 14131] loss: 0.0126862098\n",
      "[timestep: 1] [epoch: 14161] loss: 0.0073541035\n",
      "[timestep: 1] [epoch: 14191] loss: 0.0041547595\n",
      "[timestep: 1] [epoch: 14221] loss: 0.0050212801\n",
      "[timestep: 1] [epoch: 14251] loss: 0.0031530631\n",
      "[timestep: 1] [epoch: 14281] loss: 0.0030101934\n",
      "[timestep: 1] [epoch: 14311] loss: 0.0029107342\n",
      "[timestep: 1] [epoch: 14341] loss: 0.0033787857\n",
      "[timestep: 1] [epoch: 14371] loss: 0.0031521833\n",
      "[timestep: 1] [epoch: 14401] loss: 0.0033565708\n",
      "[timestep: 1] [epoch: 14431] loss: 0.0047756452\n",
      "[timestep: 1] [epoch: 14461] loss: 0.0035970239\n",
      "[timestep: 1] [epoch: 14491] loss: 0.0032026442\n",
      "[timestep: 1] [epoch: 14521] loss: 0.0045753438\n",
      "[timestep: 1] [epoch: 14551] loss: 0.0027011107\n",
      "[timestep: 1] [epoch: 14581] loss: 0.0027739978\n",
      "[timestep: 1] [epoch: 14611] loss: 0.0031344218\n",
      "[timestep: 1] [epoch: 14641] loss: 0.0027819586\n",
      "[timestep: 1] [epoch: 14671] loss: 0.0027518324\n",
      "[timestep: 1] [epoch: 14701] loss: 0.0033466201\n",
      "[timestep: 1] [epoch: 14731] loss: 0.0026580880\n",
      "[timestep: 1] [epoch: 14761] loss: 0.0039196671\n",
      "[timestep: 1] [epoch: 14791] loss: 0.0062399125\n",
      "[timestep: 1] [epoch: 14821] loss: 0.0076430119\n",
      "[timestep: 1] [epoch: 14851] loss: 0.0072520985\n",
      "[timestep: 1] [epoch: 14881] loss: 0.0067983237\n",
      "[timestep: 1] [epoch: 14911] loss: 0.0041519348\n",
      "[timestep: 1] [epoch: 14941] loss: 0.0027940439\n",
      "[timestep: 1] [epoch: 14971] loss: 0.0031449569\n",
      "[timestep: 1] [epoch: 15001] loss: 0.0031780042\n",
      "[timestep: 1] [epoch: 15031] loss: 0.0030139070\n",
      "[timestep: 1] [epoch: 15061] loss: 0.0030702231\n",
      "[timestep: 1] [epoch: 15091] loss: 0.0027575050\n",
      "[timestep: 1] [epoch: 15121] loss: 0.0026382529\n",
      "[timestep: 1] [epoch: 15151] loss: 0.0028236392\n",
      "[timestep: 1] [epoch: 15181] loss: 0.0026978524\n",
      "[timestep: 1] [epoch: 15211] loss: 0.0025544672\n",
      "[timestep: 1] [epoch: 15241] loss: 0.0025387497\n",
      "[timestep: 1] [epoch: 15271] loss: 0.0031385703\n",
      "[timestep: 1] [epoch: 15301] loss: 0.0023524025\n",
      "[timestep: 1] [epoch: 15331] loss: 0.0024700337\n",
      "[timestep: 1] [epoch: 15361] loss: 0.0028420589\n",
      "[timestep: 1] [epoch: 15391] loss: 0.0024603168\n",
      "[timestep: 1] [epoch: 15421] loss: 0.0027401913\n",
      "[timestep: 1] [epoch: 15451] loss: 0.0026839999\n",
      "[timestep: 1] [epoch: 15481] loss: 0.0025454387\n",
      "[timestep: 1] [epoch: 15511] loss: 0.0025023900\n",
      "[timestep: 1] [epoch: 15541] loss: 0.0025906072\n",
      "[timestep: 1] [epoch: 15571] loss: 0.0028724491\n",
      "[timestep: 1] [epoch: 15601] loss: 0.0031588972\n",
      "[timestep: 1] [epoch: 15631] loss: 0.0030494463\n",
      "[timestep: 1] [epoch: 15661] loss: 0.0061210506\n",
      "[timestep: 1] [epoch: 15691] loss: 0.0026524453\n",
      "[timestep: 1] [epoch: 15721] loss: 0.0024629477\n",
      "[timestep: 1] [epoch: 15751] loss: 0.0035467418\n",
      "[timestep: 1] [epoch: 15781] loss: 0.0027573211\n",
      "[timestep: 1] [epoch: 15811] loss: 0.0030054897\n",
      "[timestep: 1] [epoch: 15841] loss: 0.0030275094\n",
      "[timestep: 1] [epoch: 15871] loss: 0.0024357636\n",
      "[timestep: 1] [epoch: 15901] loss: 0.0026166574\n",
      "[timestep: 1] [epoch: 15931] loss: 0.0025864339\n",
      "[timestep: 1] [epoch: 15961] loss: 0.0026496695\n",
      "[timestep: 1] [epoch: 15991] loss: 0.0024442715\n",
      "[timestep: 1] [epoch: 16021] loss: 0.0030097514\n",
      "[timestep: 1] [epoch: 16051] loss: 0.0025844383\n",
      "[timestep: 1] [epoch: 16081] loss: 0.0035165017\n",
      "[timestep: 1] [epoch: 16111] loss: 0.0032074261\n",
      "[timestep: 1] [epoch: 16141] loss: 0.0025986733\n",
      "[timestep: 1] [epoch: 16171] loss: 0.0028649031\n",
      "[timestep: 1] [epoch: 16201] loss: 0.0024742470\n",
      "[timestep: 1] [epoch: 16231] loss: 0.0027726674\n",
      "[timestep: 1] [epoch: 16261] loss: 0.0024371301\n",
      "[timestep: 1] [epoch: 16291] loss: 0.0031949077\n",
      "[timestep: 1] [epoch: 16321] loss: 0.0023399387\n",
      "[timestep: 1] [epoch: 16351] loss: 0.0023587458\n",
      "[timestep: 1] [epoch: 16381] loss: 0.0024167653\n",
      "[timestep: 1] [epoch: 16411] loss: 0.0069942502\n",
      "[timestep: 1] [epoch: 16441] loss: 0.0045786174\n",
      "[timestep: 1] [epoch: 16471] loss: 0.0028917105\n",
      "[timestep: 1] [epoch: 16501] loss: 0.0045308480\n",
      "[timestep: 1] [epoch: 16531] loss: 0.0026271460\n",
      "[timestep: 1] [epoch: 16561] loss: 0.0025836201\n",
      "[timestep: 1] [epoch: 16591] loss: 0.0026141305\n",
      "[timestep: 1] [epoch: 16621] loss: 0.0024756512\n",
      "[timestep: 1] [epoch: 16651] loss: 0.0025188201\n",
      "[timestep: 1] [epoch: 16681] loss: 0.0029872907\n",
      "[timestep: 1] [epoch: 16711] loss: 0.0026942824\n",
      "[timestep: 1] [epoch: 16741] loss: 0.0029455270\n",
      "[timestep: 1] [epoch: 16771] loss: 0.0023989608\n",
      "[timestep: 1] [epoch: 16801] loss: 0.0025075236\n",
      "[timestep: 1] [epoch: 16831] loss: 0.0027311894\n",
      "[timestep: 1] [epoch: 16861] loss: 0.0023305661\n",
      "[timestep: 1] [epoch: 16891] loss: 0.0023271050\n",
      "[timestep: 1] [epoch: 16921] loss: 0.0023834503\n",
      "[timestep: 1] [epoch: 16951] loss: 0.0025238472\n",
      "[timestep: 1] [epoch: 16981] loss: 0.0023398467\n",
      "[timestep: 1] [epoch: 17011] loss: 0.0023274552\n",
      "[timestep: 1] [epoch: 17041] loss: 0.0023459606\n",
      "[timestep: 1] [epoch: 17071] loss: 0.0036531510\n",
      "[timestep: 1] [epoch: 17101] loss: 0.0022478658\n",
      "[timestep: 1] [epoch: 17131] loss: 0.0022196595\n",
      "[timestep: 1] [epoch: 17161] loss: 0.0024874397\n",
      "[timestep: 1] [epoch: 17191] loss: 0.0023409263\n",
      "[timestep: 1] [epoch: 17221] loss: 0.0022732615\n",
      "[timestep: 1] [epoch: 17251] loss: 0.0022390047\n",
      "[timestep: 1] [epoch: 17281] loss: 0.0034327230\n",
      "[timestep: 1] [epoch: 17311] loss: 0.0023447382\n",
      "[timestep: 1] [epoch: 17341] loss: 0.0023752870\n",
      "[timestep: 1] [epoch: 17371] loss: 0.0023456891\n",
      "[timestep: 1] [epoch: 17401] loss: 0.0024710549\n",
      "[timestep: 1] [epoch: 17431] loss: 0.0021868942\n",
      "[timestep: 1] [epoch: 17461] loss: 0.0024749713\n",
      "[timestep: 1] [epoch: 17491] loss: 0.0046453970\n",
      "[timestep: 1] [epoch: 17521] loss: 0.0069393367\n",
      "[timestep: 1] [epoch: 17551] loss: 0.0031934169\n",
      "[timestep: 1] [epoch: 17581] loss: 0.0022785726\n",
      "[timestep: 1] [epoch: 17611] loss: 0.0021727728\n",
      "[timestep: 1] [epoch: 17641] loss: 0.0021650754\n",
      "[timestep: 1] [epoch: 17671] loss: 0.0021695970\n",
      "[timestep: 1] [epoch: 17701] loss: 0.0025351660\n",
      "[timestep: 1] [epoch: 17731] loss: 0.0029079255\n",
      "[timestep: 1] [epoch: 17761] loss: 0.0029329029\n",
      "[timestep: 1] [epoch: 17791] loss: 0.0023953556\n",
      "[timestep: 1] [epoch: 17821] loss: 0.0023036865\n",
      "[timestep: 1] [epoch: 17851] loss: 0.0022848691\n",
      "[timestep: 1] [epoch: 17881] loss: 0.0021578090\n",
      "[timestep: 1] [epoch: 17911] loss: 0.0022298251\n",
      "[timestep: 1] [epoch: 17941] loss: 0.0022104627\n",
      "[timestep: 1] [epoch: 17971] loss: 0.0021686084\n",
      "[timestep: 1] [epoch: 18001] loss: 0.0022291914\n",
      "[timestep: 1] [epoch: 18031] loss: 0.0025543775\n",
      "[timestep: 1] [epoch: 18061] loss: 0.0022400413\n",
      "[timestep: 1] [epoch: 18091] loss: 0.0022083586\n",
      "[timestep: 1] [epoch: 18121] loss: 0.0021874662\n",
      "[timestep: 1] [epoch: 18151] loss: 0.0022572139\n",
      "[timestep: 1] [epoch: 18181] loss: 0.0024498710\n",
      "[timestep: 1] [epoch: 18211] loss: 0.0029245187\n",
      "[timestep: 1] [epoch: 18241] loss: 0.0022925185\n",
      "[timestep: 1] [epoch: 18271] loss: 0.0023658937\n",
      "[timestep: 1] [epoch: 18301] loss: 0.0021899487\n",
      "[timestep: 1] [epoch: 18331] loss: 0.0024591284\n",
      "[timestep: 1] [epoch: 18361] loss: 0.0021173402\n",
      "[timestep: 1] [epoch: 18391] loss: 0.0022836765\n",
      "[timestep: 1] [epoch: 18421] loss: 0.0021662847\n",
      "[timestep: 1] [epoch: 18451] loss: 0.0026613618\n",
      "[timestep: 1] [epoch: 18481] loss: 0.0022064759\n",
      "[timestep: 1] [epoch: 18511] loss: 0.0021515638\n",
      "[timestep: 1] [epoch: 18541] loss: 0.0025677332\n",
      "[timestep: 1] [epoch: 18571] loss: 0.0022389917\n",
      "[timestep: 1] [epoch: 18601] loss: 0.0024864280\n",
      "[timestep: 1] [epoch: 18631] loss: 0.0022300091\n",
      "[timestep: 1] [epoch: 18661] loss: 0.0022873520\n",
      "[timestep: 1] [epoch: 18691] loss: 0.0026557317\n",
      "[timestep: 1] [epoch: 18721] loss: 0.0024222760\n",
      "[timestep: 1] [epoch: 18751] loss: 0.0025037699\n",
      "[timestep: 1] [epoch: 18781] loss: 0.0021655797\n",
      "[timestep: 1] [epoch: 18811] loss: 0.0021642179\n",
      "[timestep: 1] [epoch: 18841] loss: 0.0022125398\n",
      "[timestep: 1] [epoch: 18871] loss: 0.0024393743\n",
      "[timestep: 1] [epoch: 18901] loss: 0.0025067686\n",
      "[timestep: 1] [epoch: 18931] loss: 0.0028994023\n",
      "[timestep: 1] [epoch: 18961] loss: 0.0021692025\n",
      "[timestep: 1] [epoch: 18991] loss: 0.0022470756\n",
      "[timestep: 1] [epoch: 19021] loss: 0.0020705222\n",
      "[timestep: 1] [epoch: 19051] loss: 0.0024959715\n",
      "[timestep: 1] [epoch: 19081] loss: 0.0023346483\n",
      "[timestep: 1] [epoch: 19111] loss: 0.0021522334\n",
      "[timestep: 1] [epoch: 19141] loss: 0.0028599517\n",
      "[timestep: 1] [epoch: 19171] loss: 0.0021190229\n",
      "[timestep: 1] [epoch: 19201] loss: 0.0022326044\n",
      "[timestep: 1] [epoch: 19231] loss: 0.0021305622\n",
      "[timestep: 1] [epoch: 19261] loss: 0.0021501537\n",
      "[timestep: 1] [epoch: 19291] loss: 0.0021349278\n",
      "[timestep: 1] [epoch: 19321] loss: 0.0023421980\n",
      "[timestep: 1] [epoch: 19351] loss: 0.0023276941\n",
      "[timestep: 1] [epoch: 19381] loss: 0.0024433164\n",
      "[timestep: 1] [epoch: 19411] loss: 0.0021206066\n",
      "[timestep: 1] [epoch: 19441] loss: 0.0021069741\n",
      "[timestep: 1] [epoch: 19471] loss: 0.0022088347\n",
      "[timestep: 1] [epoch: 19501] loss: 0.0021067574\n",
      "[timestep: 1] [epoch: 19531] loss: 0.0023259546\n",
      "[timestep: 1] [epoch: 19561] loss: 0.0022820844\n",
      "[timestep: 1] [epoch: 19591] loss: 0.0022704639\n",
      "[timestep: 1] [epoch: 19621] loss: 0.0020570036\n",
      "[timestep: 1] [epoch: 19651] loss: 0.0020836412\n",
      "[timestep: 1] [epoch: 19681] loss: 0.0021049920\n",
      "[timestep: 1] [epoch: 19711] loss: 0.0026592980\n",
      "[timestep: 1] [epoch: 19741] loss: 0.0021252166\n",
      "[timestep: 1] [epoch: 19771] loss: 0.0020947289\n",
      "[timestep: 1] [epoch: 19801] loss: 0.0022086850\n",
      "[timestep: 1] [epoch: 19831] loss: 0.0020631528\n",
      "[timestep: 1] [epoch: 19861] loss: 0.0021905811\n",
      "[timestep: 1] [epoch: 19891] loss: 0.0026708548\n",
      "[timestep: 1] [epoch: 19921] loss: 0.0021809791\n",
      "[timestep: 1] [epoch: 19951] loss: 0.0020699711\n",
      "[timestep: 1] [epoch: 19981] loss: 0.0027099394\n",
      "[timestep: 1] [epoch: 20011] loss: 0.0020337112\n",
      "[timestep: 1] [epoch: 20041] loss: 0.0022216046\n",
      "[timestep: 1] [epoch: 20071] loss: 0.0021693490\n",
      "[timestep: 1] [epoch: 20101] loss: 0.0021046579\n",
      "[timestep: 1] [epoch: 20131] loss: 0.0022022948\n",
      "[timestep: 1] [epoch: 20161] loss: 0.0020815809\n",
      "[timestep: 1] [epoch: 20191] loss: 0.0023612517\n",
      "[timestep: 1] [epoch: 20221] loss: 0.0021270905\n",
      "[timestep: 1] [epoch: 20251] loss: 0.0020861819\n",
      "[timestep: 1] [epoch: 20281] loss: 0.0021441123\n",
      "[timestep: 1] [epoch: 20311] loss: 0.0020575675\n",
      "[timestep: 1] [epoch: 20341] loss: 0.0020737720\n",
      "[timestep: 1] [epoch: 20371] loss: 0.0021377522\n",
      "[timestep: 1] [epoch: 20401] loss: 0.0020411178\n",
      "[timestep: 1] [epoch: 20431] loss: 0.0020738612\n",
      "[timestep: 1] [epoch: 20461] loss: 0.0021097402\n",
      "[timestep: 1] [epoch: 20491] loss: 0.0020291498\n",
      "[timestep: 1] [epoch: 20521] loss: 0.0022159945\n",
      "[timestep: 1] [epoch: 20551] loss: 0.0020517986\n",
      "[timestep: 1] [epoch: 20581] loss: 0.0021258756\n",
      "[timestep: 1] [epoch: 20611] loss: 0.0019868137\n",
      "[timestep: 1] [epoch: 20641] loss: 0.0020825169\n",
      "[timestep: 1] [epoch: 20671] loss: 0.0020465357\n",
      "[timestep: 1] [epoch: 20701] loss: 0.0020221828\n",
      "[timestep: 1] [epoch: 20731] loss: 0.0019321768\n",
      "[timestep: 1] [epoch: 20761] loss: 0.0022797235\n",
      "[timestep: 1] [epoch: 20791] loss: 0.0027824151\n",
      "[timestep: 1] [epoch: 20821] loss: 0.0024472079\n",
      "[timestep: 1] [epoch: 20851] loss: 0.0020489858\n",
      "[timestep: 1] [epoch: 20881] loss: 0.0021335431\n",
      "[timestep: 1] [epoch: 20911] loss: 0.0020916010\n",
      "[timestep: 1] [epoch: 20941] loss: 0.0019939253\n",
      "[timestep: 1] [epoch: 20971] loss: 0.0022095935\n",
      "[timestep: 1] [epoch: 21001] loss: 0.0023421906\n",
      "[timestep: 1] [epoch: 21031] loss: 0.0020022923\n",
      "[timestep: 1] [epoch: 21061] loss: 0.0020721150\n",
      "[timestep: 1] [epoch: 21091] loss: 0.0021324581\n",
      "[timestep: 1] [epoch: 21121] loss: 0.0020934157\n",
      "[timestep: 1] [epoch: 21151] loss: 0.0020551605\n",
      "[timestep: 1] [epoch: 21181] loss: 0.0019075441\n",
      "[timestep: 1] [epoch: 21211] loss: 0.0020787166\n",
      "[timestep: 1] [epoch: 21241] loss: 0.0019240585\n",
      "[timestep: 1] [epoch: 21271] loss: 0.0021470145\n",
      "[timestep: 1] [epoch: 21301] loss: 0.0020303871\n",
      "[timestep: 1] [epoch: 21331] loss: 0.0021953073\n",
      "[timestep: 1] [epoch: 21361] loss: 0.0025296719\n",
      "[timestep: 1] [epoch: 21391] loss: 0.0021128189\n",
      "[timestep: 1] [epoch: 21421] loss: 0.0019483846\n",
      "[timestep: 1] [epoch: 21451] loss: 0.0019483734\n",
      "[timestep: 1] [epoch: 21481] loss: 0.0019970699\n",
      "[timestep: 1] [epoch: 21511] loss: 0.0020402130\n",
      "[timestep: 1] [epoch: 21541] loss: 0.0020255451\n",
      "[timestep: 1] [epoch: 21571] loss: 0.0024151485\n",
      "[timestep: 1] [epoch: 21601] loss: 0.0019858247\n",
      "[timestep: 1] [epoch: 21631] loss: 0.0018713416\n",
      "[timestep: 1] [epoch: 21661] loss: 0.0022624652\n",
      "[timestep: 1] [epoch: 21691] loss: 0.0019743105\n",
      "[timestep: 1] [epoch: 21721] loss: 0.0020008204\n",
      "[timestep: 1] [epoch: 21751] loss: 0.0020167141\n",
      "[timestep: 1] [epoch: 21781] loss: 0.0019649547\n",
      "[timestep: 1] [epoch: 21811] loss: 0.0020331172\n",
      "[timestep: 1] [epoch: 21841] loss: 0.0020143734\n",
      "[timestep: 1] [epoch: 21871] loss: 0.0019826272\n",
      "[timestep: 1] [epoch: 21901] loss: 0.0022173047\n",
      "[timestep: 1] [epoch: 21931] loss: 0.0020715373\n",
      "[timestep: 1] [epoch: 21961] loss: 0.0021302553\n",
      "[timestep: 1] [epoch: 21991] loss: 0.0020099049\n",
      "[timestep: 1] [epoch: 22021] loss: 0.0019367884\n",
      "[timestep: 1] [epoch: 22051] loss: 0.0018980029\n",
      "[timestep: 1] [epoch: 22081] loss: 0.0019571304\n",
      "[timestep: 1] [epoch: 22111] loss: 0.0019093998\n",
      "[timestep: 1] [epoch: 22141] loss: 0.0020596939\n",
      "[timestep: 1] [epoch: 22171] loss: 0.0018747007\n",
      "[timestep: 1] [epoch: 22201] loss: 0.0019393521\n",
      "[timestep: 1] [epoch: 22231] loss: 0.0018872820\n",
      "[timestep: 1] [epoch: 22261] loss: 0.0019898689\n",
      "[timestep: 1] [epoch: 22291] loss: 0.0021688170\n",
      "[timestep: 1] [epoch: 22321] loss: 0.0021466513\n",
      "[timestep: 1] [epoch: 22351] loss: 0.0019580899\n",
      "[timestep: 1] [epoch: 22381] loss: 0.0019156422\n",
      "[timestep: 1] [epoch: 22411] loss: 0.0019908026\n",
      "[timestep: 1] [epoch: 22441] loss: 0.0019507944\n",
      "[timestep: 1] [epoch: 22471] loss: 0.0020273135\n",
      "[timestep: 1] [epoch: 22501] loss: 0.0019205736\n",
      "[timestep: 1] [epoch: 22531] loss: 0.0018800297\n",
      "[timestep: 1] [epoch: 22561] loss: 0.0019270316\n",
      "[timestep: 1] [epoch: 22591] loss: 0.0019404925\n",
      "[timestep: 1] [epoch: 22621] loss: 0.0019962466\n",
      "[timestep: 1] [epoch: 22651] loss: 0.0018993291\n",
      "[timestep: 1] [epoch: 22681] loss: 0.0021019694\n",
      "[timestep: 1] [epoch: 22711] loss: 0.0019183556\n",
      "[timestep: 1] [epoch: 22741] loss: 0.0018743374\n",
      "[timestep: 1] [epoch: 22771] loss: 0.0018399367\n",
      "[timestep: 1] [epoch: 22801] loss: 0.0018782573\n",
      "[timestep: 1] [epoch: 22831] loss: 0.0020325554\n",
      "[timestep: 1] [epoch: 22861] loss: 0.0018555720\n",
      "[timestep: 1] [epoch: 22891] loss: 0.0018351453\n",
      "[timestep: 1] [epoch: 22921] loss: 0.0018646099\n",
      "[timestep: 1] [epoch: 22951] loss: 0.0019554151\n",
      "[timestep: 1] [epoch: 22981] loss: 0.0018988051\n",
      "[timestep: 1] [epoch: 23011] loss: 0.0020206952\n",
      "[timestep: 1] [epoch: 23041] loss: 0.0019047863\n",
      "[timestep: 1] [epoch: 23071] loss: 0.0018894279\n",
      "[timestep: 1] [epoch: 23101] loss: 0.0018685968\n",
      "[timestep: 1] [epoch: 23131] loss: 0.0018230157\n",
      "[timestep: 1] [epoch: 23161] loss: 0.0020154575\n",
      "[timestep: 1] [epoch: 23191] loss: 0.0019744164\n",
      "[timestep: 1] [epoch: 23221] loss: 0.0019004504\n",
      "[timestep: 1] [epoch: 23251] loss: 0.0018751882\n",
      "[timestep: 1] [epoch: 23281] loss: 0.0018864642\n",
      "[timestep: 1] [epoch: 23311] loss: 0.0018930726\n",
      "[timestep: 1] [epoch: 23341] loss: 0.0019767270\n",
      "[timestep: 1] [epoch: 23371] loss: 0.0019208065\n",
      "[timestep: 1] [epoch: 23401] loss: 0.0018267777\n",
      "[timestep: 1] [epoch: 23431] loss: 0.0018697658\n",
      "[timestep: 1] [epoch: 23461] loss: 0.0019117710\n",
      "[timestep: 1] [epoch: 23491] loss: 0.0019190657\n",
      "[timestep: 1] [epoch: 23521] loss: 0.0019010538\n",
      "[timestep: 1] [epoch: 23551] loss: 0.0019981966\n",
      "[timestep: 1] [epoch: 23581] loss: 0.0018231845\n",
      "[timestep: 1] [epoch: 23611] loss: 0.0018836348\n",
      "[timestep: 1] [epoch: 23641] loss: 0.0019884207\n",
      "[timestep: 1] [epoch: 23671] loss: 0.0018291948\n",
      "[timestep: 1] [epoch: 23701] loss: 0.0019154174\n",
      "[timestep: 1] [epoch: 23731] loss: 0.0017841591\n",
      "[timestep: 1] [epoch: 23761] loss: 0.0017958693\n",
      "[timestep: 1] [epoch: 23791] loss: 0.0018239664\n",
      "[timestep: 1] [epoch: 23821] loss: 0.0017701739\n",
      "[timestep: 1] [epoch: 23851] loss: 0.0018897098\n",
      "[timestep: 1] [epoch: 23881] loss: 0.0018325376\n",
      "[timestep: 1] [epoch: 23911] loss: 0.0018168192\n",
      "[timestep: 1] [epoch: 23941] loss: 0.0018538348\n",
      "[timestep: 1] [epoch: 23971] loss: 0.0018360079\n",
      "[timestep: 1] [epoch: 24001] loss: 0.0018231771\n",
      "[timestep: 1] [epoch: 24031] loss: 0.0017947182\n",
      "[timestep: 1] [epoch: 24061] loss: 0.0017835463\n",
      "[timestep: 1] [epoch: 24091] loss: 0.0018728476\n",
      "[timestep: 1] [epoch: 24121] loss: 0.0018739742\n",
      "[timestep: 1] [epoch: 24151] loss: 0.0017895172\n",
      "[timestep: 1] [epoch: 24181] loss: 0.0018093435\n",
      "[timestep: 1] [epoch: 24211] loss: 0.0017352428\n",
      "[timestep: 1] [epoch: 24241] loss: 0.0018686738\n",
      "[timestep: 1] [epoch: 24271] loss: 0.0017631787\n",
      "[timestep: 1] [epoch: 24301] loss: 0.0017540690\n",
      "[timestep: 1] [epoch: 24331] loss: 0.0018786045\n",
      "[timestep: 1] [epoch: 24361] loss: 0.0018320293\n",
      "[timestep: 1] [epoch: 24391] loss: 0.0017378123\n",
      "[timestep: 1] [epoch: 24421] loss: 0.0018197903\n",
      "[timestep: 1] [epoch: 24451] loss: 0.0018725396\n",
      "[timestep: 1] [epoch: 24481] loss: 0.0018018070\n",
      "[timestep: 1] [epoch: 24511] loss: 0.0018363846\n",
      "[timestep: 1] [epoch: 24541] loss: 0.0017648737\n",
      "[timestep: 1] [epoch: 24571] loss: 0.0017593186\n",
      "[timestep: 1] [epoch: 24601] loss: 0.0017410368\n",
      "[timestep: 1] [epoch: 24631] loss: 0.0018193643\n",
      "[timestep: 1] [epoch: 24661] loss: 0.0018159524\n",
      "[timestep: 1] [epoch: 24691] loss: 0.0017114157\n",
      "[timestep: 1] [epoch: 24721] loss: 0.0020156452\n",
      "[timestep: 1] [epoch: 24751] loss: 0.0017026740\n",
      "[timestep: 1] [epoch: 24781] loss: 0.0017270647\n",
      "[timestep: 1] [epoch: 24811] loss: 0.0017439348\n",
      "[timestep: 1] [epoch: 24841] loss: 0.0018530230\n",
      "[timestep: 1] [epoch: 24871] loss: 0.0017421681\n",
      "[timestep: 1] [epoch: 24901] loss: 0.0017434978\n",
      "[timestep: 1] [epoch: 24931] loss: 0.0016912608\n",
      "[timestep: 1] [epoch: 24961] loss: 0.0017994433\n",
      "[timestep: 1] [epoch: 24991] loss: 0.0017549256\n",
      "[timestep: 1] [epoch: 25021] loss: 0.0017571490\n",
      "[timestep: 1] [epoch: 25051] loss: 0.0017361706\n",
      "[timestep: 1] [epoch: 25081] loss: 0.0017031757\n",
      "[timestep: 1] [epoch: 25111] loss: 0.0016538153\n",
      "[timestep: 1] [epoch: 25141] loss: 0.0016635403\n",
      "[timestep: 1] [epoch: 25171] loss: 0.0017600446\n",
      "[timestep: 1] [epoch: 25201] loss: 0.0017367434\n",
      "[timestep: 1] [epoch: 25231] loss: 0.0018428062\n",
      "[timestep: 1] [epoch: 25261] loss: 0.0016925265\n",
      "[timestep: 1] [epoch: 25291] loss: 0.0017438470\n",
      "[timestep: 1] [epoch: 25321] loss: 0.0017580889\n",
      "[timestep: 1] [epoch: 25351] loss: 0.0016563497\n",
      "[timestep: 1] [epoch: 25381] loss: 0.0016184933\n",
      "[timestep: 1] [epoch: 25411] loss: 0.0016699559\n",
      "[timestep: 1] [epoch: 25441] loss: 0.0017827407\n",
      "[timestep: 1] [epoch: 25471] loss: 0.0016855651\n",
      "[timestep: 1] [epoch: 25501] loss: 0.0016551617\n",
      "[timestep: 1] [epoch: 25531] loss: 0.0017128586\n",
      "[timestep: 1] [epoch: 25561] loss: 0.0017277630\n",
      "[timestep: 1] [epoch: 25591] loss: 0.0018819947\n",
      "[timestep: 1] [epoch: 25621] loss: 0.0016489177\n",
      "[timestep: 1] [epoch: 25651] loss: 0.0016732432\n",
      "[timestep: 1] [epoch: 25681] loss: 0.0016013209\n",
      "[timestep: 1] [epoch: 25711] loss: 0.0016550238\n",
      "[timestep: 1] [epoch: 25741] loss: 0.0016554735\n",
      "[timestep: 1] [epoch: 25771] loss: 0.0017660101\n",
      "[timestep: 1] [epoch: 25801] loss: 0.0016934276\n",
      "[timestep: 1] [epoch: 25831] loss: 0.0016830089\n",
      "[timestep: 1] [epoch: 25861] loss: 0.0017835940\n",
      "[timestep: 1] [epoch: 25891] loss: 0.0016159667\n",
      "[timestep: 1] [epoch: 25921] loss: 0.0016250303\n",
      "[timestep: 1] [epoch: 25951] loss: 0.0016924429\n",
      "[timestep: 1] [epoch: 25981] loss: 0.0016594769\n",
      "[timestep: 1] [epoch: 26011] loss: 0.0016230140\n",
      "[timestep: 1] [epoch: 26041] loss: 0.0016841156\n",
      "[timestep: 1] [epoch: 26071] loss: 0.0015991569\n",
      "[timestep: 1] [epoch: 26101] loss: 0.0015918328\n",
      "[timestep: 1] [epoch: 26131] loss: 0.0016016082\n",
      "[timestep: 1] [epoch: 26161] loss: 0.0015808757\n",
      "[timestep: 1] [epoch: 26191] loss: 0.0015981693\n",
      "[timestep: 1] [epoch: 26221] loss: 0.0015868581\n",
      "[timestep: 1] [epoch: 26251] loss: 0.0016264154\n",
      "[timestep: 1] [epoch: 26281] loss: 0.0016034457\n",
      "[timestep: 1] [epoch: 26311] loss: 0.0016075023\n",
      "[timestep: 1] [epoch: 26341] loss: 0.0016068347\n",
      "[timestep: 1] [epoch: 26371] loss: 0.0016437878\n",
      "[timestep: 1] [epoch: 26401] loss: 0.0015689747\n",
      "[timestep: 1] [epoch: 26431] loss: 0.0015639605\n",
      "[timestep: 1] [epoch: 26461] loss: 0.0015272268\n",
      "[timestep: 1] [epoch: 26491] loss: 0.0015407596\n",
      "[timestep: 1] [epoch: 26521] loss: 0.0016361998\n",
      "[timestep: 1] [epoch: 26551] loss: 0.0015311375\n",
      "[timestep: 1] [epoch: 26581] loss: 0.0015683532\n",
      "[timestep: 1] [epoch: 26611] loss: 0.0015699795\n",
      "[timestep: 1] [epoch: 26641] loss: 0.0015455664\n",
      "[timestep: 1] [epoch: 26671] loss: 0.0015565227\n",
      "[timestep: 1] [epoch: 26701] loss: 0.0015651000\n",
      "[timestep: 1] [epoch: 26731] loss: 0.0015602108\n",
      "[timestep: 1] [epoch: 26761] loss: 0.0016545579\n",
      "[timestep: 1] [epoch: 26791] loss: 0.0015210917\n",
      "[timestep: 1] [epoch: 26821] loss: 0.0015852757\n",
      "[timestep: 1] [epoch: 26851] loss: 0.0015897322\n",
      "[timestep: 1] [epoch: 26881] loss: 0.0015273201\n",
      "[timestep: 1] [epoch: 26911] loss: 0.0015275192\n",
      "[timestep: 1] [epoch: 26941] loss: 0.0015208678\n",
      "[timestep: 1] [epoch: 26971] loss: 0.0015387154\n",
      "[timestep: 1] [epoch: 27001] loss: 0.0015777892\n",
      "[timestep: 1] [epoch: 27031] loss: 0.0015913333\n",
      "[timestep: 1] [epoch: 27061] loss: 0.0016293719\n",
      "[timestep: 1] [epoch: 27091] loss: 0.0015312945\n",
      "[timestep: 1] [epoch: 27121] loss: 0.0015073630\n",
      "[timestep: 1] [epoch: 27151] loss: 0.0015151002\n",
      "[timestep: 1] [epoch: 27181] loss: 0.0015356836\n",
      "[timestep: 1] [epoch: 27211] loss: 0.0015585241\n",
      "[timestep: 1] [epoch: 27241] loss: 0.0015625382\n",
      "[timestep: 1] [epoch: 27271] loss: 0.0016245402\n",
      "[timestep: 1] [epoch: 27301] loss: 0.0014661371\n",
      "[timestep: 1] [epoch: 27331] loss: 0.0015670613\n",
      "[timestep: 1] [epoch: 27361] loss: 0.0015578546\n",
      "[timestep: 1] [epoch: 27391] loss: 0.0014738727\n",
      "[timestep: 1] [epoch: 27421] loss: 0.0015325770\n",
      "[timestep: 1] [epoch: 27451] loss: 0.0015034697\n",
      "[timestep: 1] [epoch: 27481] loss: 0.0015515637\n",
      "[timestep: 1] [epoch: 27511] loss: 0.0016194002\n",
      "[timestep: 1] [epoch: 27541] loss: 0.0014904316\n",
      "[timestep: 1] [epoch: 27571] loss: 0.0014908018\n",
      "[timestep: 1] [epoch: 27601] loss: 0.0015158828\n",
      "[timestep: 1] [epoch: 27631] loss: 0.0015201546\n",
      "[timestep: 1] [epoch: 27661] loss: 0.0014965364\n",
      "[timestep: 1] [epoch: 27691] loss: 0.0015460153\n",
      "[timestep: 1] [epoch: 27721] loss: 0.0015583722\n",
      "[timestep: 1] [epoch: 27751] loss: 0.0015242755\n",
      "[timestep: 1] [epoch: 27781] loss: 0.0014857005\n",
      "[timestep: 1] [epoch: 27811] loss: 0.0015236218\n",
      "[timestep: 1] [epoch: 27841] loss: 0.0014977870\n",
      "[timestep: 1] [epoch: 27871] loss: 0.0015015367\n",
      "[timestep: 1] [epoch: 27901] loss: 0.0015479515\n",
      "[timestep: 1] [epoch: 27931] loss: 0.0014980019\n",
      "[timestep: 1] [epoch: 27961] loss: 0.0014692171\n",
      "[timestep: 1] [epoch: 27991] loss: 0.0014741842\n",
      "[timestep: 1] [epoch: 28021] loss: 0.0015030471\n",
      "[timestep: 1] [epoch: 28051] loss: 0.0014657479\n",
      "[timestep: 1] [epoch: 28081] loss: 0.0014838167\n",
      "[timestep: 1] [epoch: 28111] loss: 0.0015391656\n",
      "[timestep: 1] [epoch: 28141] loss: 0.0015827689\n",
      "[timestep: 1] [epoch: 28171] loss: 0.0014703220\n",
      "[timestep: 1] [epoch: 28201] loss: 0.0015642672\n",
      "[timestep: 1] [epoch: 28231] loss: 0.0014726652\n",
      "[timestep: 1] [epoch: 28261] loss: 0.0014893085\n",
      "[timestep: 1] [epoch: 28291] loss: 0.0014426281\n",
      "[timestep: 1] [epoch: 28321] loss: 0.0014724816\n",
      "[timestep: 1] [epoch: 28351] loss: 0.0015305609\n",
      "[timestep: 1] [epoch: 28381] loss: 0.0015151207\n",
      "[timestep: 1] [epoch: 28411] loss: 0.0014857205\n",
      "[timestep: 1] [epoch: 28441] loss: 0.0015003058\n",
      "[timestep: 1] [epoch: 28471] loss: 0.0014868621\n",
      "[timestep: 1] [epoch: 28501] loss: 0.0015119953\n",
      "[timestep: 1] [epoch: 28531] loss: 0.0015087717\n",
      "[timestep: 1] [epoch: 28561] loss: 0.0014593946\n",
      "[timestep: 1] [epoch: 28591] loss: 0.0015071074\n",
      "[timestep: 1] [epoch: 28621] loss: 0.0014824680\n",
      "[timestep: 1] [epoch: 28651] loss: 0.0014568761\n",
      "[timestep: 1] [epoch: 28681] loss: 0.0015050941\n",
      "[timestep: 1] [epoch: 28711] loss: 0.0015009996\n",
      "[timestep: 1] [epoch: 28741] loss: 0.0014882400\n",
      "[timestep: 1] [epoch: 28771] loss: 0.0015282647\n",
      "[timestep: 1] [epoch: 28801] loss: 0.0015404713\n",
      "[timestep: 1] [epoch: 28831] loss: 0.0014628530\n",
      "[timestep: 1] [epoch: 28861] loss: 0.0015048035\n",
      "[timestep: 1] [epoch: 28891] loss: 0.0014844880\n",
      "[timestep: 1] [epoch: 28921] loss: 0.0015010880\n",
      "[timestep: 1] [epoch: 28951] loss: 0.0014881202\n",
      "[timestep: 1] [epoch: 28981] loss: 0.0014782485\n",
      "[timestep: 1] [epoch: 29011] loss: 0.0014957946\n",
      "[timestep: 1] [epoch: 29041] loss: 0.0015361367\n",
      "[timestep: 1] [epoch: 29071] loss: 0.0014463342\n",
      "[timestep: 1] [epoch: 29101] loss: 0.0015098685\n",
      "[timestep: 1] [epoch: 29131] loss: 0.0014598670\n",
      "[timestep: 1] [epoch: 29161] loss: 0.0014815116\n",
      "[timestep: 1] [epoch: 29191] loss: 0.0014801947\n",
      "[timestep: 1] [epoch: 29221] loss: 0.0014953652\n",
      "[timestep: 1] [epoch: 29251] loss: 0.0014711029\n",
      "[timestep: 1] [epoch: 29281] loss: 0.0014836448\n",
      "[timestep: 1] [epoch: 29311] loss: 0.0014650910\n",
      "[timestep: 1] [epoch: 29341] loss: 0.0014733837\n",
      "[timestep: 1] [epoch: 29371] loss: 0.0014918132\n",
      "[timestep: 1] [epoch: 29401] loss: 0.0014519267\n",
      "[timestep: 1] [epoch: 29431] loss: 0.0014159419\n",
      "[timestep: 1] [epoch: 29461] loss: 0.0014914192\n",
      "[timestep: 1] [epoch: 29491] loss: 0.0014921236\n",
      "[timestep: 1] [epoch: 29521] loss: 0.0014695337\n",
      "[timestep: 1] [epoch: 29551] loss: 0.0014524291\n",
      "[timestep: 1] [epoch: 29581] loss: 0.0014674691\n",
      "[timestep: 1] [epoch: 29611] loss: 0.0014567450\n",
      "[timestep: 1] [epoch: 29641] loss: 0.0014339262\n",
      "[timestep: 1] [epoch: 29671] loss: 0.0015371112\n",
      "[timestep: 1] [epoch: 29701] loss: 0.0014591181\n",
      "[timestep: 1] [epoch: 29731] loss: 0.0014482727\n",
      "[timestep: 1] [epoch: 29761] loss: 0.0014965674\n",
      "[timestep: 1] [epoch: 29791] loss: 0.0014675463\n",
      "[timestep: 1] [epoch: 29821] loss: 0.0015848352\n",
      "[timestep: 1] [epoch: 29851] loss: 0.0015024664\n",
      "[timestep: 1] [epoch: 29881] loss: 0.0014820382\n",
      "[timestep: 1] [epoch: 29911] loss: 0.0015020359\n",
      "[timestep: 1] [epoch: 29941] loss: 0.0014517852\n",
      "[timestep: 1] [epoch: 29971] loss: 0.0014898466\n",
      "[timestep: 1] [epoch: 30001] loss: 0.0014405436\n",
      "[timestep: 1] [epoch: 30031] loss: 0.0014539066\n",
      "[timestep: 1] [epoch: 30061] loss: 0.0014336024\n",
      "[timestep: 1] [epoch: 30091] loss: 0.0014397746\n",
      "[timestep: 1] [epoch: 30121] loss: 0.0014364084\n",
      "[timestep: 1] [epoch: 30151] loss: 0.0014468301\n",
      "[timestep: 1] [epoch: 30181] loss: 0.0014732574\n",
      "[timestep: 1] [epoch: 30211] loss: 0.0014313288\n",
      "[timestep: 1] [epoch: 30241] loss: 0.0014384894\n",
      "[timestep: 1] [epoch: 30271] loss: 0.0014884360\n",
      "[timestep: 1] [epoch: 30301] loss: 0.0014600594\n",
      "[timestep: 1] [epoch: 30331] loss: 0.0014399268\n",
      "[timestep: 1] [epoch: 30361] loss: 0.0014362696\n",
      "[timestep: 1] [epoch: 30391] loss: 0.0014428298\n",
      "[timestep: 1] [epoch: 30421] loss: 0.0015223565\n",
      "[timestep: 1] [epoch: 30451] loss: 0.0014944010\n",
      "[timestep: 1] [epoch: 30481] loss: 0.0015001313\n",
      "[timestep: 1] [epoch: 30511] loss: 0.0014618668\n",
      "[timestep: 1] [epoch: 30541] loss: 0.0014309319\n",
      "[timestep: 1] [epoch: 30571] loss: 0.0014488650\n",
      "[timestep: 1] [epoch: 30601] loss: 0.0014330395\n",
      "[timestep: 1] [epoch: 30631] loss: 0.0014574449\n",
      "[timestep: 1] [epoch: 30661] loss: 0.0014557650\n",
      "[timestep: 1] [epoch: 30691] loss: 0.0014991026\n",
      "[timestep: 1] [epoch: 30721] loss: 0.0014392892\n",
      "[timestep: 1] [epoch: 30751] loss: 0.0014610656\n",
      "[timestep: 1] [epoch: 30781] loss: 0.0014417256\n",
      "[timestep: 1] [epoch: 30811] loss: 0.0014240575\n",
      "[timestep: 1] [epoch: 30841] loss: 0.0014154086\n",
      "[timestep: 1] [epoch: 30871] loss: 0.0014432629\n",
      "[timestep: 1] [epoch: 30901] loss: 0.0014300649\n",
      "[timestep: 1] [epoch: 30931] loss: 0.0014067170\n",
      "[timestep: 1] [epoch: 30961] loss: 0.0014231981\n",
      "[timestep: 1] [epoch: 30991] loss: 0.0013986169\n",
      "[timestep: 1] [epoch: 31021] loss: 0.0014815156\n",
      "[timestep: 1] [epoch: 31051] loss: 0.0014945412\n",
      "[timestep: 1] [epoch: 31081] loss: 0.0014514152\n",
      "[timestep: 1] [epoch: 31111] loss: 0.0014419027\n",
      "[timestep: 1] [epoch: 31141] loss: 0.0014973138\n",
      "[timestep: 1] [epoch: 31171] loss: 0.0014477537\n",
      "[timestep: 1] [epoch: 31201] loss: 0.0014567014\n",
      "[timestep: 1] [epoch: 31231] loss: 0.0014232590\n",
      "[timestep: 1] [epoch: 31261] loss: 0.0014415290\n",
      "[timestep: 1] [epoch: 31291] loss: 0.0014771788\n",
      "[timestep: 1] [epoch: 31321] loss: 0.0014365539\n",
      "[timestep: 1] [epoch: 31351] loss: 0.0014530866\n",
      "[timestep: 1] [epoch: 31381] loss: 0.0014415075\n",
      "[timestep: 1] [epoch: 31411] loss: 0.0015227221\n",
      "[timestep: 1] [epoch: 31441] loss: 0.0014518746\n",
      "[timestep: 1] [epoch: 31471] loss: 0.0014294122\n",
      "[timestep: 1] [epoch: 31501] loss: 0.0014213717\n",
      "[timestep: 1] [epoch: 31531] loss: 0.0014914323\n",
      "[timestep: 1] [epoch: 31561] loss: 0.0013863466\n",
      "[timestep: 1] [epoch: 31591] loss: 0.0014886896\n",
      "[timestep: 1] [epoch: 31621] loss: 0.0014415812\n",
      "[timestep: 1] [epoch: 31651] loss: 0.0015306755\n",
      "[timestep: 1] [epoch: 31681] loss: 0.0014666452\n",
      "[timestep: 1] [epoch: 31711] loss: 0.0014130697\n",
      "[timestep: 1] [epoch: 31741] loss: 0.0014620994\n",
      "[timestep: 1] [epoch: 31771] loss: 0.0014381268\n",
      "[timestep: 1] [epoch: 31801] loss: 0.0014632688\n",
      "[timestep: 1] [epoch: 31831] loss: 0.0014595761\n",
      "[timestep: 1] [epoch: 31861] loss: 0.0014576413\n",
      "[timestep: 1] [epoch: 31891] loss: 0.0014734394\n",
      "[timestep: 1] [epoch: 31921] loss: 0.0014475973\n",
      "[timestep: 1] [epoch: 31951] loss: 0.0014413777\n",
      "[timestep: 1] [epoch: 31981] loss: 0.0014352910\n",
      "[timestep: 1] [epoch: 32011] loss: 0.0014428787\n",
      "[timestep: 1] [epoch: 32041] loss: 0.0014491192\n",
      "[timestep: 1] [epoch: 32071] loss: 0.0014202427\n",
      "[timestep: 1] [epoch: 32101] loss: 0.0014339502\n",
      "[timestep: 1] [epoch: 32131] loss: 0.0014391089\n",
      "[timestep: 1] [epoch: 32161] loss: 0.0014467130\n",
      "[timestep: 1] [epoch: 32191] loss: 0.0014355474\n",
      "[timestep: 1] [epoch: 32221] loss: 0.0014645115\n",
      "[timestep: 1] [epoch: 32251] loss: 0.0014482732\n",
      "[timestep: 1] [epoch: 32281] loss: 0.0014564925\n",
      "[timestep: 1] [epoch: 32311] loss: 0.0014453717\n",
      "[timestep: 1] [epoch: 32341] loss: 0.0013961555\n",
      "[timestep: 1] [epoch: 32371] loss: 0.0014166492\n",
      "[timestep: 1] [epoch: 32401] loss: 0.0014881054\n",
      "[timestep: 1] [epoch: 32431] loss: 0.0014072709\n",
      "[timestep: 1] [epoch: 32461] loss: 0.0013929365\n",
      "[timestep: 1] [epoch: 32491] loss: 0.0014006658\n",
      "[timestep: 1] [epoch: 32521] loss: 0.0014902430\n",
      "[timestep: 1] [epoch: 32551] loss: 0.0014427766\n",
      "[timestep: 1] [epoch: 32581] loss: 0.0014751842\n",
      "[timestep: 1] [epoch: 32611] loss: 0.0014432245\n",
      "[timestep: 1] [epoch: 32641] loss: 0.0014704510\n",
      "[timestep: 1] [epoch: 32671] loss: 0.0014583925\n",
      "[timestep: 1] [epoch: 32701] loss: 0.0014338838\n",
      "[timestep: 1] [epoch: 32731] loss: 0.0014408013\n",
      "[timestep: 1] [epoch: 32761] loss: 0.0014702633\n",
      "[timestep: 1] [epoch: 32791] loss: 0.0014490056\n",
      "[timestep: 1] [epoch: 32821] loss: 0.0014032613\n",
      "[timestep: 1] [epoch: 32851] loss: 0.0014185162\n",
      "[timestep: 1] [epoch: 32881] loss: 0.0014240597\n",
      "[timestep: 1] [epoch: 32911] loss: 0.0014264366\n",
      "[timestep: 1] [epoch: 32941] loss: 0.0014044130\n",
      "[timestep: 1] [epoch: 32971] loss: 0.0014547695\n",
      "[timestep: 1] [epoch: 33001] loss: 0.0014354014\n",
      "[timestep: 1] [epoch: 33031] loss: 0.0013914225\n",
      "[timestep: 1] [epoch: 33061] loss: 0.0014514427\n",
      "[timestep: 1] [epoch: 33091] loss: 0.0014115961\n",
      "[timestep: 1] [epoch: 33121] loss: 0.0014317317\n",
      "[timestep: 1] [epoch: 33151] loss: 0.0014205691\n",
      "[timestep: 1] [epoch: 33181] loss: 0.0014084089\n",
      "[timestep: 1] [epoch: 33211] loss: 0.0014650642\n",
      "[timestep: 1] [epoch: 33241] loss: 0.0014275855\n",
      "[timestep: 1] [epoch: 33271] loss: 0.0014617404\n",
      "[timestep: 1] [epoch: 33301] loss: 0.0014272429\n",
      "[timestep: 1] [epoch: 33331] loss: 0.0014363799\n",
      "[timestep: 1] [epoch: 33361] loss: 0.0014363129\n",
      "[timestep: 1] [epoch: 33391] loss: 0.0014230016\n",
      "[timestep: 1] [epoch: 33421] loss: 0.0014079047\n",
      "[timestep: 1] [epoch: 33451] loss: 0.0014352874\n",
      "[timestep: 1] [epoch: 33481] loss: 0.0014121514\n",
      "[timestep: 1] [epoch: 33511] loss: 0.0014014425\n",
      "[timestep: 1] [epoch: 33541] loss: 0.0014133494\n",
      "[timestep: 1] [epoch: 33571] loss: 0.0014118208\n",
      "[timestep: 1] [epoch: 33601] loss: 0.0014214880\n",
      "[timestep: 1] [epoch: 33631] loss: 0.0013888208\n",
      "[timestep: 1] [epoch: 33661] loss: 0.0014114472\n",
      "[timestep: 1] [epoch: 33691] loss: 0.0013905209\n",
      "[timestep: 1] [epoch: 33721] loss: 0.0014642507\n",
      "[timestep: 1] [epoch: 33751] loss: 0.0014381895\n",
      "[timestep: 1] [epoch: 33781] loss: 0.0014096005\n",
      "[timestep: 1] [epoch: 33811] loss: 0.0014030540\n",
      "[timestep: 1] [epoch: 33841] loss: 0.0013963003\n",
      "[timestep: 1] [epoch: 33871] loss: 0.0014209501\n",
      "[timestep: 1] [epoch: 33901] loss: 0.0014311199\n",
      "[timestep: 1] [epoch: 33931] loss: 0.0014209615\n",
      "[timestep: 1] [epoch: 33961] loss: 0.0014064793\n",
      "[timestep: 1] [epoch: 33991] loss: 0.0014522873\n",
      "[timestep: 1] [epoch: 34021] loss: 0.0014309434\n",
      "[timestep: 1] [epoch: 34051] loss: 0.0014149375\n",
      "[timestep: 1] [epoch: 34081] loss: 0.0014175302\n",
      "[timestep: 1] [epoch: 34111] loss: 0.0013863249\n",
      "[timestep: 1] [epoch: 34141] loss: 0.0013892455\n",
      "[timestep: 1] [epoch: 34171] loss: 0.0014126971\n",
      "[timestep: 1] [epoch: 34201] loss: 0.0014534644\n",
      "[timestep: 1] [epoch: 34231] loss: 0.0014172364\n",
      "[timestep: 1] [epoch: 34261] loss: 0.0013971021\n",
      "[timestep: 1] [epoch: 34291] loss: 0.0014471391\n",
      "[timestep: 1] [epoch: 34321] loss: 0.0014367041\n",
      "[timestep: 1] [epoch: 34351] loss: 0.0014034557\n",
      "[timestep: 1] [epoch: 34381] loss: 0.0014150541\n",
      "[timestep: 1] [epoch: 34411] loss: 0.0013858518\n",
      "[timestep: 1] [epoch: 34441] loss: 0.0013803230\n",
      "[timestep: 1] [epoch: 34471] loss: 0.0014130099\n",
      "[timestep: 1] [epoch: 34501] loss: 0.0014197334\n",
      "[timestep: 1] [epoch: 34531] loss: 0.0014160722\n",
      "[timestep: 1] [epoch: 34561] loss: 0.0014216359\n",
      "[timestep: 1] [epoch: 34591] loss: 0.0014699588\n",
      "[timestep: 1] [epoch: 34621] loss: 0.0014422563\n",
      "[timestep: 1] [epoch: 34651] loss: 0.0014458098\n",
      "[timestep: 1] [epoch: 34681] loss: 0.0014186550\n",
      "[timestep: 1] [epoch: 34711] loss: 0.0014471676\n",
      "[timestep: 1] [epoch: 34741] loss: 0.0014145928\n",
      "[timestep: 1] [epoch: 34771] loss: 0.0014155020\n",
      "[timestep: 1] [epoch: 34801] loss: 0.0013829353\n",
      "[timestep: 1] [epoch: 34831] loss: 0.0014646660\n",
      "[timestep: 1] [epoch: 34861] loss: 0.0014425461\n",
      "[timestep: 1] [epoch: 34891] loss: 0.0014027765\n",
      "[timestep: 1] [epoch: 34921] loss: 0.0013813932\n",
      "[timestep: 1] [epoch: 34951] loss: 0.0014126908\n",
      "[timestep: 1] [epoch: 34981] loss: 0.0014051142\n",
      "[timestep: 1] [epoch: 35011] loss: 0.0014064570\n",
      "[timestep: 1] [epoch: 35041] loss: 0.0013770127\n",
      "[timestep: 1] [epoch: 35071] loss: 0.0014046454\n",
      "[timestep: 1] [epoch: 35101] loss: 0.0013876436\n",
      "[timestep: 1] [epoch: 35131] loss: 0.0014638067\n",
      "[timestep: 1] [epoch: 35161] loss: 0.0013949980\n",
      "[timestep: 1] [epoch: 35191] loss: 0.0014067115\n",
      "[timestep: 1] [epoch: 35221] loss: 0.0014159703\n",
      "[timestep: 1] [epoch: 35251] loss: 0.0014118856\n",
      "[timestep: 1] [epoch: 35281] loss: 0.0013815159\n",
      "[timestep: 1] [epoch: 35311] loss: 0.0013852379\n",
      "[timestep: 1] [epoch: 35341] loss: 0.0014011170\n",
      "[timestep: 1] [epoch: 35371] loss: 0.0013904721\n",
      "[timestep: 1] [epoch: 35401] loss: 0.0013834913\n",
      "[timestep: 1] [epoch: 35431] loss: 0.0014114769\n",
      "[timestep: 1] [epoch: 35461] loss: 0.0014202074\n",
      "[timestep: 1] [epoch: 35491] loss: 0.0013992926\n",
      "[timestep: 1] [epoch: 35521] loss: 0.0014566564\n",
      "[timestep: 1] [epoch: 35551] loss: 0.0014426559\n",
      "[timestep: 1] [epoch: 35581] loss: 0.0014262429\n",
      "[timestep: 1] [epoch: 35611] loss: 0.0014317054\n",
      "[timestep: 1] [epoch: 35641] loss: 0.0014313996\n",
      "[timestep: 1] [epoch: 35671] loss: 0.0014098354\n",
      "[timestep: 1] [epoch: 35701] loss: 0.0014174669\n",
      "[timestep: 1] [epoch: 35731] loss: 0.0014443797\n",
      "[timestep: 1] [epoch: 35761] loss: 0.0013666435\n",
      "[timestep: 1] [epoch: 35791] loss: 0.0014684018\n",
      "[timestep: 1] [epoch: 35821] loss: 0.0014068678\n",
      "[timestep: 1] [epoch: 35851] loss: 0.0013888464\n",
      "[timestep: 1] [epoch: 35881] loss: 0.0013853899\n",
      "[timestep: 1] [epoch: 35911] loss: 0.0013900583\n",
      "[timestep: 1] [epoch: 35941] loss: 0.0014082947\n",
      "[timestep: 1] [epoch: 35971] loss: 0.0014163882\n",
      "[timestep: 1] [epoch: 36001] loss: 0.0014222119\n",
      "[timestep: 1] [epoch: 36031] loss: 0.0014046582\n",
      "[timestep: 1] [epoch: 36061] loss: 0.0014131225\n",
      "[timestep: 1] [epoch: 36091] loss: 0.0013891603\n",
      "[timestep: 1] [epoch: 36121] loss: 0.0013749206\n",
      "[timestep: 1] [epoch: 36151] loss: 0.0014004629\n",
      "[timestep: 1] [epoch: 36181] loss: 0.0014232213\n",
      "[timestep: 1] [epoch: 36211] loss: 0.0014183871\n",
      "[timestep: 1] [epoch: 36241] loss: 0.0014102076\n",
      "[timestep: 1] [epoch: 36271] loss: 0.0013780994\n",
      "[timestep: 1] [epoch: 36301] loss: 0.0014034497\n",
      "[timestep: 1] [epoch: 36331] loss: 0.0014425926\n",
      "[timestep: 1] [epoch: 36361] loss: 0.0014032898\n",
      "[timestep: 1] [epoch: 36391] loss: 0.0014159174\n",
      "[timestep: 1] [epoch: 36421] loss: 0.0013841023\n",
      "[timestep: 1] [epoch: 36451] loss: 0.0014007353\n",
      "[timestep: 1] [epoch: 36481] loss: 0.0013900173\n",
      "[timestep: 1] [epoch: 36511] loss: 0.0013690765\n",
      "[timestep: 1] [epoch: 36541] loss: 0.0013757234\n",
      "[timestep: 1] [epoch: 36571] loss: 0.0013820033\n",
      "[timestep: 1] [epoch: 36601] loss: 0.0013787255\n",
      "[timestep: 1] [epoch: 36631] loss: 0.0013648309\n",
      "[timestep: 1] [epoch: 36661] loss: 0.0013877071\n",
      "[timestep: 1] [epoch: 36691] loss: 0.0014296607\n",
      "[timestep: 1] [epoch: 36721] loss: 0.0013646891\n",
      "[timestep: 1] [epoch: 36751] loss: 0.0014019612\n",
      "[timestep: 1] [epoch: 36781] loss: 0.0013768439\n",
      "[timestep: 1] [epoch: 36811] loss: 0.0014065177\n",
      "[timestep: 1] [epoch: 36841] loss: 0.0014409123\n",
      "[timestep: 1] [epoch: 36871] loss: 0.0013735070\n",
      "[timestep: 1] [epoch: 36901] loss: 0.0014437456\n",
      "[timestep: 1] [epoch: 36931] loss: 0.0013991434\n",
      "[timestep: 1] [epoch: 36961] loss: 0.0014299296\n",
      "[timestep: 1] [epoch: 36991] loss: 0.0014028774\n",
      "[timestep: 1] [epoch: 37021] loss: 0.0013990469\n",
      "[timestep: 1] [epoch: 37051] loss: 0.0014093346\n",
      "[timestep: 1] [epoch: 37081] loss: 0.0014142103\n",
      "[timestep: 1] [epoch: 37111] loss: 0.0013953859\n",
      "[timestep: 1] [epoch: 37141] loss: 0.0014083681\n",
      "[timestep: 1] [epoch: 37171] loss: 0.0014043882\n",
      "[timestep: 1] [epoch: 37201] loss: 0.0013837139\n",
      "[timestep: 1] [epoch: 37231] loss: 0.0014333375\n",
      "[timestep: 1] [epoch: 37261] loss: 0.0013858129\n",
      "[timestep: 1] [epoch: 37291] loss: 0.0014178837\n",
      "[timestep: 1] [epoch: 37321] loss: 0.0013974080\n",
      "[timestep: 1] [epoch: 37351] loss: 0.0014546242\n",
      "[timestep: 1] [epoch: 37381] loss: 0.0014194713\n",
      "[timestep: 1] [epoch: 37411] loss: 0.0014158527\n",
      "[timestep: 1] [epoch: 37441] loss: 0.0013928065\n",
      "[timestep: 1] [epoch: 37471] loss: 0.0014022978\n",
      "[timestep: 1] [epoch: 37501] loss: 0.0013921449\n",
      "[timestep: 1] [epoch: 37531] loss: 0.0014217830\n",
      "[timestep: 1] [epoch: 37561] loss: 0.0014018312\n",
      "[timestep: 1] [epoch: 37591] loss: 0.0014039100\n",
      "[timestep: 1] [epoch: 37621] loss: 0.0014036120\n",
      "[timestep: 1] [epoch: 37651] loss: 0.0013956346\n",
      "[timestep: 1] [epoch: 37681] loss: 0.0014062081\n",
      "[timestep: 1] [epoch: 37711] loss: 0.0014199631\n",
      "[timestep: 1] [epoch: 37741] loss: 0.0014225107\n",
      "[timestep: 1] [epoch: 37771] loss: 0.0013976278\n",
      "[timestep: 1] [epoch: 37801] loss: 0.0013903677\n",
      "[timestep: 1] [epoch: 37831] loss: 0.0013814399\n",
      "[timestep: 1] [epoch: 37861] loss: 0.0013857645\n",
      "[timestep: 1] [epoch: 37891] loss: 0.0014510010\n",
      "[timestep: 1] [epoch: 37921] loss: 0.0013925238\n",
      "[timestep: 1] [epoch: 37951] loss: 0.0013813009\n",
      "[timestep: 1] [epoch: 37981] loss: 0.0013717504\n",
      "[timestep: 1] [epoch: 38011] loss: 0.0013616105\n",
      "[timestep: 1] [epoch: 38041] loss: 0.0013983585\n",
      "[timestep: 1] [epoch: 38071] loss: 0.0014022479\n",
      "[timestep: 1] [epoch: 38101] loss: 0.0013674586\n",
      "[timestep: 1] [epoch: 38131] loss: 0.0013716632\n",
      "[timestep: 1] [epoch: 38161] loss: 0.0013994814\n",
      "[timestep: 1] [epoch: 38191] loss: 0.0013809344\n",
      "[timestep: 1] [epoch: 38221] loss: 0.0014079763\n",
      "[timestep: 1] [epoch: 38251] loss: 0.0014259452\n",
      "[timestep: 1] [epoch: 38281] loss: 0.0014333019\n",
      "[timestep: 1] [epoch: 38311] loss: 0.0014196814\n",
      "[timestep: 1] [epoch: 38341] loss: 0.0013929623\n",
      "[timestep: 1] [epoch: 38371] loss: 0.0013927075\n",
      "[timestep: 1] [epoch: 38401] loss: 0.0013746303\n",
      "[timestep: 1] [epoch: 38431] loss: 0.0014288552\n",
      "[timestep: 1] [epoch: 38461] loss: 0.0013999620\n",
      "[timestep: 1] [epoch: 38491] loss: 0.0013772940\n",
      "[timestep: 1] [epoch: 38521] loss: 0.0013891212\n",
      "[timestep: 1] [epoch: 38551] loss: 0.0014029255\n",
      "[timestep: 1] [epoch: 38581] loss: 0.0013873603\n",
      "[timestep: 1] [epoch: 38611] loss: 0.0013991462\n",
      "[timestep: 1] [epoch: 38641] loss: 0.0013976446\n",
      "[timestep: 1] [epoch: 38671] loss: 0.0013807765\n",
      "[timestep: 1] [epoch: 38701] loss: 0.0014122374\n",
      "[timestep: 1] [epoch: 38731] loss: 0.0013861163\n",
      "[timestep: 1] [epoch: 38761] loss: 0.0014211929\n",
      "[timestep: 1] [epoch: 38791] loss: 0.0014386859\n",
      "[timestep: 1] [epoch: 38821] loss: 0.0014117431\n",
      "[timestep: 1] [epoch: 38851] loss: 0.0014129380\n",
      "[timestep: 1] [epoch: 38881] loss: 0.0013953540\n",
      "[timestep: 1] [epoch: 38911] loss: 0.0013973869\n",
      "[timestep: 1] [epoch: 38941] loss: 0.0013655701\n",
      "[timestep: 1] [epoch: 38971] loss: 0.0013656676\n",
      "[timestep: 1] [epoch: 39001] loss: 0.0014161379\n",
      "[timestep: 1] [epoch: 39031] loss: 0.0013796091\n",
      "[timestep: 1] [epoch: 39061] loss: 0.0014021688\n",
      "[timestep: 1] [epoch: 39091] loss: 0.0013790162\n",
      "[timestep: 1] [epoch: 39121] loss: 0.0014256041\n",
      "[timestep: 1] [epoch: 39151] loss: 0.0013631360\n",
      "[timestep: 1] [epoch: 39181] loss: 0.0013916912\n",
      "[timestep: 1] [epoch: 39211] loss: 0.0014085419\n",
      "[timestep: 1] [epoch: 39241] loss: 0.0014005376\n",
      "[timestep: 1] [epoch: 39271] loss: 0.0013951601\n",
      "[timestep: 1] [epoch: 39301] loss: 0.0014201782\n",
      "[timestep: 1] [epoch: 39331] loss: 0.0013806205\n",
      "[timestep: 1] [epoch: 39361] loss: 0.0013986009\n",
      "[timestep: 1] [epoch: 39391] loss: 0.0013958269\n",
      "[timestep: 1] [epoch: 39421] loss: 0.0013968875\n",
      "[timestep: 1] [epoch: 39451] loss: 0.0013771398\n",
      "[timestep: 1] [epoch: 39481] loss: 0.0014004803\n",
      "[timestep: 1] [epoch: 39511] loss: 0.0014011788\n",
      "[timestep: 1] [epoch: 39541] loss: 0.0013901342\n",
      "[timestep: 1] [epoch: 39571] loss: 0.0013493347\n",
      "[timestep: 1] [epoch: 39601] loss: 0.0013677306\n",
      "[timestep: 1] [epoch: 39631] loss: 0.0013646991\n",
      "[timestep: 1] [epoch: 39661] loss: 0.0014056603\n",
      "[timestep: 1] [epoch: 39691] loss: 0.0013597386\n",
      "[timestep: 1] [epoch: 39721] loss: 0.0014033291\n",
      "[timestep: 1] [epoch: 39751] loss: 0.0013849024\n",
      "[timestep: 1] [epoch: 39781] loss: 0.0013880066\n",
      "[timestep: 1] [epoch: 39811] loss: 0.0013884823\n",
      "[timestep: 1] [epoch: 39841] loss: 0.0013765312\n",
      "[timestep: 1] [epoch: 39871] loss: 0.0013814913\n",
      "[timestep: 1] [epoch: 39901] loss: 0.0013795715\n",
      "[timestep: 1] [epoch: 39931] loss: 0.0013688162\n",
      "[timestep: 1] [epoch: 39961] loss: 0.0013836918\n",
      "[timestep: 1] [epoch: 39991] loss: 0.0014112419\n",
      "[timestep: 1] [epoch: 40021] loss: 0.0013796083\n",
      "[timestep: 1] [epoch: 40051] loss: 0.0014242658\n",
      "[timestep: 1] [epoch: 40081] loss: 0.0014017660\n",
      "[timestep: 1] [epoch: 40111] loss: 0.0013984198\n",
      "[timestep: 1] [epoch: 40141] loss: 0.0013965173\n",
      "[timestep: 1] [epoch: 40171] loss: 0.0014067609\n",
      "[timestep: 1] [epoch: 40201] loss: 0.0014259535\n",
      "[timestep: 1] [epoch: 40231] loss: 0.0013854754\n",
      "[timestep: 1] [epoch: 40261] loss: 0.0014100899\n",
      "[timestep: 1] [epoch: 40291] loss: 0.0014171668\n",
      "[timestep: 1] [epoch: 40321] loss: 0.0014079111\n",
      "[timestep: 1] [epoch: 40351] loss: 0.0014073220\n",
      "[timestep: 1] [epoch: 40381] loss: 0.0013925680\n",
      "[timestep: 1] [epoch: 40411] loss: 0.0014303885\n",
      "[timestep: 1] [epoch: 40441] loss: 0.0014014156\n",
      "[timestep: 1] [epoch: 40471] loss: 0.0013851500\n",
      "[timestep: 1] [epoch: 40501] loss: 0.0013987578\n",
      "[timestep: 1] [epoch: 40531] loss: 0.0013850649\n",
      "[timestep: 1] [epoch: 40561] loss: 0.0013757434\n",
      "[timestep: 1] [epoch: 40591] loss: 0.0013753059\n",
      "[timestep: 1] [epoch: 40621] loss: 0.0014302441\n",
      "[timestep: 1] [epoch: 40651] loss: 0.0013970801\n",
      "[timestep: 1] [epoch: 40681] loss: 0.0013945857\n",
      "[timestep: 1] [epoch: 40711] loss: 0.0014288989\n",
      "[timestep: 1] [epoch: 40741] loss: 0.0014066542\n",
      "[timestep: 1] [epoch: 40771] loss: 0.0013867023\n",
      "[timestep: 1] [epoch: 40801] loss: 0.0014401327\n",
      "[timestep: 1] [epoch: 40831] loss: 0.0014089079\n",
      "[timestep: 1] [epoch: 40861] loss: 0.0014137984\n",
      "[timestep: 1] [epoch: 40891] loss: 0.0014097727\n",
      "[timestep: 1] [epoch: 40921] loss: 0.0013759211\n",
      "[timestep: 1] [epoch: 40951] loss: 0.0013949448\n",
      "[timestep: 1] [epoch: 40981] loss: 0.0013835883\n",
      "[timestep: 1] [epoch: 41011] loss: 0.0013938820\n",
      "[timestep: 1] [epoch: 41041] loss: 0.0013748786\n",
      "[timestep: 1] [epoch: 41071] loss: 0.0013705608\n",
      "[timestep: 1] [epoch: 41101] loss: 0.0013895314\n",
      "[timestep: 1] [epoch: 41131] loss: 0.0013848906\n",
      "[timestep: 1] [epoch: 41161] loss: 0.0013742149\n",
      "[timestep: 1] [epoch: 41191] loss: 0.0013673056\n",
      "[timestep: 1] [epoch: 41221] loss: 0.0013386441\n",
      "[timestep: 1] [epoch: 41251] loss: 0.0014056897\n",
      "[timestep: 1] [epoch: 41281] loss: 0.0013679711\n",
      "[timestep: 1] [epoch: 41311] loss: 0.0013700535\n",
      "[timestep: 1] [epoch: 41341] loss: 0.0013655047\n",
      "[timestep: 1] [epoch: 41371] loss: 0.0014005926\n",
      "[timestep: 1] [epoch: 41401] loss: 0.0014035652\n",
      "[timestep: 1] [epoch: 41431] loss: 0.0013703416\n",
      "[timestep: 1] [epoch: 41461] loss: 0.0013693739\n",
      "[timestep: 1] [epoch: 41491] loss: 0.0014033484\n",
      "[timestep: 1] [epoch: 41521] loss: 0.0013876619\n",
      "[timestep: 1] [epoch: 41551] loss: 0.0013933058\n",
      "[timestep: 1] [epoch: 41581] loss: 0.0013921970\n",
      "[timestep: 1] [epoch: 41611] loss: 0.0014268397\n",
      "[timestep: 1] [epoch: 41641] loss: 0.0013685566\n",
      "[timestep: 1] [epoch: 41671] loss: 0.0014078653\n",
      "[timestep: 1] [epoch: 41701] loss: 0.0014140762\n",
      "[timestep: 1] [epoch: 41731] loss: 0.0013848291\n",
      "[timestep: 1] [epoch: 41761] loss: 0.0013882020\n",
      "[timestep: 1] [epoch: 41791] loss: 0.0013770219\n",
      "[timestep: 1] [epoch: 41821] loss: 0.0013630562\n",
      "[timestep: 1] [epoch: 41851] loss: 0.0013868529\n",
      "[timestep: 1] [epoch: 41881] loss: 0.0014118482\n",
      "[timestep: 1] [epoch: 41911] loss: 0.0014117559\n",
      "[timestep: 1] [epoch: 41941] loss: 0.0013687491\n",
      "[timestep: 1] [epoch: 41971] loss: 0.0013652296\n",
      "[timestep: 1] [epoch: 42001] loss: 0.0013797469\n",
      "[timestep: 1] [epoch: 42031] loss: 0.0013688599\n",
      "[timestep: 1] [epoch: 42061] loss: 0.0014159738\n",
      "[timestep: 1] [epoch: 42091] loss: 0.0013923703\n",
      "[timestep: 1] [epoch: 42121] loss: 0.0013756767\n",
      "[timestep: 1] [epoch: 42151] loss: 0.0014162865\n",
      "[timestep: 1] [epoch: 42181] loss: 0.0013906372\n",
      "[timestep: 1] [epoch: 42211] loss: 0.0013700790\n",
      "[timestep: 1] [epoch: 42241] loss: 0.0013897556\n",
      "[timestep: 1] [epoch: 42271] loss: 0.0014065417\n",
      "[timestep: 1] [epoch: 42301] loss: 0.0013966176\n",
      "[timestep: 1] [epoch: 42331] loss: 0.0014043560\n",
      "[timestep: 1] [epoch: 42361] loss: 0.0013790375\n",
      "[timestep: 1] [epoch: 42391] loss: 0.0014054073\n",
      "[timestep: 1] [epoch: 42421] loss: 0.0013657506\n",
      "[timestep: 1] [epoch: 42451] loss: 0.0013906036\n",
      "[timestep: 1] [epoch: 42481] loss: 0.0013888811\n",
      "[timestep: 1] [epoch: 42511] loss: 0.0013795457\n",
      "[timestep: 1] [epoch: 42541] loss: 0.0013716752\n",
      "[timestep: 1] [epoch: 42571] loss: 0.0013975371\n",
      "[timestep: 1] [epoch: 42601] loss: 0.0013850302\n",
      "[timestep: 1] [epoch: 42631] loss: 0.0013756803\n",
      "[timestep: 1] [epoch: 42661] loss: 0.0013781565\n",
      "[timestep: 1] [epoch: 42691] loss: 0.0013832772\n",
      "[timestep: 1] [epoch: 42721] loss: 0.0013845683\n",
      "[timestep: 1] [epoch: 42751] loss: 0.0014114366\n",
      "[timestep: 1] [epoch: 42781] loss: 0.0013878660\n",
      "[timestep: 1] [epoch: 42811] loss: 0.0014275718\n",
      "[timestep: 1] [epoch: 42841] loss: 0.0013628665\n",
      "[timestep: 1] [epoch: 42871] loss: 0.0014116238\n",
      "[timestep: 1] [epoch: 42901] loss: 0.0013793542\n",
      "[timestep: 1] [epoch: 42931] loss: 0.0013912101\n",
      "[timestep: 1] [epoch: 42961] loss: 0.0014009145\n",
      "[timestep: 1] [epoch: 42991] loss: 0.0013645741\n",
      "[timestep: 1] [epoch: 43021] loss: 0.0013696380\n",
      "[timestep: 1] [epoch: 43051] loss: 0.0013684251\n",
      "[timestep: 1] [epoch: 43081] loss: 0.0013674888\n",
      "[timestep: 1] [epoch: 43111] loss: 0.0013876369\n",
      "[timestep: 1] [epoch: 43141] loss: 0.0013588145\n",
      "[timestep: 1] [epoch: 43171] loss: 0.0013869713\n",
      "[timestep: 1] [epoch: 43201] loss: 0.0013617477\n",
      "[timestep: 1] [epoch: 43231] loss: 0.0013600452\n",
      "[timestep: 1] [epoch: 43261] loss: 0.0013559563\n",
      "[timestep: 1] [epoch: 43291] loss: 0.0014340898\n",
      "[timestep: 1] [epoch: 43321] loss: 0.0014030226\n",
      "[timestep: 1] [epoch: 43351] loss: 0.0013695266\n",
      "[timestep: 1] [epoch: 43381] loss: 0.0013864916\n",
      "[timestep: 1] [epoch: 43411] loss: 0.0013962232\n",
      "[timestep: 1] [epoch: 43441] loss: 0.0013692738\n",
      "[timestep: 1] [epoch: 43471] loss: 0.0014085951\n",
      "[timestep: 1] [epoch: 43501] loss: 0.0013729885\n",
      "[timestep: 1] [epoch: 43531] loss: 0.0013836753\n",
      "[timestep: 1] [epoch: 43561] loss: 0.0013997685\n",
      "[timestep: 1] [epoch: 43591] loss: 0.0013625578\n",
      "[timestep: 1] [epoch: 43621] loss: 0.0013750658\n",
      "[timestep: 1] [epoch: 43651] loss: 0.0014221559\n",
      "[timestep: 1] [epoch: 43681] loss: 0.0013875321\n",
      "[timestep: 1] [epoch: 43711] loss: 0.0013804354\n",
      "[timestep: 1] [epoch: 43741] loss: 0.0014065520\n",
      "[timestep: 1] [epoch: 43771] loss: 0.0013885784\n",
      "[timestep: 1] [epoch: 43801] loss: 0.0013733773\n",
      "[timestep: 1] [epoch: 43831] loss: 0.0013734351\n",
      "[timestep: 1] [epoch: 43861] loss: 0.0014155753\n",
      "[timestep: 1] [epoch: 43891] loss: 0.0013796174\n",
      "[timestep: 1] [epoch: 43921] loss: 0.0013841400\n",
      "[timestep: 1] [epoch: 43951] loss: 0.0013849660\n",
      "[timestep: 1] [epoch: 43981] loss: 0.0013590755\n",
      "[timestep: 1] [epoch: 44011] loss: 0.0013620532\n",
      "[timestep: 1] [epoch: 44041] loss: 0.0013454288\n",
      "[timestep: 1] [epoch: 44071] loss: 0.0013621398\n",
      "[timestep: 1] [epoch: 44101] loss: 0.0013703788\n",
      "[timestep: 1] [epoch: 44131] loss: 0.0014014583\n",
      "[timestep: 1] [epoch: 44161] loss: 0.0013757934\n",
      "[timestep: 1] [epoch: 44191] loss: 0.0014076210\n",
      "[timestep: 1] [epoch: 44221] loss: 0.0013778915\n",
      "[timestep: 1] [epoch: 44251] loss: 0.0013479892\n",
      "[timestep: 1] [epoch: 44281] loss: 0.0013866040\n",
      "[timestep: 1] [epoch: 44311] loss: 0.0013564754\n",
      "[timestep: 1] [epoch: 44341] loss: 0.0013656744\n",
      "[timestep: 1] [epoch: 44371] loss: 0.0013715618\n",
      "[timestep: 1] [epoch: 44401] loss: 0.0013792447\n",
      "[timestep: 1] [epoch: 44431] loss: 0.0013564705\n",
      "[timestep: 1] [epoch: 44461] loss: 0.0013610387\n",
      "[timestep: 1] [epoch: 44491] loss: 0.0014021667\n",
      "[timestep: 1] [epoch: 44521] loss: 0.0014390517\n",
      "[timestep: 1] [epoch: 44551] loss: 0.0013595199\n",
      "[timestep: 1] [epoch: 44581] loss: 0.0014063104\n",
      "[timestep: 1] [epoch: 44611] loss: 0.0013698651\n",
      "[timestep: 1] [epoch: 44641] loss: 0.0013673101\n",
      "[timestep: 1] [epoch: 44671] loss: 0.0014057836\n",
      "[timestep: 1] [epoch: 44701] loss: 0.0013717986\n",
      "[timestep: 1] [epoch: 44731] loss: 0.0013983918\n",
      "[timestep: 1] [epoch: 44761] loss: 0.0013672089\n",
      "[timestep: 1] [epoch: 44791] loss: 0.0014020407\n",
      "[timestep: 1] [epoch: 44821] loss: 0.0013996634\n",
      "[timestep: 1] [epoch: 44851] loss: 0.0013920369\n",
      "[timestep: 1] [epoch: 44881] loss: 0.0013914827\n",
      "[timestep: 1] [epoch: 44911] loss: 0.0014084616\n",
      "[timestep: 1] [epoch: 44941] loss: 0.0013829155\n",
      "[timestep: 1] [epoch: 44971] loss: 0.0013998740\n",
      "[timestep: 1] [epoch: 45001] loss: 0.0014131016\n",
      "[timestep: 1] [epoch: 45031] loss: 0.0013942578\n",
      "[timestep: 1] [epoch: 45061] loss: 0.0013799929\n",
      "[timestep: 1] [epoch: 45091] loss: 0.0013699569\n",
      "[timestep: 1] [epoch: 45121] loss: 0.0013831523\n",
      "[timestep: 1] [epoch: 45151] loss: 0.0013778717\n",
      "[timestep: 1] [epoch: 45181] loss: 0.0014073944\n",
      "[timestep: 1] [epoch: 45211] loss: 0.0014011476\n",
      "[timestep: 1] [epoch: 45241] loss: 0.0014030819\n",
      "[timestep: 1] [epoch: 45271] loss: 0.0014133903\n",
      "[timestep: 1] [epoch: 45301] loss: 0.0014160089\n",
      "[timestep: 1] [epoch: 45331] loss: 0.0013988850\n",
      "[timestep: 1] [epoch: 45361] loss: 0.0013443019\n",
      "[timestep: 1] [epoch: 45391] loss: 0.0014012117\n",
      "[timestep: 1] [epoch: 45421] loss: 0.0013716914\n",
      "[timestep: 1] [epoch: 45451] loss: 0.0013645606\n",
      "[timestep: 1] [epoch: 45481] loss: 0.0013837166\n",
      "[timestep: 1] [epoch: 45511] loss: 0.0013902478\n",
      "[timestep: 1] [epoch: 45541] loss: 0.0014062624\n",
      "[timestep: 1] [epoch: 45571] loss: 0.0013601029\n",
      "[timestep: 1] [epoch: 45601] loss: 0.0013818853\n",
      "[timestep: 1] [epoch: 45631] loss: 0.0013918228\n",
      "[timestep: 1] [epoch: 45661] loss: 0.0013644029\n",
      "[timestep: 1] [epoch: 45691] loss: 0.0013953613\n",
      "[timestep: 1] [epoch: 45721] loss: 0.0013655068\n",
      "[timestep: 1] [epoch: 45751] loss: 0.0013881384\n",
      "[timestep: 1] [epoch: 45781] loss: 0.0013681350\n",
      "[timestep: 1] [epoch: 45811] loss: 0.0013653394\n",
      "[timestep: 1] [epoch: 45841] loss: 0.0013586077\n",
      "[timestep: 1] [epoch: 45871] loss: 0.0013883407\n",
      "[timestep: 1] [epoch: 45901] loss: 0.0013625668\n",
      "[timestep: 1] [epoch: 45931] loss: 0.0013414328\n",
      "[timestep: 1] [epoch: 45961] loss: 0.0013641799\n",
      "[timestep: 1] [epoch: 45991] loss: 0.0013821649\n",
      "[timestep: 1] [epoch: 46021] loss: 0.0013772186\n",
      "[timestep: 1] [epoch: 46051] loss: 0.0013747134\n",
      "[timestep: 1] [epoch: 46081] loss: 0.0013573086\n",
      "[timestep: 1] [epoch: 46111] loss: 0.0013613767\n",
      "[timestep: 1] [epoch: 46141] loss: 0.0013553839\n",
      "[timestep: 1] [epoch: 46171] loss: 0.0013867867\n",
      "[timestep: 1] [epoch: 46201] loss: 0.0013633115\n",
      "[timestep: 1] [epoch: 46231] loss: 0.0013845889\n",
      "[timestep: 1] [epoch: 46261] loss: 0.0013598588\n",
      "[timestep: 1] [epoch: 46291] loss: 0.0013520158\n",
      "[timestep: 1] [epoch: 46321] loss: 0.0013897850\n",
      "[timestep: 1] [epoch: 46351] loss: 0.0013892355\n",
      "[timestep: 1] [epoch: 46381] loss: 0.0013656656\n",
      "[timestep: 1] [epoch: 46411] loss: 0.0013569945\n",
      "[timestep: 1] [epoch: 46441] loss: 0.0013545264\n",
      "[timestep: 1] [epoch: 46471] loss: 0.0013578252\n",
      "[timestep: 1] [epoch: 46501] loss: 0.0013684939\n",
      "[timestep: 1] [epoch: 46531] loss: 0.0013699185\n",
      "[timestep: 1] [epoch: 46561] loss: 0.0013642701\n",
      "[timestep: 1] [epoch: 46591] loss: 0.0013756118\n",
      "[timestep: 1] [epoch: 46621] loss: 0.0014038730\n",
      "[timestep: 1] [epoch: 46651] loss: 0.0013997169\n",
      "[timestep: 1] [epoch: 46681] loss: 0.0013811893\n",
      "[timestep: 1] [epoch: 46711] loss: 0.0013891788\n",
      "[timestep: 1] [epoch: 46741] loss: 0.0013673799\n",
      "[timestep: 1] [epoch: 46771] loss: 0.0014059447\n",
      "[timestep: 1] [epoch: 46801] loss: 0.0013664108\n",
      "[timestep: 1] [epoch: 46831] loss: 0.0013633070\n",
      "[timestep: 1] [epoch: 46861] loss: 0.0013642285\n",
      "[timestep: 1] [epoch: 46891] loss: 0.0013447688\n",
      "[timestep: 1] [epoch: 46921] loss: 0.0013483446\n",
      "[timestep: 1] [epoch: 46951] loss: 0.0013690287\n",
      "[timestep: 1] [epoch: 46981] loss: 0.0013609724\n",
      "[timestep: 1] [epoch: 47011] loss: 0.0013651566\n",
      "[timestep: 1] [epoch: 47041] loss: 0.0014139879\n",
      "[timestep: 1] [epoch: 47071] loss: 0.0013834173\n",
      "[timestep: 1] [epoch: 47101] loss: 0.0013617147\n",
      "[timestep: 1] [epoch: 47131] loss: 0.0013400466\n",
      "[timestep: 1] [epoch: 47161] loss: 0.0013458818\n",
      "[timestep: 1] [epoch: 47191] loss: 0.0013710002\n",
      "[timestep: 1] [epoch: 47221] loss: 0.0013556893\n",
      "[timestep: 1] [epoch: 47251] loss: 0.0013697501\n",
      "[timestep: 1] [epoch: 47281] loss: 0.0013734127\n",
      "[timestep: 1] [epoch: 47311] loss: 0.0013688860\n",
      "[timestep: 1] [epoch: 47341] loss: 0.0014257405\n",
      "[timestep: 1] [epoch: 47371] loss: 0.0014056561\n",
      "[timestep: 1] [epoch: 47401] loss: 0.0014132459\n",
      "[timestep: 1] [epoch: 47431] loss: 0.0013681860\n",
      "[timestep: 1] [epoch: 47461] loss: 0.0013617345\n",
      "[timestep: 1] [epoch: 47491] loss: 0.0013763184\n",
      "[timestep: 1] [epoch: 47521] loss: 0.0013778474\n",
      "[timestep: 1] [epoch: 47551] loss: 0.0013507012\n",
      "[timestep: 1] [epoch: 47581] loss: 0.0013844150\n",
      "[timestep: 1] [epoch: 47611] loss: 0.0013899104\n",
      "[timestep: 1] [epoch: 47641] loss: 0.0013599321\n",
      "[timestep: 1] [epoch: 47671] loss: 0.0013857972\n",
      "[timestep: 1] [epoch: 47701] loss: 0.0013955566\n",
      "[timestep: 1] [epoch: 47731] loss: 0.0013640205\n",
      "[timestep: 1] [epoch: 47761] loss: 0.0013995803\n",
      "[timestep: 1] [epoch: 47791] loss: 0.0013924239\n",
      "[timestep: 1] [epoch: 47821] loss: 0.0013754787\n",
      "[timestep: 1] [epoch: 47851] loss: 0.0013782338\n",
      "[timestep: 1] [epoch: 47881] loss: 0.0013834719\n",
      "[timestep: 1] [epoch: 47911] loss: 0.0013672364\n",
      "[timestep: 1] [epoch: 47941] loss: 0.0013612884\n",
      "[timestep: 1] [epoch: 47971] loss: 0.0013702411\n",
      "[timestep: 1] [epoch: 48001] loss: 0.0013735718\n",
      "[timestep: 1] [epoch: 48031] loss: 0.0013515707\n",
      "[timestep: 1] [epoch: 48061] loss: 0.0013586945\n",
      "[timestep: 1] [epoch: 48091] loss: 0.0013319631\n",
      "[timestep: 1] [epoch: 48121] loss: 0.0013671663\n",
      "[timestep: 1] [epoch: 48151] loss: 0.0013625170\n",
      "[timestep: 1] [epoch: 48181] loss: 0.0013770575\n",
      "[timestep: 1] [epoch: 48211] loss: 0.0013612821\n",
      "[timestep: 1] [epoch: 48241] loss: 0.0013750122\n",
      "[timestep: 1] [epoch: 48271] loss: 0.0013694395\n",
      "[timestep: 1] [epoch: 48301] loss: 0.0013732873\n",
      "[timestep: 1] [epoch: 48331] loss: 0.0013627628\n",
      "[timestep: 1] [epoch: 48361] loss: 0.0013982113\n",
      "[timestep: 1] [epoch: 48391] loss: 0.0013821090\n",
      "[timestep: 1] [epoch: 48421] loss: 0.0013409732\n",
      "[timestep: 1] [epoch: 48451] loss: 0.0013737546\n",
      "[timestep: 1] [epoch: 48481] loss: 0.0013810652\n",
      "[timestep: 1] [epoch: 48511] loss: 0.0013872785\n",
      "[timestep: 1] [epoch: 48541] loss: 0.0013810911\n",
      "[timestep: 1] [epoch: 48571] loss: 0.0013704288\n",
      "[timestep: 1] [epoch: 48601] loss: 0.0013897670\n",
      "[timestep: 1] [epoch: 48631] loss: 0.0014045571\n",
      "[timestep: 1] [epoch: 48661] loss: 0.0013724647\n",
      "[timestep: 1] [epoch: 48691] loss: 0.0013591576\n",
      "[timestep: 1] [epoch: 48721] loss: 0.0013944288\n",
      "[timestep: 1] [epoch: 48751] loss: 0.0013736443\n",
      "[timestep: 1] [epoch: 48781] loss: 0.0013896250\n",
      "[timestep: 1] [epoch: 48811] loss: 0.0013644493\n",
      "[timestep: 1] [epoch: 48841] loss: 0.0013712340\n",
      "[timestep: 1] [epoch: 48871] loss: 0.0013666293\n",
      "[timestep: 1] [epoch: 48901] loss: 0.0013716917\n",
      "[timestep: 1] [epoch: 48931] loss: 0.0013957547\n",
      "[timestep: 1] [epoch: 48961] loss: 0.0013658144\n",
      "[timestep: 1] [epoch: 48991] loss: 0.0013469113\n",
      "[timestep: 1] [epoch: 49021] loss: 0.0013642103\n",
      "[timestep: 1] [epoch: 49051] loss: 0.0013719925\n",
      "[timestep: 1] [epoch: 49081] loss: 0.0013731737\n",
      "[timestep: 1] [epoch: 49111] loss: 0.0013671990\n",
      "[timestep: 1] [epoch: 49141] loss: 0.0013640875\n",
      "[timestep: 1] [epoch: 49171] loss: 0.0013926467\n",
      "[timestep: 1] [epoch: 49201] loss: 0.0013723066\n",
      "[timestep: 1] [epoch: 49231] loss: 0.0013778238\n",
      "[timestep: 1] [epoch: 49261] loss: 0.0013624448\n",
      "[timestep: 1] [epoch: 49291] loss: 0.0013856174\n",
      "[timestep: 1] [epoch: 49321] loss: 0.0013740832\n",
      "[timestep: 1] [epoch: 49351] loss: 0.0013871584\n",
      "[timestep: 1] [epoch: 49381] loss: 0.0013726762\n",
      "[timestep: 1] [epoch: 49411] loss: 0.0013644372\n",
      "[timestep: 1] [epoch: 49441] loss: 0.0013702029\n",
      "[timestep: 1] [epoch: 49471] loss: 0.0014045861\n",
      "[timestep: 1] [epoch: 49501] loss: 0.0013923942\n",
      "[timestep: 1] [epoch: 49531] loss: 0.0013958709\n",
      "[timestep: 1] [epoch: 49561] loss: 0.0013772660\n",
      "[timestep: 1] [epoch: 49591] loss: 0.0013640325\n",
      "[timestep: 1] [epoch: 49621] loss: 0.0013753788\n",
      "[timestep: 1] [epoch: 49651] loss: 0.0014002938\n",
      "[timestep: 1] [epoch: 49681] loss: 0.0014137176\n",
      "[timestep: 1] [epoch: 49711] loss: 0.0013700847\n",
      "[timestep: 1] [epoch: 49741] loss: 0.0013642012\n",
      "[timestep: 1] [epoch: 49771] loss: 0.0013637259\n",
      "[timestep: 1] [epoch: 49801] loss: 0.0013925473\n",
      "[timestep: 1] [epoch: 49831] loss: 0.0013682719\n",
      "[timestep: 1] [epoch: 49861] loss: 0.0013749960\n",
      "[timestep: 1] [epoch: 49891] loss: 0.0013656847\n",
      "[timestep: 1] [epoch: 49921] loss: 0.0013797383\n",
      "[timestep: 1] [epoch: 49951] loss: 0.0013839770\n",
      "[timestep: 1] [epoch: 49981] loss: 0.0013852197\n",
      "0.01\n",
      "[timestep: 2] [epoch: 1] loss: 3308.6240234375\n",
      "[timestep: 2] [epoch: 31] loss: 71.9997482300\n",
      "[timestep: 2] [epoch: 61] loss: 15.9386758804\n",
      "[timestep: 2] [epoch: 91] loss: 2.8814277649\n",
      "[timestep: 2] [epoch: 121] loss: 4.5132975578\n",
      "[timestep: 2] [epoch: 151] loss: 1.9537677765\n",
      "[timestep: 2] [epoch: 181] loss: 3.0470366478\n",
      "[timestep: 2] [epoch: 211] loss: 1.3729889393\n",
      "[timestep: 2] [epoch: 241] loss: 1.1528711319\n",
      "[timestep: 2] [epoch: 271] loss: 1.1785025597\n",
      "[timestep: 2] [epoch: 301] loss: 1.6302676201\n",
      "[timestep: 2] [epoch: 331] loss: 1.1040552855\n",
      "[timestep: 2] [epoch: 361] loss: 1.8363234997\n",
      "[timestep: 2] [epoch: 391] loss: 1.0730459690\n",
      "[timestep: 2] [epoch: 421] loss: 1.1293089390\n",
      "[timestep: 2] [epoch: 451] loss: 0.8940274715\n",
      "[timestep: 2] [epoch: 481] loss: 0.8866360784\n",
      "[timestep: 2] [epoch: 511] loss: 0.8013128638\n",
      "[timestep: 2] [epoch: 541] loss: 0.7513817549\n",
      "[timestep: 2] [epoch: 571] loss: 0.6128919125\n",
      "[timestep: 2] [epoch: 601] loss: 0.5518289804\n",
      "[timestep: 2] [epoch: 631] loss: 0.7689855099\n",
      "[timestep: 2] [epoch: 661] loss: 0.6282132864\n",
      "[timestep: 2] [epoch: 691] loss: 0.5688678026\n",
      "[timestep: 2] [epoch: 721] loss: 0.4458040595\n",
      "[timestep: 2] [epoch: 751] loss: 0.4558986723\n",
      "[timestep: 2] [epoch: 781] loss: 0.5097069740\n",
      "[timestep: 2] [epoch: 811] loss: 0.4425286055\n",
      "[timestep: 2] [epoch: 841] loss: 0.5669412613\n",
      "[timestep: 2] [epoch: 871] loss: 0.3756624460\n",
      "[timestep: 2] [epoch: 901] loss: 0.4841147065\n",
      "[timestep: 2] [epoch: 931] loss: 0.3197028935\n",
      "[timestep: 2] [epoch: 961] loss: 0.4954873621\n",
      "[timestep: 2] [epoch: 991] loss: 0.3533689380\n",
      "[timestep: 2] [epoch: 1021] loss: 0.8820827007\n",
      "[timestep: 2] [epoch: 1051] loss: 0.5824650526\n",
      "[timestep: 2] [epoch: 1081] loss: 0.4976705909\n",
      "[timestep: 2] [epoch: 1111] loss: 0.3615306020\n",
      "[timestep: 2] [epoch: 1141] loss: 0.2871249914\n",
      "[timestep: 2] [epoch: 1171] loss: 0.2733525634\n",
      "[timestep: 2] [epoch: 1201] loss: 0.5377519131\n",
      "[timestep: 2] [epoch: 1231] loss: 0.6834631562\n",
      "[timestep: 2] [epoch: 1261] loss: 0.4858304858\n",
      "[timestep: 2] [epoch: 1291] loss: 0.4550139010\n",
      "[timestep: 2] [epoch: 1321] loss: 0.3391892314\n",
      "[timestep: 2] [epoch: 1351] loss: 0.4132969379\n",
      "[timestep: 2] [epoch: 1381] loss: 0.3071013093\n",
      "[timestep: 2] [epoch: 1411] loss: 0.3121093512\n",
      "[timestep: 2] [epoch: 1441] loss: 0.2864888310\n",
      "[timestep: 2] [epoch: 1471] loss: 0.2774175406\n",
      "[timestep: 2] [epoch: 1501] loss: 0.3206010461\n",
      "[timestep: 2] [epoch: 1531] loss: 0.2954874039\n",
      "[timestep: 2] [epoch: 1561] loss: 0.2709141076\n",
      "[timestep: 2] [epoch: 1591] loss: 0.3042653799\n",
      "[timestep: 2] [epoch: 1621] loss: 0.2862900198\n",
      "[timestep: 2] [epoch: 1651] loss: 0.3987473845\n",
      "[timestep: 2] [epoch: 1681] loss: 0.2075711787\n",
      "[timestep: 2] [epoch: 1711] loss: 0.2517374158\n",
      "[timestep: 2] [epoch: 1741] loss: 0.2782478929\n",
      "[timestep: 2] [epoch: 1771] loss: 0.2207419574\n",
      "[timestep: 2] [epoch: 1801] loss: 0.2127186954\n",
      "[timestep: 2] [epoch: 1831] loss: 0.1919197142\n",
      "[timestep: 2] [epoch: 1861] loss: 0.1918350756\n",
      "[timestep: 2] [epoch: 1891] loss: 0.1977411211\n",
      "[timestep: 2] [epoch: 1921] loss: 0.1905326545\n",
      "[timestep: 2] [epoch: 1951] loss: 0.1309415102\n",
      "[timestep: 2] [epoch: 1981] loss: 0.1324934363\n",
      "[timestep: 2] [epoch: 2011] loss: 0.1932253838\n",
      "[timestep: 2] [epoch: 2041] loss: 0.2145280540\n",
      "[timestep: 2] [epoch: 2071] loss: 0.2155847698\n",
      "[timestep: 2] [epoch: 2101] loss: 0.2827914357\n",
      "[timestep: 2] [epoch: 2131] loss: 0.1967793107\n",
      "[timestep: 2] [epoch: 2161] loss: 0.2340946943\n",
      "[timestep: 2] [epoch: 2191] loss: 0.1621798575\n",
      "[timestep: 2] [epoch: 2221] loss: 0.1689955294\n",
      "[timestep: 2] [epoch: 2251] loss: 0.1503804624\n",
      "[timestep: 2] [epoch: 2281] loss: 0.2719271779\n",
      "[timestep: 2] [epoch: 2311] loss: 0.1481553018\n",
      "[timestep: 2] [epoch: 2341] loss: 0.1217667460\n",
      "[timestep: 2] [epoch: 2371] loss: 0.1089433879\n",
      "[timestep: 2] [epoch: 2401] loss: 0.0787760019\n",
      "[timestep: 2] [epoch: 2431] loss: 0.0871030837\n",
      "[timestep: 2] [epoch: 2461] loss: 0.1084730849\n",
      "[timestep: 2] [epoch: 2491] loss: 0.1177665293\n",
      "[timestep: 2] [epoch: 2521] loss: 0.1652730554\n",
      "[timestep: 2] [epoch: 2551] loss: 0.2121181488\n",
      "[timestep: 2] [epoch: 2581] loss: 0.0826280192\n",
      "[timestep: 2] [epoch: 2611] loss: 0.1027913466\n",
      "[timestep: 2] [epoch: 2641] loss: 0.1492597759\n",
      "[timestep: 2] [epoch: 2671] loss: 0.1384634078\n",
      "[timestep: 2] [epoch: 2701] loss: 0.0826490149\n",
      "[timestep: 2] [epoch: 2731] loss: 0.1439994574\n",
      "[timestep: 2] [epoch: 2761] loss: 0.0873542503\n",
      "[timestep: 2] [epoch: 2791] loss: 0.0591621920\n",
      "[timestep: 2] [epoch: 2821] loss: 0.0713380128\n",
      "[timestep: 2] [epoch: 2851] loss: 0.1317509115\n",
      "[timestep: 2] [epoch: 2881] loss: 0.0721971244\n",
      "[timestep: 2] [epoch: 2911] loss: 0.0451457128\n",
      "[timestep: 2] [epoch: 2941] loss: 0.1207154393\n",
      "[timestep: 2] [epoch: 2971] loss: 0.0793695748\n",
      "[timestep: 2] [epoch: 3001] loss: 0.0556108654\n",
      "[timestep: 2] [epoch: 3031] loss: 0.1270147413\n",
      "[timestep: 2] [epoch: 3061] loss: 0.1075356677\n",
      "[timestep: 2] [epoch: 3091] loss: 0.1021999717\n",
      "[timestep: 2] [epoch: 3121] loss: 0.0736946762\n",
      "[timestep: 2] [epoch: 3151] loss: 0.0775347352\n",
      "[timestep: 2] [epoch: 3181] loss: 0.0913816467\n",
      "[timestep: 2] [epoch: 3211] loss: 0.1731890440\n",
      "[timestep: 2] [epoch: 3241] loss: 0.0775553659\n",
      "[timestep: 2] [epoch: 3271] loss: 0.1006354392\n",
      "[timestep: 2] [epoch: 3301] loss: 0.0952103361\n",
      "[timestep: 2] [epoch: 3331] loss: 0.0699537620\n",
      "[timestep: 2] [epoch: 3361] loss: 0.0579972565\n",
      "[timestep: 2] [epoch: 3391] loss: 0.0773018748\n",
      "[timestep: 2] [epoch: 3421] loss: 0.1067263633\n",
      "[timestep: 2] [epoch: 3451] loss: 0.1339144856\n",
      "[timestep: 2] [epoch: 3481] loss: 0.1144319475\n",
      "[timestep: 2] [epoch: 3511] loss: 0.0306666307\n",
      "[timestep: 2] [epoch: 3541] loss: 0.0539227352\n",
      "[timestep: 2] [epoch: 3571] loss: 0.0859951153\n",
      "[timestep: 2] [epoch: 3601] loss: 0.0907362700\n",
      "[timestep: 2] [epoch: 3631] loss: 0.1218260899\n",
      "[timestep: 2] [epoch: 3661] loss: 0.0725124031\n",
      "[timestep: 2] [epoch: 3691] loss: 0.0512052961\n",
      "[timestep: 2] [epoch: 3721] loss: 0.0680416226\n",
      "[timestep: 2] [epoch: 3751] loss: 0.0874128863\n",
      "[timestep: 2] [epoch: 3781] loss: 0.0428795479\n",
      "[timestep: 2] [epoch: 3811] loss: 0.0442550555\n",
      "[timestep: 2] [epoch: 3841] loss: 0.0976234525\n",
      "[timestep: 2] [epoch: 3871] loss: 0.0390373319\n",
      "[timestep: 2] [epoch: 3901] loss: 0.0694218203\n",
      "[timestep: 2] [epoch: 3931] loss: 0.1285498440\n",
      "[timestep: 2] [epoch: 3961] loss: 0.0683994144\n",
      "[timestep: 2] [epoch: 3991] loss: 0.1185162514\n",
      "[timestep: 2] [epoch: 4021] loss: 0.0711992010\n",
      "[timestep: 2] [epoch: 4051] loss: 0.0462446027\n",
      "[timestep: 2] [epoch: 4081] loss: 0.0667766035\n",
      "[timestep: 2] [epoch: 4111] loss: 0.1205627993\n",
      "[timestep: 2] [epoch: 4141] loss: 0.0472537503\n",
      "[timestep: 2] [epoch: 4171] loss: 0.0327699333\n",
      "[timestep: 2] [epoch: 4201] loss: 0.0945726782\n",
      "[timestep: 2] [epoch: 4231] loss: 0.0817642063\n",
      "[timestep: 2] [epoch: 4261] loss: 0.0873911083\n",
      "[timestep: 2] [epoch: 4291] loss: 0.0554373488\n",
      "[timestep: 2] [epoch: 4321] loss: 0.0693843737\n",
      "[timestep: 2] [epoch: 4351] loss: 0.0866810828\n",
      "[timestep: 2] [epoch: 4381] loss: 0.0794483870\n",
      "[timestep: 2] [epoch: 4411] loss: 0.0779724121\n",
      "[timestep: 2] [epoch: 4441] loss: 0.1056789309\n",
      "[timestep: 2] [epoch: 4471] loss: 0.0365254208\n",
      "[timestep: 2] [epoch: 4501] loss: 0.0463382490\n",
      "[timestep: 2] [epoch: 4531] loss: 0.1266524047\n",
      "[timestep: 2] [epoch: 4561] loss: 0.0332682431\n",
      "[timestep: 2] [epoch: 4591] loss: 0.0323182046\n",
      "[timestep: 2] [epoch: 4621] loss: 0.0501858816\n",
      "[timestep: 2] [epoch: 4651] loss: 0.0992573351\n",
      "[timestep: 2] [epoch: 4681] loss: 0.0989811271\n",
      "[timestep: 2] [epoch: 4711] loss: 0.0340241119\n",
      "[timestep: 2] [epoch: 4741] loss: 0.0191897787\n",
      "[timestep: 2] [epoch: 4771] loss: 0.0539031625\n",
      "[timestep: 2] [epoch: 4801] loss: 0.0948634669\n",
      "[timestep: 2] [epoch: 4831] loss: 0.0425543636\n",
      "[timestep: 2] [epoch: 4861] loss: 0.1013513431\n",
      "[timestep: 2] [epoch: 4891] loss: 0.0857347399\n",
      "[timestep: 2] [epoch: 4921] loss: 0.0857757404\n",
      "[timestep: 2] [epoch: 4951] loss: 0.0756422281\n",
      "[timestep: 2] [epoch: 4981] loss: 0.0357849896\n",
      "[timestep: 2] [epoch: 5011] loss: 0.0606367439\n",
      "[timestep: 2] [epoch: 5041] loss: 0.0449904464\n",
      "[timestep: 2] [epoch: 5071] loss: 0.0172558837\n",
      "[timestep: 2] [epoch: 5101] loss: 0.0393023044\n",
      "[timestep: 2] [epoch: 5131] loss: 0.0374024808\n",
      "[timestep: 2] [epoch: 5161] loss: 0.1328260303\n",
      "[timestep: 2] [epoch: 5191] loss: 0.0517221354\n",
      "[timestep: 2] [epoch: 5221] loss: 0.0489802919\n",
      "[timestep: 2] [epoch: 5251] loss: 0.0283457898\n",
      "[timestep: 2] [epoch: 5281] loss: 0.0488664024\n",
      "[timestep: 2] [epoch: 5311] loss: 0.0999785066\n",
      "[timestep: 2] [epoch: 5341] loss: 0.0517796651\n",
      "[timestep: 2] [epoch: 5371] loss: 0.0328574739\n",
      "[timestep: 2] [epoch: 5401] loss: 0.0353474952\n",
      "[timestep: 2] [epoch: 5431] loss: 0.0476759113\n",
      "[timestep: 2] [epoch: 5461] loss: 0.0572720617\n",
      "[timestep: 2] [epoch: 5491] loss: 0.0558487326\n",
      "[timestep: 2] [epoch: 5521] loss: 0.0289723445\n",
      "[timestep: 2] [epoch: 5551] loss: 0.0250730310\n",
      "[timestep: 2] [epoch: 5581] loss: 0.0358086526\n",
      "[timestep: 2] [epoch: 5611] loss: 0.0635733008\n",
      "[timestep: 2] [epoch: 5641] loss: 0.0610890090\n",
      "[timestep: 2] [epoch: 5671] loss: 0.0155583629\n",
      "[timestep: 2] [epoch: 5701] loss: 0.0140433572\n",
      "[timestep: 2] [epoch: 5731] loss: 0.0228638761\n",
      "[timestep: 2] [epoch: 5761] loss: 0.0253682956\n",
      "[timestep: 2] [epoch: 5791] loss: 0.0355226137\n",
      "[timestep: 2] [epoch: 5821] loss: 0.0275216457\n",
      "[timestep: 2] [epoch: 5851] loss: 0.0469679087\n",
      "[timestep: 2] [epoch: 5881] loss: 0.0309062656\n",
      "[timestep: 2] [epoch: 5911] loss: 0.0276032034\n",
      "[timestep: 2] [epoch: 5941] loss: 0.0428129584\n",
      "[timestep: 2] [epoch: 5971] loss: 0.0260540657\n",
      "[timestep: 2] [epoch: 6001] loss: 0.0389720872\n",
      "[timestep: 2] [epoch: 6031] loss: 0.0220260210\n",
      "[timestep: 2] [epoch: 6061] loss: 0.0137155950\n",
      "[timestep: 2] [epoch: 6091] loss: 0.0752022266\n",
      "[timestep: 2] [epoch: 6121] loss: 0.0452262759\n",
      "[timestep: 2] [epoch: 6151] loss: 0.0181098431\n",
      "[timestep: 2] [epoch: 6181] loss: 0.0285059996\n",
      "[timestep: 2] [epoch: 6211] loss: 0.0299150608\n",
      "[timestep: 2] [epoch: 6241] loss: 0.0469608605\n",
      "[timestep: 2] [epoch: 6271] loss: 0.0662952065\n",
      "[timestep: 2] [epoch: 6301] loss: 0.0202818513\n",
      "[timestep: 2] [epoch: 6331] loss: 0.0366231240\n",
      "[timestep: 2] [epoch: 6361] loss: 0.0152913248\n",
      "[timestep: 2] [epoch: 6391] loss: 0.0306569971\n",
      "[timestep: 2] [epoch: 6421] loss: 0.0247566998\n",
      "[timestep: 2] [epoch: 6451] loss: 0.0272193793\n",
      "[timestep: 2] [epoch: 6481] loss: 0.0222716872\n",
      "[timestep: 2] [epoch: 6511] loss: 0.0439013317\n",
      "[timestep: 2] [epoch: 6541] loss: 0.0435381085\n",
      "[timestep: 2] [epoch: 6571] loss: 0.0336343125\n",
      "[timestep: 2] [epoch: 6601] loss: 0.0414917246\n",
      "[timestep: 2] [epoch: 6631] loss: 0.0663216263\n",
      "[timestep: 2] [epoch: 6661] loss: 0.0523199253\n",
      "[timestep: 2] [epoch: 6691] loss: 0.0250827037\n",
      "[timestep: 2] [epoch: 6721] loss: 0.0419563539\n",
      "[timestep: 2] [epoch: 6751] loss: 0.0170956906\n",
      "[timestep: 2] [epoch: 6781] loss: 0.0256278366\n",
      "[timestep: 2] [epoch: 6811] loss: 0.0298822485\n",
      "[timestep: 2] [epoch: 6841] loss: 0.0267341919\n",
      "[timestep: 2] [epoch: 6871] loss: 0.0640450567\n",
      "[timestep: 2] [epoch: 6901] loss: 0.0151711162\n",
      "[timestep: 2] [epoch: 6931] loss: 0.0272983089\n",
      "[timestep: 2] [epoch: 6961] loss: 0.0207127184\n",
      "[timestep: 2] [epoch: 6991] loss: 0.0228897445\n",
      "[timestep: 2] [epoch: 7021] loss: 0.0204121470\n",
      "[timestep: 2] [epoch: 7051] loss: 0.0199330114\n",
      "[timestep: 2] [epoch: 7081] loss: 0.0337381735\n",
      "[timestep: 2] [epoch: 7111] loss: 0.0231135562\n",
      "[timestep: 2] [epoch: 7141] loss: 0.0450230762\n",
      "[timestep: 2] [epoch: 7171] loss: 0.0249127895\n",
      "[timestep: 2] [epoch: 7201] loss: 0.0318715200\n",
      "[timestep: 2] [epoch: 7231] loss: 0.0280352514\n",
      "[timestep: 2] [epoch: 7261] loss: 0.0184619278\n",
      "[timestep: 2] [epoch: 7291] loss: 0.0486526191\n",
      "[timestep: 2] [epoch: 7321] loss: 0.0224505905\n",
      "[timestep: 2] [epoch: 7351] loss: 0.0455965176\n",
      "[timestep: 2] [epoch: 7381] loss: 0.0346435010\n",
      "[timestep: 2] [epoch: 7411] loss: 0.0189023465\n",
      "[timestep: 2] [epoch: 7441] loss: 0.0202126764\n",
      "[timestep: 2] [epoch: 7471] loss: 0.0227288697\n",
      "[timestep: 2] [epoch: 7501] loss: 0.0133857690\n",
      "[timestep: 2] [epoch: 7531] loss: 0.0135648232\n",
      "[timestep: 2] [epoch: 7561] loss: 0.0243106578\n",
      "[timestep: 2] [epoch: 7591] loss: 0.0270553119\n",
      "[timestep: 2] [epoch: 7621] loss: 0.0162641481\n",
      "[timestep: 2] [epoch: 7651] loss: 0.0259647723\n",
      "[timestep: 2] [epoch: 7681] loss: 0.0188936442\n",
      "[timestep: 2] [epoch: 7711] loss: 0.0249187984\n",
      "[timestep: 2] [epoch: 7741] loss: 0.0367183946\n",
      "[timestep: 2] [epoch: 7771] loss: 0.0476489291\n",
      "[timestep: 2] [epoch: 7801] loss: 0.0411497243\n",
      "[timestep: 2] [epoch: 7831] loss: 0.0291051734\n",
      "[timestep: 2] [epoch: 7861] loss: 0.0176659860\n",
      "[timestep: 2] [epoch: 7891] loss: 0.0196285266\n",
      "[timestep: 2] [epoch: 7921] loss: 0.0197745748\n",
      "[timestep: 2] [epoch: 7951] loss: 0.0247589834\n",
      "[timestep: 2] [epoch: 7981] loss: 0.0248337928\n",
      "[timestep: 2] [epoch: 8011] loss: 0.0526397154\n",
      "[timestep: 2] [epoch: 8041] loss: 0.0150219779\n",
      "[timestep: 2] [epoch: 8071] loss: 0.0254695639\n",
      "[timestep: 2] [epoch: 8101] loss: 0.0389870554\n",
      "[timestep: 2] [epoch: 8131] loss: 0.0119677354\n",
      "[timestep: 2] [epoch: 8161] loss: 0.0304819494\n",
      "[timestep: 2] [epoch: 8191] loss: 0.0332040936\n",
      "[timestep: 2] [epoch: 8221] loss: 0.0284522735\n",
      "[timestep: 2] [epoch: 8251] loss: 0.0260864142\n",
      "[timestep: 2] [epoch: 8281] loss: 0.0382007062\n",
      "[timestep: 2] [epoch: 8311] loss: 0.0147347264\n",
      "[timestep: 2] [epoch: 8341] loss: 0.0284903571\n",
      "[timestep: 2] [epoch: 8371] loss: 0.0220434815\n",
      "[timestep: 2] [epoch: 8401] loss: 0.0134755578\n",
      "[timestep: 2] [epoch: 8431] loss: 0.0248014405\n",
      "[timestep: 2] [epoch: 8461] loss: 0.0124111995\n",
      "[timestep: 2] [epoch: 8491] loss: 0.0042639780\n",
      "[timestep: 2] [epoch: 8521] loss: 0.0131021682\n",
      "[timestep: 2] [epoch: 8551] loss: 0.0136520229\n",
      "[timestep: 2] [epoch: 8581] loss: 0.0108208787\n",
      "[timestep: 2] [epoch: 8611] loss: 0.0075371787\n",
      "[timestep: 2] [epoch: 8641] loss: 0.0107962899\n",
      "[timestep: 2] [epoch: 8671] loss: 0.0134502407\n",
      "[timestep: 2] [epoch: 8701] loss: 0.0192047395\n",
      "[timestep: 2] [epoch: 8731] loss: 0.0173194893\n",
      "[timestep: 2] [epoch: 8761] loss: 0.0210427269\n",
      "[timestep: 2] [epoch: 8791] loss: 0.0134156030\n",
      "[timestep: 2] [epoch: 8821] loss: 0.0102877356\n",
      "[timestep: 2] [epoch: 8851] loss: 0.0072205691\n",
      "[timestep: 2] [epoch: 8881] loss: 0.0030655551\n",
      "[timestep: 2] [epoch: 8911] loss: 0.0150840245\n",
      "[timestep: 2] [epoch: 8941] loss: 0.0084245624\n",
      "[timestep: 2] [epoch: 8971] loss: 0.0085523250\n",
      "[timestep: 2] [epoch: 9001] loss: 0.0069704354\n",
      "[timestep: 2] [epoch: 9031] loss: 0.0174205005\n",
      "[timestep: 2] [epoch: 9061] loss: 0.0218326040\n",
      "[timestep: 2] [epoch: 9091] loss: 0.0260755215\n",
      "[timestep: 2] [epoch: 9121] loss: 0.0213906020\n",
      "[timestep: 2] [epoch: 9151] loss: 0.0193467662\n",
      "[timestep: 2] [epoch: 9181] loss: 0.0231976733\n",
      "[timestep: 2] [epoch: 9211] loss: 0.0124760736\n",
      "[timestep: 2] [epoch: 9241] loss: 0.0128902970\n",
      "[timestep: 2] [epoch: 9271] loss: 0.0172894020\n",
      "[timestep: 2] [epoch: 9301] loss: 0.0153639298\n",
      "[timestep: 2] [epoch: 9331] loss: 0.0191714969\n",
      "[timestep: 2] [epoch: 9361] loss: 0.0147717912\n",
      "[timestep: 2] [epoch: 9391] loss: 0.0102173164\n",
      "[timestep: 2] [epoch: 9421] loss: 0.0094060116\n",
      "[timestep: 2] [epoch: 9451] loss: 0.0150221437\n",
      "[timestep: 2] [epoch: 9481] loss: 0.0090188310\n",
      "[timestep: 2] [epoch: 9511] loss: 0.0058876360\n",
      "[timestep: 2] [epoch: 9541] loss: 0.0078212172\n",
      "[timestep: 2] [epoch: 9571] loss: 0.0048441743\n",
      "[timestep: 2] [epoch: 9601] loss: 0.0145037565\n",
      "[timestep: 2] [epoch: 9631] loss: 0.0123296082\n",
      "[timestep: 2] [epoch: 9661] loss: 0.0123573784\n",
      "[timestep: 2] [epoch: 9691] loss: 0.0090848915\n",
      "[timestep: 2] [epoch: 9721] loss: 0.0113796089\n",
      "[timestep: 2] [epoch: 9751] loss: 0.0061227260\n",
      "[timestep: 2] [epoch: 9781] loss: 0.0117740221\n",
      "[timestep: 2] [epoch: 9811] loss: 0.0167256091\n",
      "[timestep: 2] [epoch: 9841] loss: 0.0394438803\n",
      "[timestep: 2] [epoch: 9871] loss: 0.0209488217\n",
      "[timestep: 2] [epoch: 9901] loss: 0.0113845747\n",
      "[timestep: 2] [epoch: 9931] loss: 0.0297943335\n",
      "[timestep: 2] [epoch: 9961] loss: 0.0234596916\n",
      "[timestep: 2] [epoch: 9991] loss: 0.0303635374\n",
      "[timestep: 2] [epoch: 10021] loss: 0.0152609441\n",
      "[timestep: 2] [epoch: 10051] loss: 0.0393183604\n",
      "[timestep: 2] [epoch: 10081] loss: 0.0187034998\n",
      "[timestep: 2] [epoch: 10111] loss: 0.0276843794\n",
      "[timestep: 2] [epoch: 10141] loss: 0.0109871095\n",
      "[timestep: 2] [epoch: 10171] loss: 0.0138834165\n",
      "[timestep: 2] [epoch: 10201] loss: 0.0142942220\n",
      "[timestep: 2] [epoch: 10231] loss: 0.0147270150\n",
      "[timestep: 2] [epoch: 10261] loss: 0.0140558667\n",
      "[timestep: 2] [epoch: 10291] loss: 0.0092922095\n",
      "[timestep: 2] [epoch: 10321] loss: 0.0110998778\n",
      "[timestep: 2] [epoch: 10351] loss: 0.0136678945\n",
      "[timestep: 2] [epoch: 10381] loss: 0.0148333786\n",
      "[timestep: 2] [epoch: 10411] loss: 0.0092749204\n",
      "[timestep: 2] [epoch: 10441] loss: 0.0110207358\n",
      "[timestep: 2] [epoch: 10471] loss: 0.0085000973\n",
      "[timestep: 2] [epoch: 10501] loss: 0.0104267783\n",
      "[timestep: 2] [epoch: 10531] loss: 0.0103120711\n",
      "[timestep: 2] [epoch: 10561] loss: 0.0138826389\n",
      "[timestep: 2] [epoch: 10591] loss: 0.0119063109\n",
      "[timestep: 2] [epoch: 10621] loss: 0.0097541008\n",
      "[timestep: 2] [epoch: 10651] loss: 0.0178446975\n",
      "[timestep: 2] [epoch: 10681] loss: 0.0064784540\n",
      "[timestep: 2] [epoch: 10711] loss: 0.0070610023\n",
      "[timestep: 2] [epoch: 10741] loss: 0.0118687842\n",
      "[timestep: 2] [epoch: 10771] loss: 0.0162810870\n",
      "[timestep: 2] [epoch: 10801] loss: 0.0041017430\n",
      "[timestep: 2] [epoch: 10831] loss: 0.0092552034\n",
      "[timestep: 2] [epoch: 10861] loss: 0.0064922986\n",
      "[timestep: 2] [epoch: 10891] loss: 0.0088218823\n",
      "[timestep: 2] [epoch: 10921] loss: 0.0056580063\n",
      "[timestep: 2] [epoch: 10951] loss: 0.0059014517\n",
      "[timestep: 2] [epoch: 10981] loss: 0.0089637274\n",
      "[timestep: 2] [epoch: 11011] loss: 0.0041504987\n",
      "[timestep: 2] [epoch: 11041] loss: 0.0024591850\n",
      "[timestep: 2] [epoch: 11071] loss: 0.0033952049\n",
      "[timestep: 2] [epoch: 11101] loss: 0.0031813649\n",
      "[timestep: 2] [epoch: 11131] loss: 0.0123744234\n",
      "[timestep: 2] [epoch: 11161] loss: 0.0104842111\n",
      "[timestep: 2] [epoch: 11191] loss: 0.0045199739\n",
      "[timestep: 2] [epoch: 11221] loss: 0.0095895035\n",
      "[timestep: 2] [epoch: 11251] loss: 0.0086431485\n",
      "[timestep: 2] [epoch: 11281] loss: 0.0158461016\n",
      "[timestep: 2] [epoch: 11311] loss: 0.0114271641\n",
      "[timestep: 2] [epoch: 11341] loss: 0.0042051142\n",
      "[timestep: 2] [epoch: 11371] loss: 0.0081170667\n",
      "[timestep: 2] [epoch: 11401] loss: 0.0106861545\n",
      "[timestep: 2] [epoch: 11431] loss: 0.0048044724\n",
      "[timestep: 2] [epoch: 11461] loss: 0.0120555060\n",
      "[timestep: 2] [epoch: 11491] loss: 0.0040295180\n",
      "[timestep: 2] [epoch: 11521] loss: 0.0120335035\n",
      "[timestep: 2] [epoch: 11551] loss: 0.0061640032\n",
      "[timestep: 2] [epoch: 11581] loss: 0.0028430398\n",
      "[timestep: 2] [epoch: 11611] loss: 0.0089938845\n",
      "[timestep: 2] [epoch: 11641] loss: 0.0128787505\n",
      "[timestep: 2] [epoch: 11671] loss: 0.0070396308\n",
      "[timestep: 2] [epoch: 11701] loss: 0.0049803536\n",
      "[timestep: 2] [epoch: 11731] loss: 0.0072002970\n",
      "[timestep: 2] [epoch: 11761] loss: 0.0150715038\n",
      "[timestep: 2] [epoch: 11791] loss: 0.0076854583\n",
      "[timestep: 2] [epoch: 11821] loss: 0.0084492099\n",
      "[timestep: 2] [epoch: 11851] loss: 0.0089097507\n",
      "[timestep: 2] [epoch: 11881] loss: 0.0080177905\n",
      "[timestep: 2] [epoch: 11911] loss: 0.0035364898\n",
      "[timestep: 2] [epoch: 11941] loss: 0.0131107718\n",
      "[timestep: 2] [epoch: 11971] loss: 0.0114841871\n",
      "[timestep: 2] [epoch: 12001] loss: 0.0028150489\n",
      "[timestep: 2] [epoch: 12031] loss: 0.0064622522\n",
      "[timestep: 2] [epoch: 12061] loss: 0.0069902660\n",
      "[timestep: 2] [epoch: 12091] loss: 0.0073161558\n",
      "[timestep: 2] [epoch: 12121] loss: 0.0085953493\n",
      "[timestep: 2] [epoch: 12151] loss: 0.0041205939\n",
      "[timestep: 2] [epoch: 12181] loss: 0.0019839718\n",
      "[timestep: 2] [epoch: 12211] loss: 0.0108955698\n",
      "[timestep: 2] [epoch: 12241] loss: 0.0092747305\n",
      "[timestep: 2] [epoch: 12271] loss: 0.0050409455\n",
      "[timestep: 2] [epoch: 12301] loss: 0.0052882442\n",
      "[timestep: 2] [epoch: 12331] loss: 0.0075931535\n",
      "[timestep: 2] [epoch: 12361] loss: 0.0049385563\n",
      "[timestep: 2] [epoch: 12391] loss: 0.0059177559\n",
      "[timestep: 2] [epoch: 12421] loss: 0.0067968885\n",
      "[timestep: 2] [epoch: 12451] loss: 0.0062859408\n",
      "[timestep: 2] [epoch: 12481] loss: 0.0051970691\n",
      "[timestep: 2] [epoch: 12511] loss: 0.0082289688\n",
      "[timestep: 2] [epoch: 12541] loss: 0.0048791752\n",
      "[timestep: 2] [epoch: 12571] loss: 0.0066016475\n",
      "[timestep: 2] [epoch: 12601] loss: 0.0051555824\n",
      "[timestep: 2] [epoch: 12631] loss: 0.0092381584\n",
      "[timestep: 2] [epoch: 12661] loss: 0.0055173370\n",
      "[timestep: 2] [epoch: 12691] loss: 0.0149490098\n",
      "[timestep: 2] [epoch: 12721] loss: 0.0089080418\n",
      "[timestep: 2] [epoch: 12751] loss: 0.0112759694\n",
      "[timestep: 2] [epoch: 12781] loss: 0.0049312850\n",
      "[timestep: 2] [epoch: 12811] loss: 0.0100169759\n",
      "[timestep: 2] [epoch: 12841] loss: 0.0016361054\n",
      "[timestep: 2] [epoch: 12871] loss: 0.0031618676\n",
      "[timestep: 2] [epoch: 12901] loss: 0.0051828260\n",
      "[timestep: 2] [epoch: 12931] loss: 0.0042569116\n",
      "[timestep: 2] [epoch: 12961] loss: 0.0024354393\n",
      "[timestep: 2] [epoch: 12991] loss: 0.0031683156\n",
      "[timestep: 2] [epoch: 13021] loss: 0.0068147182\n",
      "[timestep: 2] [epoch: 13051] loss: 0.0107220216\n",
      "[timestep: 2] [epoch: 13081] loss: 0.0043070768\n",
      "[timestep: 2] [epoch: 13111] loss: 0.0036391264\n",
      "[timestep: 2] [epoch: 13141] loss: 0.0071909763\n",
      "[timestep: 2] [epoch: 13171] loss: 0.0067502894\n",
      "[timestep: 2] [epoch: 13201] loss: 0.0074385423\n",
      "[timestep: 2] [epoch: 13231] loss: 0.0066609988\n",
      "[timestep: 2] [epoch: 13261] loss: 0.0082971063\n",
      "[timestep: 2] [epoch: 13291] loss: 0.0022214812\n",
      "[timestep: 2] [epoch: 13321] loss: 0.0023128795\n",
      "[timestep: 2] [epoch: 13351] loss: 0.0076822955\n",
      "[timestep: 2] [epoch: 13381] loss: 0.0066812411\n",
      "[timestep: 2] [epoch: 13411] loss: 0.0073388293\n",
      "[timestep: 2] [epoch: 13441] loss: 0.0047735679\n",
      "[timestep: 2] [epoch: 13471] loss: 0.0064761122\n",
      "[timestep: 2] [epoch: 13501] loss: 0.0053378390\n",
      "[timestep: 2] [epoch: 13531] loss: 0.0030054443\n",
      "[timestep: 2] [epoch: 13561] loss: 0.0026215166\n",
      "[timestep: 2] [epoch: 13591] loss: 0.0032072770\n",
      "[timestep: 2] [epoch: 13621] loss: 0.0016610494\n",
      "[timestep: 2] [epoch: 13651] loss: 0.0012574892\n",
      "[timestep: 2] [epoch: 13681] loss: 0.0032554874\n",
      "[timestep: 2] [epoch: 13711] loss: 0.0028711772\n",
      "[timestep: 2] [epoch: 13741] loss: 0.0017511232\n",
      "[timestep: 2] [epoch: 13771] loss: 0.0023152209\n",
      "[timestep: 2] [epoch: 13801] loss: 0.0018291946\n",
      "[timestep: 2] [epoch: 13831] loss: 0.0013554973\n",
      "[timestep: 2] [epoch: 13861] loss: 0.0014395609\n",
      "[timestep: 2] [epoch: 13891] loss: 0.0014399597\n",
      "[timestep: 2] [epoch: 13921] loss: 0.0016114232\n",
      "[timestep: 2] [epoch: 13951] loss: 0.0022692052\n",
      "[timestep: 2] [epoch: 13981] loss: 0.0015039404\n",
      "[timestep: 2] [epoch: 14011] loss: 0.0018797822\n",
      "[timestep: 2] [epoch: 14041] loss: 0.0034370774\n",
      "[timestep: 2] [epoch: 14071] loss: 0.0029726152\n",
      "[timestep: 2] [epoch: 14101] loss: 0.0015396711\n",
      "[timestep: 2] [epoch: 14131] loss: 0.0015339057\n",
      "[timestep: 2] [epoch: 14161] loss: 0.0013719123\n",
      "[timestep: 2] [epoch: 14191] loss: 0.0043830504\n",
      "[timestep: 2] [epoch: 14221] loss: 0.0013312312\n",
      "[timestep: 2] [epoch: 14251] loss: 0.0012153734\n",
      "[timestep: 2] [epoch: 14281] loss: 0.0014949170\n",
      "[timestep: 2] [epoch: 14311] loss: 0.0014063090\n",
      "[timestep: 2] [epoch: 14341] loss: 0.0062751290\n",
      "[timestep: 2] [epoch: 14371] loss: 0.0045415070\n",
      "[timestep: 2] [epoch: 14401] loss: 0.0065462003\n",
      "[timestep: 2] [epoch: 14431] loss: 0.0062433900\n",
      "[timestep: 2] [epoch: 14461] loss: 0.0048047965\n",
      "[timestep: 2] [epoch: 14491] loss: 0.0043680472\n",
      "[timestep: 2] [epoch: 14521] loss: 0.0030258980\n",
      "[timestep: 2] [epoch: 14551] loss: 0.0032780296\n",
      "[timestep: 2] [epoch: 14581] loss: 0.0059004603\n",
      "[timestep: 2] [epoch: 14611] loss: 0.0016819967\n",
      "[timestep: 2] [epoch: 14641] loss: 0.0012344175\n",
      "[timestep: 2] [epoch: 14671] loss: 0.0017319156\n",
      "[timestep: 2] [epoch: 14701] loss: 0.0025673404\n",
      "[timestep: 2] [epoch: 14731] loss: 0.0067202784\n",
      "[timestep: 2] [epoch: 14761] loss: 0.0063711964\n",
      "[timestep: 2] [epoch: 14791] loss: 0.0019636874\n",
      "[timestep: 2] [epoch: 14821] loss: 0.0022501252\n",
      "[timestep: 2] [epoch: 14851] loss: 0.0017771282\n",
      "[timestep: 2] [epoch: 14881] loss: 0.0022409479\n",
      "[timestep: 2] [epoch: 14911] loss: 0.0013294050\n",
      "[timestep: 2] [epoch: 14941] loss: 0.0022396476\n",
      "[timestep: 2] [epoch: 14971] loss: 0.0015698696\n",
      "[timestep: 2] [epoch: 15001] loss: 0.0012783767\n",
      "[timestep: 2] [epoch: 15031] loss: 0.0016014648\n",
      "[timestep: 2] [epoch: 15061] loss: 0.0012234708\n",
      "[timestep: 2] [epoch: 15091] loss: 0.0020128596\n",
      "[timestep: 2] [epoch: 15121] loss: 0.0018074929\n",
      "[timestep: 2] [epoch: 15151] loss: 0.0019781394\n",
      "[timestep: 2] [epoch: 15181] loss: 0.0015240083\n",
      "[timestep: 2] [epoch: 15211] loss: 0.0017625454\n",
      "[timestep: 2] [epoch: 15241] loss: 0.0013060730\n",
      "[timestep: 2] [epoch: 15271] loss: 0.0024161877\n",
      "[timestep: 2] [epoch: 15301] loss: 0.0015416003\n",
      "[timestep: 2] [epoch: 15331] loss: 0.0014513244\n",
      "[timestep: 2] [epoch: 15361] loss: 0.0013776859\n",
      "[timestep: 2] [epoch: 15391] loss: 0.0013100203\n",
      "[timestep: 2] [epoch: 15421] loss: 0.0031081564\n",
      "[timestep: 2] [epoch: 15451] loss: 0.0068979273\n",
      "[timestep: 2] [epoch: 15481] loss: 0.0030161173\n",
      "[timestep: 2] [epoch: 15511] loss: 0.0034781154\n",
      "[timestep: 2] [epoch: 15541] loss: 0.0032426328\n",
      "[timestep: 2] [epoch: 15571] loss: 0.0044611823\n",
      "[timestep: 2] [epoch: 15601] loss: 0.0028401152\n",
      "[timestep: 2] [epoch: 15631] loss: 0.0041622231\n",
      "[timestep: 2] [epoch: 15661] loss: 0.0035785146\n",
      "[timestep: 2] [epoch: 15691] loss: 0.0046022455\n",
      "[timestep: 2] [epoch: 15721] loss: 0.0029769738\n",
      "[timestep: 2] [epoch: 15751] loss: 0.0044936957\n",
      "[timestep: 2] [epoch: 15781] loss: 0.0020948127\n",
      "[timestep: 2] [epoch: 15811] loss: 0.0050226981\n",
      "[timestep: 2] [epoch: 15841] loss: 0.0028359345\n",
      "[timestep: 2] [epoch: 15871] loss: 0.0040529612\n",
      "[timestep: 2] [epoch: 15901] loss: 0.0038856105\n",
      "[timestep: 2] [epoch: 15931] loss: 0.0039033771\n",
      "[timestep: 2] [epoch: 15961] loss: 0.0026683137\n",
      "[timestep: 2] [epoch: 15991] loss: 0.0022215887\n",
      "[timestep: 2] [epoch: 16021] loss: 0.0030490770\n",
      "[timestep: 2] [epoch: 16051] loss: 0.0034998581\n",
      "[timestep: 2] [epoch: 16081] loss: 0.0042985626\n",
      "[timestep: 2] [epoch: 16111] loss: 0.0012660224\n",
      "[timestep: 2] [epoch: 16141] loss: 0.0012501038\n",
      "[timestep: 2] [epoch: 16171] loss: 0.0017591976\n",
      "[timestep: 2] [epoch: 16201] loss: 0.0012856335\n",
      "[timestep: 2] [epoch: 16231] loss: 0.0012192193\n",
      "[timestep: 2] [epoch: 16261] loss: 0.0015440164\n",
      "[timestep: 2] [epoch: 16291] loss: 0.0014292970\n",
      "[timestep: 2] [epoch: 16321] loss: 0.0011201894\n",
      "[timestep: 2] [epoch: 16351] loss: 0.0015979711\n",
      "[timestep: 2] [epoch: 16381] loss: 0.0013203339\n",
      "[timestep: 2] [epoch: 16411] loss: 0.0013192520\n",
      "[timestep: 2] [epoch: 16441] loss: 0.0011006084\n",
      "[timestep: 2] [epoch: 16471] loss: 0.0016510857\n",
      "[timestep: 2] [epoch: 16501] loss: 0.0015248363\n",
      "[timestep: 2] [epoch: 16531] loss: 0.0012815234\n",
      "[timestep: 2] [epoch: 16561] loss: 0.0012036730\n",
      "[timestep: 2] [epoch: 16591] loss: 0.0018421875\n",
      "[timestep: 2] [epoch: 16621] loss: 0.0013608906\n",
      "[timestep: 2] [epoch: 16651] loss: 0.0014150749\n",
      "[timestep: 2] [epoch: 16681] loss: 0.0011799266\n",
      "[timestep: 2] [epoch: 16711] loss: 0.0012051775\n",
      "[timestep: 2] [epoch: 16741] loss: 0.0013191521\n",
      "[timestep: 2] [epoch: 16771] loss: 0.0016510501\n",
      "[timestep: 2] [epoch: 16801] loss: 0.0011244495\n",
      "[timestep: 2] [epoch: 16831] loss: 0.0016871372\n",
      "[timestep: 2] [epoch: 16861] loss: 0.0012779320\n",
      "[timestep: 2] [epoch: 16891] loss: 0.0014145677\n",
      "[timestep: 2] [epoch: 16921] loss: 0.0015242863\n",
      "[timestep: 2] [epoch: 16951] loss: 0.0012613765\n",
      "[timestep: 2] [epoch: 16981] loss: 0.0014898507\n",
      "[timestep: 2] [epoch: 17011] loss: 0.0011503834\n",
      "[timestep: 2] [epoch: 17041] loss: 0.0013534474\n",
      "[timestep: 2] [epoch: 17071] loss: 0.0013538958\n",
      "[timestep: 2] [epoch: 17101] loss: 0.0012259260\n",
      "[timestep: 2] [epoch: 17131] loss: 0.0012644725\n",
      "[timestep: 2] [epoch: 17161] loss: 0.0011872977\n",
      "[timestep: 2] [epoch: 17191] loss: 0.0012715473\n",
      "[timestep: 2] [epoch: 17221] loss: 0.0011787207\n",
      "[timestep: 2] [epoch: 17251] loss: 0.0014061861\n",
      "[timestep: 2] [epoch: 17281] loss: 0.0016075531\n",
      "[timestep: 2] [epoch: 17311] loss: 0.0017279088\n",
      "[timestep: 2] [epoch: 17341] loss: 0.0012434274\n",
      "[timestep: 2] [epoch: 17371] loss: 0.0024926881\n",
      "[timestep: 2] [epoch: 17401] loss: 0.0017377408\n",
      "[timestep: 2] [epoch: 17431] loss: 0.0011227899\n",
      "[timestep: 2] [epoch: 17461] loss: 0.0012690502\n",
      "[timestep: 2] [epoch: 17491] loss: 0.0012064213\n",
      "[timestep: 2] [epoch: 17521] loss: 0.0015282256\n",
      "[timestep: 2] [epoch: 17551] loss: 0.0031028029\n",
      "[timestep: 2] [epoch: 17581] loss: 0.0017547642\n",
      "[timestep: 2] [epoch: 17611] loss: 0.0023007684\n",
      "[timestep: 2] [epoch: 17641] loss: 0.0012151450\n",
      "[timestep: 2] [epoch: 17671] loss: 0.0042735348\n",
      "[timestep: 2] [epoch: 17701] loss: 0.0047561899\n",
      "[timestep: 2] [epoch: 17731] loss: 0.0011845340\n",
      "[timestep: 2] [epoch: 17761] loss: 0.0013243428\n",
      "[timestep: 2] [epoch: 17791] loss: 0.0011221592\n",
      "[timestep: 2] [epoch: 17821] loss: 0.0012741101\n",
      "[timestep: 2] [epoch: 17851] loss: 0.0012991560\n",
      "[timestep: 2] [epoch: 17881] loss: 0.0012132681\n",
      "[timestep: 2] [epoch: 17911] loss: 0.0014310712\n",
      "[timestep: 2] [epoch: 17941] loss: 0.0016000632\n",
      "[timestep: 2] [epoch: 17971] loss: 0.0010963591\n",
      "[timestep: 2] [epoch: 18001] loss: 0.0010693115\n",
      "[timestep: 2] [epoch: 18031] loss: 0.0011105937\n",
      "[timestep: 2] [epoch: 18061] loss: 0.0014106503\n",
      "[timestep: 2] [epoch: 18091] loss: 0.0013177551\n",
      "[timestep: 2] [epoch: 18121] loss: 0.0012719929\n",
      "[timestep: 2] [epoch: 18151] loss: 0.0012407838\n",
      "[timestep: 2] [epoch: 18181] loss: 0.0012932705\n",
      "[timestep: 2] [epoch: 18211] loss: 0.0015780190\n",
      "[timestep: 2] [epoch: 18241] loss: 0.0012333500\n",
      "[timestep: 2] [epoch: 18271] loss: 0.0010864798\n",
      "[timestep: 2] [epoch: 18301] loss: 0.0010616835\n",
      "[timestep: 2] [epoch: 18331] loss: 0.0011599200\n",
      "[timestep: 2] [epoch: 18361] loss: 0.0011036423\n",
      "[timestep: 2] [epoch: 18391] loss: 0.0011212680\n",
      "[timestep: 2] [epoch: 18421] loss: 0.0010755041\n",
      "[timestep: 2] [epoch: 18451] loss: 0.0012869161\n",
      "[timestep: 2] [epoch: 18481] loss: 0.0010901117\n",
      "[timestep: 2] [epoch: 18511] loss: 0.0013082512\n",
      "[timestep: 2] [epoch: 18541] loss: 0.0010950305\n",
      "[timestep: 2] [epoch: 18571] loss: 0.0010985751\n",
      "[timestep: 2] [epoch: 18601] loss: 0.0010863519\n",
      "[timestep: 2] [epoch: 18631] loss: 0.0012521341\n",
      "[timestep: 2] [epoch: 18661] loss: 0.0012454685\n",
      "[timestep: 2] [epoch: 18691] loss: 0.0021869673\n",
      "[timestep: 2] [epoch: 18721] loss: 0.0010644739\n",
      "[timestep: 2] [epoch: 18751] loss: 0.0011278675\n",
      "[timestep: 2] [epoch: 18781] loss: 0.0011392967\n",
      "[timestep: 2] [epoch: 18811] loss: 0.0011428569\n",
      "[timestep: 2] [epoch: 18841] loss: 0.0012300258\n",
      "[timestep: 2] [epoch: 18871] loss: 0.0012185064\n",
      "[timestep: 2] [epoch: 18901] loss: 0.0010445660\n",
      "[timestep: 2] [epoch: 18931] loss: 0.0011080923\n",
      "[timestep: 2] [epoch: 18961] loss: 0.0012891551\n",
      "[timestep: 2] [epoch: 18991] loss: 0.0010920429\n",
      "[timestep: 2] [epoch: 19021] loss: 0.0010980337\n",
      "[timestep: 2] [epoch: 19051] loss: 0.0011708069\n",
      "[timestep: 2] [epoch: 19081] loss: 0.0013473778\n",
      "[timestep: 2] [epoch: 19111] loss: 0.0014797801\n",
      "[timestep: 2] [epoch: 19141] loss: 0.0014326017\n",
      "[timestep: 2] [epoch: 19171] loss: 0.0011149911\n",
      "[timestep: 2] [epoch: 19201] loss: 0.0011100604\n",
      "[timestep: 2] [epoch: 19231] loss: 0.0012356227\n",
      "[timestep: 2] [epoch: 19261] loss: 0.0011753431\n",
      "[timestep: 2] [epoch: 19291] loss: 0.0010826043\n",
      "[timestep: 2] [epoch: 19321] loss: 0.0013329047\n",
      "[timestep: 2] [epoch: 19351] loss: 0.0017406885\n",
      "[timestep: 2] [epoch: 19381] loss: 0.0011134484\n",
      "[timestep: 2] [epoch: 19411] loss: 0.0009416555\n",
      "[timestep: 2] [epoch: 19441] loss: 0.0010426885\n",
      "[timestep: 2] [epoch: 19471] loss: 0.0011726199\n",
      "[timestep: 2] [epoch: 19501] loss: 0.0010814511\n",
      "[timestep: 2] [epoch: 19531] loss: 0.0012839144\n",
      "[timestep: 2] [epoch: 19561] loss: 0.0010762056\n",
      "[timestep: 2] [epoch: 19591] loss: 0.0011859424\n",
      "[timestep: 2] [epoch: 19621] loss: 0.0012154628\n",
      "[timestep: 2] [epoch: 19651] loss: 0.0010501624\n",
      "[timestep: 2] [epoch: 19681] loss: 0.0011505911\n",
      "[timestep: 2] [epoch: 19711] loss: 0.0009935197\n",
      "[timestep: 2] [epoch: 19741] loss: 0.0019853110\n",
      "[timestep: 2] [epoch: 19771] loss: 0.0011700171\n",
      "[timestep: 2] [epoch: 19801] loss: 0.0011885364\n",
      "[timestep: 2] [epoch: 19831] loss: 0.0011441490\n",
      "[timestep: 2] [epoch: 19861] loss: 0.0010719552\n",
      "[timestep: 2] [epoch: 19891] loss: 0.0010894081\n",
      "[timestep: 2] [epoch: 19921] loss: 0.0017293496\n",
      "[timestep: 2] [epoch: 19951] loss: 0.0010123359\n",
      "[timestep: 2] [epoch: 19981] loss: 0.0011599190\n",
      "[timestep: 2] [epoch: 20011] loss: 0.0009889116\n",
      "[timestep: 2] [epoch: 20041] loss: 0.0011873082\n",
      "[timestep: 2] [epoch: 20071] loss: 0.0010619225\n",
      "[timestep: 2] [epoch: 20101] loss: 0.0010365995\n",
      "[timestep: 2] [epoch: 20131] loss: 0.0010147510\n",
      "[timestep: 2] [epoch: 20161] loss: 0.0016098771\n",
      "[timestep: 2] [epoch: 20191] loss: 0.0010116810\n",
      "[timestep: 2] [epoch: 20221] loss: 0.0009954735\n",
      "[timestep: 2] [epoch: 20251] loss: 0.0010190778\n",
      "[timestep: 2] [epoch: 20281] loss: 0.0011197571\n",
      "[timestep: 2] [epoch: 20311] loss: 0.0009922048\n",
      "[timestep: 2] [epoch: 20341] loss: 0.0011141299\n",
      "[timestep: 2] [epoch: 20371] loss: 0.0009642181\n",
      "[timestep: 2] [epoch: 20401] loss: 0.0012990399\n",
      "[timestep: 2] [epoch: 20431] loss: 0.0011301849\n",
      "[timestep: 2] [epoch: 20461] loss: 0.0011162106\n",
      "[timestep: 2] [epoch: 20491] loss: 0.0017841362\n",
      "[timestep: 2] [epoch: 20521] loss: 0.0011522323\n",
      "[timestep: 2] [epoch: 20551] loss: 0.0009816589\n",
      "[timestep: 2] [epoch: 20581] loss: 0.0010899033\n",
      "[timestep: 2] [epoch: 20611] loss: 0.0010095380\n",
      "[timestep: 2] [epoch: 20641] loss: 0.0010615542\n",
      "[timestep: 2] [epoch: 20671] loss: 0.0012164642\n",
      "[timestep: 2] [epoch: 20701] loss: 0.0011155161\n",
      "[timestep: 2] [epoch: 20731] loss: 0.0010025536\n",
      "[timestep: 2] [epoch: 20761] loss: 0.0009663534\n",
      "[timestep: 2] [epoch: 20791] loss: 0.0011467333\n",
      "[timestep: 2] [epoch: 20821] loss: 0.0011629247\n",
      "[timestep: 2] [epoch: 20851] loss: 0.0010980371\n",
      "[timestep: 2] [epoch: 20881] loss: 0.0009515840\n",
      "[timestep: 2] [epoch: 20911] loss: 0.0009739338\n",
      "[timestep: 2] [epoch: 20941] loss: 0.0011543339\n",
      "[timestep: 2] [epoch: 20971] loss: 0.0011560275\n",
      "[timestep: 2] [epoch: 21001] loss: 0.0011178637\n",
      "[timestep: 2] [epoch: 21031] loss: 0.0009185890\n",
      "[timestep: 2] [epoch: 21061] loss: 0.0013569352\n",
      "[timestep: 2] [epoch: 21091] loss: 0.0009590119\n",
      "[timestep: 2] [epoch: 21121] loss: 0.0010579953\n",
      "[timestep: 2] [epoch: 21151] loss: 0.0011322069\n",
      "[timestep: 2] [epoch: 21181] loss: 0.0009062629\n",
      "[timestep: 2] [epoch: 21211] loss: 0.0009688528\n",
      "[timestep: 2] [epoch: 21241] loss: 0.0009988414\n",
      "[timestep: 2] [epoch: 21271] loss: 0.0011612598\n",
      "[timestep: 2] [epoch: 21301] loss: 0.0009685059\n",
      "[timestep: 2] [epoch: 21331] loss: 0.0009897328\n",
      "[timestep: 2] [epoch: 21361] loss: 0.0013191177\n",
      "[timestep: 2] [epoch: 21391] loss: 0.0009444831\n",
      "[timestep: 2] [epoch: 21421] loss: 0.0011067446\n",
      "[timestep: 2] [epoch: 21451] loss: 0.0010745900\n",
      "[timestep: 2] [epoch: 21481] loss: 0.0010936921\n",
      "[timestep: 2] [epoch: 21511] loss: 0.0008988745\n",
      "[timestep: 2] [epoch: 21541] loss: 0.0011265359\n",
      "[timestep: 2] [epoch: 21571] loss: 0.0009101696\n",
      "[timestep: 2] [epoch: 21601] loss: 0.0012190300\n",
      "[timestep: 2] [epoch: 21631] loss: 0.0015612999\n",
      "[timestep: 2] [epoch: 21661] loss: 0.0009660210\n",
      "[timestep: 2] [epoch: 21691] loss: 0.0010165198\n",
      "[timestep: 2] [epoch: 21721] loss: 0.0009487115\n",
      "[timestep: 2] [epoch: 21751] loss: 0.0009744699\n",
      "[timestep: 2] [epoch: 21781] loss: 0.0009343273\n",
      "[timestep: 2] [epoch: 21811] loss: 0.0009123094\n",
      "[timestep: 2] [epoch: 21841] loss: 0.0012520610\n",
      "[timestep: 2] [epoch: 21871] loss: 0.0010116851\n",
      "[timestep: 2] [epoch: 21901] loss: 0.0010268437\n",
      "[timestep: 2] [epoch: 21931] loss: 0.0009083247\n",
      "[timestep: 2] [epoch: 21961] loss: 0.0009230665\n",
      "[timestep: 2] [epoch: 21991] loss: 0.0009710889\n",
      "[timestep: 2] [epoch: 22021] loss: 0.0009684015\n",
      "[timestep: 2] [epoch: 22051] loss: 0.0013771742\n",
      "[timestep: 2] [epoch: 22081] loss: 0.0010253702\n",
      "[timestep: 2] [epoch: 22111] loss: 0.0010415153\n",
      "[timestep: 2] [epoch: 22141] loss: 0.0010109805\n",
      "[timestep: 2] [epoch: 22171] loss: 0.0009810552\n",
      "[timestep: 2] [epoch: 22201] loss: 0.0010379213\n",
      "[timestep: 2] [epoch: 22231] loss: 0.0010165907\n",
      "[timestep: 2] [epoch: 22261] loss: 0.0009846319\n",
      "[timestep: 2] [epoch: 22291] loss: 0.0008897045\n",
      "[timestep: 2] [epoch: 22321] loss: 0.0009308291\n",
      "[timestep: 2] [epoch: 22351] loss: 0.0012885492\n",
      "[timestep: 2] [epoch: 22381] loss: 0.0008912988\n",
      "[timestep: 2] [epoch: 22411] loss: 0.0009232407\n",
      "[timestep: 2] [epoch: 22441] loss: 0.0009114140\n",
      "[timestep: 2] [epoch: 22471] loss: 0.0009631431\n",
      "[timestep: 2] [epoch: 22501] loss: 0.0014422026\n",
      "[timestep: 2] [epoch: 22531] loss: 0.0011549841\n",
      "[timestep: 2] [epoch: 22561] loss: 0.0009003158\n",
      "[timestep: 2] [epoch: 22591] loss: 0.0009448427\n",
      "[timestep: 2] [epoch: 22621] loss: 0.0009164787\n",
      "[timestep: 2] [epoch: 22651] loss: 0.0009451438\n",
      "[timestep: 2] [epoch: 22681] loss: 0.0009863111\n",
      "[timestep: 2] [epoch: 22711] loss: 0.0009008880\n",
      "[timestep: 2] [epoch: 22741] loss: 0.0009900869\n",
      "[timestep: 2] [epoch: 22771] loss: 0.0009138422\n",
      "[timestep: 2] [epoch: 22801] loss: 0.0008984781\n",
      "[timestep: 2] [epoch: 22831] loss: 0.0009487926\n",
      "[timestep: 2] [epoch: 22861] loss: 0.0009814173\n",
      "[timestep: 2] [epoch: 22891] loss: 0.0009424748\n",
      "[timestep: 2] [epoch: 22921] loss: 0.0009496165\n",
      "[timestep: 2] [epoch: 22951] loss: 0.0008988171\n",
      "[timestep: 2] [epoch: 22981] loss: 0.0009275977\n",
      "[timestep: 2] [epoch: 23011] loss: 0.0008768601\n",
      "[timestep: 2] [epoch: 23041] loss: 0.0008857812\n",
      "[timestep: 2] [epoch: 23071] loss: 0.0009664440\n",
      "[timestep: 2] [epoch: 23101] loss: 0.0009070451\n",
      "[timestep: 2] [epoch: 23131] loss: 0.0010770173\n",
      "[timestep: 2] [epoch: 23161] loss: 0.0009402351\n",
      "[timestep: 2] [epoch: 23191] loss: 0.0009777634\n",
      "[timestep: 2] [epoch: 23221] loss: 0.0009366405\n",
      "[timestep: 2] [epoch: 23251] loss: 0.0009254341\n",
      "[timestep: 2] [epoch: 23281] loss: 0.0009315542\n",
      "[timestep: 2] [epoch: 23311] loss: 0.0009435499\n",
      "[timestep: 2] [epoch: 23341] loss: 0.0008402003\n",
      "[timestep: 2] [epoch: 23371] loss: 0.0009120456\n",
      "[timestep: 2] [epoch: 23401] loss: 0.0009246023\n",
      "[timestep: 2] [epoch: 23431] loss: 0.0008811390\n",
      "[timestep: 2] [epoch: 23461] loss: 0.0009208164\n",
      "[timestep: 2] [epoch: 23491] loss: 0.0010446466\n",
      "[timestep: 2] [epoch: 23521] loss: 0.0008551610\n",
      "[timestep: 2] [epoch: 23551] loss: 0.0009706393\n",
      "[timestep: 2] [epoch: 23581] loss: 0.0009255430\n",
      "[timestep: 2] [epoch: 23611] loss: 0.0009035321\n",
      "[timestep: 2] [epoch: 23641] loss: 0.0010246495\n",
      "[timestep: 2] [epoch: 23671] loss: 0.0012599754\n",
      "[timestep: 2] [epoch: 23701] loss: 0.0011301280\n",
      "[timestep: 2] [epoch: 23731] loss: 0.0008624035\n",
      "[timestep: 2] [epoch: 23761] loss: 0.0008821986\n",
      "[timestep: 2] [epoch: 23791] loss: 0.0008735120\n",
      "[timestep: 2] [epoch: 23821] loss: 0.0010358595\n",
      "[timestep: 2] [epoch: 23851] loss: 0.0008512831\n",
      "[timestep: 2] [epoch: 23881] loss: 0.0008834751\n",
      "[timestep: 2] [epoch: 23911] loss: 0.0011117933\n",
      "[timestep: 2] [epoch: 23941] loss: 0.0009954741\n",
      "[timestep: 2] [epoch: 23971] loss: 0.0008560171\n",
      "[timestep: 2] [epoch: 24001] loss: 0.0008742024\n",
      "[timestep: 2] [epoch: 24031] loss: 0.0009418625\n",
      "[timestep: 2] [epoch: 24061] loss: 0.0008438481\n",
      "[timestep: 2] [epoch: 24091] loss: 0.0009424113\n",
      "[timestep: 2] [epoch: 24121] loss: 0.0010471623\n",
      "[timestep: 2] [epoch: 24151] loss: 0.0008694197\n",
      "[timestep: 2] [epoch: 24181] loss: 0.0009060660\n",
      "[timestep: 2] [epoch: 24211] loss: 0.0008988079\n",
      "[timestep: 2] [epoch: 24241] loss: 0.0008641600\n",
      "[timestep: 2] [epoch: 24271] loss: 0.0008780822\n",
      "[timestep: 2] [epoch: 24301] loss: 0.0008879128\n",
      "[timestep: 2] [epoch: 24331] loss: 0.0009118757\n",
      "[timestep: 2] [epoch: 24361] loss: 0.0008456155\n",
      "[timestep: 2] [epoch: 24391] loss: 0.0008696180\n",
      "[timestep: 2] [epoch: 24421] loss: 0.0008777046\n",
      "[timestep: 2] [epoch: 24451] loss: 0.0010006616\n",
      "[timestep: 2] [epoch: 24481] loss: 0.0008095033\n",
      "[timestep: 2] [epoch: 24511] loss: 0.0008869646\n",
      "[timestep: 2] [epoch: 24541] loss: 0.0008534938\n",
      "[timestep: 2] [epoch: 24571] loss: 0.0008479519\n",
      "[timestep: 2] [epoch: 24601] loss: 0.0008676025\n",
      "[timestep: 2] [epoch: 24631] loss: 0.0008489125\n",
      "[timestep: 2] [epoch: 24661] loss: 0.0008372660\n",
      "[timestep: 2] [epoch: 24691] loss: 0.0008485343\n",
      "[timestep: 2] [epoch: 24721] loss: 0.0008445018\n",
      "[timestep: 2] [epoch: 24751] loss: 0.0009209220\n",
      "[timestep: 2] [epoch: 24781] loss: 0.0009883274\n",
      "[timestep: 2] [epoch: 24811] loss: 0.0008866953\n",
      "[timestep: 2] [epoch: 24841] loss: 0.0008700804\n",
      "[timestep: 2] [epoch: 24871] loss: 0.0009701729\n",
      "[timestep: 2] [epoch: 24901] loss: 0.0009222882\n",
      "[timestep: 2] [epoch: 24931] loss: 0.0008383875\n",
      "[timestep: 2] [epoch: 24961] loss: 0.0009449433\n",
      "[timestep: 2] [epoch: 24991] loss: 0.0008926292\n",
      "[timestep: 2] [epoch: 25021] loss: 0.0008567848\n",
      "[timestep: 2] [epoch: 25051] loss: 0.0008956203\n",
      "[timestep: 2] [epoch: 25081] loss: 0.0010158552\n",
      "[timestep: 2] [epoch: 25111] loss: 0.0008496232\n",
      "[timestep: 2] [epoch: 25141] loss: 0.0008808678\n",
      "[timestep: 2] [epoch: 25171] loss: 0.0008659583\n",
      "[timestep: 2] [epoch: 25201] loss: 0.0008093771\n",
      "[timestep: 2] [epoch: 25231] loss: 0.0009087516\n",
      "[timestep: 2] [epoch: 25261] loss: 0.0010377788\n",
      "[timestep: 2] [epoch: 25291] loss: 0.0009574888\n",
      "[timestep: 2] [epoch: 25321] loss: 0.0009256899\n",
      "[timestep: 2] [epoch: 25351] loss: 0.0008872723\n",
      "[timestep: 2] [epoch: 25381] loss: 0.0008838956\n",
      "[timestep: 2] [epoch: 25411] loss: 0.0010979830\n",
      "[timestep: 2] [epoch: 25441] loss: 0.0008715023\n",
      "[timestep: 2] [epoch: 25471] loss: 0.0008633384\n",
      "[timestep: 2] [epoch: 25501] loss: 0.0008807088\n",
      "[timestep: 2] [epoch: 25531] loss: 0.0008591218\n",
      "[timestep: 2] [epoch: 25561] loss: 0.0009463579\n",
      "[timestep: 2] [epoch: 25591] loss: 0.0009457178\n",
      "[timestep: 2] [epoch: 25621] loss: 0.0008940354\n",
      "[timestep: 2] [epoch: 25651] loss: 0.0009319474\n",
      "[timestep: 2] [epoch: 25681] loss: 0.0009300198\n",
      "[timestep: 2] [epoch: 25711] loss: 0.0008630369\n",
      "[timestep: 2] [epoch: 25741] loss: 0.0008513146\n",
      "[timestep: 2] [epoch: 25771] loss: 0.0008617434\n",
      "[timestep: 2] [epoch: 25801] loss: 0.0009027722\n",
      "[timestep: 2] [epoch: 25831] loss: 0.0008559446\n",
      "[timestep: 2] [epoch: 25861] loss: 0.0008789106\n",
      "[timestep: 2] [epoch: 25891] loss: 0.0008318225\n",
      "[timestep: 2] [epoch: 25921] loss: 0.0008460882\n",
      "[timestep: 2] [epoch: 25951] loss: 0.0009310531\n",
      "[timestep: 2] [epoch: 25981] loss: 0.0009107618\n",
      "[timestep: 2] [epoch: 26011] loss: 0.0008780302\n",
      "[timestep: 2] [epoch: 26041] loss: 0.0008318071\n",
      "[timestep: 2] [epoch: 26071] loss: 0.0008857557\n",
      "[timestep: 2] [epoch: 26101] loss: 0.0009971717\n",
      "[timestep: 2] [epoch: 26131] loss: 0.0009881287\n",
      "[timestep: 2] [epoch: 26161] loss: 0.0008138682\n",
      "[timestep: 2] [epoch: 26191] loss: 0.0008448124\n",
      "[timestep: 2] [epoch: 26221] loss: 0.0008703056\n",
      "[timestep: 2] [epoch: 26251] loss: 0.0009742917\n",
      "[timestep: 2] [epoch: 26281] loss: 0.0008296466\n",
      "[timestep: 2] [epoch: 26311] loss: 0.0008579105\n",
      "[timestep: 2] [epoch: 26341] loss: 0.0008809170\n",
      "[timestep: 2] [epoch: 26371] loss: 0.0009926436\n",
      "[timestep: 2] [epoch: 26401] loss: 0.0008708119\n",
      "[timestep: 2] [epoch: 26431] loss: 0.0009972192\n",
      "[timestep: 2] [epoch: 26461] loss: 0.0008618260\n",
      "[timestep: 2] [epoch: 26491] loss: 0.0008946690\n",
      "[timestep: 2] [epoch: 26521] loss: 0.0008292734\n",
      "[timestep: 2] [epoch: 26551] loss: 0.0008232564\n",
      "[timestep: 2] [epoch: 26581] loss: 0.0008814650\n",
      "[timestep: 2] [epoch: 26611] loss: 0.0008240258\n",
      "[timestep: 2] [epoch: 26641] loss: 0.0008348812\n",
      "[timestep: 2] [epoch: 26671] loss: 0.0008355325\n",
      "[timestep: 2] [epoch: 26701] loss: 0.0008681555\n",
      "[timestep: 2] [epoch: 26731] loss: 0.0009208361\n",
      "[timestep: 2] [epoch: 26761] loss: 0.0008098928\n",
      "[timestep: 2] [epoch: 26791] loss: 0.0008204791\n",
      "[timestep: 2] [epoch: 26821] loss: 0.0008358179\n",
      "[timestep: 2] [epoch: 26851] loss: 0.0008462360\n",
      "[timestep: 2] [epoch: 26881] loss: 0.0008787826\n",
      "[timestep: 2] [epoch: 26911] loss: 0.0008533605\n",
      "[timestep: 2] [epoch: 26941] loss: 0.0008185557\n",
      "[timestep: 2] [epoch: 26971] loss: 0.0008321438\n",
      "[timestep: 2] [epoch: 27001] loss: 0.0008220925\n",
      "[timestep: 2] [epoch: 27031] loss: 0.0008130773\n",
      "[timestep: 2] [epoch: 27061] loss: 0.0008136326\n",
      "[timestep: 2] [epoch: 27091] loss: 0.0008788301\n",
      "[timestep: 2] [epoch: 27121] loss: 0.0008366714\n",
      "[timestep: 2] [epoch: 27151] loss: 0.0008268305\n",
      "[timestep: 2] [epoch: 27181] loss: 0.0008153771\n",
      "[timestep: 2] [epoch: 27211] loss: 0.0007882142\n",
      "[timestep: 2] [epoch: 27241] loss: 0.0009143580\n",
      "[timestep: 2] [epoch: 27271] loss: 0.0008608311\n",
      "[timestep: 2] [epoch: 27301] loss: 0.0008408704\n",
      "[timestep: 2] [epoch: 27331] loss: 0.0008425908\n",
      "[timestep: 2] [epoch: 27361] loss: 0.0008376399\n",
      "[timestep: 2] [epoch: 27391] loss: 0.0008140091\n",
      "[timestep: 2] [epoch: 27421] loss: 0.0008661045\n",
      "[timestep: 2] [epoch: 27451] loss: 0.0008294156\n",
      "[timestep: 2] [epoch: 27481] loss: 0.0008356186\n",
      "[timestep: 2] [epoch: 27511] loss: 0.0008348291\n",
      "[timestep: 2] [epoch: 27541] loss: 0.0008045505\n",
      "[timestep: 2] [epoch: 27571] loss: 0.0008672697\n",
      "[timestep: 2] [epoch: 27601] loss: 0.0008296317\n",
      "[timestep: 2] [epoch: 27631] loss: 0.0008228431\n",
      "[timestep: 2] [epoch: 27661] loss: 0.0008402959\n",
      "[timestep: 2] [epoch: 27691] loss: 0.0008749514\n",
      "[timestep: 2] [epoch: 27721] loss: 0.0007983354\n",
      "[timestep: 2] [epoch: 27751] loss: 0.0008075295\n",
      "[timestep: 2] [epoch: 27781] loss: 0.0008394615\n",
      "[timestep: 2] [epoch: 27811] loss: 0.0008745127\n",
      "[timestep: 2] [epoch: 27841] loss: 0.0008241090\n",
      "[timestep: 2] [epoch: 27871] loss: 0.0008521742\n",
      "[timestep: 2] [epoch: 27901] loss: 0.0008665611\n",
      "[timestep: 2] [epoch: 27931] loss: 0.0008676068\n",
      "[timestep: 2] [epoch: 27961] loss: 0.0008003681\n",
      "[timestep: 2] [epoch: 27991] loss: 0.0008367908\n",
      "[timestep: 2] [epoch: 28021] loss: 0.0008423697\n",
      "[timestep: 2] [epoch: 28051] loss: 0.0008350636\n",
      "[timestep: 2] [epoch: 28081] loss: 0.0008266774\n",
      "[timestep: 2] [epoch: 28111] loss: 0.0008019129\n",
      "[timestep: 2] [epoch: 28141] loss: 0.0008264642\n",
      "[timestep: 2] [epoch: 28171] loss: 0.0008343471\n",
      "[timestep: 2] [epoch: 28201] loss: 0.0008006133\n",
      "[timestep: 2] [epoch: 28231] loss: 0.0008616153\n",
      "[timestep: 2] [epoch: 28261] loss: 0.0008440031\n",
      "[timestep: 2] [epoch: 28291] loss: 0.0007959408\n",
      "[timestep: 2] [epoch: 28321] loss: 0.0008254976\n",
      "[timestep: 2] [epoch: 28351] loss: 0.0008091721\n",
      "[timestep: 2] [epoch: 28381] loss: 0.0008046927\n",
      "[timestep: 2] [epoch: 28411] loss: 0.0008267420\n",
      "[timestep: 2] [epoch: 28441] loss: 0.0008028208\n",
      "[timestep: 2] [epoch: 28471] loss: 0.0007986994\n",
      "[timestep: 2] [epoch: 28501] loss: 0.0008017856\n",
      "[timestep: 2] [epoch: 28531] loss: 0.0008218396\n",
      "[timestep: 2] [epoch: 28561] loss: 0.0008133927\n",
      "[timestep: 2] [epoch: 28591] loss: 0.0008381761\n",
      "[timestep: 2] [epoch: 28621] loss: 0.0008112979\n",
      "[timestep: 2] [epoch: 28651] loss: 0.0008043681\n",
      "[timestep: 2] [epoch: 28681] loss: 0.0008224378\n",
      "[timestep: 2] [epoch: 28711] loss: 0.0008077918\n",
      "[timestep: 2] [epoch: 28741] loss: 0.0008093101\n",
      "[timestep: 2] [epoch: 28771] loss: 0.0008015565\n",
      "[timestep: 2] [epoch: 28801] loss: 0.0008100320\n",
      "[timestep: 2] [epoch: 28831] loss: 0.0008128436\n",
      "[timestep: 2] [epoch: 28861] loss: 0.0008013679\n",
      "[timestep: 2] [epoch: 28891] loss: 0.0008010798\n",
      "[timestep: 2] [epoch: 28921] loss: 0.0007923659\n",
      "[timestep: 2] [epoch: 28951] loss: 0.0008084378\n",
      "[timestep: 2] [epoch: 28981] loss: 0.0008166697\n",
      "[timestep: 2] [epoch: 29011] loss: 0.0007908347\n",
      "[timestep: 2] [epoch: 29041] loss: 0.0008193419\n",
      "[timestep: 2] [epoch: 29071] loss: 0.0008228262\n",
      "[timestep: 2] [epoch: 29101] loss: 0.0008048815\n",
      "[timestep: 2] [epoch: 29131] loss: 0.0008173198\n",
      "[timestep: 2] [epoch: 29161] loss: 0.0008482033\n",
      "[timestep: 2] [epoch: 29191] loss: 0.0008032620\n",
      "[timestep: 2] [epoch: 29221] loss: 0.0007790183\n",
      "[timestep: 2] [epoch: 29251] loss: 0.0008424364\n",
      "[timestep: 2] [epoch: 29281] loss: 0.0008244435\n",
      "[timestep: 2] [epoch: 29311] loss: 0.0007818699\n",
      "[timestep: 2] [epoch: 29341] loss: 0.0007980432\n",
      "[timestep: 2] [epoch: 29371] loss: 0.0007830132\n",
      "[timestep: 2] [epoch: 29401] loss: 0.0008164236\n",
      "[timestep: 2] [epoch: 29431] loss: 0.0007999423\n",
      "[timestep: 2] [epoch: 29461] loss: 0.0007759023\n",
      "[timestep: 2] [epoch: 29491] loss: 0.0007967559\n",
      "[timestep: 2] [epoch: 29521] loss: 0.0007581791\n",
      "[timestep: 2] [epoch: 29551] loss: 0.0007959610\n",
      "[timestep: 2] [epoch: 29581] loss: 0.0008365005\n",
      "[timestep: 2] [epoch: 29611] loss: 0.0008057439\n",
      "[timestep: 2] [epoch: 29641] loss: 0.0008098613\n",
      "[timestep: 2] [epoch: 29671] loss: 0.0007836563\n",
      "[timestep: 2] [epoch: 29701] loss: 0.0007901554\n",
      "[timestep: 2] [epoch: 29731] loss: 0.0008297387\n",
      "[timestep: 2] [epoch: 29761] loss: 0.0007782002\n",
      "[timestep: 2] [epoch: 29791] loss: 0.0007930588\n",
      "[timestep: 2] [epoch: 29821] loss: 0.0007923947\n",
      "[timestep: 2] [epoch: 29851] loss: 0.0007811786\n",
      "[timestep: 2] [epoch: 29881] loss: 0.0008249384\n",
      "[timestep: 2] [epoch: 29911] loss: 0.0008067992\n",
      "[timestep: 2] [epoch: 29941] loss: 0.0007871774\n",
      "[timestep: 2] [epoch: 29971] loss: 0.0007764597\n",
      "[timestep: 2] [epoch: 30001] loss: 0.0007748465\n",
      "[timestep: 2] [epoch: 30031] loss: 0.0008004211\n",
      "[timestep: 2] [epoch: 30061] loss: 0.0009029495\n",
      "[timestep: 2] [epoch: 30091] loss: 0.0008469303\n",
      "[timestep: 2] [epoch: 30121] loss: 0.0008314425\n",
      "[timestep: 2] [epoch: 30151] loss: 0.0008002904\n",
      "[timestep: 2] [epoch: 30181] loss: 0.0007872379\n",
      "[timestep: 2] [epoch: 30211] loss: 0.0008110749\n",
      "[timestep: 2] [epoch: 30241] loss: 0.0008210726\n",
      "[timestep: 2] [epoch: 30271] loss: 0.0007669410\n",
      "[timestep: 2] [epoch: 30301] loss: 0.0008080882\n",
      "[timestep: 2] [epoch: 30331] loss: 0.0007926309\n",
      "[timestep: 2] [epoch: 30361] loss: 0.0008336711\n",
      "[timestep: 2] [epoch: 30391] loss: 0.0008227387\n",
      "[timestep: 2] [epoch: 30421] loss: 0.0007937946\n",
      "[timestep: 2] [epoch: 30451] loss: 0.0008107310\n",
      "[timestep: 2] [epoch: 30481] loss: 0.0008450569\n",
      "[timestep: 2] [epoch: 30511] loss: 0.0008338343\n",
      "[timestep: 2] [epoch: 30541] loss: 0.0008114810\n",
      "[timestep: 2] [epoch: 30571] loss: 0.0007949178\n",
      "[timestep: 2] [epoch: 30601] loss: 0.0007617625\n",
      "[timestep: 2] [epoch: 30631] loss: 0.0007726254\n",
      "[timestep: 2] [epoch: 30661] loss: 0.0007740674\n",
      "[timestep: 2] [epoch: 30691] loss: 0.0007818079\n",
      "[timestep: 2] [epoch: 30721] loss: 0.0007563428\n",
      "[timestep: 2] [epoch: 30751] loss: 0.0007481510\n",
      "[timestep: 2] [epoch: 30781] loss: 0.0008123448\n",
      "[timestep: 2] [epoch: 30811] loss: 0.0007665203\n",
      "[timestep: 2] [epoch: 30841] loss: 0.0008535992\n",
      "[timestep: 2] [epoch: 30871] loss: 0.0008344464\n",
      "[timestep: 2] [epoch: 30901] loss: 0.0007993956\n",
      "[timestep: 2] [epoch: 30931] loss: 0.0008108600\n",
      "[timestep: 2] [epoch: 30961] loss: 0.0007954213\n",
      "[timestep: 2] [epoch: 30991] loss: 0.0007892474\n",
      "[timestep: 2] [epoch: 31021] loss: 0.0007878019\n",
      "[timestep: 2] [epoch: 31051] loss: 0.0007750452\n",
      "[timestep: 2] [epoch: 31081] loss: 0.0007760092\n",
      "[timestep: 2] [epoch: 31111] loss: 0.0007712734\n",
      "[timestep: 2] [epoch: 31141] loss: 0.0008044405\n",
      "[timestep: 2] [epoch: 31171] loss: 0.0008076167\n",
      "[timestep: 2] [epoch: 31201] loss: 0.0008075708\n",
      "[timestep: 2] [epoch: 31231] loss: 0.0007758080\n",
      "[timestep: 2] [epoch: 31261] loss: 0.0007522943\n",
      "[timestep: 2] [epoch: 31291] loss: 0.0007843063\n",
      "[timestep: 2] [epoch: 31321] loss: 0.0007780286\n",
      "[timestep: 2] [epoch: 31351] loss: 0.0007790131\n",
      "[timestep: 2] [epoch: 31381] loss: 0.0007903227\n",
      "[timestep: 2] [epoch: 31411] loss: 0.0007525430\n",
      "[timestep: 2] [epoch: 31441] loss: 0.0007638423\n",
      "[timestep: 2] [epoch: 31471] loss: 0.0007579166\n",
      "[timestep: 2] [epoch: 31501] loss: 0.0007743023\n",
      "[timestep: 2] [epoch: 31531] loss: 0.0007673511\n",
      "[timestep: 2] [epoch: 31561] loss: 0.0007963766\n",
      "[timestep: 2] [epoch: 31591] loss: 0.0007902657\n",
      "[timestep: 2] [epoch: 31621] loss: 0.0008094928\n",
      "[timestep: 2] [epoch: 31651] loss: 0.0007916542\n",
      "[timestep: 2] [epoch: 31681] loss: 0.0008105353\n",
      "[timestep: 2] [epoch: 31711] loss: 0.0007704135\n",
      "[timestep: 2] [epoch: 31741] loss: 0.0007753308\n",
      "[timestep: 2] [epoch: 31771] loss: 0.0007664378\n",
      "[timestep: 2] [epoch: 31801] loss: 0.0008132264\n",
      "[timestep: 2] [epoch: 31831] loss: 0.0008689029\n",
      "[timestep: 2] [epoch: 31861] loss: 0.0007963276\n",
      "[timestep: 2] [epoch: 31891] loss: 0.0007893882\n",
      "[timestep: 2] [epoch: 31921] loss: 0.0007518929\n",
      "[timestep: 2] [epoch: 31951] loss: 0.0008034750\n",
      "[timestep: 2] [epoch: 31981] loss: 0.0007799150\n",
      "[timestep: 2] [epoch: 32011] loss: 0.0007749455\n",
      "[timestep: 2] [epoch: 32041] loss: 0.0007477228\n",
      "[timestep: 2] [epoch: 32071] loss: 0.0007586580\n",
      "[timestep: 2] [epoch: 32101] loss: 0.0007685630\n",
      "[timestep: 2] [epoch: 32131] loss: 0.0007713208\n",
      "[timestep: 2] [epoch: 32161] loss: 0.0007695298\n",
      "[timestep: 2] [epoch: 32191] loss: 0.0007773694\n",
      "[timestep: 2] [epoch: 32221] loss: 0.0007888421\n",
      "[timestep: 2] [epoch: 32251] loss: 0.0007606183\n",
      "[timestep: 2] [epoch: 32281] loss: 0.0007703797\n",
      "[timestep: 2] [epoch: 32311] loss: 0.0007613788\n",
      "[timestep: 2] [epoch: 32341] loss: 0.0007639698\n",
      "[timestep: 2] [epoch: 32371] loss: 0.0007567386\n",
      "[timestep: 2] [epoch: 32401] loss: 0.0007499447\n",
      "[timestep: 2] [epoch: 32431] loss: 0.0007734516\n",
      "[timestep: 2] [epoch: 32461] loss: 0.0007766522\n",
      "[timestep: 2] [epoch: 32491] loss: 0.0007712132\n",
      "[timestep: 2] [epoch: 32521] loss: 0.0007420932\n",
      "[timestep: 2] [epoch: 32551] loss: 0.0007675877\n",
      "[timestep: 2] [epoch: 32581] loss: 0.0008120600\n",
      "[timestep: 2] [epoch: 32611] loss: 0.0007871169\n",
      "[timestep: 2] [epoch: 32641] loss: 0.0008085447\n",
      "[timestep: 2] [epoch: 32671] loss: 0.0007670892\n",
      "[timestep: 2] [epoch: 32701] loss: 0.0007682149\n",
      "[timestep: 2] [epoch: 32731] loss: 0.0008010133\n",
      "[timestep: 2] [epoch: 32761] loss: 0.0008473338\n",
      "[timestep: 2] [epoch: 32791] loss: 0.0007522673\n",
      "[timestep: 2] [epoch: 32821] loss: 0.0007639989\n",
      "[timestep: 2] [epoch: 32851] loss: 0.0007701986\n",
      "[timestep: 2] [epoch: 32881] loss: 0.0007881569\n",
      "[timestep: 2] [epoch: 32911] loss: 0.0007497653\n",
      "[timestep: 2] [epoch: 32941] loss: 0.0007726087\n",
      "[timestep: 2] [epoch: 32971] loss: 0.0007920568\n",
      "[timestep: 2] [epoch: 33001] loss: 0.0007705889\n",
      "[timestep: 2] [epoch: 33031] loss: 0.0007853222\n",
      "[timestep: 2] [epoch: 33061] loss: 0.0007661479\n",
      "[timestep: 2] [epoch: 33091] loss: 0.0008199322\n",
      "[timestep: 2] [epoch: 33121] loss: 0.0007743117\n",
      "[timestep: 2] [epoch: 33151] loss: 0.0007973090\n",
      "[timestep: 2] [epoch: 33181] loss: 0.0007686095\n",
      "[timestep: 2] [epoch: 33211] loss: 0.0007482357\n",
      "[timestep: 2] [epoch: 33241] loss: 0.0007331518\n",
      "[timestep: 2] [epoch: 33271] loss: 0.0007344179\n",
      "[timestep: 2] [epoch: 33301] loss: 0.0007963607\n",
      "[timestep: 2] [epoch: 33331] loss: 0.0007479957\n",
      "[timestep: 2] [epoch: 33361] loss: 0.0007506490\n",
      "[timestep: 2] [epoch: 33391] loss: 0.0007743962\n",
      "[timestep: 2] [epoch: 33421] loss: 0.0007454914\n",
      "[timestep: 2] [epoch: 33451] loss: 0.0007374182\n",
      "[timestep: 2] [epoch: 33481] loss: 0.0007755081\n",
      "[timestep: 2] [epoch: 33511] loss: 0.0007665457\n",
      "[timestep: 2] [epoch: 33541] loss: 0.0007823998\n",
      "[timestep: 2] [epoch: 33571] loss: 0.0007544156\n",
      "[timestep: 2] [epoch: 33601] loss: 0.0007416063\n",
      "[timestep: 2] [epoch: 33631] loss: 0.0007741398\n",
      "[timestep: 2] [epoch: 33661] loss: 0.0007613585\n",
      "[timestep: 2] [epoch: 33691] loss: 0.0007902950\n",
      "[timestep: 2] [epoch: 33721] loss: 0.0007654318\n",
      "[timestep: 2] [epoch: 33751] loss: 0.0007543946\n",
      "[timestep: 2] [epoch: 33781] loss: 0.0007555468\n",
      "[timestep: 2] [epoch: 33811] loss: 0.0007462518\n",
      "[timestep: 2] [epoch: 33841] loss: 0.0007542215\n",
      "[timestep: 2] [epoch: 33871] loss: 0.0007621668\n",
      "[timestep: 2] [epoch: 33901] loss: 0.0007481762\n",
      "[timestep: 2] [epoch: 33931] loss: 0.0007624010\n",
      "[timestep: 2] [epoch: 33961] loss: 0.0007651756\n",
      "[timestep: 2] [epoch: 33991] loss: 0.0007657654\n",
      "[timestep: 2] [epoch: 34021] loss: 0.0007801190\n",
      "[timestep: 2] [epoch: 34051] loss: 0.0008071312\n",
      "[timestep: 2] [epoch: 34081] loss: 0.0007964701\n",
      "[timestep: 2] [epoch: 34111] loss: 0.0008029452\n",
      "[timestep: 2] [epoch: 34141] loss: 0.0007662234\n",
      "[timestep: 2] [epoch: 34171] loss: 0.0007444260\n",
      "[timestep: 2] [epoch: 34201] loss: 0.0007574582\n",
      "[timestep: 2] [epoch: 34231] loss: 0.0007687476\n",
      "[timestep: 2] [epoch: 34261] loss: 0.0007706261\n",
      "[timestep: 2] [epoch: 34291] loss: 0.0007437730\n",
      "[timestep: 2] [epoch: 34321] loss: 0.0007369859\n",
      "[timestep: 2] [epoch: 34351] loss: 0.0007597642\n",
      "[timestep: 2] [epoch: 34381] loss: 0.0007538764\n",
      "[timestep: 2] [epoch: 34411] loss: 0.0007428851\n",
      "[timestep: 2] [epoch: 34441] loss: 0.0007332176\n",
      "[timestep: 2] [epoch: 34471] loss: 0.0007483056\n",
      "[timestep: 2] [epoch: 34501] loss: 0.0007668256\n",
      "[timestep: 2] [epoch: 34531] loss: 0.0007432241\n",
      "[timestep: 2] [epoch: 34561] loss: 0.0007634055\n",
      "[timestep: 2] [epoch: 34591] loss: 0.0007449053\n",
      "[timestep: 2] [epoch: 34621] loss: 0.0007634312\n",
      "[timestep: 2] [epoch: 34651] loss: 0.0007562919\n",
      "[timestep: 2] [epoch: 34681] loss: 0.0007436317\n",
      "[timestep: 2] [epoch: 34711] loss: 0.0007321463\n",
      "[timestep: 2] [epoch: 34741] loss: 0.0007549302\n",
      "[timestep: 2] [epoch: 34771] loss: 0.0007417288\n",
      "[timestep: 2] [epoch: 34801] loss: 0.0007652148\n",
      "[timestep: 2] [epoch: 34831] loss: 0.0007304979\n",
      "[timestep: 2] [epoch: 34861] loss: 0.0007638152\n",
      "[timestep: 2] [epoch: 34891] loss: 0.0007598310\n",
      "[timestep: 2] [epoch: 34921] loss: 0.0007683500\n",
      "[timestep: 2] [epoch: 34951] loss: 0.0007403423\n",
      "[timestep: 2] [epoch: 34981] loss: 0.0007828685\n",
      "[timestep: 2] [epoch: 35011] loss: 0.0007972141\n",
      "[timestep: 2] [epoch: 35041] loss: 0.0007742930\n",
      "[timestep: 2] [epoch: 35071] loss: 0.0007929581\n",
      "[timestep: 2] [epoch: 35101] loss: 0.0007753006\n",
      "[timestep: 2] [epoch: 35131] loss: 0.0007452304\n",
      "[timestep: 2] [epoch: 35161] loss: 0.0007619973\n",
      "[timestep: 2] [epoch: 35191] loss: 0.0007453226\n",
      "[timestep: 2] [epoch: 35221] loss: 0.0007476934\n",
      "[timestep: 2] [epoch: 35251] loss: 0.0007618877\n",
      "[timestep: 2] [epoch: 35281] loss: 0.0007654934\n",
      "[timestep: 2] [epoch: 35311] loss: 0.0007396240\n",
      "[timestep: 2] [epoch: 35341] loss: 0.0007757169\n",
      "[timestep: 2] [epoch: 35371] loss: 0.0007630949\n",
      "[timestep: 2] [epoch: 35401] loss: 0.0007471539\n",
      "[timestep: 2] [epoch: 35431] loss: 0.0007595633\n",
      "[timestep: 2] [epoch: 35461] loss: 0.0007303369\n",
      "[timestep: 2] [epoch: 35491] loss: 0.0007508629\n",
      "[timestep: 2] [epoch: 35521] loss: 0.0007543580\n",
      "[timestep: 2] [epoch: 35551] loss: 0.0007470018\n",
      "[timestep: 2] [epoch: 35581] loss: 0.0007439730\n",
      "[timestep: 2] [epoch: 35611] loss: 0.0007381099\n",
      "[timestep: 2] [epoch: 35641] loss: 0.0007376368\n",
      "[timestep: 2] [epoch: 35671] loss: 0.0007591650\n",
      "[timestep: 2] [epoch: 35701] loss: 0.0007546894\n",
      "[timestep: 2] [epoch: 35731] loss: 0.0007412446\n",
      "[timestep: 2] [epoch: 35761] loss: 0.0007495810\n",
      "[timestep: 2] [epoch: 35791] loss: 0.0007556134\n",
      "[timestep: 2] [epoch: 35821] loss: 0.0007762562\n",
      "[timestep: 2] [epoch: 35851] loss: 0.0007520433\n",
      "[timestep: 2] [epoch: 35881] loss: 0.0007384638\n",
      "[timestep: 2] [epoch: 35911] loss: 0.0007466205\n",
      "[timestep: 2] [epoch: 35941] loss: 0.0007989388\n",
      "[timestep: 2] [epoch: 35971] loss: 0.0007531513\n",
      "[timestep: 2] [epoch: 36001] loss: 0.0007783884\n",
      "[timestep: 2] [epoch: 36031] loss: 0.0007363097\n",
      "[timestep: 2] [epoch: 36061] loss: 0.0007647399\n",
      "[timestep: 2] [epoch: 36091] loss: 0.0007450911\n",
      "[timestep: 2] [epoch: 36121] loss: 0.0007485170\n",
      "[timestep: 2] [epoch: 36151] loss: 0.0007674464\n",
      "[timestep: 2] [epoch: 36181] loss: 0.0007445622\n",
      "[timestep: 2] [epoch: 36211] loss: 0.0007606656\n",
      "[timestep: 2] [epoch: 36241] loss: 0.0007535706\n",
      "[timestep: 2] [epoch: 36271] loss: 0.0007593500\n",
      "[timestep: 2] [epoch: 36301] loss: 0.0007600408\n",
      "[timestep: 2] [epoch: 36331] loss: 0.0007632584\n",
      "[timestep: 2] [epoch: 36361] loss: 0.0007698147\n",
      "[timestep: 2] [epoch: 36391] loss: 0.0007652163\n",
      "[timestep: 2] [epoch: 36421] loss: 0.0007506288\n",
      "[timestep: 2] [epoch: 36451] loss: 0.0007393926\n",
      "[timestep: 2] [epoch: 36481] loss: 0.0007609390\n",
      "[timestep: 2] [epoch: 36511] loss: 0.0007538985\n",
      "[timestep: 2] [epoch: 36541] loss: 0.0007397563\n",
      "[timestep: 2] [epoch: 36571] loss: 0.0007455503\n",
      "[timestep: 2] [epoch: 36601] loss: 0.0007706630\n",
      "[timestep: 2] [epoch: 36631] loss: 0.0007453860\n",
      "[timestep: 2] [epoch: 36661] loss: 0.0007283284\n",
      "[timestep: 2] [epoch: 36691] loss: 0.0007604216\n",
      "[timestep: 2] [epoch: 36721] loss: 0.0007744876\n",
      "[timestep: 2] [epoch: 36751] loss: 0.0007537989\n",
      "[timestep: 2] [epoch: 36781] loss: 0.0007575249\n",
      "[timestep: 2] [epoch: 36811] loss: 0.0007556386\n",
      "[timestep: 2] [epoch: 36841] loss: 0.0007451639\n",
      "[timestep: 2] [epoch: 36871] loss: 0.0007233692\n",
      "[timestep: 2] [epoch: 36901] loss: 0.0007715659\n",
      "[timestep: 2] [epoch: 36931] loss: 0.0007477124\n",
      "[timestep: 2] [epoch: 36961] loss: 0.0007793037\n",
      "[timestep: 2] [epoch: 36991] loss: 0.0007269281\n",
      "[timestep: 2] [epoch: 37021] loss: 0.0007417786\n",
      "[timestep: 2] [epoch: 37051] loss: 0.0007277223\n",
      "[timestep: 2] [epoch: 37081] loss: 0.0007332326\n",
      "[timestep: 2] [epoch: 37111] loss: 0.0007732282\n",
      "[timestep: 2] [epoch: 37141] loss: 0.0007535717\n",
      "[timestep: 2] [epoch: 37171] loss: 0.0007333206\n",
      "[timestep: 2] [epoch: 37201] loss: 0.0007622995\n",
      "[timestep: 2] [epoch: 37231] loss: 0.0007184219\n",
      "[timestep: 2] [epoch: 37261] loss: 0.0007478031\n",
      "[timestep: 2] [epoch: 37291] loss: 0.0007323509\n",
      "[timestep: 2] [epoch: 37321] loss: 0.0007476297\n",
      "[timestep: 2] [epoch: 37351] loss: 0.0007518303\n",
      "[timestep: 2] [epoch: 37381] loss: 0.0007500406\n",
      "[timestep: 2] [epoch: 37411] loss: 0.0007350361\n",
      "[timestep: 2] [epoch: 37441] loss: 0.0007354710\n",
      "[timestep: 2] [epoch: 37471] loss: 0.0007238920\n",
      "[timestep: 2] [epoch: 37501] loss: 0.0007335830\n",
      "[timestep: 2] [epoch: 37531] loss: 0.0007289103\n",
      "[timestep: 2] [epoch: 37561] loss: 0.0007316847\n",
      "[timestep: 2] [epoch: 37591] loss: 0.0007301673\n",
      "[timestep: 2] [epoch: 37621] loss: 0.0007607498\n",
      "[timestep: 2] [epoch: 37651] loss: 0.0007533297\n",
      "[timestep: 2] [epoch: 37681] loss: 0.0007292824\n",
      "[timestep: 2] [epoch: 37711] loss: 0.0007262182\n",
      "[timestep: 2] [epoch: 37741] loss: 0.0007339664\n",
      "[timestep: 2] [epoch: 37771] loss: 0.0007580172\n",
      "[timestep: 2] [epoch: 37801] loss: 0.0007348191\n",
      "[timestep: 2] [epoch: 37831] loss: 0.0007789073\n",
      "[timestep: 2] [epoch: 37861] loss: 0.0007380410\n",
      "[timestep: 2] [epoch: 37891] loss: 0.0007300794\n",
      "[timestep: 2] [epoch: 37921] loss: 0.0007408629\n",
      "[timestep: 2] [epoch: 37951] loss: 0.0007525638\n",
      "[timestep: 2] [epoch: 37981] loss: 0.0007362468\n",
      "[timestep: 2] [epoch: 38011] loss: 0.0007339356\n",
      "[timestep: 2] [epoch: 38041] loss: 0.0007313495\n",
      "[timestep: 2] [epoch: 38071] loss: 0.0007360585\n",
      "[timestep: 2] [epoch: 38101] loss: 0.0007268889\n",
      "[timestep: 2] [epoch: 38131] loss: 0.0007436856\n",
      "[timestep: 2] [epoch: 38161] loss: 0.0007299019\n",
      "[timestep: 2] [epoch: 38191] loss: 0.0007344968\n",
      "[timestep: 2] [epoch: 38221] loss: 0.0007332280\n",
      "[timestep: 2] [epoch: 38251] loss: 0.0007307527\n",
      "[timestep: 2] [epoch: 38281] loss: 0.0007701839\n",
      "[timestep: 2] [epoch: 38311] loss: 0.0007575419\n",
      "[timestep: 2] [epoch: 38341] loss: 0.0007318948\n",
      "[timestep: 2] [epoch: 38371] loss: 0.0007380119\n",
      "[timestep: 2] [epoch: 38401] loss: 0.0007387577\n",
      "[timestep: 2] [epoch: 38431] loss: 0.0007179131\n",
      "[timestep: 2] [epoch: 38461] loss: 0.0007309355\n",
      "[timestep: 2] [epoch: 38491] loss: 0.0007518748\n",
      "[timestep: 2] [epoch: 38521] loss: 0.0007416000\n",
      "[timestep: 2] [epoch: 38551] loss: 0.0007398675\n",
      "[timestep: 2] [epoch: 38581] loss: 0.0007236131\n",
      "[timestep: 2] [epoch: 38611] loss: 0.0007356906\n",
      "[timestep: 2] [epoch: 38641] loss: 0.0007245955\n",
      "[timestep: 2] [epoch: 38671] loss: 0.0007320706\n",
      "[timestep: 2] [epoch: 38701] loss: 0.0007293103\n",
      "[timestep: 2] [epoch: 38731] loss: 0.0007419325\n",
      "[timestep: 2] [epoch: 38761] loss: 0.0007424469\n",
      "[timestep: 2] [epoch: 38791] loss: 0.0007745951\n",
      "[timestep: 2] [epoch: 38821] loss: 0.0007534578\n",
      "[timestep: 2] [epoch: 38851] loss: 0.0007613740\n",
      "[timestep: 2] [epoch: 38881] loss: 0.0007506792\n",
      "[timestep: 2] [epoch: 38911] loss: 0.0007402349\n",
      "[timestep: 2] [epoch: 38941] loss: 0.0007613133\n",
      "[timestep: 2] [epoch: 38971] loss: 0.0007463555\n",
      "[timestep: 2] [epoch: 39001] loss: 0.0007317781\n",
      "[timestep: 2] [epoch: 39031] loss: 0.0007270544\n",
      "[timestep: 2] [epoch: 39061] loss: 0.0007526053\n",
      "[timestep: 2] [epoch: 39091] loss: 0.0007734700\n",
      "[timestep: 2] [epoch: 39121] loss: 0.0007469095\n",
      "[timestep: 2] [epoch: 39151] loss: 0.0007248662\n",
      "[timestep: 2] [epoch: 39181] loss: 0.0007630108\n",
      "[timestep: 2] [epoch: 39211] loss: 0.0007396603\n",
      "[timestep: 2] [epoch: 39241] loss: 0.0007214224\n",
      "[timestep: 2] [epoch: 39271] loss: 0.0007231719\n",
      "[timestep: 2] [epoch: 39301] loss: 0.0007347112\n",
      "[timestep: 2] [epoch: 39331] loss: 0.0007572924\n",
      "[timestep: 2] [epoch: 39361] loss: 0.0007355682\n",
      "[timestep: 2] [epoch: 39391] loss: 0.0007347323\n",
      "[timestep: 2] [epoch: 39421] loss: 0.0007389131\n",
      "[timestep: 2] [epoch: 39451] loss: 0.0007370503\n",
      "[timestep: 2] [epoch: 39481] loss: 0.0007419335\n",
      "[timestep: 2] [epoch: 39511] loss: 0.0007271876\n",
      "[timestep: 2] [epoch: 39541] loss: 0.0007364797\n",
      "[timestep: 2] [epoch: 39571] loss: 0.0007558445\n",
      "[timestep: 2] [epoch: 39601] loss: 0.0007373702\n",
      "[timestep: 2] [epoch: 39631] loss: 0.0007877938\n",
      "[timestep: 2] [epoch: 39661] loss: 0.0007595895\n",
      "[timestep: 2] [epoch: 39691] loss: 0.0007632126\n",
      "[timestep: 2] [epoch: 39721] loss: 0.0007248888\n",
      "[timestep: 2] [epoch: 39751] loss: 0.0007317545\n",
      "[timestep: 2] [epoch: 39781] loss: 0.0007313034\n",
      "[timestep: 2] [epoch: 39811] loss: 0.0007376896\n",
      "[timestep: 2] [epoch: 39841] loss: 0.0007301967\n",
      "[timestep: 2] [epoch: 39871] loss: 0.0007390693\n",
      "[timestep: 2] [epoch: 39901] loss: 0.0007320393\n",
      "[timestep: 2] [epoch: 39931] loss: 0.0007479521\n",
      "[timestep: 2] [epoch: 39961] loss: 0.0007469765\n",
      "[timestep: 2] [epoch: 39991] loss: 0.0007336842\n",
      "[timestep: 2] [epoch: 40021] loss: 0.0007541607\n",
      "[timestep: 2] [epoch: 40051] loss: 0.0007202657\n",
      "[timestep: 2] [epoch: 40081] loss: 0.0007434599\n",
      "[timestep: 2] [epoch: 40111] loss: 0.0007307169\n",
      "[timestep: 2] [epoch: 40141] loss: 0.0007501899\n",
      "[timestep: 2] [epoch: 40171] loss: 0.0007454497\n",
      "[timestep: 2] [epoch: 40201] loss: 0.0007314513\n",
      "[timestep: 2] [epoch: 40231] loss: 0.0007099265\n",
      "[timestep: 2] [epoch: 40261] loss: 0.0007703508\n",
      "[timestep: 2] [epoch: 40291] loss: 0.0007243116\n",
      "[timestep: 2] [epoch: 40321] loss: 0.0007352732\n",
      "[timestep: 2] [epoch: 40351] loss: 0.0007225894\n",
      "[timestep: 2] [epoch: 40381] loss: 0.0007453017\n",
      "[timestep: 2] [epoch: 40411] loss: 0.0007260179\n",
      "[timestep: 2] [epoch: 40441] loss: 0.0007318311\n",
      "[timestep: 2] [epoch: 40471] loss: 0.0007321351\n",
      "[timestep: 2] [epoch: 40501] loss: 0.0007329006\n",
      "[timestep: 2] [epoch: 40531] loss: 0.0007309116\n",
      "[timestep: 2] [epoch: 40561] loss: 0.0007511100\n",
      "[timestep: 2] [epoch: 40591] loss: 0.0007293852\n",
      "[timestep: 2] [epoch: 40621] loss: 0.0007437901\n",
      "[timestep: 2] [epoch: 40651] loss: 0.0007268073\n",
      "[timestep: 2] [epoch: 40681] loss: 0.0007368276\n",
      "[timestep: 2] [epoch: 40711] loss: 0.0007324770\n",
      "[timestep: 2] [epoch: 40741] loss: 0.0007194306\n",
      "[timestep: 2] [epoch: 40771] loss: 0.0007479064\n",
      "[timestep: 2] [epoch: 40801] loss: 0.0007377787\n",
      "[timestep: 2] [epoch: 40831] loss: 0.0007088105\n",
      "[timestep: 2] [epoch: 40861] loss: 0.0007107627\n",
      "[timestep: 2] [epoch: 40891] loss: 0.0007411198\n",
      "[timestep: 2] [epoch: 40921] loss: 0.0007463719\n",
      "[timestep: 2] [epoch: 40951] loss: 0.0007565041\n",
      "[timestep: 2] [epoch: 40981] loss: 0.0007459947\n",
      "[timestep: 2] [epoch: 41011] loss: 0.0007332991\n",
      "[timestep: 2] [epoch: 41041] loss: 0.0007413692\n",
      "[timestep: 2] [epoch: 41071] loss: 0.0007527829\n",
      "[timestep: 2] [epoch: 41101] loss: 0.0007309347\n",
      "[timestep: 2] [epoch: 41131] loss: 0.0007398739\n",
      "[timestep: 2] [epoch: 41161] loss: 0.0007530266\n",
      "[timestep: 2] [epoch: 41191] loss: 0.0007477885\n",
      "[timestep: 2] [epoch: 41221] loss: 0.0007324583\n",
      "[timestep: 2] [epoch: 41251] loss: 0.0007261425\n",
      "[timestep: 2] [epoch: 41281] loss: 0.0007569540\n",
      "[timestep: 2] [epoch: 41311] loss: 0.0007383775\n",
      "[timestep: 2] [epoch: 41341] loss: 0.0007293332\n",
      "[timestep: 2] [epoch: 41371] loss: 0.0007498428\n",
      "[timestep: 2] [epoch: 41401] loss: 0.0007261017\n",
      "[timestep: 2] [epoch: 41431] loss: 0.0007203511\n",
      "[timestep: 2] [epoch: 41461] loss: 0.0007460577\n",
      "[timestep: 2] [epoch: 41491] loss: 0.0007221929\n",
      "[timestep: 2] [epoch: 41521] loss: 0.0007245539\n",
      "[timestep: 2] [epoch: 41551] loss: 0.0007229614\n",
      "[timestep: 2] [epoch: 41581] loss: 0.0007353557\n",
      "[timestep: 2] [epoch: 41611] loss: 0.0007442492\n",
      "[timestep: 2] [epoch: 41641] loss: 0.0007328528\n",
      "[timestep: 2] [epoch: 41671] loss: 0.0007317228\n",
      "[timestep: 2] [epoch: 41701] loss: 0.0007308037\n",
      "[timestep: 2] [epoch: 41731] loss: 0.0007331481\n",
      "[timestep: 2] [epoch: 41761] loss: 0.0007363375\n",
      "[timestep: 2] [epoch: 41791] loss: 0.0007320575\n",
      "[timestep: 2] [epoch: 41821] loss: 0.0007300345\n",
      "[timestep: 2] [epoch: 41851] loss: 0.0007219245\n",
      "[timestep: 2] [epoch: 41881] loss: 0.0007075095\n",
      "[timestep: 2] [epoch: 41911] loss: 0.0007219500\n",
      "[timestep: 2] [epoch: 41941] loss: 0.0007187180\n",
      "[timestep: 2] [epoch: 41971] loss: 0.0007136439\n",
      "[timestep: 2] [epoch: 42001] loss: 0.0007172410\n",
      "[timestep: 2] [epoch: 42031] loss: 0.0007261339\n",
      "[timestep: 2] [epoch: 42061] loss: 0.0007124141\n",
      "[timestep: 2] [epoch: 42091] loss: 0.0007064966\n",
      "[timestep: 2] [epoch: 42121] loss: 0.0006953855\n",
      "[timestep: 2] [epoch: 42151] loss: 0.0007011583\n",
      "[timestep: 2] [epoch: 42181] loss: 0.0007257999\n",
      "[timestep: 2] [epoch: 42211] loss: 0.0007164796\n",
      "[timestep: 2] [epoch: 42241] loss: 0.0007247282\n",
      "[timestep: 2] [epoch: 42271] loss: 0.0007448834\n",
      "[timestep: 2] [epoch: 42301] loss: 0.0007322684\n",
      "[timestep: 2] [epoch: 42331] loss: 0.0007324566\n",
      "[timestep: 2] [epoch: 42361] loss: 0.0007188024\n",
      "[timestep: 2] [epoch: 42391] loss: 0.0007277298\n",
      "[timestep: 2] [epoch: 42421] loss: 0.0007294029\n",
      "[timestep: 2] [epoch: 42451] loss: 0.0007381785\n",
      "[timestep: 2] [epoch: 42481] loss: 0.0007272878\n",
      "[timestep: 2] [epoch: 42511] loss: 0.0007283638\n",
      "[timestep: 2] [epoch: 42541] loss: 0.0007371331\n",
      "[timestep: 2] [epoch: 42571] loss: 0.0007334086\n",
      "[timestep: 2] [epoch: 42601] loss: 0.0007307625\n",
      "[timestep: 2] [epoch: 42631] loss: 0.0007103636\n",
      "[timestep: 2] [epoch: 42661] loss: 0.0007323693\n",
      "[timestep: 2] [epoch: 42691] loss: 0.0007253109\n",
      "[timestep: 2] [epoch: 42721] loss: 0.0007342553\n",
      "[timestep: 2] [epoch: 42751] loss: 0.0007157814\n",
      "[timestep: 2] [epoch: 42781] loss: 0.0007255540\n",
      "[timestep: 2] [epoch: 42811] loss: 0.0007167489\n",
      "[timestep: 2] [epoch: 42841] loss: 0.0007249730\n",
      "[timestep: 2] [epoch: 42871] loss: 0.0007238337\n",
      "[timestep: 2] [epoch: 42901] loss: 0.0007302847\n",
      "[timestep: 2] [epoch: 42931] loss: 0.0007070149\n",
      "[timestep: 2] [epoch: 42961] loss: 0.0007238174\n",
      "[timestep: 2] [epoch: 42991] loss: 0.0007249303\n",
      "[timestep: 2] [epoch: 43021] loss: 0.0007158061\n",
      "[timestep: 2] [epoch: 43051] loss: 0.0007310947\n",
      "[timestep: 2] [epoch: 43081] loss: 0.0007444574\n",
      "[timestep: 2] [epoch: 43111] loss: 0.0007245117\n",
      "[timestep: 2] [epoch: 43141] loss: 0.0007253729\n",
      "[timestep: 2] [epoch: 43171] loss: 0.0007242030\n",
      "[timestep: 2] [epoch: 43201] loss: 0.0007102896\n",
      "[timestep: 2] [epoch: 43231] loss: 0.0007330700\n",
      "[timestep: 2] [epoch: 43261] loss: 0.0007489175\n",
      "[timestep: 2] [epoch: 43291] loss: 0.0007338488\n",
      "[timestep: 2] [epoch: 43321] loss: 0.0007165064\n",
      "[timestep: 2] [epoch: 43351] loss: 0.0007138769\n",
      "[timestep: 2] [epoch: 43381] loss: 0.0007165152\n",
      "[timestep: 2] [epoch: 43411] loss: 0.0007034515\n",
      "[timestep: 2] [epoch: 43441] loss: 0.0007285664\n",
      "[timestep: 2] [epoch: 43471] loss: 0.0007277208\n",
      "[timestep: 2] [epoch: 43501] loss: 0.0007348723\n",
      "[timestep: 2] [epoch: 43531] loss: 0.0007162219\n",
      "[timestep: 2] [epoch: 43561] loss: 0.0007245066\n",
      "[timestep: 2] [epoch: 43591] loss: 0.0007611609\n",
      "[timestep: 2] [epoch: 43621] loss: 0.0007467972\n",
      "[timestep: 2] [epoch: 43651] loss: 0.0007435164\n",
      "[timestep: 2] [epoch: 43681] loss: 0.0007545342\n",
      "[timestep: 2] [epoch: 43711] loss: 0.0007297825\n",
      "[timestep: 2] [epoch: 43741] loss: 0.0007198855\n",
      "[timestep: 2] [epoch: 43771] loss: 0.0007439716\n",
      "[timestep: 2] [epoch: 43801] loss: 0.0007325492\n",
      "[timestep: 2] [epoch: 43831] loss: 0.0007321020\n",
      "[timestep: 2] [epoch: 43861] loss: 0.0007273194\n",
      "[timestep: 2] [epoch: 43891] loss: 0.0007362873\n",
      "[timestep: 2] [epoch: 43921] loss: 0.0007384730\n",
      "[timestep: 2] [epoch: 43951] loss: 0.0007407621\n",
      "[timestep: 2] [epoch: 43981] loss: 0.0007294172\n",
      "[timestep: 2] [epoch: 44011] loss: 0.0007404293\n",
      "[timestep: 2] [epoch: 44041] loss: 0.0007398236\n",
      "[timestep: 2] [epoch: 44071] loss: 0.0007360952\n",
      "[timestep: 2] [epoch: 44101] loss: 0.0007256821\n",
      "[timestep: 2] [epoch: 44131] loss: 0.0007304163\n",
      "[timestep: 2] [epoch: 44161] loss: 0.0007437672\n",
      "[timestep: 2] [epoch: 44191] loss: 0.0007202288\n",
      "[timestep: 2] [epoch: 44221] loss: 0.0007430948\n",
      "[timestep: 2] [epoch: 44251] loss: 0.0007368947\n",
      "[timestep: 2] [epoch: 44281] loss: 0.0007205915\n",
      "[timestep: 2] [epoch: 44311] loss: 0.0007292897\n",
      "[timestep: 2] [epoch: 44341] loss: 0.0007293798\n",
      "[timestep: 2] [epoch: 44371] loss: 0.0007386247\n",
      "[timestep: 2] [epoch: 44401] loss: 0.0007319114\n",
      "[timestep: 2] [epoch: 44431] loss: 0.0007306521\n",
      "[timestep: 2] [epoch: 44461] loss: 0.0007320180\n",
      "[timestep: 2] [epoch: 44491] loss: 0.0007622080\n",
      "[timestep: 2] [epoch: 44521] loss: 0.0007264956\n",
      "[timestep: 2] [epoch: 44551] loss: 0.0007482657\n",
      "[timestep: 2] [epoch: 44581] loss: 0.0007313468\n",
      "[timestep: 2] [epoch: 44611] loss: 0.0007433904\n",
      "[timestep: 2] [epoch: 44641] loss: 0.0007567141\n",
      "[timestep: 2] [epoch: 44671] loss: 0.0007277519\n",
      "[timestep: 2] [epoch: 44701] loss: 0.0007247039\n",
      "[timestep: 2] [epoch: 44731] loss: 0.0007276213\n",
      "[timestep: 2] [epoch: 44761] loss: 0.0007282632\n",
      "[timestep: 2] [epoch: 44791] loss: 0.0007245111\n",
      "[timestep: 2] [epoch: 44821] loss: 0.0007112727\n",
      "[timestep: 2] [epoch: 44851] loss: 0.0007291415\n",
      "[timestep: 2] [epoch: 44881] loss: 0.0007271299\n",
      "[timestep: 2] [epoch: 44911] loss: 0.0007221142\n",
      "[timestep: 2] [epoch: 44941] loss: 0.0007304652\n",
      "[timestep: 2] [epoch: 44971] loss: 0.0007471035\n",
      "[timestep: 2] [epoch: 45001] loss: 0.0007490700\n",
      "[timestep: 2] [epoch: 45031] loss: 0.0007208246\n",
      "[timestep: 2] [epoch: 45061] loss: 0.0007206075\n",
      "[timestep: 2] [epoch: 45091] loss: 0.0007429869\n",
      "[timestep: 2] [epoch: 45121] loss: 0.0007274162\n",
      "[timestep: 2] [epoch: 45151] loss: 0.0007433741\n",
      "[timestep: 2] [epoch: 45181] loss: 0.0007394325\n",
      "[timestep: 2] [epoch: 45211] loss: 0.0007179681\n",
      "[timestep: 2] [epoch: 45241] loss: 0.0007572061\n",
      "[timestep: 2] [epoch: 45271] loss: 0.0007263027\n",
      "[timestep: 2] [epoch: 45301] loss: 0.0007104196\n",
      "[timestep: 2] [epoch: 45331] loss: 0.0007198440\n",
      "[timestep: 2] [epoch: 45361] loss: 0.0007178661\n",
      "[timestep: 2] [epoch: 45391] loss: 0.0007263413\n",
      "[timestep: 2] [epoch: 45421] loss: 0.0007243075\n",
      "[timestep: 2] [epoch: 45451] loss: 0.0007365332\n",
      "[timestep: 2] [epoch: 45481] loss: 0.0007248304\n",
      "[timestep: 2] [epoch: 45511] loss: 0.0007226837\n",
      "[timestep: 2] [epoch: 45541] loss: 0.0007115636\n",
      "[timestep: 2] [epoch: 45571] loss: 0.0007208507\n",
      "[timestep: 2] [epoch: 45601] loss: 0.0007352753\n",
      "[timestep: 2] [epoch: 45631] loss: 0.0007316929\n",
      "[timestep: 2] [epoch: 45661] loss: 0.0007217109\n",
      "[timestep: 2] [epoch: 45691] loss: 0.0007385491\n",
      "[timestep: 2] [epoch: 45721] loss: 0.0007374170\n",
      "[timestep: 2] [epoch: 45751] loss: 0.0007161741\n",
      "[timestep: 2] [epoch: 45781] loss: 0.0007108112\n",
      "[timestep: 2] [epoch: 45811] loss: 0.0007264171\n",
      "[timestep: 2] [epoch: 45841] loss: 0.0007267025\n",
      "[timestep: 2] [epoch: 45871] loss: 0.0007324572\n",
      "[timestep: 2] [epoch: 45901] loss: 0.0007237128\n",
      "[timestep: 2] [epoch: 45931] loss: 0.0007021239\n",
      "[timestep: 2] [epoch: 45961] loss: 0.0007190683\n",
      "[timestep: 2] [epoch: 45991] loss: 0.0007187309\n",
      "[timestep: 2] [epoch: 46021] loss: 0.0007176857\n",
      "[timestep: 2] [epoch: 46051] loss: 0.0007169805\n",
      "[timestep: 2] [epoch: 46081] loss: 0.0007157451\n",
      "[timestep: 2] [epoch: 46111] loss: 0.0007110137\n",
      "[timestep: 2] [epoch: 46141] loss: 0.0007227599\n",
      "[timestep: 2] [epoch: 46171] loss: 0.0007243486\n",
      "[timestep: 2] [epoch: 46201] loss: 0.0007232146\n",
      "[timestep: 2] [epoch: 46231] loss: 0.0007226149\n",
      "[timestep: 2] [epoch: 46261] loss: 0.0007304883\n",
      "[timestep: 2] [epoch: 46291] loss: 0.0007143309\n",
      "[timestep: 2] [epoch: 46321] loss: 0.0007491906\n",
      "[timestep: 2] [epoch: 46351] loss: 0.0007268887\n",
      "[timestep: 2] [epoch: 46381] loss: 0.0007276122\n",
      "[timestep: 2] [epoch: 46411] loss: 0.0007176484\n",
      "[timestep: 2] [epoch: 46441] loss: 0.0007280297\n",
      "[timestep: 2] [epoch: 46471] loss: 0.0007406155\n",
      "[timestep: 2] [epoch: 46501] loss: 0.0007371877\n",
      "[timestep: 2] [epoch: 46531] loss: 0.0007400947\n",
      "[timestep: 2] [epoch: 46561] loss: 0.0007181693\n",
      "[timestep: 2] [epoch: 46591] loss: 0.0007246329\n",
      "[timestep: 2] [epoch: 46621] loss: 0.0007163093\n",
      "[timestep: 2] [epoch: 46651] loss: 0.0007092372\n",
      "[timestep: 2] [epoch: 46681] loss: 0.0007041702\n",
      "[timestep: 2] [epoch: 46711] loss: 0.0007217918\n",
      "[timestep: 2] [epoch: 46741] loss: 0.0007135762\n",
      "[timestep: 2] [epoch: 46771] loss: 0.0007124072\n",
      "[timestep: 2] [epoch: 46801] loss: 0.0007054382\n",
      "[timestep: 2] [epoch: 46831] loss: 0.0007216608\n",
      "[timestep: 2] [epoch: 46861] loss: 0.0007107428\n",
      "[timestep: 2] [epoch: 46891] loss: 0.0007181213\n",
      "[timestep: 2] [epoch: 46921] loss: 0.0007283691\n",
      "[timestep: 2] [epoch: 46951] loss: 0.0007280550\n",
      "[timestep: 2] [epoch: 46981] loss: 0.0007247869\n",
      "[timestep: 2] [epoch: 47011] loss: 0.0007158461\n",
      "[timestep: 2] [epoch: 47041] loss: 0.0007211156\n",
      "[timestep: 2] [epoch: 47071] loss: 0.0007408076\n",
      "[timestep: 2] [epoch: 47101] loss: 0.0007270165\n",
      "[timestep: 2] [epoch: 47131] loss: 0.0007220053\n",
      "[timestep: 2] [epoch: 47161] loss: 0.0007437856\n",
      "[timestep: 2] [epoch: 47191] loss: 0.0007268289\n",
      "[timestep: 2] [epoch: 47221] loss: 0.0007036575\n",
      "[timestep: 2] [epoch: 47251] loss: 0.0007201907\n",
      "[timestep: 2] [epoch: 47281] loss: 0.0007207815\n",
      "[timestep: 2] [epoch: 47311] loss: 0.0007193267\n",
      "[timestep: 2] [epoch: 47341] loss: 0.0007374841\n",
      "[timestep: 2] [epoch: 47371] loss: 0.0007197374\n",
      "[timestep: 2] [epoch: 47401] loss: 0.0007052455\n",
      "[timestep: 2] [epoch: 47431] loss: 0.0007173244\n",
      "[timestep: 2] [epoch: 47461] loss: 0.0007206461\n",
      "[timestep: 2] [epoch: 47491] loss: 0.0007302096\n",
      "[timestep: 2] [epoch: 47521] loss: 0.0007250832\n",
      "[timestep: 2] [epoch: 47551] loss: 0.0007221914\n",
      "[timestep: 2] [epoch: 47581] loss: 0.0007087269\n",
      "[timestep: 2] [epoch: 47611] loss: 0.0007223028\n",
      "[timestep: 2] [epoch: 47641] loss: 0.0007307659\n",
      "[timestep: 2] [epoch: 47671] loss: 0.0007133378\n",
      "[timestep: 2] [epoch: 47701] loss: 0.0007404262\n",
      "[timestep: 2] [epoch: 47731] loss: 0.0007237243\n",
      "[timestep: 2] [epoch: 47761] loss: 0.0007229156\n",
      "[timestep: 2] [epoch: 47791] loss: 0.0007097095\n",
      "[timestep: 2] [epoch: 47821] loss: 0.0007304361\n",
      "[timestep: 2] [epoch: 47851] loss: 0.0007099279\n",
      "[timestep: 2] [epoch: 47881] loss: 0.0007067017\n",
      "[timestep: 2] [epoch: 47911] loss: 0.0007229901\n",
      "[timestep: 2] [epoch: 47941] loss: 0.0007329099\n",
      "[timestep: 2] [epoch: 47971] loss: 0.0007230531\n",
      "[timestep: 2] [epoch: 48001] loss: 0.0007231056\n",
      "[timestep: 2] [epoch: 48031] loss: 0.0007091821\n",
      "[timestep: 2] [epoch: 48061] loss: 0.0007179590\n",
      "[timestep: 2] [epoch: 48091] loss: 0.0007180830\n",
      "[timestep: 2] [epoch: 48121] loss: 0.0007155489\n",
      "[timestep: 2] [epoch: 48151] loss: 0.0007278420\n",
      "[timestep: 2] [epoch: 48181] loss: 0.0007151206\n",
      "[timestep: 2] [epoch: 48211] loss: 0.0007183374\n",
      "[timestep: 2] [epoch: 48241] loss: 0.0007322525\n",
      "[timestep: 2] [epoch: 48271] loss: 0.0007253520\n",
      "[timestep: 2] [epoch: 48301] loss: 0.0007255584\n",
      "[timestep: 2] [epoch: 48331] loss: 0.0007229536\n",
      "[timestep: 2] [epoch: 48361] loss: 0.0007262120\n",
      "[timestep: 2] [epoch: 48391] loss: 0.0007213954\n",
      "[timestep: 2] [epoch: 48421] loss: 0.0007219553\n",
      "[timestep: 2] [epoch: 48451] loss: 0.0007373532\n",
      "[timestep: 2] [epoch: 48481] loss: 0.0007372691\n",
      "[timestep: 2] [epoch: 48511] loss: 0.0007238602\n",
      "[timestep: 2] [epoch: 48541] loss: 0.0007203150\n",
      "[timestep: 2] [epoch: 48571] loss: 0.0007237474\n",
      "[timestep: 2] [epoch: 48601] loss: 0.0007216332\n",
      "[timestep: 2] [epoch: 48631] loss: 0.0007228106\n",
      "[timestep: 2] [epoch: 48661] loss: 0.0007191544\n",
      "[timestep: 2] [epoch: 48691] loss: 0.0007226491\n",
      "[timestep: 2] [epoch: 48721] loss: 0.0007304506\n",
      "[timestep: 2] [epoch: 48751] loss: 0.0007123912\n",
      "[timestep: 2] [epoch: 48781] loss: 0.0007124520\n",
      "[timestep: 2] [epoch: 48811] loss: 0.0007149649\n",
      "[timestep: 2] [epoch: 48841] loss: 0.0007161193\n",
      "[timestep: 2] [epoch: 48871] loss: 0.0007218005\n",
      "[timestep: 2] [epoch: 48901] loss: 0.0007162732\n",
      "[timestep: 2] [epoch: 48931] loss: 0.0007084615\n",
      "[timestep: 2] [epoch: 48961] loss: 0.0007026334\n",
      "[timestep: 2] [epoch: 48991] loss: 0.0007208810\n",
      "[timestep: 2] [epoch: 49021] loss: 0.0007297597\n",
      "[timestep: 2] [epoch: 49051] loss: 0.0007337611\n",
      "[timestep: 2] [epoch: 49081] loss: 0.0007210355\n",
      "[timestep: 2] [epoch: 49111] loss: 0.0007359474\n",
      "[timestep: 2] [epoch: 49141] loss: 0.0007145134\n",
      "[timestep: 2] [epoch: 49171] loss: 0.0006981256\n",
      "[timestep: 2] [epoch: 49201] loss: 0.0007076025\n",
      "[timestep: 2] [epoch: 49231] loss: 0.0007229812\n",
      "[timestep: 2] [epoch: 49261] loss: 0.0007221366\n",
      "[timestep: 2] [epoch: 49291] loss: 0.0007148180\n",
      "[timestep: 2] [epoch: 49321] loss: 0.0007157364\n",
      "[timestep: 2] [epoch: 49351] loss: 0.0007235694\n",
      "[timestep: 2] [epoch: 49381] loss: 0.0007329624\n",
      "[timestep: 2] [epoch: 49411] loss: 0.0007210923\n",
      "[timestep: 2] [epoch: 49441] loss: 0.0007246622\n",
      "[timestep: 2] [epoch: 49471] loss: 0.0007261918\n",
      "[timestep: 2] [epoch: 49501] loss: 0.0007116973\n",
      "[timestep: 2] [epoch: 49531] loss: 0.0007185148\n",
      "[timestep: 2] [epoch: 49561] loss: 0.0007215200\n",
      "[timestep: 2] [epoch: 49591] loss: 0.0007196529\n",
      "[timestep: 2] [epoch: 49621] loss: 0.0007212929\n",
      "[timestep: 2] [epoch: 49651] loss: 0.0007292868\n",
      "[timestep: 2] [epoch: 49681] loss: 0.0007479062\n",
      "[timestep: 2] [epoch: 49711] loss: 0.0007154751\n",
      "[timestep: 2] [epoch: 49741] loss: 0.0007147471\n",
      "[timestep: 2] [epoch: 49771] loss: 0.0007248606\n",
      "[timestep: 2] [epoch: 49801] loss: 0.0007287019\n",
      "[timestep: 2] [epoch: 49831] loss: 0.0007334128\n",
      "[timestep: 2] [epoch: 49861] loss: 0.0007270471\n",
      "[timestep: 2] [epoch: 49891] loss: 0.0007373209\n",
      "[timestep: 2] [epoch: 49921] loss: 0.0007429499\n",
      "[timestep: 2] [epoch: 49951] loss: 0.0007196362\n",
      "[timestep: 2] [epoch: 49981] loss: 0.0007613185\n",
      "0.01\n",
      "[timestep: 3] [epoch: 1] loss: 2529.4333496094\n",
      "[timestep: 3] [epoch: 31] loss: 16.4725952148\n",
      "[timestep: 3] [epoch: 61] loss: 13.2976388931\n",
      "[timestep: 3] [epoch: 91] loss: 11.6099462509\n",
      "[timestep: 3] [epoch: 121] loss: 9.1936082840\n",
      "[timestep: 3] [epoch: 151] loss: 3.5889029503\n",
      "[timestep: 3] [epoch: 181] loss: 5.6787662506\n",
      "[timestep: 3] [epoch: 211] loss: 2.1736102104\n",
      "[timestep: 3] [epoch: 241] loss: 2.1597638130\n",
      "[timestep: 3] [epoch: 271] loss: 3.2330985069\n",
      "[timestep: 3] [epoch: 301] loss: 2.1270658970\n",
      "[timestep: 3] [epoch: 331] loss: 2.3396008015\n",
      "[timestep: 3] [epoch: 361] loss: 2.1032004356\n",
      "[timestep: 3] [epoch: 391] loss: 2.1441938877\n",
      "[timestep: 3] [epoch: 421] loss: 1.9160234928\n",
      "[timestep: 3] [epoch: 451] loss: 1.7903950214\n",
      "[timestep: 3] [epoch: 481] loss: 2.0916361809\n",
      "[timestep: 3] [epoch: 511] loss: 2.0657377243\n",
      "[timestep: 3] [epoch: 541] loss: 1.7406718731\n",
      "[timestep: 3] [epoch: 571] loss: 1.7596716881\n",
      "[timestep: 3] [epoch: 601] loss: 1.9399266243\n",
      "[timestep: 3] [epoch: 631] loss: 1.7629168034\n",
      "[timestep: 3] [epoch: 661] loss: 1.7489548922\n",
      "[timestep: 3] [epoch: 691] loss: 1.6999914646\n",
      "[timestep: 3] [epoch: 721] loss: 1.8756158352\n",
      "[timestep: 3] [epoch: 751] loss: 1.9851515293\n",
      "[timestep: 3] [epoch: 781] loss: 1.7830563784\n",
      "[timestep: 3] [epoch: 811] loss: 1.6850235462\n",
      "[timestep: 3] [epoch: 841] loss: 1.6890861988\n",
      "[timestep: 3] [epoch: 871] loss: 2.0388071537\n",
      "[timestep: 3] [epoch: 901] loss: 1.8799555302\n",
      "[timestep: 3] [epoch: 931] loss: 1.6978652477\n",
      "[timestep: 3] [epoch: 961] loss: 1.7335889339\n",
      "[timestep: 3] [epoch: 991] loss: 1.7068649530\n",
      "[timestep: 3] [epoch: 1021] loss: 1.6823031902\n",
      "[timestep: 3] [epoch: 1051] loss: 1.7068374157\n",
      "[timestep: 3] [epoch: 1081] loss: 1.6801295280\n",
      "[timestep: 3] [epoch: 1111] loss: 1.6707468033\n",
      "[timestep: 3] [epoch: 1141] loss: 1.6588854790\n",
      "[timestep: 3] [epoch: 1171] loss: 1.6829087734\n",
      "[timestep: 3] [epoch: 1201] loss: 1.6382534504\n",
      "[timestep: 3] [epoch: 1231] loss: 1.6596633196\n",
      "[timestep: 3] [epoch: 1261] loss: 1.7633459568\n",
      "[timestep: 3] [epoch: 1291] loss: 1.6617871523\n",
      "[timestep: 3] [epoch: 1321] loss: 1.6988549232\n",
      "[timestep: 3] [epoch: 1351] loss: 1.6331219673\n",
      "[timestep: 3] [epoch: 1381] loss: 1.6659197807\n",
      "[timestep: 3] [epoch: 1411] loss: 1.6595561504\n",
      "[timestep: 3] [epoch: 1441] loss: 1.6289091110\n",
      "[timestep: 3] [epoch: 1471] loss: 1.6831016541\n",
      "[timestep: 3] [epoch: 1501] loss: 1.6452078819\n",
      "[timestep: 3] [epoch: 1531] loss: 1.6786568165\n",
      "[timestep: 3] [epoch: 1561] loss: 1.6526150703\n",
      "[timestep: 3] [epoch: 1591] loss: 1.6734588146\n",
      "[timestep: 3] [epoch: 1621] loss: 1.6665215492\n",
      "[timestep: 3] [epoch: 1651] loss: 1.6150001287\n",
      "[timestep: 3] [epoch: 1681] loss: 1.6377440691\n",
      "[timestep: 3] [epoch: 1711] loss: 1.6142548323\n",
      "[timestep: 3] [epoch: 1741] loss: 1.6693887711\n",
      "[timestep: 3] [epoch: 1771] loss: 1.6002228260\n",
      "[timestep: 3] [epoch: 1801] loss: 1.6084194183\n",
      "[timestep: 3] [epoch: 1831] loss: 1.6599807739\n",
      "[timestep: 3] [epoch: 1861] loss: 1.6591732502\n",
      "[timestep: 3] [epoch: 1891] loss: 1.6361457109\n",
      "[timestep: 3] [epoch: 1921] loss: 1.5874395370\n",
      "[timestep: 3] [epoch: 1951] loss: 1.6313115358\n",
      "[timestep: 3] [epoch: 1981] loss: 1.6487023830\n",
      "[timestep: 3] [epoch: 2011] loss: 1.6013289690\n",
      "[timestep: 3] [epoch: 2041] loss: 1.6138577461\n",
      "[timestep: 3] [epoch: 2071] loss: 1.6115217209\n",
      "[timestep: 3] [epoch: 2101] loss: 1.6348838806\n",
      "[timestep: 3] [epoch: 2131] loss: 1.6544342041\n",
      "[timestep: 3] [epoch: 2161] loss: 1.6163767576\n",
      "[timestep: 3] [epoch: 2191] loss: 1.6298539639\n",
      "[timestep: 3] [epoch: 2221] loss: 1.6136534214\n",
      "[timestep: 3] [epoch: 2251] loss: 1.5935535431\n",
      "[timestep: 3] [epoch: 2281] loss: 1.6179792881\n",
      "[timestep: 3] [epoch: 2311] loss: 1.6029105186\n",
      "[timestep: 3] [epoch: 2341] loss: 1.6000181437\n",
      "[timestep: 3] [epoch: 2371] loss: 1.5848417282\n",
      "[timestep: 3] [epoch: 2401] loss: 1.6036250591\n",
      "[timestep: 3] [epoch: 2431] loss: 1.6193957329\n",
      "[timestep: 3] [epoch: 2461] loss: 1.6032756567\n",
      "[timestep: 3] [epoch: 2491] loss: 1.0005838871\n",
      "[timestep: 3] [epoch: 2521] loss: 0.7968984246\n",
      "[timestep: 3] [epoch: 2551] loss: 0.5660856962\n",
      "[timestep: 3] [epoch: 2581] loss: 0.7118792534\n",
      "[timestep: 3] [epoch: 2611] loss: 0.5432190895\n",
      "[timestep: 3] [epoch: 2641] loss: 0.4771881700\n",
      "[timestep: 3] [epoch: 2671] loss: 0.5506263971\n",
      "[timestep: 3] [epoch: 2701] loss: 0.6584309340\n",
      "[timestep: 3] [epoch: 2731] loss: 0.5247348547\n",
      "[timestep: 3] [epoch: 2761] loss: 0.4645920992\n",
      "[timestep: 3] [epoch: 2791] loss: 0.4186692834\n",
      "[timestep: 3] [epoch: 2821] loss: 0.4409453571\n",
      "[timestep: 3] [epoch: 2851] loss: 0.4119318724\n",
      "[timestep: 3] [epoch: 2881] loss: 0.3952608407\n",
      "[timestep: 3] [epoch: 2911] loss: 0.3483034968\n",
      "[timestep: 3] [epoch: 2941] loss: 0.4054200649\n",
      "[timestep: 3] [epoch: 2971] loss: 0.3393061161\n",
      "[timestep: 3] [epoch: 3001] loss: 0.3358042240\n",
      "[timestep: 3] [epoch: 3031] loss: 0.3756281137\n",
      "[timestep: 3] [epoch: 3061] loss: 0.3216394186\n",
      "[timestep: 3] [epoch: 3091] loss: 0.3600167036\n",
      "[timestep: 3] [epoch: 3121] loss: 0.3173750043\n",
      "[timestep: 3] [epoch: 3151] loss: 0.3073338270\n",
      "[timestep: 3] [epoch: 3181] loss: 0.3221922517\n",
      "[timestep: 3] [epoch: 3211] loss: 0.2926675081\n",
      "[timestep: 3] [epoch: 3241] loss: 0.2458182573\n",
      "[timestep: 3] [epoch: 3271] loss: 0.3523347080\n",
      "[timestep: 3] [epoch: 3301] loss: 0.2333109677\n",
      "[timestep: 3] [epoch: 3331] loss: 0.2565859556\n",
      "[timestep: 3] [epoch: 3361] loss: 0.2453914583\n",
      "[timestep: 3] [epoch: 3391] loss: 0.2367839813\n",
      "[timestep: 3] [epoch: 3421] loss: 0.2405810803\n",
      "[timestep: 3] [epoch: 3451] loss: 0.2446044981\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7df2d-c1f4-4fd8-8e18-0867674cdd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
