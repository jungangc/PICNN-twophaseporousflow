{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab949826-be6b-4436-84e9-b0bffacaf4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/user/jungangc/PICNN-2phase/PICNN-2phaseflow-constBHP-64by64-heter-TransferLearning-50stepsby2-final/Codes\n",
      "0.01\n",
      "[timestep: 1] [epoch: 1] loss: 0.0776444674\n",
      "[timestep: 1] [epoch: 31] loss: 0.0762058496\n",
      "[timestep: 1] [epoch: 61] loss: 0.0227218159\n",
      "[timestep: 1] [epoch: 91] loss: 0.0387076885\n",
      "[timestep: 1] [epoch: 121] loss: 0.0202467367\n",
      "[timestep: 1] [epoch: 151] loss: 0.0082398672\n",
      "[timestep: 1] [epoch: 181] loss: 0.0131882159\n",
      "[timestep: 1] [epoch: 211] loss: 0.0161460191\n",
      "[timestep: 1] [epoch: 241] loss: 0.0164231583\n",
      "[timestep: 1] [epoch: 271] loss: 0.0132293282\n",
      "[timestep: 1] [epoch: 301] loss: 0.0173204504\n",
      "[timestep: 1] [epoch: 331] loss: 0.0182261430\n",
      "[timestep: 1] [epoch: 361] loss: 0.0231446624\n",
      "[timestep: 1] [epoch: 391] loss: 0.0157485008\n",
      "[timestep: 1] [epoch: 421] loss: 0.0117210876\n",
      "[timestep: 1] [epoch: 451] loss: 0.0157221034\n",
      "[timestep: 1] [epoch: 481] loss: 0.0260236524\n",
      "[timestep: 1] [epoch: 511] loss: 0.0377818123\n",
      "[timestep: 1] [epoch: 541] loss: 0.0205453373\n",
      "[timestep: 1] [epoch: 571] loss: 0.0093449913\n",
      "[timestep: 1] [epoch: 601] loss: 0.0050525395\n",
      "[timestep: 1] [epoch: 631] loss: 0.0046611326\n",
      "[timestep: 1] [epoch: 661] loss: 0.0033397905\n",
      "[timestep: 1] [epoch: 691] loss: 0.0207799710\n",
      "[timestep: 1] [epoch: 721] loss: 0.0052059507\n",
      "[timestep: 1] [epoch: 751] loss: 0.0078355102\n",
      "[timestep: 1] [epoch: 781] loss: 0.0078266934\n",
      "[timestep: 1] [epoch: 811] loss: 0.0175009258\n",
      "[timestep: 1] [epoch: 841] loss: 0.0206292998\n",
      "[timestep: 1] [epoch: 871] loss: 0.0363191143\n",
      "[timestep: 1] [epoch: 901] loss: 0.0390154049\n",
      "[timestep: 1] [epoch: 931] loss: 0.0085866572\n",
      "[timestep: 1] [epoch: 961] loss: 0.0145624261\n",
      "[timestep: 1] [epoch: 991] loss: 0.0097253975\n",
      "[timestep: 1] [epoch: 1021] loss: 0.0118274922\n",
      "[timestep: 1] [epoch: 1051] loss: 0.0113413353\n",
      "[timestep: 1] [epoch: 1081] loss: 0.0083195157\n",
      "[timestep: 1] [epoch: 1111] loss: 0.0065734955\n",
      "[timestep: 1] [epoch: 1141] loss: 0.0136796385\n",
      "[timestep: 1] [epoch: 1171] loss: 0.0221839361\n",
      "[timestep: 1] [epoch: 1201] loss: 0.0223324932\n",
      "[timestep: 1] [epoch: 1231] loss: 0.0224308241\n",
      "[timestep: 1] [epoch: 1261] loss: 0.0173702948\n",
      "[timestep: 1] [epoch: 1291] loss: 0.0156326555\n",
      "[timestep: 1] [epoch: 1321] loss: 0.0111105703\n",
      "[timestep: 1] [epoch: 1351] loss: 0.0116358027\n",
      "[timestep: 1] [epoch: 1381] loss: 0.0052925153\n",
      "[timestep: 1] [epoch: 1411] loss: 0.0057649808\n",
      "[timestep: 1] [epoch: 1441] loss: 0.0060693538\n",
      "[timestep: 1] [epoch: 1471] loss: 0.0116352709\n",
      "[timestep: 1] [epoch: 1501] loss: 0.0100150183\n",
      "[timestep: 1] [epoch: 1531] loss: 0.0147521058\n",
      "[timestep: 1] [epoch: 1561] loss: 0.0068267644\n",
      "[timestep: 1] [epoch: 1591] loss: 0.0143234245\n",
      "[timestep: 1] [epoch: 1621] loss: 0.0068370253\n",
      "[timestep: 1] [epoch: 1651] loss: 0.0116358455\n",
      "[timestep: 1] [epoch: 1681] loss: 0.0201687403\n",
      "[timestep: 1] [epoch: 1711] loss: 0.0121748950\n",
      "[timestep: 1] [epoch: 1741] loss: 0.0132204536\n",
      "[timestep: 1] [epoch: 1771] loss: 0.0024225207\n",
      "[timestep: 1] [epoch: 1801] loss: 0.0062575894\n",
      "[timestep: 1] [epoch: 1831] loss: 0.0051568551\n",
      "[timestep: 1] [epoch: 1861] loss: 0.0079963366\n",
      "[timestep: 1] [epoch: 1891] loss: 0.0066584689\n",
      "[timestep: 1] [epoch: 1921] loss: 0.0086887162\n",
      "[timestep: 1] [epoch: 1951] loss: 0.0054236166\n",
      "[timestep: 1] [epoch: 1981] loss: 0.0091901682\n",
      "[timestep: 1] [epoch: 2011] loss: 0.0101338997\n",
      "[timestep: 1] [epoch: 2041] loss: 0.0241057891\n",
      "[timestep: 1] [epoch: 2071] loss: 0.0266864356\n",
      "[timestep: 1] [epoch: 2101] loss: 0.0078415740\n",
      "[timestep: 1] [epoch: 2131] loss: 0.0143287033\n",
      "[timestep: 1] [epoch: 2161] loss: 0.0103038857\n",
      "[timestep: 1] [epoch: 2191] loss: 0.0099273901\n",
      "[timestep: 1] [epoch: 2221] loss: 0.0051309518\n",
      "[timestep: 1] [epoch: 2251] loss: 0.0094246622\n",
      "[timestep: 1] [epoch: 2281] loss: 0.0016627995\n",
      "[timestep: 1] [epoch: 2311] loss: 0.0082877027\n",
      "[timestep: 1] [epoch: 2341] loss: 0.0101103373\n",
      "[timestep: 1] [epoch: 2371] loss: 0.0064958539\n",
      "[timestep: 1] [epoch: 2401] loss: 0.0079077836\n",
      "[timestep: 1] [epoch: 2431] loss: 0.0250989404\n",
      "[timestep: 1] [epoch: 2461] loss: 0.0105813276\n",
      "[timestep: 1] [epoch: 2491] loss: 0.0208727345\n",
      "[timestep: 1] [epoch: 2521] loss: 0.0101008741\n",
      "[timestep: 1] [epoch: 2551] loss: 0.0096413679\n",
      "[timestep: 1] [epoch: 2581] loss: 0.0039304728\n",
      "[timestep: 1] [epoch: 2611] loss: 0.0042777499\n",
      "[timestep: 1] [epoch: 2641] loss: 0.0041046846\n",
      "[timestep: 1] [epoch: 2671] loss: 0.0087174848\n",
      "[timestep: 1] [epoch: 2701] loss: 0.0069315559\n",
      "[timestep: 1] [epoch: 2731] loss: 0.0041503534\n",
      "[timestep: 1] [epoch: 2761] loss: 0.0080339722\n",
      "[timestep: 1] [epoch: 2791] loss: 0.0067380355\n",
      "[timestep: 1] [epoch: 2821] loss: 0.0067446316\n",
      "[timestep: 1] [epoch: 2851] loss: 0.0049951617\n",
      "[timestep: 1] [epoch: 2881] loss: 0.0138954055\n",
      "[timestep: 1] [epoch: 2911] loss: 0.0096839834\n",
      "[timestep: 1] [epoch: 2941] loss: 0.0048491596\n",
      "[timestep: 1] [epoch: 2971] loss: 0.0084709637\n",
      "[timestep: 1] [epoch: 3001] loss: 0.0077380263\n",
      "[timestep: 1] [epoch: 3031] loss: 0.0113764443\n",
      "[timestep: 1] [epoch: 3061] loss: 0.0142858941\n",
      "[timestep: 1] [epoch: 3091] loss: 0.0114952354\n",
      "[timestep: 1] [epoch: 3121] loss: 0.0126685873\n",
      "[timestep: 1] [epoch: 3151] loss: 0.0038784498\n",
      "[timestep: 1] [epoch: 3181] loss: 0.0056319395\n",
      "[timestep: 1] [epoch: 3211] loss: 0.0049314229\n",
      "[timestep: 1] [epoch: 3241] loss: 0.0132288421\n",
      "[timestep: 1] [epoch: 3271] loss: 0.0044483291\n",
      "[timestep: 1] [epoch: 3301] loss: 0.0083828550\n",
      "[timestep: 1] [epoch: 3331] loss: 0.0103017557\n",
      "[timestep: 1] [epoch: 3361] loss: 0.0040756487\n",
      "[timestep: 1] [epoch: 3391] loss: 0.0015115393\n",
      "[timestep: 1] [epoch: 3421] loss: 0.0021404179\n",
      "[timestep: 1] [epoch: 3451] loss: 0.0036729304\n",
      "[timestep: 1] [epoch: 3481] loss: 0.0016390714\n",
      "[timestep: 1] [epoch: 3511] loss: 0.0127301896\n",
      "[timestep: 1] [epoch: 3541] loss: 0.0065935655\n",
      "[timestep: 1] [epoch: 3571] loss: 0.0035274678\n",
      "[timestep: 1] [epoch: 3601] loss: 0.0065111695\n",
      "[timestep: 1] [epoch: 3631] loss: 0.0076105925\n",
      "[timestep: 1] [epoch: 3661] loss: 0.0058764769\n",
      "[timestep: 1] [epoch: 3691] loss: 0.0095280148\n",
      "[timestep: 1] [epoch: 3721] loss: 0.0026268251\n",
      "0.01\n",
      "[timestep: 2] [epoch: 1] loss: 0.9334982038\n",
      "[timestep: 2] [epoch: 31] loss: 0.1098070517\n",
      "[timestep: 2] [epoch: 61] loss: 0.0328061134\n",
      "[timestep: 2] [epoch: 91] loss: 0.0362833068\n",
      "[timestep: 2] [epoch: 121] loss: 0.0051575638\n",
      "[timestep: 2] [epoch: 151] loss: 0.0072478750\n",
      "[timestep: 2] [epoch: 181] loss: 0.0061414354\n",
      "[timestep: 2] [epoch: 211] loss: 0.0048682955\n",
      "[timestep: 2] [epoch: 241] loss: 0.0087697543\n",
      "[timestep: 2] [epoch: 271] loss: 0.0106909331\n",
      "[timestep: 2] [epoch: 301] loss: 0.0059148734\n",
      "[timestep: 2] [epoch: 331] loss: 0.0127207227\n",
      "[timestep: 2] [epoch: 361] loss: 0.0088695548\n",
      "[timestep: 2] [epoch: 391] loss: 0.0104931677\n",
      "[timestep: 2] [epoch: 421] loss: 0.0089565041\n",
      "[timestep: 2] [epoch: 451] loss: 0.0139724799\n",
      "[timestep: 2] [epoch: 481] loss: 0.0248989556\n",
      "[timestep: 2] [epoch: 511] loss: 0.0052635632\n",
      "[timestep: 2] [epoch: 541] loss: 0.0048810472\n",
      "[timestep: 2] [epoch: 571] loss: 0.0100929039\n",
      "[timestep: 2] [epoch: 601] loss: 0.0104556177\n",
      "[timestep: 2] [epoch: 631] loss: 0.0050782571\n",
      "[timestep: 2] [epoch: 661] loss: 0.0046869963\n",
      "[timestep: 2] [epoch: 691] loss: 0.0101799294\n",
      "[timestep: 2] [epoch: 721] loss: 0.0096196001\n",
      "[timestep: 2] [epoch: 751] loss: 0.0094167069\n",
      "[timestep: 2] [epoch: 781] loss: 0.0071048271\n",
      "[timestep: 2] [epoch: 811] loss: 0.0059520267\n",
      "[timestep: 2] [epoch: 841] loss: 0.0091332318\n",
      "[timestep: 2] [epoch: 871] loss: 0.0072802906\n",
      "[timestep: 2] [epoch: 901] loss: 0.0093292650\n",
      "[timestep: 2] [epoch: 931] loss: 0.0158101209\n",
      "[timestep: 2] [epoch: 961] loss: 0.0038490295\n",
      "[timestep: 2] [epoch: 991] loss: 0.0051495149\n",
      "[timestep: 2] [epoch: 1021] loss: 0.0117614307\n",
      "[timestep: 2] [epoch: 1051] loss: 0.0072500068\n",
      "[timestep: 2] [epoch: 1081] loss: 0.0126465559\n",
      "[timestep: 2] [epoch: 1111] loss: 0.0088070314\n",
      "[timestep: 2] [epoch: 1141] loss: 0.0071362676\n",
      "[timestep: 2] [epoch: 1171] loss: 0.0030066515\n",
      "[timestep: 2] [epoch: 1201] loss: 0.0025273226\n",
      "[timestep: 2] [epoch: 1231] loss: 0.0073906486\n",
      "[timestep: 2] [epoch: 1261] loss: 0.0040616496\n",
      "[timestep: 2] [epoch: 1291] loss: 0.0048634498\n",
      "[timestep: 2] [epoch: 1321] loss: 0.0074880696\n",
      "[timestep: 2] [epoch: 1351] loss: 0.0048478367\n",
      "[timestep: 2] [epoch: 1381] loss: 0.0090527833\n",
      "[timestep: 2] [epoch: 1411] loss: 0.0083081061\n",
      "[timestep: 2] [epoch: 1441] loss: 0.0069908970\n",
      "[timestep: 2] [epoch: 1471] loss: 0.0080119884\n",
      "[timestep: 2] [epoch: 1501] loss: 0.0043019732\n",
      "[timestep: 2] [epoch: 1531] loss: 0.0088231340\n",
      "[timestep: 2] [epoch: 1561] loss: 0.0070314538\n",
      "[timestep: 2] [epoch: 1591] loss: 0.0277556162\n",
      "[timestep: 2] [epoch: 1621] loss: 0.0044086054\n",
      "[timestep: 2] [epoch: 1651] loss: 0.0109703830\n",
      "[timestep: 2] [epoch: 1681] loss: 0.0190301687\n",
      "[timestep: 2] [epoch: 1711] loss: 0.0118167596\n",
      "[timestep: 2] [epoch: 1741] loss: 0.0066947113\n",
      "[timestep: 2] [epoch: 1771] loss: 0.0143577810\n",
      "[timestep: 2] [epoch: 1801] loss: 0.0081671551\n",
      "[timestep: 2] [epoch: 1831] loss: 0.0014151004\n",
      "[timestep: 2] [epoch: 1861] loss: 0.0016492205\n",
      "[timestep: 2] [epoch: 1891] loss: 0.0016820028\n",
      "[timestep: 2] [epoch: 1921] loss: 0.0067018191\n",
      "[timestep: 2] [epoch: 1951] loss: 0.0051485812\n",
      "[timestep: 2] [epoch: 1981] loss: 0.0101858415\n",
      "[timestep: 2] [epoch: 2011] loss: 0.0062139360\n",
      "[timestep: 2] [epoch: 2041] loss: 0.0081702350\n",
      "[timestep: 2] [epoch: 2071] loss: 0.0063886661\n",
      "[timestep: 2] [epoch: 2101] loss: 0.0063230782\n",
      "[timestep: 2] [epoch: 2131] loss: 0.0075158430\n",
      "[timestep: 2] [epoch: 2161] loss: 0.0050745411\n",
      "[timestep: 2] [epoch: 2191] loss: 0.0062046065\n",
      "[timestep: 2] [epoch: 2221] loss: 0.0147531200\n",
      "[timestep: 2] [epoch: 2251] loss: 0.0055602160\n",
      "[timestep: 2] [epoch: 2281] loss: 0.0071883933\n",
      "[timestep: 2] [epoch: 2311] loss: 0.0048022661\n",
      "[timestep: 2] [epoch: 2341] loss: 0.0114894928\n",
      "[timestep: 2] [epoch: 2371] loss: 0.0090866452\n",
      "[timestep: 2] [epoch: 2401] loss: 0.0056988676\n",
      "[timestep: 2] [epoch: 2431] loss: 0.0085635278\n",
      "[timestep: 2] [epoch: 2461] loss: 0.0030241660\n",
      "[timestep: 2] [epoch: 2491] loss: 0.0061103990\n",
      "[timestep: 2] [epoch: 2521] loss: 0.0027542869\n",
      "[timestep: 2] [epoch: 2551] loss: 0.0059747468\n",
      "[timestep: 2] [epoch: 2581] loss: 0.0068336576\n",
      "[timestep: 2] [epoch: 2611] loss: 0.0047263904\n",
      "[timestep: 2] [epoch: 2641] loss: 0.0031253984\n",
      "[timestep: 2] [epoch: 2671] loss: 0.0109969266\n",
      "[timestep: 2] [epoch: 2701] loss: 0.0047453381\n",
      "[timestep: 2] [epoch: 2731] loss: 0.0064961743\n",
      "[timestep: 2] [epoch: 2761] loss: 0.0038879919\n",
      "[timestep: 2] [epoch: 2791] loss: 0.0061036651\n",
      "[timestep: 2] [epoch: 2821] loss: 0.0074360664\n",
      "[timestep: 2] [epoch: 2851] loss: 0.0064622732\n",
      "[timestep: 2] [epoch: 2881] loss: 0.0038048467\n",
      "[timestep: 2] [epoch: 2911] loss: 0.0018959285\n",
      "[timestep: 2] [epoch: 2941] loss: 0.0048903376\n",
      "[timestep: 2] [epoch: 2971] loss: 0.0010976212\n",
      "0.01\n",
      "[timestep: 3] [epoch: 1] loss: 0.8923900127\n",
      "[timestep: 3] [epoch: 31] loss: 0.0738416463\n",
      "[timestep: 3] [epoch: 61] loss: 0.0332513377\n",
      "[timestep: 3] [epoch: 91] loss: 0.0148662440\n",
      "[timestep: 3] [epoch: 121] loss: 0.0141736371\n",
      "[timestep: 3] [epoch: 151] loss: 0.0186117012\n",
      "[timestep: 3] [epoch: 181] loss: 0.0191825964\n",
      "[timestep: 3] [epoch: 211] loss: 0.0174752902\n",
      "[timestep: 3] [epoch: 241] loss: 0.0204398911\n",
      "[timestep: 3] [epoch: 271] loss: 0.0195143484\n",
      "[timestep: 3] [epoch: 301] loss: 0.0199455172\n",
      "[timestep: 3] [epoch: 331] loss: 0.0199098065\n",
      "[timestep: 3] [epoch: 361] loss: 0.0175624043\n",
      "[timestep: 3] [epoch: 391] loss: 0.0227991547\n",
      "[timestep: 3] [epoch: 421] loss: 0.0201883335\n",
      "[timestep: 3] [epoch: 451] loss: 0.0140504083\n",
      "[timestep: 3] [epoch: 481] loss: 0.0146655496\n",
      "[timestep: 3] [epoch: 511] loss: 0.0159227140\n",
      "[timestep: 3] [epoch: 541] loss: 0.0155717889\n",
      "[timestep: 3] [epoch: 571] loss: 0.0267381966\n",
      "[timestep: 3] [epoch: 601] loss: 0.0202672966\n",
      "[timestep: 3] [epoch: 631] loss: 0.0178506374\n",
      "[timestep: 3] [epoch: 661] loss: 0.0208410788\n",
      "[timestep: 3] [epoch: 691] loss: 0.0151983900\n",
      "[timestep: 3] [epoch: 721] loss: 0.0303392913\n",
      "[timestep: 3] [epoch: 751] loss: 0.0165346339\n",
      "[timestep: 3] [epoch: 781] loss: 0.0175236650\n",
      "[timestep: 3] [epoch: 811] loss: 0.0240389816\n",
      "[timestep: 3] [epoch: 841] loss: 0.0181064159\n",
      "[timestep: 3] [epoch: 871] loss: 0.0182071477\n",
      "[timestep: 3] [epoch: 901] loss: 0.0206583291\n",
      "[timestep: 3] [epoch: 931] loss: 0.0189858526\n",
      "[timestep: 3] [epoch: 961] loss: 0.0176088624\n",
      "[timestep: 3] [epoch: 991] loss: 0.0274534672\n",
      "[timestep: 3] [epoch: 1021] loss: 0.0240745470\n",
      "[timestep: 3] [epoch: 1051] loss: 0.0189865101\n",
      "[timestep: 3] [epoch: 1081] loss: 0.0182066858\n",
      "[timestep: 3] [epoch: 1111] loss: 0.0201912187\n",
      "[timestep: 3] [epoch: 1141] loss: 0.0167375244\n",
      "[timestep: 3] [epoch: 1171] loss: 0.0253113844\n",
      "[timestep: 3] [epoch: 1201] loss: 0.0155494940\n",
      "[timestep: 3] [epoch: 1231] loss: 0.0207283981\n",
      "[timestep: 3] [epoch: 1261] loss: 0.0182940327\n",
      "[timestep: 3] [epoch: 1291] loss: 0.0189696904\n",
      "[timestep: 3] [epoch: 1321] loss: 0.0171583779\n",
      "[timestep: 3] [epoch: 1351] loss: 0.0170113761\n",
      "[timestep: 3] [epoch: 1381] loss: 0.0198988989\n",
      "[timestep: 3] [epoch: 1411] loss: 0.0171935484\n",
      "[timestep: 3] [epoch: 1441] loss: 0.0171145275\n",
      "[timestep: 3] [epoch: 1471] loss: 0.0193904415\n",
      "[timestep: 3] [epoch: 1501] loss: 0.0169380754\n",
      "[timestep: 3] [epoch: 1531] loss: 0.0175081436\n",
      "[timestep: 3] [epoch: 1561] loss: 0.0146051943\n",
      "[timestep: 3] [epoch: 1591] loss: 0.0285696425\n",
      "[timestep: 3] [epoch: 1621] loss: 0.0187293794\n",
      "[timestep: 3] [epoch: 1651] loss: 0.0188066997\n",
      "[timestep: 3] [epoch: 1681] loss: 0.0154897915\n",
      "[timestep: 3] [epoch: 1711] loss: 0.0157067943\n",
      "[timestep: 3] [epoch: 1741] loss: 0.0151438098\n",
      "[timestep: 3] [epoch: 1771] loss: 0.0186421983\n",
      "[timestep: 3] [epoch: 1801] loss: 0.0147425616\n",
      "[timestep: 3] [epoch: 1831] loss: 0.0136089157\n",
      "[timestep: 3] [epoch: 1861] loss: 0.0121715944\n",
      "[timestep: 3] [epoch: 1891] loss: 0.0209285505\n",
      "[timestep: 3] [epoch: 1921] loss: 0.0169636179\n",
      "[timestep: 3] [epoch: 1951] loss: 0.0096782437\n",
      "[timestep: 3] [epoch: 1981] loss: 0.0099435905\n",
      "[timestep: 3] [epoch: 2011] loss: 0.0160832182\n",
      "[timestep: 3] [epoch: 2041] loss: 0.0224549808\n",
      "[timestep: 3] [epoch: 2071] loss: 0.0074022738\n",
      "[timestep: 3] [epoch: 2101] loss: 0.0120509844\n",
      "[timestep: 3] [epoch: 2131] loss: 0.0076186536\n",
      "0.01\n",
      "[timestep: 4] [epoch: 1] loss: 0.8725764751\n",
      "[timestep: 4] [epoch: 31] loss: 0.1206940562\n",
      "[timestep: 4] [epoch: 61] loss: 0.0420302376\n",
      "[timestep: 4] [epoch: 91] loss: 0.0196487680\n",
      "[timestep: 4] [epoch: 121] loss: 0.0026537823\n",
      "[timestep: 4] [epoch: 151] loss: 0.0046213390\n",
      "[timestep: 4] [epoch: 181] loss: 0.0011765106\n",
      "[timestep: 4] [epoch: 211] loss: 0.0108424099\n",
      "[timestep: 4] [epoch: 241] loss: 0.0077341204\n",
      "[timestep: 4] [epoch: 271] loss: 0.0159720145\n",
      "[timestep: 4] [epoch: 301] loss: 0.0051626493\n",
      "[timestep: 4] [epoch: 331] loss: 0.0121200280\n",
      "[timestep: 4] [epoch: 361] loss: 0.0071478444\n",
      "[timestep: 4] [epoch: 391] loss: 0.0141421743\n",
      "[timestep: 4] [epoch: 421] loss: 0.0054685706\n",
      "[timestep: 4] [epoch: 451] loss: 0.0125063676\n",
      "[timestep: 4] [epoch: 481] loss: 0.0051102657\n",
      "[timestep: 4] [epoch: 511] loss: 0.0059515778\n",
      "[timestep: 4] [epoch: 541] loss: 0.0071799550\n",
      "[timestep: 4] [epoch: 571] loss: 0.0075255558\n",
      "[timestep: 4] [epoch: 601] loss: 0.0058716321\n",
      "[timestep: 4] [epoch: 631] loss: 0.0100859944\n",
      "[timestep: 4] [epoch: 661] loss: 0.0084976908\n",
      "[timestep: 4] [epoch: 691] loss: 0.0110108387\n",
      "[timestep: 4] [epoch: 721] loss: 0.0058288127\n",
      "[timestep: 4] [epoch: 751] loss: 0.0064812684\n",
      "[timestep: 4] [epoch: 781] loss: 0.0089844093\n",
      "[timestep: 4] [epoch: 811] loss: 0.0080452375\n",
      "[timestep: 4] [epoch: 841] loss: 0.0076070502\n",
      "[timestep: 4] [epoch: 871] loss: 0.0051992289\n",
      "[timestep: 4] [epoch: 901] loss: 0.0059109991\n",
      "[timestep: 4] [epoch: 931] loss: 0.0056687975\n",
      "[timestep: 4] [epoch: 961] loss: 0.0070086773\n",
      "[timestep: 4] [epoch: 991] loss: 0.0126632983\n",
      "[timestep: 4] [epoch: 1021] loss: 0.0047444077\n",
      "[timestep: 4] [epoch: 1051] loss: 0.0077562965\n",
      "[timestep: 4] [epoch: 1081] loss: 0.0062391134\n",
      "[timestep: 4] [epoch: 1111] loss: 0.0039345212\n",
      "[timestep: 4] [epoch: 1141] loss: 0.0059317155\n",
      "[timestep: 4] [epoch: 1171] loss: 0.0047875699\n",
      "[timestep: 4] [epoch: 1201] loss: 0.0142122451\n",
      "[timestep: 4] [epoch: 1231] loss: 0.0054125842\n",
      "[timestep: 4] [epoch: 1261] loss: 0.0079930201\n",
      "[timestep: 4] [epoch: 1291] loss: 0.0059331423\n",
      "[timestep: 4] [epoch: 1321] loss: 0.0116983149\n",
      "0.01\n",
      "[timestep: 5] [epoch: 1] loss: 0.8651322126\n",
      "[timestep: 5] [epoch: 31] loss: 0.1183427125\n",
      "[timestep: 5] [epoch: 61] loss: 0.0234566256\n",
      "[timestep: 5] [epoch: 91] loss: 0.0031471034\n",
      "[timestep: 5] [epoch: 121] loss: 0.0090618599\n",
      "[timestep: 5] [epoch: 151] loss: 0.0040725577\n",
      "0.01\n",
      "[timestep: 6] [epoch: 1] loss: 0.8522514701\n",
      "[timestep: 6] [epoch: 31] loss: 0.0685429126\n",
      "[timestep: 6] [epoch: 61] loss: 0.0090343421\n",
      "[timestep: 6] [epoch: 91] loss: 0.0166737996\n",
      "[timestep: 6] [epoch: 121] loss: 0.0041599339\n",
      "0.01\n",
      "[timestep: 7] [epoch: 1] loss: 0.8399899602\n",
      "[timestep: 7] [epoch: 31] loss: 0.0430137962\n",
      "[timestep: 7] [epoch: 61] loss: 0.0209454261\n",
      "[timestep: 7] [epoch: 91] loss: 0.0143660950\n",
      "[timestep: 7] [epoch: 121] loss: 0.0054568648\n",
      "[timestep: 7] [epoch: 151] loss: 0.0121040940\n",
      "[timestep: 7] [epoch: 181] loss: 0.0125553226\n",
      "[timestep: 7] [epoch: 211] loss: 0.0239556357\n",
      "[timestep: 7] [epoch: 241] loss: 0.0074960138\n",
      "[timestep: 7] [epoch: 271] loss: 0.0089584347\n",
      "[timestep: 7] [epoch: 301] loss: 0.0049749115\n",
      "0.01\n",
      "[timestep: 8] [epoch: 1] loss: 0.8396345377\n",
      "[timestep: 8] [epoch: 31] loss: 0.0440430790\n",
      "[timestep: 8] [epoch: 61] loss: 0.0188656710\n",
      "[timestep: 8] [epoch: 91] loss: 0.0133819794\n",
      "0.01\n",
      "[timestep: 9] [epoch: 1] loss: 0.8456788063\n",
      "[timestep: 9] [epoch: 31] loss: 0.0462429971\n",
      "[timestep: 9] [epoch: 61] loss: 0.0075046076\n",
      "[timestep: 9] [epoch: 91] loss: 0.0319808386\n",
      "[timestep: 9] [epoch: 121] loss: 0.0162142627\n",
      "[timestep: 9] [epoch: 151] loss: 0.0097884769\n",
      "[timestep: 9] [epoch: 181] loss: 0.0029946603\n",
      "[timestep: 9] [epoch: 211] loss: 0.0133005586\n",
      "[timestep: 9] [epoch: 241] loss: 0.0074923974\n",
      "[timestep: 9] [epoch: 271] loss: 0.0063333656\n",
      "[timestep: 9] [epoch: 301] loss: 0.0023083440\n",
      "[timestep: 9] [epoch: 331] loss: 0.0111398883\n",
      "[timestep: 9] [epoch: 361] loss: 0.0169511717\n",
      "[timestep: 9] [epoch: 391] loss: 0.0067556161\n",
      "[timestep: 9] [epoch: 421] loss: 0.0121061383\n",
      "[timestep: 9] [epoch: 451] loss: 0.0072813150\n",
      "[timestep: 9] [epoch: 481] loss: 0.0224196687\n",
      "[timestep: 9] [epoch: 511] loss: 0.0137667675\n",
      "[timestep: 9] [epoch: 541] loss: 0.0082795415\n",
      "[timestep: 9] [epoch: 571] loss: 0.0021403437\n",
      "[timestep: 9] [epoch: 601] loss: 0.0157109462\n",
      "0.01\n",
      "[timestep: 10] [epoch: 1] loss: 0.8256465793\n",
      "[timestep: 10] [epoch: 31] loss: 0.0614717901\n",
      "[timestep: 10] [epoch: 61] loss: 0.0294345077\n",
      "[timestep: 10] [epoch: 91] loss: 0.0038134223\n",
      "[timestep: 10] [epoch: 121] loss: 0.0121362349\n",
      "[timestep: 10] [epoch: 151] loss: 0.0024716617\n",
      "[timestep: 10] [epoch: 181] loss: 0.0052914340\n",
      "[timestep: 10] [epoch: 211] loss: 0.0149730835\n",
      "[timestep: 10] [epoch: 241] loss: 0.0107558491\n",
      "[timestep: 10] [epoch: 271] loss: 0.0052907271\n",
      "[timestep: 10] [epoch: 301] loss: 0.0069243489\n",
      "[timestep: 10] [epoch: 331] loss: 0.0241793096\n",
      "[timestep: 10] [epoch: 361] loss: 0.0105038267\n",
      "[timestep: 10] [epoch: 391] loss: 0.0091439970\n",
      "[timestep: 10] [epoch: 421] loss: 0.0298182815\n",
      "[timestep: 10] [epoch: 451] loss: 0.0140506607\n",
      "[timestep: 10] [epoch: 481] loss: 0.0117249750\n",
      "[timestep: 10] [epoch: 511] loss: 0.0075718332\n",
      "[timestep: 10] [epoch: 541] loss: 0.0146828508\n",
      "[timestep: 10] [epoch: 571] loss: 0.0113792401\n",
      "[timestep: 10] [epoch: 601] loss: 0.0111776115\n",
      "[timestep: 10] [epoch: 631] loss: 0.0091602076\n",
      "[timestep: 10] [epoch: 661] loss: 0.0065294849\n",
      "[timestep: 10] [epoch: 691] loss: 0.0157661662\n",
      "[timestep: 10] [epoch: 721] loss: 0.0027252117\n",
      "[timestep: 10] [epoch: 751] loss: 0.0150117371\n",
      "[timestep: 10] [epoch: 781] loss: 0.0063736932\n",
      "[timestep: 10] [epoch: 811] loss: 0.0019231763\n",
      "[timestep: 10] [epoch: 841] loss: 0.0034576892\n",
      "[timestep: 10] [epoch: 871] loss: 0.0039756815\n",
      "[timestep: 10] [epoch: 901] loss: 0.0095810778\n",
      "0.01\n",
      "[timestep: 11] [epoch: 1] loss: 0.8245496154\n",
      "[timestep: 11] [epoch: 31] loss: 0.0522368401\n",
      "[timestep: 11] [epoch: 61] loss: 0.0156658441\n",
      "[timestep: 11] [epoch: 91] loss: 0.0047771353\n",
      "[timestep: 11] [epoch: 121] loss: 0.0089349914\n",
      "[timestep: 11] [epoch: 151] loss: 0.0024672558\n",
      "[timestep: 11] [epoch: 181] loss: 0.0181102213\n",
      "[timestep: 11] [epoch: 211] loss: 0.0132435625\n",
      "[timestep: 11] [epoch: 241] loss: 0.0141445212\n",
      "[timestep: 11] [epoch: 271] loss: 0.0051678456\n",
      "[timestep: 11] [epoch: 301] loss: 0.0041902522\n",
      "[timestep: 11] [epoch: 331] loss: 0.0091546895\n",
      "[timestep: 11] [epoch: 361] loss: 0.0121662561\n",
      "[timestep: 11] [epoch: 391] loss: 0.0029232071\n",
      "[timestep: 11] [epoch: 421] loss: 0.0046864762\n",
      "[timestep: 11] [epoch: 451] loss: 0.0029827249\n",
      "[timestep: 11] [epoch: 481] loss: 0.0053471820\n",
      "[timestep: 11] [epoch: 511] loss: 0.0044792518\n",
      "0.01\n",
      "[timestep: 12] [epoch: 1] loss: 0.8181968927\n",
      "[timestep: 12] [epoch: 31] loss: 0.0489412583\n",
      "[timestep: 12] [epoch: 61] loss: 0.0037485289\n",
      "[timestep: 12] [epoch: 91] loss: 0.0019176856\n",
      "[timestep: 12] [epoch: 121] loss: 0.0123230107\n",
      "0.01\n",
      "[timestep: 13] [epoch: 1] loss: 0.8250526190\n",
      "[timestep: 13] [epoch: 31] loss: 0.0693790019\n",
      "[timestep: 13] [epoch: 61] loss: 0.0066613685\n",
      "[timestep: 13] [epoch: 91] loss: 0.0091596823\n",
      "[timestep: 13] [epoch: 121] loss: 0.0100205801\n",
      "[timestep: 13] [epoch: 151] loss: 0.0119008143\n",
      "[timestep: 13] [epoch: 181] loss: 0.0127615863\n",
      "[timestep: 13] [epoch: 211] loss: 0.0112727471\n",
      "[timestep: 13] [epoch: 241] loss: 0.0100805666\n",
      "[timestep: 13] [epoch: 271] loss: 0.0168431066\n",
      "0.01\n",
      "[timestep: 14] [epoch: 1] loss: 0.8223006129\n",
      "[timestep: 14] [epoch: 31] loss: 0.0663709268\n",
      "[timestep: 14] [epoch: 61] loss: 0.0117365345\n",
      "[timestep: 14] [epoch: 91] loss: 0.0130818598\n",
      "[timestep: 14] [epoch: 121] loss: 0.0091290213\n",
      "[timestep: 14] [epoch: 151] loss: 0.0133554861\n",
      "[timestep: 14] [epoch: 181] loss: 0.0122665875\n",
      "[timestep: 14] [epoch: 211] loss: 0.0183503851\n",
      "[timestep: 14] [epoch: 241] loss: 0.0134120341\n",
      "[timestep: 14] [epoch: 271] loss: 0.0119099710\n",
      "[timestep: 14] [epoch: 301] loss: 0.0050013079\n",
      "[timestep: 14] [epoch: 331] loss: 0.0089382809\n",
      "[timestep: 14] [epoch: 361] loss: 0.0188677311\n",
      "[timestep: 14] [epoch: 391] loss: 0.0074475217\n",
      "[timestep: 14] [epoch: 421] loss: 0.0125998016\n",
      "[timestep: 14] [epoch: 451] loss: 0.0056987461\n",
      "[timestep: 14] [epoch: 481] loss: 0.0248633642\n",
      "[timestep: 14] [epoch: 511] loss: 0.0057712458\n",
      "[timestep: 14] [epoch: 541] loss: 0.0058089886\n",
      "[timestep: 14] [epoch: 571] loss: 0.0112779178\n",
      "[timestep: 14] [epoch: 601] loss: 0.0046754042\n",
      "[timestep: 14] [epoch: 631] loss: 0.0341434553\n",
      "[timestep: 14] [epoch: 661] loss: 0.0066299471\n",
      "[timestep: 14] [epoch: 691] loss: 0.0083197895\n",
      "[timestep: 14] [epoch: 721] loss: 0.0081870519\n",
      "[timestep: 14] [epoch: 751] loss: 0.0146748312\n",
      "[timestep: 14] [epoch: 781] loss: 0.0093041658\n",
      "[timestep: 14] [epoch: 811] loss: 0.0177462772\n",
      "[timestep: 14] [epoch: 841] loss: 0.0055985292\n",
      "[timestep: 14] [epoch: 871] loss: 0.0133371763\n",
      "[timestep: 14] [epoch: 901] loss: 0.0080433339\n",
      "[timestep: 14] [epoch: 931] loss: 0.0066042566\n",
      "0.01\n",
      "[timestep: 15] [epoch: 1] loss: 0.8041092753\n",
      "[timestep: 15] [epoch: 31] loss: 0.0570274740\n",
      "[timestep: 15] [epoch: 61] loss: 0.0054130726\n",
      "[timestep: 15] [epoch: 91] loss: 0.0055893427\n",
      "[timestep: 15] [epoch: 121] loss: 0.0082263593\n",
      "[timestep: 15] [epoch: 151] loss: 0.0033916479\n",
      "[timestep: 15] [epoch: 181] loss: 0.0061557963\n",
      "[timestep: 15] [epoch: 211] loss: 0.0024106975\n",
      "[timestep: 15] [epoch: 241] loss: 0.0046876427\n",
      "[timestep: 15] [epoch: 271] loss: 0.0066328775\n",
      "[timestep: 15] [epoch: 301] loss: 0.0114801852\n",
      "[timestep: 15] [epoch: 331] loss: 0.0121589107\n",
      "[timestep: 15] [epoch: 361] loss: 0.0064553861\n",
      "[timestep: 15] [epoch: 391] loss: 0.0058105318\n",
      "[timestep: 15] [epoch: 421] loss: 0.0223150533\n",
      "[timestep: 15] [epoch: 451] loss: 0.0024647443\n",
      "[timestep: 15] [epoch: 481] loss: 0.0096651036\n",
      "[timestep: 15] [epoch: 511] loss: 0.0052823657\n",
      "[timestep: 15] [epoch: 541] loss: 0.0085984552\n",
      "[timestep: 15] [epoch: 571] loss: 0.0025291988\n",
      "[timestep: 15] [epoch: 601] loss: 0.0040934561\n",
      "[timestep: 15] [epoch: 631] loss: 0.0111104175\n",
      "[timestep: 15] [epoch: 661] loss: 0.0073570181\n",
      "[timestep: 15] [epoch: 691] loss: 0.0033480963\n",
      "[timestep: 15] [epoch: 721] loss: 0.0034658653\n",
      "[timestep: 15] [epoch: 751] loss: 0.0206955019\n",
      "[timestep: 15] [epoch: 781] loss: 0.0065131262\n",
      "[timestep: 15] [epoch: 811] loss: 0.0033688070\n",
      "[timestep: 15] [epoch: 841] loss: 0.0047156573\n",
      "[timestep: 15] [epoch: 871] loss: 0.0127313305\n",
      "[timestep: 15] [epoch: 901] loss: 0.0016969221\n",
      "[timestep: 15] [epoch: 931] loss: 0.0018671268\n",
      "[timestep: 15] [epoch: 961] loss: 0.0100378096\n",
      "[timestep: 15] [epoch: 991] loss: 0.0049206745\n",
      "[timestep: 15] [epoch: 1021] loss: 0.0177971814\n",
      "[timestep: 15] [epoch: 1051] loss: 0.0031759273\n",
      "[timestep: 15] [epoch: 1081] loss: 0.0054473612\n",
      "[timestep: 15] [epoch: 1111] loss: 0.0149524966\n",
      "[timestep: 15] [epoch: 1141] loss: 0.0033668780\n",
      "[timestep: 15] [epoch: 1171] loss: 0.0022368599\n",
      "[timestep: 15] [epoch: 1201] loss: 0.0041345111\n",
      "[timestep: 15] [epoch: 1231] loss: 0.0060510947\n",
      "[timestep: 15] [epoch: 1261] loss: 0.0106606279\n",
      "[timestep: 15] [epoch: 1291] loss: 0.0142565696\n",
      "[timestep: 15] [epoch: 1321] loss: 0.0096789114\n",
      "[timestep: 15] [epoch: 1351] loss: 0.0086185243\n",
      "[timestep: 15] [epoch: 1381] loss: 0.0031646052\n",
      "[timestep: 15] [epoch: 1411] loss: 0.0147507265\n",
      "[timestep: 15] [epoch: 1441] loss: 0.0036982754\n",
      "[timestep: 15] [epoch: 1471] loss: 0.0036213002\n",
      "[timestep: 15] [epoch: 1501] loss: 0.0039994828\n",
      "[timestep: 15] [epoch: 1531] loss: 0.0115820644\n",
      "[timestep: 15] [epoch: 1561] loss: 0.0096088629\n",
      "[timestep: 15] [epoch: 1591] loss: 0.0120684216\n",
      "[timestep: 15] [epoch: 1621] loss: 0.0158369187\n",
      "[timestep: 15] [epoch: 1651] loss: 0.0137316361\n",
      "[timestep: 15] [epoch: 1681] loss: 0.0145884091\n",
      "[timestep: 15] [epoch: 1711] loss: 0.0089336578\n",
      "[timestep: 15] [epoch: 1741] loss: 0.0069872169\n",
      "[timestep: 15] [epoch: 1771] loss: 0.0161035210\n",
      "[timestep: 15] [epoch: 1801] loss: 0.0075286161\n",
      "[timestep: 15] [epoch: 1831] loss: 0.0057177963\n",
      "[timestep: 15] [epoch: 1861] loss: 0.0092238942\n",
      "[timestep: 15] [epoch: 1891] loss: 0.0076201381\n",
      "[timestep: 15] [epoch: 1921] loss: 0.0071871490\n",
      "[timestep: 15] [epoch: 1951] loss: 0.0068075764\n",
      "[timestep: 15] [epoch: 1981] loss: 0.0059133843\n",
      "[timestep: 15] [epoch: 2011] loss: 0.0075427676\n",
      "[timestep: 15] [epoch: 2041] loss: 0.0090613337\n",
      "[timestep: 15] [epoch: 2071] loss: 0.0054418622\n",
      "[timestep: 15] [epoch: 2101] loss: 0.0122605450\n",
      "[timestep: 15] [epoch: 2131] loss: 0.0071115699\n",
      "[timestep: 15] [epoch: 2161] loss: 0.0183282979\n",
      "[timestep: 15] [epoch: 2191] loss: 0.0445591360\n",
      "[timestep: 15] [epoch: 2221] loss: 0.0092370678\n",
      "[timestep: 15] [epoch: 2251] loss: 0.0102632679\n",
      "[timestep: 15] [epoch: 2281] loss: 0.0015570730\n",
      "0.01\n",
      "[timestep: 16] [epoch: 1] loss: 0.8046816587\n",
      "[timestep: 16] [epoch: 31] loss: 0.0293377042\n",
      "[timestep: 16] [epoch: 61] loss: 0.0054964591\n",
      "[timestep: 16] [epoch: 91] loss: 0.0147936251\n",
      "[timestep: 16] [epoch: 121] loss: 0.0054127490\n",
      "[timestep: 16] [epoch: 151] loss: 0.0080252402\n",
      "[timestep: 16] [epoch: 181] loss: 0.0068161185\n",
      "[timestep: 16] [epoch: 211] loss: 0.0126662506\n",
      "[timestep: 16] [epoch: 241] loss: 0.0036136203\n",
      "[timestep: 16] [epoch: 271] loss: 0.0192185454\n",
      "[timestep: 16] [epoch: 301] loss: 0.0038312019\n",
      "[timestep: 16] [epoch: 331] loss: 0.0032315606\n",
      "[timestep: 16] [epoch: 361] loss: 0.0117147304\n",
      "[timestep: 16] [epoch: 391] loss: 0.0047746599\n",
      "[timestep: 16] [epoch: 421] loss: 0.0039550895\n",
      "[timestep: 16] [epoch: 451] loss: 0.0085158553\n",
      "[timestep: 16] [epoch: 481] loss: 0.0155605413\n",
      "[timestep: 16] [epoch: 511] loss: 0.0032203309\n",
      "[timestep: 16] [epoch: 541] loss: 0.0024023815\n",
      "[timestep: 16] [epoch: 571] loss: 0.0034173569\n",
      "[timestep: 16] [epoch: 601] loss: 0.0028214876\n",
      "[timestep: 16] [epoch: 631] loss: 0.0060426239\n",
      "[timestep: 16] [epoch: 661] loss: 0.0079418328\n",
      "[timestep: 16] [epoch: 691] loss: 0.0070759119\n",
      "[timestep: 16] [epoch: 721] loss: 0.0070084147\n",
      "[timestep: 16] [epoch: 751] loss: 0.0391500220\n",
      "[timestep: 16] [epoch: 781] loss: 0.0046799961\n",
      "[timestep: 16] [epoch: 811] loss: 0.0088071767\n",
      "[timestep: 16] [epoch: 841] loss: 0.0046630362\n",
      "[timestep: 16] [epoch: 871] loss: 0.0137605425\n",
      "[timestep: 16] [epoch: 901] loss: 0.0022595630\n",
      "[timestep: 16] [epoch: 931] loss: 0.0061054677\n",
      "[timestep: 16] [epoch: 961] loss: 0.0049545188\n",
      "[timestep: 16] [epoch: 991] loss: 0.0030568251\n",
      "[timestep: 16] [epoch: 1021] loss: 0.0073133600\n",
      "[timestep: 16] [epoch: 1051] loss: 0.0098352563\n",
      "[timestep: 16] [epoch: 1081] loss: 0.0081375567\n",
      "[timestep: 16] [epoch: 1111] loss: 0.0061157439\n",
      "[timestep: 16] [epoch: 1141] loss: 0.0071926336\n",
      "[timestep: 16] [epoch: 1171] loss: 0.0046894122\n",
      "[timestep: 16] [epoch: 1201] loss: 0.0047374587\n",
      "[timestep: 16] [epoch: 1231] loss: 0.0032485155\n",
      "[timestep: 16] [epoch: 1261] loss: 0.0074792719\n",
      "[timestep: 16] [epoch: 1291] loss: 0.0067057088\n",
      "[timestep: 16] [epoch: 1321] loss: 0.0090281703\n",
      "[timestep: 16] [epoch: 1351] loss: 0.0041785575\n",
      "[timestep: 16] [epoch: 1381] loss: 0.0026564472\n",
      "[timestep: 16] [epoch: 1411] loss: 0.0080223726\n",
      "[timestep: 16] [epoch: 1441] loss: 0.0037317025\n",
      "[timestep: 16] [epoch: 1471] loss: 0.0137508474\n",
      "[timestep: 16] [epoch: 1501] loss: 0.0069006584\n",
      "[timestep: 16] [epoch: 1531] loss: 0.0039508976\n",
      "[timestep: 16] [epoch: 1561] loss: 0.0300120935\n",
      "[timestep: 16] [epoch: 1591] loss: 0.0035642018\n",
      "[timestep: 16] [epoch: 1621] loss: 0.0054857209\n",
      "[timestep: 16] [epoch: 1651] loss: 0.0061165919\n",
      "[timestep: 16] [epoch: 1681] loss: 0.0049783681\n",
      "[timestep: 16] [epoch: 1711] loss: 0.0058353478\n",
      "[timestep: 16] [epoch: 1741] loss: 0.0050480170\n",
      "[timestep: 16] [epoch: 1771] loss: 0.0023885146\n",
      "[timestep: 16] [epoch: 1801] loss: 0.0161846150\n",
      "[timestep: 16] [epoch: 1831] loss: 0.0115646226\n",
      "[timestep: 16] [epoch: 1861] loss: 0.0086038243\n",
      "[timestep: 16] [epoch: 1891] loss: 0.0076593505\n",
      "[timestep: 16] [epoch: 1921] loss: 0.0028061047\n",
      "[timestep: 16] [epoch: 1951] loss: 0.0043186685\n",
      "[timestep: 16] [epoch: 1981] loss: 0.0059717838\n",
      "[timestep: 16] [epoch: 2011] loss: 0.0042502899\n",
      "[timestep: 16] [epoch: 2041] loss: 0.0094900802\n",
      "[timestep: 16] [epoch: 2071] loss: 0.0041178521\n",
      "[timestep: 16] [epoch: 2101] loss: 0.0247838106\n",
      "[timestep: 16] [epoch: 2131] loss: 0.0035630986\n",
      "[timestep: 16] [epoch: 2161] loss: 0.0033333190\n",
      "[timestep: 16] [epoch: 2191] loss: 0.0057799751\n",
      "[timestep: 16] [epoch: 2221] loss: 0.0059478823\n",
      "[timestep: 16] [epoch: 2251] loss: 0.0046265777\n",
      "[timestep: 16] [epoch: 2281] loss: 0.0056976085\n",
      "[timestep: 16] [epoch: 2311] loss: 0.0026916179\n",
      "[timestep: 16] [epoch: 2341] loss: 0.0187425092\n",
      "[timestep: 16] [epoch: 2371] loss: 0.0065275026\n",
      "[timestep: 16] [epoch: 2401] loss: 0.0072908523\n",
      "[timestep: 16] [epoch: 2431] loss: 0.0039025112\n",
      "[timestep: 16] [epoch: 2461] loss: 0.0047402140\n",
      "[timestep: 16] [epoch: 2491] loss: 0.0027695554\n",
      "[timestep: 16] [epoch: 2521] loss: 0.0041477457\n",
      "[timestep: 16] [epoch: 2551] loss: 0.0118358433\n",
      "[timestep: 16] [epoch: 2581] loss: 0.0105042905\n",
      "[timestep: 16] [epoch: 2611] loss: 0.0063124560\n",
      "[timestep: 16] [epoch: 2641] loss: 0.0034536039\n",
      "[timestep: 16] [epoch: 2671] loss: 0.0048771817\n",
      "[timestep: 16] [epoch: 2701] loss: 0.0036315504\n",
      "[timestep: 16] [epoch: 2731] loss: 0.0048369486\n",
      "[timestep: 16] [epoch: 2761] loss: 0.0063373921\n",
      "[timestep: 16] [epoch: 2791] loss: 0.0040185507\n",
      "[timestep: 16] [epoch: 2821] loss: 0.0037460278\n",
      "[timestep: 16] [epoch: 2851] loss: 0.0119959014\n",
      "[timestep: 16] [epoch: 2881] loss: 0.0083955247\n",
      "[timestep: 16] [epoch: 2911] loss: 0.0038358285\n",
      "[timestep: 16] [epoch: 2941] loss: 0.0037578952\n",
      "[timestep: 16] [epoch: 2971] loss: 0.0059947744\n",
      "[timestep: 16] [epoch: 3001] loss: 0.0043256734\n",
      "[timestep: 16] [epoch: 3031] loss: 0.0066875769\n",
      "[timestep: 16] [epoch: 3061] loss: 0.0067667672\n",
      "[timestep: 16] [epoch: 3091] loss: 0.0086345542\n",
      "[timestep: 16] [epoch: 3121] loss: 0.0094040763\n",
      "[timestep: 16] [epoch: 3151] loss: 0.0026064375\n",
      "[timestep: 16] [epoch: 3181] loss: 0.0071872631\n",
      "[timestep: 16] [epoch: 3211] loss: 0.0042946273\n",
      "[timestep: 16] [epoch: 3241] loss: 0.0024300816\n",
      "[timestep: 16] [epoch: 3271] loss: 0.0090639535\n",
      "[timestep: 16] [epoch: 3301] loss: 0.0036991157\n",
      "[timestep: 16] [epoch: 3331] loss: 0.0036893561\n",
      "[timestep: 16] [epoch: 3361] loss: 0.0038462114\n",
      "[timestep: 16] [epoch: 3391] loss: 0.0065793735\n",
      "[timestep: 16] [epoch: 3421] loss: 0.0030728406\n",
      "[timestep: 16] [epoch: 3451] loss: 0.0023537388\n",
      "[timestep: 16] [epoch: 3481] loss: 0.0030951141\n",
      "[timestep: 16] [epoch: 3511] loss: 0.0044279085\n",
      "[timestep: 16] [epoch: 3541] loss: 0.0028105574\n",
      "[timestep: 16] [epoch: 3571] loss: 0.0025554635\n",
      "[timestep: 16] [epoch: 3601] loss: 0.0035647429\n",
      "[timestep: 16] [epoch: 3631] loss: 0.0033683290\n",
      "[timestep: 16] [epoch: 3661] loss: 0.0037893392\n",
      "[timestep: 16] [epoch: 3691] loss: 0.0047593447\n",
      "[timestep: 16] [epoch: 3721] loss: 0.0044650426\n",
      "[timestep: 16] [epoch: 3751] loss: 0.0078224000\n",
      "[timestep: 16] [epoch: 3781] loss: 0.0036512446\n",
      "[timestep: 16] [epoch: 3811] loss: 0.0032422869\n",
      "[timestep: 16] [epoch: 3841] loss: 0.0117385425\n",
      "[timestep: 16] [epoch: 3871] loss: 0.0059350636\n",
      "[timestep: 16] [epoch: 3901] loss: 0.0056169746\n",
      "[timestep: 16] [epoch: 3931] loss: 0.0080027264\n",
      "[timestep: 16] [epoch: 3961] loss: 0.0054837335\n",
      "[timestep: 16] [epoch: 3991] loss: 0.0046106977\n",
      "[timestep: 16] [epoch: 4021] loss: 0.0034844580\n",
      "[timestep: 16] [epoch: 4051] loss: 0.0025547340\n",
      "[timestep: 16] [epoch: 4081] loss: 0.0069383606\n",
      "[timestep: 16] [epoch: 4111] loss: 0.0035218799\n",
      "[timestep: 16] [epoch: 4141] loss: 0.0024633757\n",
      "[timestep: 16] [epoch: 4171] loss: 0.0053688223\n",
      "[timestep: 16] [epoch: 4201] loss: 0.0019577374\n",
      "[timestep: 16] [epoch: 4231] loss: 0.0043778582\n",
      "[timestep: 16] [epoch: 4261] loss: 0.0037155992\n",
      "[timestep: 16] [epoch: 4291] loss: 0.0087387580\n",
      "[timestep: 16] [epoch: 4321] loss: 0.0073141111\n",
      "[timestep: 16] [epoch: 4351] loss: 0.0036235775\n",
      "[timestep: 16] [epoch: 4381] loss: 0.0019502603\n",
      "[timestep: 16] [epoch: 4411] loss: 0.0022840644\n",
      "[timestep: 16] [epoch: 4441] loss: 0.0042980621\n",
      "[timestep: 16] [epoch: 4471] loss: 0.0036145374\n",
      "[timestep: 16] [epoch: 4501] loss: 0.0048321625\n",
      "[timestep: 16] [epoch: 4531] loss: 0.0041184742\n",
      "[timestep: 16] [epoch: 4561] loss: 0.0039327908\n",
      "[timestep: 16] [epoch: 4591] loss: 0.0047047557\n",
      "[timestep: 16] [epoch: 4621] loss: 0.0028648749\n",
      "[timestep: 16] [epoch: 4651] loss: 0.0110779852\n",
      "[timestep: 16] [epoch: 4681] loss: 0.0024213879\n",
      "[timestep: 16] [epoch: 4711] loss: 0.0029790867\n",
      "[timestep: 16] [epoch: 4741] loss: 0.0033994801\n",
      "[timestep: 16] [epoch: 4771] loss: 0.0110376067\n",
      "[timestep: 16] [epoch: 4801] loss: 0.0033550975\n",
      "[timestep: 16] [epoch: 4831] loss: 0.0048102224\n",
      "[timestep: 16] [epoch: 4861] loss: 0.0113308094\n",
      "[timestep: 16] [epoch: 4891] loss: 0.0050845323\n",
      "[timestep: 16] [epoch: 4921] loss: 0.0022134641\n",
      "[timestep: 16] [epoch: 4951] loss: 0.0030179424\n",
      "[timestep: 16] [epoch: 4981] loss: 0.0128924455\n",
      "[timestep: 16] [epoch: 5011] loss: 0.0057541700\n",
      "[timestep: 16] [epoch: 5041] loss: 0.0022452418\n",
      "[timestep: 16] [epoch: 5071] loss: 0.0021877822\n",
      "[timestep: 16] [epoch: 5101] loss: 0.0212911069\n",
      "[timestep: 16] [epoch: 5131] loss: 0.0071290866\n",
      "[timestep: 16] [epoch: 5161] loss: 0.0025813791\n",
      "[timestep: 16] [epoch: 5191] loss: 0.0035543661\n",
      "[timestep: 16] [epoch: 5221] loss: 0.0071046399\n",
      "[timestep: 16] [epoch: 5251] loss: 0.0040821144\n",
      "[timestep: 16] [epoch: 5281] loss: 0.0046309289\n",
      "[timestep: 16] [epoch: 5311] loss: 0.0024619345\n",
      "[timestep: 16] [epoch: 5341] loss: 0.0031304432\n",
      "[timestep: 16] [epoch: 5371] loss: 0.0066981390\n",
      "[timestep: 16] [epoch: 5401] loss: 0.0116877258\n",
      "[timestep: 16] [epoch: 5431] loss: 0.0065332032\n",
      "[timestep: 16] [epoch: 5461] loss: 0.0035748214\n",
      "[timestep: 16] [epoch: 5491] loss: 0.0019378831\n",
      "[timestep: 16] [epoch: 5521] loss: 0.0021660293\n",
      "[timestep: 16] [epoch: 5551] loss: 0.0074008657\n",
      "[timestep: 16] [epoch: 5581] loss: 0.0362016708\n",
      "[timestep: 16] [epoch: 5611] loss: 0.0035529169\n",
      "[timestep: 16] [epoch: 5641] loss: 0.0020798519\n",
      "[timestep: 16] [epoch: 5671] loss: 0.0017131297\n",
      "[timestep: 16] [epoch: 5701] loss: 0.0023942594\n",
      "[timestep: 16] [epoch: 5731] loss: 0.0022102180\n",
      "[timestep: 16] [epoch: 5761] loss: 0.0019075972\n",
      "[timestep: 16] [epoch: 5791] loss: 0.0040634507\n",
      "[timestep: 16] [epoch: 5821] loss: 0.0086676348\n",
      "[timestep: 16] [epoch: 5851] loss: 0.0058041862\n",
      "[timestep: 16] [epoch: 5881] loss: 0.0028543642\n",
      "[timestep: 16] [epoch: 5911] loss: 0.0026935781\n",
      "[timestep: 16] [epoch: 5941] loss: 0.0029203440\n",
      "[timestep: 16] [epoch: 5971] loss: 0.0020896844\n",
      "[timestep: 16] [epoch: 6001] loss: 0.0027113967\n",
      "[timestep: 16] [epoch: 6031] loss: 0.0141980294\n",
      "[timestep: 16] [epoch: 6061] loss: 0.0074685793\n",
      "[timestep: 16] [epoch: 6091] loss: 0.0028829800\n",
      "[timestep: 16] [epoch: 6121] loss: 0.0015927001\n",
      "[timestep: 16] [epoch: 6151] loss: 0.0019704322\n",
      "[timestep: 16] [epoch: 6181] loss: 0.0017500448\n",
      "[timestep: 16] [epoch: 6211] loss: 0.0021257366\n",
      "[timestep: 16] [epoch: 6241] loss: 0.0012573000\n",
      "[timestep: 16] [epoch: 6271] loss: 0.0095248967\n",
      "[timestep: 16] [epoch: 6301] loss: 0.0105252564\n",
      "[timestep: 16] [epoch: 6331] loss: 0.0031546275\n",
      "[timestep: 16] [epoch: 6361] loss: 0.0026277322\n",
      "[timestep: 16] [epoch: 6391] loss: 0.0013795224\n",
      "[timestep: 16] [epoch: 6421] loss: 0.0027262182\n",
      "[timestep: 16] [epoch: 6451] loss: 0.0031341040\n",
      "[timestep: 16] [epoch: 6481] loss: 0.0032140769\n",
      "[timestep: 16] [epoch: 6511] loss: 0.0044361148\n",
      "[timestep: 16] [epoch: 6541] loss: 0.0047151358\n",
      "[timestep: 16] [epoch: 6571] loss: 0.0023594694\n",
      "[timestep: 16] [epoch: 6601] loss: 0.0024544816\n",
      "0.01\n",
      "[timestep: 17] [epoch: 1] loss: 0.8039413691\n",
      "[timestep: 17] [epoch: 31] loss: 0.0275751185\n",
      "[timestep: 17] [epoch: 61] loss: 0.0061580115\n",
      "[timestep: 17] [epoch: 91] loss: 0.0057326118\n",
      "[timestep: 17] [epoch: 121] loss: 0.0076713115\n",
      "[timestep: 17] [epoch: 151] loss: 0.0075197001\n",
      "[timestep: 17] [epoch: 181] loss: 0.0131765809\n",
      "[timestep: 17] [epoch: 211] loss: 0.0048011434\n",
      "[timestep: 17] [epoch: 241] loss: 0.0115504935\n",
      "[timestep: 17] [epoch: 271] loss: 0.0071231467\n",
      "[timestep: 17] [epoch: 301] loss: 0.0071539897\n",
      "[timestep: 17] [epoch: 331] loss: 0.0075205648\n",
      "[timestep: 17] [epoch: 361] loss: 0.0051378310\n",
      "[timestep: 17] [epoch: 391] loss: 0.0243462063\n",
      "[timestep: 17] [epoch: 421] loss: 0.0059399321\n",
      "[timestep: 17] [epoch: 451] loss: 0.0173083954\n",
      "[timestep: 17] [epoch: 481] loss: 0.0056845285\n",
      "[timestep: 17] [epoch: 511] loss: 0.0181572661\n",
      "[timestep: 17] [epoch: 541] loss: 0.0110620614\n",
      "[timestep: 17] [epoch: 571] loss: 0.0077267974\n",
      "[timestep: 17] [epoch: 601] loss: 0.0126727307\n",
      "[timestep: 17] [epoch: 631] loss: 0.0227887034\n",
      "[timestep: 17] [epoch: 661] loss: 0.0214299113\n",
      "[timestep: 17] [epoch: 691] loss: 0.0070488998\n",
      "[timestep: 17] [epoch: 721] loss: 0.0058038319\n",
      "[timestep: 17] [epoch: 751] loss: 0.0088547152\n",
      "[timestep: 17] [epoch: 781] loss: 0.0091243386\n",
      "[timestep: 17] [epoch: 811] loss: 0.0043179682\n",
      "[timestep: 17] [epoch: 841] loss: 0.0052536321\n",
      "[timestep: 17] [epoch: 871] loss: 0.0213209465\n",
      "[timestep: 17] [epoch: 901] loss: 0.0048032487\n",
      "[timestep: 17] [epoch: 931] loss: 0.0061929147\n",
      "[timestep: 17] [epoch: 961] loss: 0.0071258117\n",
      "[timestep: 17] [epoch: 991] loss: 0.0061413408\n",
      "[timestep: 17] [epoch: 1021] loss: 0.0051283254\n",
      "[timestep: 17] [epoch: 1051] loss: 0.0051381718\n",
      "[timestep: 17] [epoch: 1081] loss: 0.0107217114\n",
      "[timestep: 17] [epoch: 1111] loss: 0.0086388122\n",
      "[timestep: 17] [epoch: 1141] loss: 0.0061544152\n",
      "[timestep: 17] [epoch: 1171] loss: 0.0065750903\n",
      "[timestep: 17] [epoch: 1201] loss: 0.0073242038\n",
      "[timestep: 17] [epoch: 1231] loss: 0.0046591493\n",
      "[timestep: 17] [epoch: 1261] loss: 0.0057732849\n",
      "[timestep: 17] [epoch: 1291] loss: 0.0084915068\n",
      "[timestep: 17] [epoch: 1321] loss: 0.0053335028\n",
      "[timestep: 17] [epoch: 1351] loss: 0.0069030593\n",
      "[timestep: 17] [epoch: 1381] loss: 0.0094084488\n",
      "[timestep: 17] [epoch: 1411] loss: 0.0083464347\n",
      "[timestep: 17] [epoch: 1441] loss: 0.0050509060\n",
      "[timestep: 17] [epoch: 1471] loss: 0.0099236434\n",
      "[timestep: 17] [epoch: 1501] loss: 0.0099500846\n",
      "[timestep: 17] [epoch: 1531] loss: 0.0156273097\n",
      "[timestep: 17] [epoch: 1561] loss: 0.0092154667\n",
      "[timestep: 17] [epoch: 1591] loss: 0.0121655967\n",
      "[timestep: 17] [epoch: 1621] loss: 0.0059724883\n",
      "[timestep: 17] [epoch: 1651] loss: 0.0042964881\n",
      "[timestep: 17] [epoch: 1681] loss: 0.0076540867\n",
      "[timestep: 17] [epoch: 1711] loss: 0.0064253313\n",
      "[timestep: 17] [epoch: 1741] loss: 0.0041146907\n",
      "[timestep: 17] [epoch: 1771] loss: 0.0050665531\n",
      "[timestep: 17] [epoch: 1801] loss: 0.0060556456\n",
      "[timestep: 17] [epoch: 1831] loss: 0.0058346391\n",
      "[timestep: 17] [epoch: 1861] loss: 0.0083341049\n",
      "[timestep: 17] [epoch: 1891] loss: 0.0137942992\n",
      "[timestep: 17] [epoch: 1921] loss: 0.0063517513\n",
      "[timestep: 17] [epoch: 1951] loss: 0.0093078269\n",
      "[timestep: 17] [epoch: 1981] loss: 0.0127100637\n",
      "[timestep: 17] [epoch: 2011] loss: 0.0084664114\n",
      "[timestep: 17] [epoch: 2041] loss: 0.0072380248\n",
      "[timestep: 17] [epoch: 2071] loss: 0.0052272892\n",
      "[timestep: 17] [epoch: 2101] loss: 0.0054715746\n",
      "[timestep: 17] [epoch: 2131] loss: 0.0055343173\n",
      "[timestep: 17] [epoch: 2161] loss: 0.0240069684\n",
      "[timestep: 17] [epoch: 2191] loss: 0.0082348362\n",
      "[timestep: 17] [epoch: 2221] loss: 0.0049931910\n",
      "[timestep: 17] [epoch: 2251] loss: 0.0055360617\n",
      "[timestep: 17] [epoch: 2281] loss: 0.0067794397\n",
      "[timestep: 17] [epoch: 2311] loss: 0.0073789107\n",
      "[timestep: 17] [epoch: 2341] loss: 0.0088548958\n",
      "[timestep: 17] [epoch: 2371] loss: 0.0056438223\n",
      "[timestep: 17] [epoch: 2401] loss: 0.0087131187\n",
      "[timestep: 17] [epoch: 2431] loss: 0.0045732316\n",
      "[timestep: 17] [epoch: 2461] loss: 0.0177496038\n",
      "[timestep: 17] [epoch: 2491] loss: 0.0067604543\n",
      "[timestep: 17] [epoch: 2521] loss: 0.0045916028\n",
      "[timestep: 17] [epoch: 2551] loss: 0.0074800951\n",
      "[timestep: 17] [epoch: 2581] loss: 0.0058159465\n",
      "[timestep: 17] [epoch: 2611] loss: 0.0061627058\n",
      "[timestep: 17] [epoch: 2641] loss: 0.0046398491\n",
      "[timestep: 17] [epoch: 2671] loss: 0.0051065665\n",
      "[timestep: 17] [epoch: 2701] loss: 0.0089265089\n",
      "[timestep: 17] [epoch: 2731] loss: 0.0071673053\n",
      "[timestep: 17] [epoch: 2761] loss: 0.0044370522\n",
      "[timestep: 17] [epoch: 2791] loss: 0.0044763065\n",
      "[timestep: 17] [epoch: 2821] loss: 0.0069067571\n",
      "[timestep: 17] [epoch: 2851] loss: 0.0093167741\n",
      "[timestep: 17] [epoch: 2881] loss: 0.0111861276\n",
      "[timestep: 17] [epoch: 2911] loss: 0.0137447920\n",
      "[timestep: 17] [epoch: 2941] loss: 0.0046062102\n",
      "[timestep: 17] [epoch: 2971] loss: 0.0052092490\n",
      "[timestep: 17] [epoch: 3001] loss: 0.0043752277\n",
      "[timestep: 17] [epoch: 3031] loss: 0.0049262065\n",
      "[timestep: 17] [epoch: 3061] loss: 0.0066753412\n",
      "[timestep: 17] [epoch: 3091] loss: 0.0130773168\n",
      "[timestep: 17] [epoch: 3121] loss: 0.0060414402\n",
      "[timestep: 17] [epoch: 3151] loss: 0.0062171868\n",
      "[timestep: 17] [epoch: 3181] loss: 0.0132072847\n",
      "[timestep: 17] [epoch: 3211] loss: 0.0066872980\n",
      "[timestep: 17] [epoch: 3241] loss: 0.0051172515\n",
      "[timestep: 17] [epoch: 3271] loss: 0.0045693098\n",
      "[timestep: 17] [epoch: 3301] loss: 0.0139396153\n",
      "[timestep: 17] [epoch: 3331] loss: 0.0124784075\n",
      "[timestep: 17] [epoch: 3361] loss: 0.0143926078\n",
      "[timestep: 17] [epoch: 3391] loss: 0.0062341290\n",
      "[timestep: 17] [epoch: 3421] loss: 0.0046981191\n",
      "[timestep: 17] [epoch: 3451] loss: 0.0068917247\n",
      "[timestep: 17] [epoch: 3481] loss: 0.0066456958\n",
      "[timestep: 17] [epoch: 3511] loss: 0.0056738546\n",
      "[timestep: 17] [epoch: 3541] loss: 0.0048583676\n",
      "[timestep: 17] [epoch: 3571] loss: 0.0046176910\n",
      "[timestep: 17] [epoch: 3601] loss: 0.0245676078\n",
      "[timestep: 17] [epoch: 3631] loss: 0.0074102590\n",
      "[timestep: 17] [epoch: 3661] loss: 0.0058689155\n",
      "[timestep: 17] [epoch: 3691] loss: 0.0044735521\n",
      "[timestep: 17] [epoch: 3721] loss: 0.0047465870\n",
      "[timestep: 17] [epoch: 3751] loss: 0.0137706483\n",
      "[timestep: 17] [epoch: 3781] loss: 0.0089297518\n",
      "[timestep: 17] [epoch: 3811] loss: 0.0067203594\n",
      "[timestep: 17] [epoch: 3841] loss: 0.0048657237\n",
      "[timestep: 17] [epoch: 3871] loss: 0.0044093654\n",
      "[timestep: 17] [epoch: 3901] loss: 0.0085450923\n",
      "[timestep: 17] [epoch: 3931] loss: 0.0043411488\n",
      "[timestep: 17] [epoch: 3961] loss: 0.0072027845\n",
      "[timestep: 17] [epoch: 3991] loss: 0.0047510331\n",
      "[timestep: 17] [epoch: 4021] loss: 0.0071432944\n",
      "[timestep: 17] [epoch: 4051] loss: 0.0046092090\n",
      "[timestep: 17] [epoch: 4081] loss: 0.0045720721\n",
      "[timestep: 17] [epoch: 4111] loss: 0.0069725928\n",
      "[timestep: 17] [epoch: 4141] loss: 0.0049856058\n",
      "[timestep: 17] [epoch: 4171] loss: 0.0066556283\n",
      "[timestep: 17] [epoch: 4201] loss: 0.0133115333\n",
      "[timestep: 17] [epoch: 4231] loss: 0.0050625084\n",
      "[timestep: 17] [epoch: 4261] loss: 0.0047057103\n",
      "[timestep: 17] [epoch: 4291] loss: 0.0048134448\n",
      "[timestep: 17] [epoch: 4321] loss: 0.0067713186\n",
      "[timestep: 17] [epoch: 4351] loss: 0.0069470587\n",
      "[timestep: 17] [epoch: 4381] loss: 0.0151687916\n",
      "[timestep: 17] [epoch: 4411] loss: 0.0069250516\n",
      "[timestep: 17] [epoch: 4441] loss: 0.0044188509\n",
      "[timestep: 17] [epoch: 4471] loss: 0.0049905567\n",
      "[timestep: 17] [epoch: 4501] loss: 0.0045564827\n",
      "[timestep: 17] [epoch: 4531] loss: 0.0050457856\n",
      "[timestep: 17] [epoch: 4561] loss: 0.0053938087\n",
      "[timestep: 17] [epoch: 4591] loss: 0.0207772106\n",
      "[timestep: 17] [epoch: 4621] loss: 0.0090621784\n",
      "[timestep: 17] [epoch: 4651] loss: 0.0073152706\n",
      "[timestep: 17] [epoch: 4681] loss: 0.0055466043\n",
      "[timestep: 17] [epoch: 4711] loss: 0.0044283969\n",
      "[timestep: 17] [epoch: 4741] loss: 0.0050751045\n",
      "[timestep: 17] [epoch: 4771] loss: 0.0082826177\n",
      "[timestep: 17] [epoch: 4801] loss: 0.0073808059\n",
      "[timestep: 17] [epoch: 4831] loss: 0.0076229936\n",
      "[timestep: 17] [epoch: 4861] loss: 0.0061011054\n",
      "[timestep: 17] [epoch: 4891] loss: 0.0054306900\n",
      "[timestep: 17] [epoch: 4921] loss: 0.0049830400\n",
      "[timestep: 17] [epoch: 4951] loss: 0.0060003521\n",
      "[timestep: 17] [epoch: 4981] loss: 0.0201071315\n",
      "[timestep: 17] [epoch: 5011] loss: 0.0096576223\n",
      "[timestep: 17] [epoch: 5041] loss: 0.0044098017\n",
      "[timestep: 17] [epoch: 5071] loss: 0.0049133189\n",
      "[timestep: 17] [epoch: 5101] loss: 0.0047909748\n",
      "[timestep: 17] [epoch: 5131] loss: 0.0054922616\n",
      "[timestep: 17] [epoch: 5161] loss: 0.0049762018\n",
      "[timestep: 17] [epoch: 5191] loss: 0.0065086270\n",
      "[timestep: 17] [epoch: 5221] loss: 0.0086989375\n",
      "[timestep: 17] [epoch: 5251] loss: 0.0060306815\n",
      "[timestep: 17] [epoch: 5281] loss: 0.0045925342\n",
      "[timestep: 17] [epoch: 5311] loss: 0.0061751739\n",
      "[timestep: 17] [epoch: 5341] loss: 0.0062148459\n",
      "[timestep: 17] [epoch: 5371] loss: 0.0080137625\n",
      "[timestep: 17] [epoch: 5401] loss: 0.0053548999\n",
      "[timestep: 17] [epoch: 5431] loss: 0.0083354581\n",
      "[timestep: 17] [epoch: 5461] loss: 0.0051267762\n",
      "[timestep: 17] [epoch: 5491] loss: 0.0048676766\n",
      "[timestep: 17] [epoch: 5521] loss: 0.0095149837\n",
      "[timestep: 17] [epoch: 5551] loss: 0.0044308491\n",
      "[timestep: 17] [epoch: 5581] loss: 0.0054772580\n",
      "[timestep: 17] [epoch: 5611] loss: 0.0093172956\n",
      "[timestep: 17] [epoch: 5641] loss: 0.0120243290\n",
      "[timestep: 17] [epoch: 5671] loss: 0.0108633358\n",
      "[timestep: 17] [epoch: 5701] loss: 0.0050926954\n",
      "[timestep: 17] [epoch: 5731] loss: 0.0042302161\n",
      "[timestep: 17] [epoch: 5761] loss: 0.0043784557\n",
      "[timestep: 17] [epoch: 5791] loss: 0.0043548672\n",
      "[timestep: 17] [epoch: 5821] loss: 0.0043951152\n",
      "[timestep: 17] [epoch: 5851] loss: 0.0073805111\n",
      "[timestep: 17] [epoch: 5881] loss: 0.0063278107\n",
      "[timestep: 17] [epoch: 5911] loss: 0.0044604400\n",
      "[timestep: 17] [epoch: 5941] loss: 0.0043719923\n",
      "[timestep: 17] [epoch: 5971] loss: 0.0048026186\n",
      "[timestep: 17] [epoch: 6001] loss: 0.0066124098\n",
      "[timestep: 17] [epoch: 6031] loss: 0.0059972503\n",
      "[timestep: 17] [epoch: 6061] loss: 0.0047829729\n",
      "[timestep: 17] [epoch: 6091] loss: 0.0050362321\n",
      "[timestep: 17] [epoch: 6121] loss: 0.0044352673\n",
      "[timestep: 17] [epoch: 6151] loss: 0.0151004307\n",
      "[timestep: 17] [epoch: 6181] loss: 0.0055004377\n",
      "[timestep: 17] [epoch: 6211] loss: 0.0042441683\n",
      "[timestep: 17] [epoch: 6241] loss: 0.0042275796\n",
      "[timestep: 17] [epoch: 6271] loss: 0.0087140817\n",
      "[timestep: 17] [epoch: 6301] loss: 0.0050368011\n",
      "[timestep: 17] [epoch: 6331] loss: 0.0053984337\n",
      "[timestep: 17] [epoch: 6361] loss: 0.0076479260\n",
      "[timestep: 17] [epoch: 6391] loss: 0.0051640510\n",
      "[timestep: 17] [epoch: 6421] loss: 0.0044321599\n",
      "[timestep: 17] [epoch: 6451] loss: 0.0050409902\n",
      "[timestep: 17] [epoch: 6481] loss: 0.0079043815\n",
      "[timestep: 17] [epoch: 6511] loss: 0.0047884374\n",
      "[timestep: 17] [epoch: 6541] loss: 0.0068306490\n",
      "[timestep: 17] [epoch: 6571] loss: 0.0050715590\n",
      "[timestep: 17] [epoch: 6601] loss: 0.0148410164\n",
      "[timestep: 17] [epoch: 6631] loss: 0.0094758421\n",
      "[timestep: 17] [epoch: 6661] loss: 0.0071304273\n",
      "[timestep: 17] [epoch: 6691] loss: 0.0071423021\n",
      "[timestep: 17] [epoch: 6721] loss: 0.0047450964\n",
      "[timestep: 17] [epoch: 6751] loss: 0.0076398626\n",
      "[timestep: 17] [epoch: 6781] loss: 0.0063312496\n",
      "[timestep: 17] [epoch: 6811] loss: 0.0056765545\n",
      "[timestep: 17] [epoch: 6841] loss: 0.0044944263\n",
      "[timestep: 17] [epoch: 6871] loss: 0.0043220259\n",
      "[timestep: 17] [epoch: 6901] loss: 0.0049333884\n",
      "[timestep: 17] [epoch: 6931] loss: 0.0141136153\n",
      "[timestep: 17] [epoch: 6961] loss: 0.0097282361\n",
      "[timestep: 17] [epoch: 6991] loss: 0.0056740418\n",
      "[timestep: 17] [epoch: 7021] loss: 0.0041116998\n",
      "[timestep: 17] [epoch: 7051] loss: 0.0042909253\n",
      "[timestep: 17] [epoch: 7081] loss: 0.0041239695\n",
      "[timestep: 17] [epoch: 7111] loss: 0.0044441717\n",
      "[timestep: 17] [epoch: 7141] loss: 0.0042334800\n",
      "[timestep: 17] [epoch: 7171] loss: 0.0068254364\n",
      "[timestep: 17] [epoch: 7201] loss: 0.0042927666\n",
      "[timestep: 17] [epoch: 7231] loss: 0.0050996710\n",
      "[timestep: 17] [epoch: 7261] loss: 0.0043281172\n",
      "[timestep: 17] [epoch: 7291] loss: 0.0046038013\n",
      "[timestep: 17] [epoch: 7321] loss: 0.0089990264\n",
      "[timestep: 17] [epoch: 7351] loss: 0.0125533510\n",
      "[timestep: 17] [epoch: 7381] loss: 0.0060545020\n",
      "[timestep: 17] [epoch: 7411] loss: 0.0042138384\n",
      "[timestep: 17] [epoch: 7441] loss: 0.0043903384\n",
      "[timestep: 17] [epoch: 7471] loss: 0.0042316481\n",
      "[timestep: 17] [epoch: 7501] loss: 0.0057478291\n",
      "[timestep: 17] [epoch: 7531] loss: 0.0068471059\n",
      "[timestep: 17] [epoch: 7561] loss: 0.0048048939\n",
      "[timestep: 17] [epoch: 7591] loss: 0.0044482262\n",
      "[timestep: 17] [epoch: 7621] loss: 0.0130475480\n",
      "[timestep: 17] [epoch: 7651] loss: 0.0056941854\n",
      "[timestep: 17] [epoch: 7681] loss: 0.0056877341\n",
      "[timestep: 17] [epoch: 7711] loss: 0.0059072571\n",
      "[timestep: 17] [epoch: 7741] loss: 0.0045641409\n",
      "[timestep: 17] [epoch: 7771] loss: 0.0074988301\n",
      "[timestep: 17] [epoch: 7801] loss: 0.0062582623\n",
      "[timestep: 17] [epoch: 7831] loss: 0.0044159936\n",
      "[timestep: 17] [epoch: 7861] loss: 0.0045060571\n",
      "[timestep: 17] [epoch: 7891] loss: 0.0049577644\n",
      "[timestep: 17] [epoch: 7921] loss: 0.0056263795\n",
      "[timestep: 17] [epoch: 7951] loss: 0.0055564726\n",
      "[timestep: 17] [epoch: 7981] loss: 0.0067515853\n",
      "[timestep: 17] [epoch: 8011] loss: 0.0050932681\n",
      "[timestep: 17] [epoch: 8041] loss: 0.0052094618\n",
      "[timestep: 17] [epoch: 8071] loss: 0.0053814491\n",
      "[timestep: 17] [epoch: 8101] loss: 0.0052369414\n",
      "[timestep: 17] [epoch: 8131] loss: 0.0053091976\n",
      "[timestep: 17] [epoch: 8161] loss: 0.0064170449\n",
      "[timestep: 17] [epoch: 8191] loss: 0.0053370884\n",
      "[timestep: 17] [epoch: 8221] loss: 0.0056358194\n",
      "[timestep: 17] [epoch: 8251] loss: 0.0282402262\n",
      "[timestep: 17] [epoch: 8281] loss: 0.0467354953\n",
      "[timestep: 17] [epoch: 8311] loss: 0.0117696188\n",
      "[timestep: 17] [epoch: 8341] loss: 0.0052428325\n",
      "[timestep: 17] [epoch: 8371] loss: 0.0036192082\n",
      "[timestep: 17] [epoch: 8401] loss: 0.0046666982\n",
      "[timestep: 17] [epoch: 8431] loss: 0.0012547547\n",
      "[timestep: 17] [epoch: 8461] loss: 0.0010245771\n",
      "0.01\n",
      "[timestep: 18] [epoch: 1] loss: 0.7927799821\n",
      "[timestep: 18] [epoch: 31] loss: 0.0281763989\n",
      "[timestep: 18] [epoch: 61] loss: 0.0110870134\n",
      "[timestep: 18] [epoch: 91] loss: 0.0100820214\n",
      "[timestep: 18] [epoch: 121] loss: 0.0112215169\n",
      "[timestep: 18] [epoch: 151] loss: 0.0112525728\n",
      "[timestep: 18] [epoch: 181] loss: 0.0117377555\n",
      "[timestep: 18] [epoch: 211] loss: 0.0098772915\n",
      "[timestep: 18] [epoch: 241] loss: 0.0100384196\n",
      "[timestep: 18] [epoch: 271] loss: 0.0103942808\n",
      "[timestep: 18] [epoch: 301] loss: 0.0107451100\n",
      "[timestep: 18] [epoch: 331] loss: 0.0108351540\n",
      "[timestep: 18] [epoch: 361] loss: 0.0350900367\n",
      "[timestep: 18] [epoch: 391] loss: 0.0129016526\n",
      "[timestep: 18] [epoch: 421] loss: 0.0170157291\n",
      "[timestep: 18] [epoch: 451] loss: 0.0100440197\n",
      "[timestep: 18] [epoch: 481] loss: 0.0070576519\n",
      "[timestep: 18] [epoch: 511] loss: 0.0027049580\n",
      "[timestep: 18] [epoch: 541] loss: 0.0095427986\n",
      "[timestep: 18] [epoch: 571] loss: 0.0201666579\n",
      "[timestep: 18] [epoch: 601] loss: 0.0025249179\n",
      "[timestep: 18] [epoch: 631] loss: 0.0035013803\n",
      "[timestep: 18] [epoch: 661] loss: 0.0062475195\n",
      "[timestep: 18] [epoch: 691] loss: 0.0020704290\n",
      "[timestep: 18] [epoch: 721] loss: 0.0045431079\n",
      "[timestep: 18] [epoch: 751] loss: 0.0034180793\n",
      "[timestep: 18] [epoch: 781] loss: 0.0105514731\n",
      "[timestep: 18] [epoch: 811] loss: 0.0017051540\n",
      "[timestep: 18] [epoch: 841] loss: 0.0035934155\n",
      "[timestep: 18] [epoch: 871] loss: 0.0020545316\n",
      "[timestep: 18] [epoch: 901] loss: 0.0162505619\n",
      "[timestep: 18] [epoch: 931] loss: 0.0024711718\n",
      "[timestep: 18] [epoch: 961] loss: 0.0029219009\n",
      "0.01\n",
      "[timestep: 19] [epoch: 1] loss: 0.7881034017\n",
      "[timestep: 19] [epoch: 31] loss: 0.0353987664\n",
      "[timestep: 19] [epoch: 61] loss: 0.0169205070\n",
      "[timestep: 19] [epoch: 91] loss: 0.0035087047\n",
      "[timestep: 19] [epoch: 121] loss: 0.0024052623\n",
      "[timestep: 19] [epoch: 151] loss: 0.0027093338\n",
      "[timestep: 19] [epoch: 181] loss: 0.0058041727\n",
      "[timestep: 19] [epoch: 211] loss: 0.0032245293\n",
      "[timestep: 19] [epoch: 241] loss: 0.0045319833\n",
      "[timestep: 19] [epoch: 271] loss: 0.0055858763\n",
      "[timestep: 19] [epoch: 301] loss: 0.0212654620\n",
      "[timestep: 19] [epoch: 331] loss: 0.0048349770\n",
      "[timestep: 19] [epoch: 361] loss: 0.0102361664\n",
      "[timestep: 19] [epoch: 391] loss: 0.0036101767\n",
      "[timestep: 19] [epoch: 421] loss: 0.0036186548\n",
      "[timestep: 19] [epoch: 451] loss: 0.0069374349\n",
      "[timestep: 19] [epoch: 481] loss: 0.0025450345\n",
      "[timestep: 19] [epoch: 511] loss: 0.0030408809\n",
      "[timestep: 19] [epoch: 541] loss: 0.0030078231\n",
      "[timestep: 19] [epoch: 571] loss: 0.0023098635\n",
      "[timestep: 19] [epoch: 601] loss: 0.0097799413\n",
      "[timestep: 19] [epoch: 631] loss: 0.0066367607\n",
      "[timestep: 19] [epoch: 661] loss: 0.0199354645\n",
      "[timestep: 19] [epoch: 691] loss: 0.0032819386\n",
      "[timestep: 19] [epoch: 721] loss: 0.0038148258\n",
      "[timestep: 19] [epoch: 751] loss: 0.0041808020\n",
      "[timestep: 19] [epoch: 781] loss: 0.0029815319\n",
      "[timestep: 19] [epoch: 811] loss: 0.0024370947\n",
      "[timestep: 19] [epoch: 841] loss: 0.0064113922\n",
      "[timestep: 19] [epoch: 871] loss: 0.0080278181\n",
      "[timestep: 19] [epoch: 901] loss: 0.0048194658\n",
      "[timestep: 19] [epoch: 931] loss: 0.0029871773\n",
      "[timestep: 19] [epoch: 961] loss: 0.0048440685\n",
      "[timestep: 19] [epoch: 991] loss: 0.0071567572\n",
      "[timestep: 19] [epoch: 1021] loss: 0.0032960298\n",
      "[timestep: 19] [epoch: 1051] loss: 0.0058931052\n",
      "[timestep: 19] [epoch: 1081] loss: 0.0071866498\n",
      "[timestep: 19] [epoch: 1111] loss: 0.0024073692\n",
      "[timestep: 19] [epoch: 1141] loss: 0.0062985234\n",
      "[timestep: 19] [epoch: 1171] loss: 0.0047693499\n",
      "[timestep: 19] [epoch: 1201] loss: 0.0055200034\n",
      "[timestep: 19] [epoch: 1231] loss: 0.0026378776\n",
      "[timestep: 19] [epoch: 1261] loss: 0.0077119740\n",
      "[timestep: 19] [epoch: 1291] loss: 0.0032541566\n",
      "[timestep: 19] [epoch: 1321] loss: 0.0024425797\n",
      "[timestep: 19] [epoch: 1351] loss: 0.0030106087\n",
      "[timestep: 19] [epoch: 1381] loss: 0.0060885623\n",
      "[timestep: 19] [epoch: 1411] loss: 0.0069816071\n",
      "[timestep: 19] [epoch: 1441] loss: 0.0058311326\n",
      "[timestep: 19] [epoch: 1471] loss: 0.0036151423\n",
      "[timestep: 19] [epoch: 1501] loss: 0.0076545672\n",
      "[timestep: 19] [epoch: 1531] loss: 0.0034616906\n",
      "[timestep: 19] [epoch: 1561] loss: 0.0024478720\n",
      "[timestep: 19] [epoch: 1591] loss: 0.0079273703\n",
      "[timestep: 19] [epoch: 1621] loss: 0.0020732209\n",
      "[timestep: 19] [epoch: 1651] loss: 0.0021998675\n",
      "[timestep: 19] [epoch: 1681] loss: 0.0036294470\n",
      "[timestep: 19] [epoch: 1711] loss: 0.0042351177\n",
      "[timestep: 19] [epoch: 1741] loss: 0.0035761439\n",
      "[timestep: 19] [epoch: 1771] loss: 0.0033268766\n",
      "[timestep: 19] [epoch: 1801] loss: 0.0177796073\n",
      "[timestep: 19] [epoch: 1831] loss: 0.0145544149\n",
      "[timestep: 19] [epoch: 1861] loss: 0.0082064644\n",
      "[timestep: 19] [epoch: 1891] loss: 0.0478586890\n",
      "[timestep: 19] [epoch: 1921] loss: 0.0030721568\n",
      "[timestep: 19] [epoch: 1951] loss: 0.0015882386\n",
      "[timestep: 19] [epoch: 1981] loss: 0.0018665907\n",
      "[timestep: 19] [epoch: 2011] loss: 0.0016288152\n",
      "[timestep: 19] [epoch: 2041] loss: 0.0015078965\n",
      "[timestep: 19] [epoch: 2071] loss: 0.0036995313\n",
      "[timestep: 19] [epoch: 2101] loss: 0.0035682376\n",
      "[timestep: 19] [epoch: 2131] loss: 0.0017603633\n",
      "[timestep: 19] [epoch: 2161] loss: 0.0019938697\n",
      "[timestep: 19] [epoch: 2191] loss: 0.0037112683\n",
      "[timestep: 19] [epoch: 2221] loss: 0.0027262289\n",
      "[timestep: 19] [epoch: 2251] loss: 0.0028968484\n",
      "[timestep: 19] [epoch: 2281] loss: 0.0029458622\n",
      "[timestep: 19] [epoch: 2311] loss: 0.0022874889\n",
      "[timestep: 19] [epoch: 2341] loss: 0.0045406469\n",
      "[timestep: 19] [epoch: 2371] loss: 0.0049806796\n",
      "[timestep: 19] [epoch: 2401] loss: 0.0130408024\n",
      "[timestep: 19] [epoch: 2431] loss: 0.0026071137\n",
      "[timestep: 19] [epoch: 2461] loss: 0.0050578667\n",
      "[timestep: 19] [epoch: 2491] loss: 0.0059119267\n",
      "[timestep: 19] [epoch: 2521] loss: 0.0041584321\n",
      "[timestep: 19] [epoch: 2551] loss: 0.0021367462\n",
      "[timestep: 19] [epoch: 2581] loss: 0.0064679035\n",
      "[timestep: 19] [epoch: 2611] loss: 0.0027526477\n",
      "[timestep: 19] [epoch: 2641] loss: 0.0018598003\n",
      "[timestep: 19] [epoch: 2671] loss: 0.0018039711\n",
      "[timestep: 19] [epoch: 2701] loss: 0.0060905563\n",
      "[timestep: 19] [epoch: 2731] loss: 0.0050328160\n",
      "[timestep: 19] [epoch: 2761] loss: 0.0042888746\n",
      "[timestep: 19] [epoch: 2791] loss: 0.0024445378\n",
      "[timestep: 19] [epoch: 2821] loss: 0.0023604566\n",
      "[timestep: 19] [epoch: 2851] loss: 0.0023273446\n",
      "[timestep: 19] [epoch: 2881] loss: 0.0059141573\n",
      "[timestep: 19] [epoch: 2911] loss: 0.0018020917\n",
      "[timestep: 19] [epoch: 2941] loss: 0.0031066951\n",
      "[timestep: 19] [epoch: 2971] loss: 0.0030764451\n",
      "[timestep: 19] [epoch: 3001] loss: 0.0043295668\n",
      "[timestep: 19] [epoch: 3031] loss: 0.0020934176\n",
      "[timestep: 19] [epoch: 3061] loss: 0.0032302146\n",
      "[timestep: 19] [epoch: 3091] loss: 0.0152110383\n",
      "[timestep: 19] [epoch: 3121] loss: 0.0056460397\n",
      "[timestep: 19] [epoch: 3151] loss: 0.0022040613\n",
      "[timestep: 19] [epoch: 3181] loss: 0.0036434415\n",
      "[timestep: 19] [epoch: 3211] loss: 0.0021494057\n",
      "[timestep: 19] [epoch: 3241] loss: 0.0038838026\n",
      "[timestep: 19] [epoch: 3271] loss: 0.0043764813\n",
      "[timestep: 19] [epoch: 3301] loss: 0.0019756453\n",
      "[timestep: 19] [epoch: 3331] loss: 0.0023754667\n",
      "[timestep: 19] [epoch: 3361] loss: 0.0020034155\n",
      "[timestep: 19] [epoch: 3391] loss: 0.0074070580\n",
      "[timestep: 19] [epoch: 3421] loss: 0.0027673778\n",
      "[timestep: 19] [epoch: 3451] loss: 0.0018962382\n",
      "[timestep: 19] [epoch: 3481] loss: 0.0024519227\n",
      "[timestep: 19] [epoch: 3511] loss: 0.0046409545\n",
      "[timestep: 19] [epoch: 3541] loss: 0.0085714106\n",
      "[timestep: 19] [epoch: 3571] loss: 0.0100227837\n",
      "[timestep: 19] [epoch: 3601] loss: 0.0184806529\n",
      "[timestep: 19] [epoch: 3631] loss: 0.0093093645\n",
      "[timestep: 19] [epoch: 3661] loss: 0.0113934632\n",
      "[timestep: 19] [epoch: 3691] loss: 0.0108217755\n",
      "[timestep: 19] [epoch: 3721] loss: 0.0043947482\n",
      "[timestep: 19] [epoch: 3751] loss: 0.0089991782\n",
      "[timestep: 19] [epoch: 3781] loss: 0.0055260742\n",
      "[timestep: 19] [epoch: 3811] loss: 0.0063560684\n",
      "[timestep: 19] [epoch: 3841] loss: 0.0059538856\n",
      "[timestep: 19] [epoch: 3871] loss: 0.0074906461\n",
      "[timestep: 19] [epoch: 3901] loss: 0.0037490383\n",
      "[timestep: 19] [epoch: 3931] loss: 0.0073536127\n",
      "[timestep: 19] [epoch: 3961] loss: 0.0077807470\n",
      "[timestep: 19] [epoch: 3991] loss: 0.0061088498\n",
      "[timestep: 19] [epoch: 4021] loss: 0.0043961303\n",
      "[timestep: 19] [epoch: 4051] loss: 0.0064855833\n",
      "[timestep: 19] [epoch: 4081] loss: 0.0063595939\n",
      "[timestep: 19] [epoch: 4111] loss: 0.0084831202\n",
      "[timestep: 19] [epoch: 4141] loss: 0.0085160304\n",
      "[timestep: 19] [epoch: 4171] loss: 0.0072645405\n",
      "[timestep: 19] [epoch: 4201] loss: 0.0040732380\n",
      "[timestep: 19] [epoch: 4231] loss: 0.0057804873\n",
      "[timestep: 19] [epoch: 4261] loss: 0.0034873241\n",
      "[timestep: 19] [epoch: 4291] loss: 0.0036727330\n",
      "[timestep: 19] [epoch: 4321] loss: 0.0016362000\n",
      "[timestep: 19] [epoch: 4351] loss: 0.0022728480\n",
      "[timestep: 19] [epoch: 4381] loss: 0.0046172338\n",
      "[timestep: 19] [epoch: 4411] loss: 0.0019913306\n",
      "[timestep: 19] [epoch: 4441] loss: 0.0021823538\n",
      "[timestep: 19] [epoch: 4471] loss: 0.0025427202\n",
      "[timestep: 19] [epoch: 4501] loss: 0.0116056651\n",
      "[timestep: 19] [epoch: 4531] loss: 0.0031420323\n",
      "[timestep: 19] [epoch: 4561] loss: 0.0015657763\n",
      "[timestep: 19] [epoch: 4591] loss: 0.0016700313\n",
      "[timestep: 19] [epoch: 4621] loss: 0.0014193568\n",
      "[timestep: 19] [epoch: 4651] loss: 0.0018963570\n",
      "[timestep: 19] [epoch: 4681] loss: 0.0115210954\n",
      "[timestep: 19] [epoch: 4711] loss: 0.0024296334\n",
      "[timestep: 19] [epoch: 4741] loss: 0.0017741079\n",
      "[timestep: 19] [epoch: 4771] loss: 0.0048711863\n",
      "[timestep: 19] [epoch: 4801] loss: 0.0020575162\n",
      "[timestep: 19] [epoch: 4831] loss: 0.0016935156\n",
      "[timestep: 19] [epoch: 4861] loss: 0.0019878068\n",
      "[timestep: 19] [epoch: 4891] loss: 0.0039161304\n",
      "[timestep: 19] [epoch: 4921] loss: 0.0017912481\n",
      "[timestep: 19] [epoch: 4951] loss: 0.0118243154\n",
      "[timestep: 19] [epoch: 4981] loss: 0.0023777816\n",
      "[timestep: 19] [epoch: 5011] loss: 0.0034072504\n",
      "[timestep: 19] [epoch: 5041] loss: 0.0025809151\n",
      "[timestep: 19] [epoch: 5071] loss: 0.0072095608\n",
      "[timestep: 19] [epoch: 5101] loss: 0.0018708429\n",
      "[timestep: 19] [epoch: 5131] loss: 0.0026691998\n",
      "[timestep: 19] [epoch: 5161] loss: 0.0046565700\n",
      "[timestep: 19] [epoch: 5191] loss: 0.0030887078\n",
      "[timestep: 19] [epoch: 5221] loss: 0.0023273518\n",
      "[timestep: 19] [epoch: 5251] loss: 0.0023164940\n",
      "[timestep: 19] [epoch: 5281] loss: 0.0022516293\n",
      "[timestep: 19] [epoch: 5311] loss: 0.0067727352\n",
      "[timestep: 19] [epoch: 5341] loss: 0.0018537098\n",
      "[timestep: 19] [epoch: 5371] loss: 0.0015474471\n",
      "[timestep: 19] [epoch: 5401] loss: 0.0021653357\n",
      "[timestep: 19] [epoch: 5431] loss: 0.0102018230\n",
      "[timestep: 19] [epoch: 5461] loss: 0.0073062247\n",
      "[timestep: 19] [epoch: 5491] loss: 0.0130091961\n",
      "[timestep: 19] [epoch: 5521] loss: 0.0135106994\n",
      "[timestep: 19] [epoch: 5551] loss: 0.0027290708\n",
      "[timestep: 19] [epoch: 5581] loss: 0.0022985917\n",
      "[timestep: 19] [epoch: 5611] loss: 0.0017156745\n",
      "[timestep: 19] [epoch: 5641] loss: 0.0019538463\n",
      "[timestep: 19] [epoch: 5671] loss: 0.0069331806\n",
      "[timestep: 19] [epoch: 5701] loss: 0.0015579833\n",
      "[timestep: 19] [epoch: 5731] loss: 0.0026642615\n",
      "[timestep: 19] [epoch: 5761] loss: 0.0027410723\n",
      "[timestep: 19] [epoch: 5791] loss: 0.0030676092\n",
      "[timestep: 19] [epoch: 5821] loss: 0.0015687719\n",
      "[timestep: 19] [epoch: 5851] loss: 0.0026538251\n",
      "[timestep: 19] [epoch: 5881] loss: 0.0019631335\n",
      "[timestep: 19] [epoch: 5911] loss: 0.0072090379\n",
      "[timestep: 19] [epoch: 5941] loss: 0.0039604045\n",
      "[timestep: 19] [epoch: 5971] loss: 0.0021839964\n",
      "[timestep: 19] [epoch: 6001] loss: 0.0018589355\n",
      "[timestep: 19] [epoch: 6031] loss: 0.0036165498\n",
      "[timestep: 19] [epoch: 6061] loss: 0.0026539250\n",
      "[timestep: 19] [epoch: 6091] loss: 0.0044306694\n",
      "[timestep: 19] [epoch: 6121] loss: 0.0019289968\n",
      "[timestep: 19] [epoch: 6151] loss: 0.0020733092\n",
      "[timestep: 19] [epoch: 6181] loss: 0.0026360094\n",
      "[timestep: 19] [epoch: 6211] loss: 0.0017939868\n",
      "[timestep: 19] [epoch: 6241] loss: 0.0250313133\n",
      "[timestep: 19] [epoch: 6271] loss: 0.0034334152\n",
      "[timestep: 19] [epoch: 6301] loss: 0.0020605277\n",
      "[timestep: 19] [epoch: 6331] loss: 0.0016649504\n",
      "[timestep: 19] [epoch: 6361] loss: 0.0016606334\n",
      "[timestep: 19] [epoch: 6391] loss: 0.0016164309\n",
      "[timestep: 19] [epoch: 6421] loss: 0.0018041244\n",
      "[timestep: 19] [epoch: 6451] loss: 0.0016309625\n",
      "[timestep: 19] [epoch: 6481] loss: 0.0023886668\n",
      "[timestep: 19] [epoch: 6511] loss: 0.0029619606\n",
      "[timestep: 19] [epoch: 6541] loss: 0.0040288679\n",
      "[timestep: 19] [epoch: 6571] loss: 0.0135075795\n",
      "[timestep: 19] [epoch: 6601] loss: 0.0091859447\n",
      "[timestep: 19] [epoch: 6631] loss: 0.0024440514\n",
      "[timestep: 19] [epoch: 6661] loss: 0.0017135066\n",
      "[timestep: 19] [epoch: 6691] loss: 0.0015798692\n",
      "[timestep: 19] [epoch: 6721] loss: 0.0029098056\n",
      "[timestep: 19] [epoch: 6751] loss: 0.0027849120\n",
      "[timestep: 19] [epoch: 6781] loss: 0.0018581379\n",
      "[timestep: 19] [epoch: 6811] loss: 0.0027783532\n",
      "[timestep: 19] [epoch: 6841] loss: 0.0022201000\n",
      "[timestep: 19] [epoch: 6871] loss: 0.0018467031\n",
      "[timestep: 19] [epoch: 6901] loss: 0.0019286100\n",
      "[timestep: 19] [epoch: 6931] loss: 0.0016908585\n",
      "[timestep: 19] [epoch: 6961] loss: 0.0243494175\n",
      "[timestep: 19] [epoch: 6991] loss: 0.0046674116\n",
      "[timestep: 19] [epoch: 7021] loss: 0.0019181096\n",
      "[timestep: 19] [epoch: 7051] loss: 0.0016931889\n",
      "[timestep: 19] [epoch: 7081] loss: 0.0016170846\n",
      "[timestep: 19] [epoch: 7111] loss: 0.0014332917\n",
      "[timestep: 19] [epoch: 7141] loss: 0.0020484922\n",
      "[timestep: 19] [epoch: 7171] loss: 0.0037371977\n",
      "[timestep: 19] [epoch: 7201] loss: 0.0037425361\n",
      "[timestep: 19] [epoch: 7231] loss: 0.0039897067\n",
      "[timestep: 19] [epoch: 7261] loss: 0.0047554402\n",
      "[timestep: 19] [epoch: 7291] loss: 0.0032679141\n",
      "[timestep: 19] [epoch: 7321] loss: 0.0018679409\n",
      "[timestep: 19] [epoch: 7351] loss: 0.0081150513\n",
      "[timestep: 19] [epoch: 7381] loss: 0.0087829027\n",
      "[timestep: 19] [epoch: 7411] loss: 0.0019629826\n",
      "[timestep: 19] [epoch: 7441] loss: 0.0016135663\n",
      "[timestep: 19] [epoch: 7471] loss: 0.0014737162\n",
      "[timestep: 19] [epoch: 7501] loss: 0.0027265996\n",
      "[timestep: 19] [epoch: 7531] loss: 0.0019007715\n",
      "[timestep: 19] [epoch: 7561] loss: 0.0020699310\n",
      "[timestep: 19] [epoch: 7591] loss: 0.0044443887\n",
      "[timestep: 19] [epoch: 7621] loss: 0.0023061514\n",
      "[timestep: 19] [epoch: 7651] loss: 0.0104560982\n",
      "[timestep: 19] [epoch: 7681] loss: 0.0166318696\n",
      "[timestep: 19] [epoch: 7711] loss: 0.0067204218\n",
      "[timestep: 19] [epoch: 7741] loss: 0.0014799089\n",
      "[timestep: 19] [epoch: 7771] loss: 0.0014937758\n",
      "[timestep: 19] [epoch: 7801] loss: 0.0014927068\n",
      "[timestep: 19] [epoch: 7831] loss: 0.0013985869\n",
      "[timestep: 19] [epoch: 7861] loss: 0.0014820443\n",
      "[timestep: 19] [epoch: 7891] loss: 0.0014996153\n",
      "[timestep: 19] [epoch: 7921] loss: 0.0022078964\n",
      "[timestep: 19] [epoch: 7951] loss: 0.0015651761\n",
      "[timestep: 19] [epoch: 7981] loss: 0.0024317349\n",
      "[timestep: 19] [epoch: 8011] loss: 0.0015054226\n",
      "[timestep: 19] [epoch: 8041] loss: 0.0020571167\n",
      "[timestep: 19] [epoch: 8071] loss: 0.0062403223\n",
      "[timestep: 19] [epoch: 8101] loss: 0.0020411126\n",
      "[timestep: 19] [epoch: 8131] loss: 0.0019433072\n",
      "[timestep: 19] [epoch: 8161] loss: 0.0052069183\n",
      "[timestep: 19] [epoch: 8191] loss: 0.0015058714\n",
      "[timestep: 19] [epoch: 8221] loss: 0.0015137664\n",
      "[timestep: 19] [epoch: 8251] loss: 0.0021895673\n",
      "[timestep: 19] [epoch: 8281] loss: 0.0021552851\n",
      "[timestep: 19] [epoch: 8311] loss: 0.0043382249\n",
      "[timestep: 19] [epoch: 8341] loss: 0.0037985221\n",
      "[timestep: 19] [epoch: 8371] loss: 0.0017808527\n",
      "[timestep: 19] [epoch: 8401] loss: 0.0025760182\n",
      "[timestep: 19] [epoch: 8431] loss: 0.0019078230\n",
      "[timestep: 19] [epoch: 8461] loss: 0.0015148836\n",
      "[timestep: 19] [epoch: 8491] loss: 0.0107617397\n",
      "[timestep: 19] [epoch: 8521] loss: 0.0034122490\n",
      "[timestep: 19] [epoch: 8551] loss: 0.0013216983\n",
      "[timestep: 19] [epoch: 8581] loss: 0.0024209844\n",
      "[timestep: 19] [epoch: 8611] loss: 0.0010388849\n",
      "[timestep: 19] [epoch: 8641] loss: 0.0011066380\n",
      "[timestep: 19] [epoch: 8671] loss: 0.0013143953\n",
      "[timestep: 19] [epoch: 8701] loss: 0.0017623316\n",
      "[timestep: 19] [epoch: 8731] loss: 0.0024523831\n",
      "[timestep: 19] [epoch: 8761] loss: 0.0023662075\n",
      "[timestep: 19] [epoch: 8791] loss: 0.0059167026\n",
      "[timestep: 19] [epoch: 8821] loss: 0.0022990196\n",
      "[timestep: 19] [epoch: 8851] loss: 0.0016363438\n",
      "[timestep: 19] [epoch: 8881] loss: 0.0015400583\n",
      "[timestep: 19] [epoch: 8911] loss: 0.0015667272\n",
      "[timestep: 19] [epoch: 8941] loss: 0.0016195519\n",
      "[timestep: 19] [epoch: 8971] loss: 0.0026710406\n",
      "[timestep: 19] [epoch: 9001] loss: 0.0017162838\n",
      "[timestep: 19] [epoch: 9031] loss: 0.0029641576\n",
      "[timestep: 19] [epoch: 9061] loss: 0.0017507445\n",
      "[timestep: 19] [epoch: 9091] loss: 0.0017933969\n",
      "[timestep: 19] [epoch: 9121] loss: 0.0013594890\n",
      "[timestep: 19] [epoch: 9151] loss: 0.0015906538\n",
      "[timestep: 19] [epoch: 9181] loss: 0.0017746990\n",
      "[timestep: 19] [epoch: 9211] loss: 0.0046572131\n",
      "[timestep: 19] [epoch: 9241] loss: 0.0025619431\n",
      "[timestep: 19] [epoch: 9271] loss: 0.0014982321\n",
      "[timestep: 19] [epoch: 9301] loss: 0.0064183930\n",
      "[timestep: 19] [epoch: 9331] loss: 0.0013714249\n",
      "[timestep: 19] [epoch: 9361] loss: 0.0016434120\n",
      "[timestep: 19] [epoch: 9391] loss: 0.0018585217\n",
      "[timestep: 19] [epoch: 9421] loss: 0.0054434873\n",
      "[timestep: 19] [epoch: 9451] loss: 0.0010857412\n",
      "[timestep: 19] [epoch: 9481] loss: 0.0017384309\n",
      "[timestep: 19] [epoch: 9511] loss: 0.0011336416\n",
      "[timestep: 19] [epoch: 9541] loss: 0.0013366623\n",
      "[timestep: 19] [epoch: 9571] loss: 0.0029403931\n",
      "[timestep: 19] [epoch: 9601] loss: 0.0024447972\n",
      "[timestep: 19] [epoch: 9631] loss: 0.0015413940\n",
      "[timestep: 19] [epoch: 9661] loss: 0.0014000611\n",
      "[timestep: 19] [epoch: 9691] loss: 0.0113941636\n",
      "[timestep: 19] [epoch: 9721] loss: 0.0016794463\n",
      "[timestep: 19] [epoch: 9751] loss: 0.0011973155\n",
      "[timestep: 19] [epoch: 9781] loss: 0.0013164561\n",
      "[timestep: 19] [epoch: 9811] loss: 0.0011940254\n",
      "[timestep: 19] [epoch: 9841] loss: 0.0013195190\n",
      "[timestep: 19] [epoch: 9871] loss: 0.0064748726\n",
      "[timestep: 19] [epoch: 9901] loss: 0.0034551476\n",
      "[timestep: 19] [epoch: 9931] loss: 0.0012198262\n",
      "[timestep: 19] [epoch: 9961] loss: 0.0012570012\n",
      "0.01\n",
      "[timestep: 20] [epoch: 1] loss: 0.7934160233\n",
      "[timestep: 20] [epoch: 31] loss: 0.0171707198\n",
      "[timestep: 20] [epoch: 61] loss: 0.0014646754\n",
      "0.01\n",
      "[timestep: 21] [epoch: 1] loss: 0.7815767527\n",
      "[timestep: 21] [epoch: 31] loss: 0.0294088628\n",
      "[timestep: 21] [epoch: 61] loss: 0.0069952840\n",
      "[timestep: 21] [epoch: 91] loss: 0.0033292079\n",
      "0.01\n",
      "[timestep: 22] [epoch: 1] loss: 0.7781528234\n",
      "[timestep: 22] [epoch: 31] loss: 0.0381353572\n",
      "[timestep: 22] [epoch: 61] loss: 0.0023975729\n",
      "[timestep: 22] [epoch: 91] loss: 0.0014300789\n",
      "[timestep: 22] [epoch: 121] loss: 0.0014251543\n",
      "[timestep: 22] [epoch: 151] loss: 0.0014168292\n",
      "[timestep: 22] [epoch: 181] loss: 0.0035703259\n",
      "[timestep: 22] [epoch: 211] loss: 0.0049910992\n",
      "[timestep: 22] [epoch: 241] loss: 0.0015973824\n",
      "[timestep: 22] [epoch: 271] loss: 0.0063507166\n",
      "[timestep: 22] [epoch: 301] loss: 0.0039643561\n",
      "[timestep: 22] [epoch: 331] loss: 0.0022316556\n",
      "[timestep: 22] [epoch: 361] loss: 0.0023081168\n",
      "[timestep: 22] [epoch: 391] loss: 0.0024137367\n",
      "[timestep: 22] [epoch: 421] loss: 0.0027392590\n",
      "[timestep: 22] [epoch: 451] loss: 0.0034582100\n",
      "[timestep: 22] [epoch: 481] loss: 0.0017491984\n",
      "[timestep: 22] [epoch: 511] loss: 0.0133762378\n",
      "[timestep: 22] [epoch: 541] loss: 0.0023805923\n",
      "[timestep: 22] [epoch: 571] loss: 0.0071828002\n",
      "[timestep: 22] [epoch: 601] loss: 0.0071234843\n",
      "[timestep: 22] [epoch: 631] loss: 0.0027412274\n",
      "[timestep: 22] [epoch: 661] loss: 0.0093634045\n",
      "[timestep: 22] [epoch: 691] loss: 0.0027968620\n",
      "[timestep: 22] [epoch: 721] loss: 0.0044297492\n",
      "[timestep: 22] [epoch: 751] loss: 0.0037833350\n",
      "[timestep: 22] [epoch: 781] loss: 0.0021171388\n",
      "[timestep: 22] [epoch: 811] loss: 0.0081908945\n",
      "[timestep: 22] [epoch: 841] loss: 0.0042789998\n",
      "[timestep: 22] [epoch: 871] loss: 0.0016712405\n",
      "[timestep: 22] [epoch: 901] loss: 0.0082690166\n",
      "[timestep: 22] [epoch: 931] loss: 0.0037843662\n",
      "[timestep: 22] [epoch: 961] loss: 0.0061727734\n",
      "0.01\n",
      "[timestep: 23] [epoch: 1] loss: 0.7762349844\n",
      "[timestep: 23] [epoch: 31] loss: 0.0295803249\n",
      "[timestep: 23] [epoch: 61] loss: 0.0018730562\n",
      "0.01\n",
      "[timestep: 24] [epoch: 1] loss: 0.7763853073\n",
      "[timestep: 24] [epoch: 31] loss: 0.0278385431\n",
      "[timestep: 24] [epoch: 61] loss: 0.0030604885\n",
      "0.01\n",
      "[timestep: 25] [epoch: 1] loss: 0.7740669250\n",
      "[timestep: 25] [epoch: 31] loss: 0.0206984114\n",
      "[timestep: 25] [epoch: 61] loss: 0.0025435835\n",
      "[timestep: 25] [epoch: 91] loss: 0.0012816312\n",
      "0.01\n",
      "[timestep: 26] [epoch: 1] loss: 0.9672775269\n",
      "[timestep: 26] [epoch: 31] loss: 0.0316529050\n",
      "[timestep: 26] [epoch: 61] loss: 0.0024683708\n",
      "[timestep: 26] [epoch: 91] loss: 0.0010215756\n",
      "0.01\n",
      "[timestep: 27] [epoch: 1] loss: 0.6211483479\n",
      "[timestep: 27] [epoch: 31] loss: 0.6605025530\n",
      "[timestep: 27] [epoch: 61] loss: 0.0424550660\n",
      "[timestep: 27] [epoch: 91] loss: 0.0063133715\n",
      "[timestep: 27] [epoch: 121] loss: 0.0025674959\n",
      "[timestep: 27] [epoch: 151] loss: 0.0101620108\n",
      "[timestep: 27] [epoch: 181] loss: 0.0021021487\n",
      "[timestep: 27] [epoch: 211] loss: 0.0029600149\n",
      "[timestep: 27] [epoch: 241] loss: 0.0038156700\n",
      "[timestep: 27] [epoch: 271] loss: 0.0029187163\n",
      "[timestep: 27] [epoch: 301] loss: 0.0037598622\n",
      "[timestep: 27] [epoch: 331] loss: 0.0074541257\n",
      "[timestep: 27] [epoch: 361] loss: 0.0108942911\n",
      "[timestep: 27] [epoch: 391] loss: 0.0129173677\n",
      "[timestep: 27] [epoch: 421] loss: 0.0016596161\n",
      "[timestep: 27] [epoch: 451] loss: 0.0116077736\n",
      "[timestep: 27] [epoch: 481] loss: 0.0071922131\n",
      "[timestep: 27] [epoch: 511] loss: 0.0071358406\n",
      "[timestep: 27] [epoch: 541] loss: 0.0022069686\n",
      "[timestep: 27] [epoch: 571] loss: 0.0015359246\n",
      "[timestep: 27] [epoch: 601] loss: 0.0144422399\n",
      "[timestep: 27] [epoch: 631] loss: 0.0020378123\n",
      "[timestep: 27] [epoch: 661] loss: 0.0031871968\n",
      "[timestep: 27] [epoch: 691] loss: 0.0023453089\n",
      "[timestep: 27] [epoch: 721] loss: 0.0014200854\n",
      "[timestep: 27] [epoch: 751] loss: 0.0169122070\n",
      "[timestep: 27] [epoch: 781] loss: 0.0039644726\n",
      "[timestep: 27] [epoch: 811] loss: 0.0021568201\n",
      "[timestep: 27] [epoch: 841] loss: 0.0031715892\n",
      "[timestep: 27] [epoch: 871] loss: 0.0284842979\n",
      "[timestep: 27] [epoch: 901] loss: 0.0017606063\n",
      "[timestep: 27] [epoch: 931] loss: 0.0017993494\n",
      "[timestep: 27] [epoch: 961] loss: 0.0021925243\n",
      "[timestep: 27] [epoch: 991] loss: 0.0174521171\n",
      "[timestep: 27] [epoch: 1021] loss: 0.0042669075\n",
      "[timestep: 27] [epoch: 1051] loss: 0.0065736980\n",
      "[timestep: 27] [epoch: 1081] loss: 0.0085409544\n",
      "[timestep: 27] [epoch: 1111] loss: 0.0022075069\n",
      "[timestep: 27] [epoch: 1141] loss: 0.0053454703\n",
      "[timestep: 27] [epoch: 1171] loss: 0.0046816943\n",
      "[timestep: 27] [epoch: 1201] loss: 0.0160453059\n",
      "[timestep: 27] [epoch: 1231] loss: 0.0028735271\n",
      "[timestep: 27] [epoch: 1261] loss: 0.0087625375\n",
      "[timestep: 27] [epoch: 1291] loss: 0.0109783206\n",
      "[timestep: 27] [epoch: 1321] loss: 0.0015988906\n",
      "[timestep: 27] [epoch: 1351] loss: 0.0018174248\n",
      "[timestep: 27] [epoch: 1381] loss: 0.0071336711\n",
      "[timestep: 27] [epoch: 1411] loss: 0.0019323851\n",
      "[timestep: 27] [epoch: 1441] loss: 0.0053287256\n",
      "[timestep: 27] [epoch: 1471] loss: 0.0037180816\n",
      "[timestep: 27] [epoch: 1501] loss: 0.0148446467\n",
      "[timestep: 27] [epoch: 1531] loss: 0.0046192016\n",
      "[timestep: 27] [epoch: 1561] loss: 0.0037585027\n",
      "[timestep: 27] [epoch: 1591] loss: 0.0060368711\n",
      "[timestep: 27] [epoch: 1621] loss: 0.0093529746\n",
      "[timestep: 27] [epoch: 1651] loss: 0.0025372682\n",
      "[timestep: 27] [epoch: 1681] loss: 0.0098454757\n",
      "[timestep: 27] [epoch: 1711] loss: 0.0040911813\n",
      "[timestep: 27] [epoch: 1741] loss: 0.0023893621\n",
      "[timestep: 27] [epoch: 1771] loss: 0.0025927424\n",
      "[timestep: 27] [epoch: 1801] loss: 0.0028642612\n",
      "[timestep: 27] [epoch: 1831] loss: 0.0067865765\n",
      "[timestep: 27] [epoch: 1861] loss: 0.0020769159\n",
      "[timestep: 27] [epoch: 1891] loss: 0.0060610380\n",
      "[timestep: 27] [epoch: 1921] loss: 0.0030660466\n",
      "[timestep: 27] [epoch: 1951] loss: 0.0026994077\n",
      "[timestep: 27] [epoch: 1981] loss: 0.0041507403\n",
      "[timestep: 27] [epoch: 2011] loss: 0.0044746539\n",
      "[timestep: 27] [epoch: 2041] loss: 0.0091500841\n",
      "[timestep: 27] [epoch: 2071] loss: 0.0038920874\n",
      "[timestep: 27] [epoch: 2101] loss: 0.0029855752\n",
      "[timestep: 27] [epoch: 2131] loss: 0.0042795362\n",
      "[timestep: 27] [epoch: 2161] loss: 0.0065839170\n",
      "[timestep: 27] [epoch: 2191] loss: 0.0019962301\n",
      "[timestep: 27] [epoch: 2221] loss: 0.0012583813\n",
      "[timestep: 27] [epoch: 2251] loss: 0.0123843653\n",
      "[timestep: 27] [epoch: 2281] loss: 0.0048755845\n",
      "[timestep: 27] [epoch: 2311] loss: 0.0010031256\n",
      "[timestep: 27] [epoch: 2341] loss: 0.0020177879\n",
      "[timestep: 27] [epoch: 2371] loss: 0.0073951618\n",
      "[timestep: 27] [epoch: 2401] loss: 0.0044171964\n",
      "[timestep: 27] [epoch: 2431] loss: 0.0020191111\n",
      "[timestep: 27] [epoch: 2461] loss: 0.0030755405\n",
      "[timestep: 27] [epoch: 2491] loss: 0.0038101487\n",
      "[timestep: 27] [epoch: 2521] loss: 0.0033948286\n",
      "[timestep: 27] [epoch: 2551] loss: 0.0026561758\n",
      "[timestep: 27] [epoch: 2581] loss: 0.0146112796\n",
      "[timestep: 27] [epoch: 2611] loss: 0.0042966893\n",
      "[timestep: 27] [epoch: 2641] loss: 0.0026655947\n",
      "[timestep: 27] [epoch: 2671] loss: 0.0055187284\n",
      "[timestep: 27] [epoch: 2701] loss: 0.0022056168\n",
      "0.01\n",
      "[timestep: 28] [epoch: 1] loss: 0.6079327464\n",
      "[timestep: 28] [epoch: 31] loss: 0.0302213412\n",
      "[timestep: 28] [epoch: 61] loss: 0.0028817491\n",
      "[timestep: 28] [epoch: 91] loss: 0.0012917165\n",
      "[timestep: 28] [epoch: 121] loss: 0.0012610960\n",
      "[timestep: 28] [epoch: 151] loss: 0.0011184169\n",
      "[timestep: 28] [epoch: 181] loss: 0.0076434719\n",
      "[timestep: 28] [epoch: 211] loss: 0.0051370645\n",
      "[timestep: 28] [epoch: 241] loss: 0.0243645888\n",
      "[timestep: 28] [epoch: 271] loss: 0.0018251945\n",
      "[timestep: 28] [epoch: 301] loss: 0.0024390598\n",
      "[timestep: 28] [epoch: 331] loss: 0.0030224801\n",
      "[timestep: 28] [epoch: 361] loss: 0.0027398015\n",
      "[timestep: 28] [epoch: 391] loss: 0.0069025434\n",
      "[timestep: 28] [epoch: 421] loss: 0.0018139879\n",
      "[timestep: 28] [epoch: 451] loss: 0.0155021548\n",
      "[timestep: 28] [epoch: 481] loss: 0.0019391689\n",
      "[timestep: 28] [epoch: 511] loss: 0.0069692871\n",
      "[timestep: 28] [epoch: 541] loss: 0.0071526878\n",
      "[timestep: 28] [epoch: 571] loss: 0.0029796257\n",
      "[timestep: 28] [epoch: 601] loss: 0.0092180241\n",
      "[timestep: 28] [epoch: 631] loss: 0.0013049690\n",
      "[timestep: 28] [epoch: 661] loss: 0.0140114427\n",
      "[timestep: 28] [epoch: 691] loss: 0.0023369538\n",
      "[timestep: 28] [epoch: 721] loss: 0.0026736418\n",
      "[timestep: 28] [epoch: 751] loss: 0.0132116377\n",
      "[timestep: 28] [epoch: 781] loss: 0.0018963026\n",
      "[timestep: 28] [epoch: 811] loss: 0.0038544838\n",
      "[timestep: 28] [epoch: 841] loss: 0.0044088392\n",
      "[timestep: 28] [epoch: 871] loss: 0.0158735849\n",
      "[timestep: 28] [epoch: 901] loss: 0.0032008761\n",
      "[timestep: 28] [epoch: 931] loss: 0.0076064994\n",
      "[timestep: 28] [epoch: 961] loss: 0.0015965297\n",
      "[timestep: 28] [epoch: 991] loss: 0.0019188228\n",
      "[timestep: 28] [epoch: 1021] loss: 0.0057810289\n",
      "0.01\n",
      "[timestep: 29] [epoch: 1] loss: 0.6081968546\n",
      "[timestep: 29] [epoch: 31] loss: 0.0288799591\n",
      "[timestep: 29] [epoch: 61] loss: 0.0026369216\n",
      "[timestep: 29] [epoch: 91] loss: 0.0010594163\n",
      "0.01\n",
      "[timestep: 30] [epoch: 1] loss: 0.6064051390\n",
      "[timestep: 30] [epoch: 31] loss: 0.0402941518\n",
      "[timestep: 30] [epoch: 61] loss: 0.0030154926\n",
      "[timestep: 30] [epoch: 91] loss: 0.0010095029\n",
      "0.01\n",
      "[timestep: 31] [epoch: 1] loss: 0.5989127159\n",
      "[timestep: 31] [epoch: 31] loss: 0.0448409244\n",
      "[timestep: 31] [epoch: 61] loss: 0.0036667788\n",
      "[timestep: 31] [epoch: 91] loss: 0.0010562394\n",
      "0.01\n",
      "[timestep: 32] [epoch: 1] loss: 0.5954608917\n",
      "[timestep: 32] [epoch: 31] loss: 0.0484526418\n",
      "[timestep: 32] [epoch: 61] loss: 0.0041337353\n",
      "[timestep: 32] [epoch: 91] loss: 0.0010421444\n",
      "0.01\n",
      "[timestep: 33] [epoch: 1] loss: 0.5976367593\n",
      "[timestep: 33] [epoch: 31] loss: 0.0519107357\n",
      "[timestep: 33] [epoch: 61] loss: 0.0033224453\n",
      "[timestep: 33] [epoch: 91] loss: 0.0010463723\n",
      "0.01\n",
      "[timestep: 34] [epoch: 1] loss: 0.5956472754\n",
      "[timestep: 34] [epoch: 31] loss: 0.0662470832\n",
      "[timestep: 34] [epoch: 61] loss: 0.0045958618\n",
      "[timestep: 34] [epoch: 91] loss: 0.0012315225\n",
      "0.01\n",
      "[timestep: 35] [epoch: 1] loss: 0.6014333963\n",
      "[timestep: 35] [epoch: 31] loss: 0.0784037560\n",
      "[timestep: 35] [epoch: 61] loss: 0.0045859655\n",
      "[timestep: 35] [epoch: 91] loss: 0.0015638766\n",
      "[timestep: 35] [epoch: 121] loss: 0.0011164413\n",
      "[timestep: 35] [epoch: 151] loss: 0.0072789080\n",
      "[timestep: 35] [epoch: 181] loss: 0.0052238302\n",
      "[timestep: 35] [epoch: 211] loss: 0.0073897149\n",
      "[timestep: 35] [epoch: 241] loss: 0.0035068931\n",
      "[timestep: 35] [epoch: 271] loss: 0.0081659071\n",
      "[timestep: 35] [epoch: 301] loss: 0.0554472283\n",
      "[timestep: 35] [epoch: 331] loss: 0.0115175098\n",
      "[timestep: 35] [epoch: 361] loss: 0.0014833603\n",
      "[timestep: 35] [epoch: 391] loss: 0.0152651081\n",
      "[timestep: 35] [epoch: 421] loss: 0.0025712741\n",
      "[timestep: 35] [epoch: 451] loss: 0.0091377404\n",
      "[timestep: 35] [epoch: 481] loss: 0.0020229348\n",
      "[timestep: 35] [epoch: 511] loss: 0.0109074917\n",
      "[timestep: 35] [epoch: 541] loss: 0.0020666448\n",
      "[timestep: 35] [epoch: 571] loss: 0.0348714329\n",
      "[timestep: 35] [epoch: 601] loss: 0.0186796226\n",
      "[timestep: 35] [epoch: 631] loss: 0.0082198922\n",
      "[timestep: 35] [epoch: 661] loss: 0.0037221757\n",
      "[timestep: 35] [epoch: 691] loss: 0.0071915602\n",
      "[timestep: 35] [epoch: 721] loss: 0.0042759888\n",
      "[timestep: 35] [epoch: 751] loss: 0.0030814046\n",
      "[timestep: 35] [epoch: 781] loss: 0.0075829457\n",
      "[timestep: 35] [epoch: 811] loss: 0.0106668994\n",
      "[timestep: 35] [epoch: 841] loss: 0.0027365100\n",
      "[timestep: 35] [epoch: 871] loss: 0.0300597921\n",
      "[timestep: 35] [epoch: 901] loss: 0.0026890021\n",
      "[timestep: 35] [epoch: 931] loss: 0.0011741153\n",
      "0.01\n",
      "[timestep: 36] [epoch: 1] loss: 0.5880766511\n",
      "[timestep: 36] [epoch: 31] loss: 0.0478054732\n",
      "[timestep: 36] [epoch: 61] loss: 0.0033623246\n",
      "[timestep: 36] [epoch: 91] loss: 0.0012349101\n",
      "[timestep: 36] [epoch: 121] loss: 0.0017540108\n",
      "[timestep: 36] [epoch: 151] loss: 0.0033194197\n",
      "[timestep: 36] [epoch: 181] loss: 0.0014024666\n",
      "[timestep: 36] [epoch: 211] loss: 0.0018509675\n",
      "[timestep: 36] [epoch: 241] loss: 0.0075811073\n",
      "[timestep: 36] [epoch: 271] loss: 0.0021711837\n",
      "[timestep: 36] [epoch: 301] loss: 0.0023558175\n",
      "[timestep: 36] [epoch: 331] loss: 0.0045232084\n",
      "[timestep: 36] [epoch: 361] loss: 0.0035618416\n",
      "[timestep: 36] [epoch: 391] loss: 0.0059122778\n",
      "[timestep: 36] [epoch: 421] loss: 0.0015913600\n",
      "[timestep: 36] [epoch: 451] loss: 0.0038986153\n",
      "[timestep: 36] [epoch: 481] loss: 0.0061263917\n",
      "[timestep: 36] [epoch: 511] loss: 0.0035633193\n",
      "[timestep: 36] [epoch: 541] loss: 0.0519980863\n",
      "[timestep: 36] [epoch: 571] loss: 0.0036713986\n",
      "[timestep: 36] [epoch: 601] loss: 0.0106127961\n",
      "[timestep: 36] [epoch: 631] loss: 0.0128639191\n",
      "[timestep: 36] [epoch: 661] loss: 0.0133474255\n",
      "[timestep: 36] [epoch: 691] loss: 0.0028098454\n",
      "[timestep: 36] [epoch: 721] loss: 0.0026961640\n",
      "[timestep: 36] [epoch: 751] loss: 0.0041418830\n",
      "[timestep: 36] [epoch: 781] loss: 0.0013440629\n",
      "[timestep: 36] [epoch: 811] loss: 0.0129322447\n",
      "[timestep: 36] [epoch: 841] loss: 0.0025905701\n",
      "[timestep: 36] [epoch: 871] loss: 0.0052581877\n",
      "[timestep: 36] [epoch: 901] loss: 0.0276067499\n",
      "[timestep: 36] [epoch: 931] loss: 0.0020084186\n",
      "[timestep: 36] [epoch: 961] loss: 0.0024461220\n",
      "[timestep: 36] [epoch: 991] loss: 0.0098837512\n",
      "[timestep: 36] [epoch: 1021] loss: 0.0012638922\n",
      "0.01\n",
      "[timestep: 37] [epoch: 1] loss: 0.5808730125\n",
      "[timestep: 37] [epoch: 31] loss: 0.0456885584\n",
      "[timestep: 37] [epoch: 61] loss: 0.0041009462\n",
      "[timestep: 37] [epoch: 91] loss: 0.0012158379\n",
      "0.01\n",
      "[timestep: 38] [epoch: 1] loss: 0.5840779543\n",
      "[timestep: 38] [epoch: 31] loss: 0.0778477788\n",
      "[timestep: 38] [epoch: 61] loss: 0.0058088126\n",
      "[timestep: 38] [epoch: 91] loss: 0.0014939299\n",
      "[timestep: 38] [epoch: 121] loss: 0.0011141493\n",
      "[timestep: 38] [epoch: 151] loss: 0.0009716273\n",
      "0.01\n",
      "[timestep: 39] [epoch: 1] loss: 0.5794878602\n",
      "[timestep: 39] [epoch: 31] loss: 0.0650215968\n",
      "[timestep: 39] [epoch: 61] loss: 0.0072077028\n",
      "[timestep: 39] [epoch: 91] loss: 0.0030429009\n",
      "[timestep: 39] [epoch: 121] loss: 0.0014295661\n",
      "[timestep: 39] [epoch: 151] loss: 0.0020193502\n",
      "[timestep: 39] [epoch: 181] loss: 0.0034377454\n",
      "[timestep: 39] [epoch: 211] loss: 0.0042081513\n",
      "[timestep: 39] [epoch: 241] loss: 0.0120470570\n",
      "[timestep: 39] [epoch: 271] loss: 0.0057449881\n",
      "[timestep: 39] [epoch: 301] loss: 0.0097246990\n",
      "[timestep: 39] [epoch: 331] loss: 0.0142499059\n",
      "[timestep: 39] [epoch: 361] loss: 0.0019869916\n",
      "[timestep: 39] [epoch: 391] loss: 0.0056347782\n",
      "[timestep: 39] [epoch: 421] loss: 0.0018789286\n",
      "[timestep: 39] [epoch: 451] loss: 0.0092648324\n",
      "[timestep: 39] [epoch: 481] loss: 0.0067318901\n",
      "[timestep: 39] [epoch: 511] loss: 0.0030618820\n",
      "[timestep: 39] [epoch: 541] loss: 0.0133856507\n",
      "[timestep: 39] [epoch: 571] loss: 0.0023277598\n",
      "[timestep: 39] [epoch: 601] loss: 0.0110207172\n",
      "[timestep: 39] [epoch: 631] loss: 0.0044236509\n",
      "[timestep: 39] [epoch: 661] loss: 0.0042313524\n",
      "[timestep: 39] [epoch: 691] loss: 0.0063382103\n",
      "[timestep: 39] [epoch: 721] loss: 0.0037572898\n",
      "[timestep: 39] [epoch: 751] loss: 0.0116937729\n",
      "[timestep: 39] [epoch: 781] loss: 0.0045648413\n",
      "[timestep: 39] [epoch: 811] loss: 0.0012326373\n",
      "[timestep: 39] [epoch: 841] loss: 0.0164866745\n",
      "[timestep: 39] [epoch: 871] loss: 0.0014049963\n",
      "[timestep: 39] [epoch: 901] loss: 0.0385210365\n",
      "[timestep: 39] [epoch: 931] loss: 0.0019980432\n",
      "[timestep: 39] [epoch: 961] loss: 0.0135994814\n",
      "[timestep: 39] [epoch: 991] loss: 0.0112642767\n",
      "[timestep: 39] [epoch: 1021] loss: 0.0022315783\n",
      "[timestep: 39] [epoch: 1051] loss: 0.0016052277\n",
      "[timestep: 39] [epoch: 1081] loss: 0.0262208320\n",
      "[timestep: 39] [epoch: 1111] loss: 0.0041849231\n",
      "[timestep: 39] [epoch: 1141] loss: 0.0127214082\n",
      "[timestep: 39] [epoch: 1171] loss: 0.0068453760\n",
      "[timestep: 39] [epoch: 1201] loss: 0.0088951280\n",
      "[timestep: 39] [epoch: 1231] loss: 0.0024300828\n",
      "[timestep: 39] [epoch: 1261] loss: 0.0140617900\n",
      "[timestep: 39] [epoch: 1291] loss: 0.0034835753\n",
      "[timestep: 39] [epoch: 1321] loss: 0.0056619262\n",
      "[timestep: 39] [epoch: 1351] loss: 0.0327002779\n",
      "[timestep: 39] [epoch: 1381] loss: 0.0025389660\n",
      "[timestep: 39] [epoch: 1411] loss: 0.0015898698\n",
      "[timestep: 39] [epoch: 1441] loss: 0.0071105976\n",
      "[timestep: 39] [epoch: 1471] loss: 0.0038246270\n",
      "[timestep: 39] [epoch: 1501] loss: 0.0078642648\n",
      "[timestep: 39] [epoch: 1531] loss: 0.0029351902\n",
      "[timestep: 39] [epoch: 1561] loss: 0.0139504410\n",
      "[timestep: 39] [epoch: 1591] loss: 0.0031316006\n",
      "[timestep: 39] [epoch: 1621] loss: 0.0053988174\n",
      "[timestep: 39] [epoch: 1651] loss: 0.0057969368\n",
      "[timestep: 39] [epoch: 1681] loss: 0.0120781958\n",
      "[timestep: 39] [epoch: 1711] loss: 0.0024502613\n",
      "[timestep: 39] [epoch: 1741] loss: 0.0027019917\n",
      "[timestep: 39] [epoch: 1771] loss: 0.0039662784\n",
      "[timestep: 39] [epoch: 1801] loss: 0.0042968206\n",
      "[timestep: 39] [epoch: 1831] loss: 0.0090168668\n",
      "[timestep: 39] [epoch: 1861] loss: 0.0028720628\n",
      "0.01\n",
      "[timestep: 40] [epoch: 1] loss: 0.5783524513\n",
      "[timestep: 40] [epoch: 31] loss: 0.0599395111\n",
      "[timestep: 40] [epoch: 61] loss: 0.0055872663\n",
      "[timestep: 40] [epoch: 91] loss: 0.0037771184\n",
      "[timestep: 40] [epoch: 121] loss: 0.0034231371\n",
      "[timestep: 40] [epoch: 151] loss: 0.0034794887\n",
      "[timestep: 40] [epoch: 181] loss: 0.0060520940\n",
      "[timestep: 40] [epoch: 211] loss: 0.0091356216\n",
      "[timestep: 40] [epoch: 241] loss: 0.0080183484\n",
      "[timestep: 40] [epoch: 271] loss: 0.0044573788\n",
      "[timestep: 40] [epoch: 301] loss: 0.0115339458\n",
      "[timestep: 40] [epoch: 331] loss: 0.0070811622\n",
      "[timestep: 40] [epoch: 361] loss: 0.0087446691\n",
      "[timestep: 40] [epoch: 391] loss: 0.0106231114\n",
      "[timestep: 40] [epoch: 421] loss: 0.0046865093\n",
      "[timestep: 40] [epoch: 451] loss: 0.0052170157\n",
      "[timestep: 40] [epoch: 481] loss: 0.0087835109\n",
      "[timestep: 40] [epoch: 511] loss: 0.0085815731\n",
      "[timestep: 40] [epoch: 541] loss: 0.0163627621\n",
      "[timestep: 40] [epoch: 571] loss: 0.0137254391\n",
      "[timestep: 40] [epoch: 601] loss: 0.0103538390\n",
      "[timestep: 40] [epoch: 631] loss: 0.0047882367\n",
      "[timestep: 40] [epoch: 661] loss: 0.0122722145\n",
      "[timestep: 40] [epoch: 691] loss: 0.0050396542\n",
      "[timestep: 40] [epoch: 721] loss: 0.0059286766\n",
      "[timestep: 40] [epoch: 751] loss: 0.0471485928\n",
      "[timestep: 40] [epoch: 781] loss: 0.0057234229\n",
      "[timestep: 40] [epoch: 811] loss: 0.0038371976\n",
      "[timestep: 40] [epoch: 841] loss: 0.0129156774\n",
      "[timestep: 40] [epoch: 871] loss: 0.0055269101\n",
      "[timestep: 40] [epoch: 901] loss: 0.0242224224\n",
      "[timestep: 40] [epoch: 931] loss: 0.0053221546\n",
      "[timestep: 40] [epoch: 961] loss: 0.0021122396\n",
      "[timestep: 40] [epoch: 991] loss: 0.0043291789\n",
      "[timestep: 40] [epoch: 1021] loss: 0.0292985439\n",
      "[timestep: 40] [epoch: 1051] loss: 0.0022149934\n",
      "[timestep: 40] [epoch: 1081] loss: 0.0015825030\n",
      "[timestep: 40] [epoch: 1111] loss: 0.0078865215\n",
      "0.01\n",
      "[timestep: 41] [epoch: 1] loss: 0.5752841234\n",
      "[timestep: 41] [epoch: 31] loss: 0.0323136002\n",
      "[timestep: 41] [epoch: 61] loss: 0.0033779289\n",
      "[timestep: 41] [epoch: 91] loss: 0.0012802703\n",
      "0.01\n",
      "[timestep: 42] [epoch: 1] loss: 0.5782152414\n",
      "[timestep: 42] [epoch: 31] loss: 0.0582994334\n",
      "[timestep: 42] [epoch: 61] loss: 0.0054230504\n",
      "[timestep: 42] [epoch: 91] loss: 0.0014043315\n",
      "[timestep: 42] [epoch: 121] loss: 0.0013162120\n",
      "[timestep: 42] [epoch: 151] loss: 0.0038567083\n",
      "[timestep: 42] [epoch: 181] loss: 0.0046578883\n",
      "[timestep: 42] [epoch: 211] loss: 0.0035114593\n",
      "[timestep: 42] [epoch: 241] loss: 0.0042295102\n",
      "[timestep: 42] [epoch: 271] loss: 0.0015902184\n",
      "[timestep: 42] [epoch: 301] loss: 0.0094129592\n",
      "[timestep: 42] [epoch: 331] loss: 0.0062093860\n",
      "[timestep: 42] [epoch: 361] loss: 0.0076810019\n",
      "[timestep: 42] [epoch: 391] loss: 0.0140961725\n",
      "[timestep: 42] [epoch: 421] loss: 0.0049704518\n",
      "[timestep: 42] [epoch: 451] loss: 0.0025157880\n",
      "[timestep: 42] [epoch: 481] loss: 0.0037674303\n",
      "[timestep: 42] [epoch: 511] loss: 0.0123508386\n",
      "[timestep: 42] [epoch: 541] loss: 0.0023248349\n",
      "[timestep: 42] [epoch: 571] loss: 0.0047681788\n",
      "[timestep: 42] [epoch: 601] loss: 0.0022928570\n",
      "[timestep: 42] [epoch: 631] loss: 0.0013726833\n",
      "[timestep: 42] [epoch: 661] loss: 0.0025045583\n",
      "[timestep: 42] [epoch: 691] loss: 0.0045224144\n",
      "0.01\n",
      "[timestep: 43] [epoch: 1] loss: 0.5914987922\n",
      "[timestep: 43] [epoch: 31] loss: 0.0578525141\n",
      "[timestep: 43] [epoch: 61] loss: 0.0039096223\n",
      "[timestep: 43] [epoch: 91] loss: 0.0012643836\n",
      "[timestep: 43] [epoch: 121] loss: 0.0013801225\n",
      "0.01\n",
      "[timestep: 44] [epoch: 1] loss: 0.5771827698\n",
      "[timestep: 44] [epoch: 31] loss: 0.0787048340\n",
      "[timestep: 44] [epoch: 61] loss: 0.0052307295\n",
      "[timestep: 44] [epoch: 91] loss: 0.0013543996\n",
      "0.01\n",
      "[timestep: 45] [epoch: 1] loss: 0.5645300150\n",
      "[timestep: 45] [epoch: 31] loss: 0.0593459159\n",
      "[timestep: 45] [epoch: 61] loss: 0.0052336068\n",
      "[timestep: 45] [epoch: 91] loss: 0.0013782387\n",
      "0.01\n",
      "[timestep: 46] [epoch: 1] loss: 0.5625832081\n",
      "[timestep: 46] [epoch: 31] loss: 0.0656009763\n",
      "[timestep: 46] [epoch: 61] loss: 0.0061627296\n",
      "[timestep: 46] [epoch: 91] loss: 0.0012039633\n",
      "0.01\n",
      "[timestep: 47] [epoch: 1] loss: 0.5746387243\n",
      "[timestep: 47] [epoch: 31] loss: 0.0633054823\n",
      "[timestep: 47] [epoch: 61] loss: 0.0056614615\n",
      "[timestep: 47] [epoch: 91] loss: 0.0014274258\n",
      "0.01\n",
      "[timestep: 48] [epoch: 1] loss: 0.5574835539\n",
      "[timestep: 48] [epoch: 31] loss: 0.0795085281\n",
      "[timestep: 48] [epoch: 61] loss: 0.0066477600\n",
      "[timestep: 48] [epoch: 91] loss: 0.0016680114\n",
      "0.01\n",
      "[timestep: 49] [epoch: 1] loss: 0.5593067408\n",
      "[timestep: 49] [epoch: 31] loss: 0.1340216398\n",
      "[timestep: 49] [epoch: 61] loss: 0.0080853952\n",
      "[timestep: 49] [epoch: 91] loss: 0.0023444295\n",
      "[timestep: 49] [epoch: 121] loss: 0.0017367080\n",
      "[timestep: 49] [epoch: 151] loss: 0.0042304602\n",
      "[timestep: 49] [epoch: 181] loss: 0.0023195422\n",
      "[timestep: 49] [epoch: 211] loss: 0.0027019368\n",
      "[timestep: 49] [epoch: 241] loss: 0.0146732051\n",
      "[timestep: 49] [epoch: 271] loss: 0.0169021450\n",
      "[timestep: 49] [epoch: 301] loss: 0.0297962539\n",
      "[timestep: 49] [epoch: 331] loss: 0.0121795470\n",
      "[timestep: 49] [epoch: 361] loss: 0.0062905694\n",
      "[timestep: 49] [epoch: 391] loss: 0.0062306086\n",
      "[timestep: 49] [epoch: 421] loss: 0.0036187242\n",
      "[timestep: 49] [epoch: 451] loss: 0.0214732923\n",
      "[timestep: 49] [epoch: 481] loss: 0.0151596423\n",
      "[timestep: 49] [epoch: 511] loss: 0.0012351349\n",
      "[timestep: 49] [epoch: 541] loss: 0.0292558558\n",
      "[timestep: 49] [epoch: 571] loss: 0.0079927314\n",
      "[timestep: 49] [epoch: 601] loss: 0.0248967279\n",
      "[timestep: 49] [epoch: 631] loss: 0.0020771213\n",
      "0.01\n",
      "[timestep: 50] [epoch: 1] loss: 0.5509380102\n",
      "[timestep: 50] [epoch: 31] loss: 0.0980559140\n",
      "[timestep: 50] [epoch: 61] loss: 0.0037936494\n",
      "The training time is:  4767.678489208221\n"
     ]
    }
   ],
   "source": [
    "!python main_infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078f02b-1b2e-4cf3-8c1a-0a92ce67c540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
