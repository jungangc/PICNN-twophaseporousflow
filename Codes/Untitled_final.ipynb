{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc14add8-2eca-4c6a-88cb-0c1487d91183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/user/jungangc/PICNN-2phase/PICNN-2phaseflow-constBHP-64by64-heter-TransferLearning-50steps-final-lightweight/Codes\n",
      "0.01\n",
      "[timestep: 1] [epoch: 1] loss: 1624.1723632812\n",
      "[timestep: 1] [epoch: 31] loss: 6.2251749039\n",
      "[timestep: 1] [epoch: 61] loss: 2.6976625919\n",
      "[timestep: 1] [epoch: 91] loss: 2.0117549896\n",
      "[timestep: 1] [epoch: 121] loss: 0.9637241960\n",
      "[timestep: 1] [epoch: 151] loss: 0.9383466840\n",
      "[timestep: 1] [epoch: 181] loss: 1.1735578775\n",
      "[timestep: 1] [epoch: 211] loss: 0.7635592222\n",
      "[timestep: 1] [epoch: 241] loss: 2.3041243553\n",
      "[timestep: 1] [epoch: 271] loss: 1.0149388313\n",
      "[timestep: 1] [epoch: 301] loss: 1.1753828526\n",
      "[timestep: 1] [epoch: 331] loss: 0.8183990717\n",
      "[timestep: 1] [epoch: 361] loss: 0.6798797250\n",
      "[timestep: 1] [epoch: 391] loss: 0.8069437146\n",
      "[timestep: 1] [epoch: 421] loss: 0.9204134941\n",
      "[timestep: 1] [epoch: 451] loss: 0.7254873514\n",
      "[timestep: 1] [epoch: 481] loss: 0.7852170467\n",
      "[timestep: 1] [epoch: 511] loss: 0.7610983253\n",
      "[timestep: 1] [epoch: 541] loss: 0.7277518511\n",
      "[timestep: 1] [epoch: 571] loss: 0.6831859350\n",
      "[timestep: 1] [epoch: 601] loss: 0.7209923267\n",
      "[timestep: 1] [epoch: 631] loss: 0.6805668473\n",
      "[timestep: 1] [epoch: 661] loss: 0.5778619051\n",
      "[timestep: 1] [epoch: 691] loss: 0.5573853254\n",
      "[timestep: 1] [epoch: 721] loss: 0.5383609533\n",
      "[timestep: 1] [epoch: 751] loss: 0.6144148707\n",
      "[timestep: 1] [epoch: 781] loss: 0.5953462124\n",
      "[timestep: 1] [epoch: 811] loss: 0.5093380213\n",
      "[timestep: 1] [epoch: 841] loss: 0.4091103077\n",
      "[timestep: 1] [epoch: 871] loss: 0.4429582953\n",
      "[timestep: 1] [epoch: 901] loss: 0.3792275786\n",
      "[timestep: 1] [epoch: 931] loss: 0.3704263568\n",
      "[timestep: 1] [epoch: 961] loss: 0.4053399861\n",
      "[timestep: 1] [epoch: 991] loss: 0.4164285064\n",
      "[timestep: 1] [epoch: 1021] loss: 0.3320568800\n",
      "[timestep: 1] [epoch: 1051] loss: 0.3928439617\n",
      "[timestep: 1] [epoch: 1081] loss: 0.3813124299\n",
      "[timestep: 1] [epoch: 1111] loss: 0.3771004677\n",
      "[timestep: 1] [epoch: 1141] loss: 0.3668745458\n",
      "[timestep: 1] [epoch: 1171] loss: 0.3306635916\n",
      "[timestep: 1] [epoch: 1201] loss: 0.2846822739\n",
      "[timestep: 1] [epoch: 1231] loss: 0.3476510346\n",
      "[timestep: 1] [epoch: 1261] loss: 0.4166959226\n",
      "[timestep: 1] [epoch: 1291] loss: 0.3564234376\n",
      "[timestep: 1] [epoch: 1321] loss: 0.3529499471\n",
      "[timestep: 1] [epoch: 1351] loss: 0.2975958586\n",
      "[timestep: 1] [epoch: 1381] loss: 0.3574358821\n",
      "[timestep: 1] [epoch: 1411] loss: 0.3399437368\n",
      "[timestep: 1] [epoch: 1441] loss: 0.3819996417\n",
      "[timestep: 1] [epoch: 1471] loss: 0.3606293201\n",
      "[timestep: 1] [epoch: 1501] loss: 0.3503753245\n",
      "[timestep: 1] [epoch: 1531] loss: 0.3510843515\n",
      "[timestep: 1] [epoch: 1561] loss: 0.3388396502\n",
      "[timestep: 1] [epoch: 1591] loss: 0.3393733501\n",
      "[timestep: 1] [epoch: 1621] loss: 0.3255091310\n",
      "[timestep: 1] [epoch: 1651] loss: 0.2663400173\n",
      "[timestep: 1] [epoch: 1681] loss: 0.3274484873\n",
      "[timestep: 1] [epoch: 1711] loss: 0.3016610146\n",
      "[timestep: 1] [epoch: 1741] loss: 0.2638206482\n",
      "[timestep: 1] [epoch: 1771] loss: 0.2525433898\n",
      "[timestep: 1] [epoch: 1801] loss: 0.2449962199\n",
      "[timestep: 1] [epoch: 1831] loss: 0.2208752632\n",
      "[timestep: 1] [epoch: 1861] loss: 0.2014470100\n",
      "[timestep: 1] [epoch: 1891] loss: 0.1782747805\n",
      "[timestep: 1] [epoch: 1921] loss: 0.1641469896\n",
      "[timestep: 1] [epoch: 1951] loss: 0.1528726667\n",
      "[timestep: 1] [epoch: 1981] loss: 0.1812421083\n",
      "[timestep: 1] [epoch: 2011] loss: 0.2466847450\n",
      "[timestep: 1] [epoch: 2041] loss: 0.1631115526\n",
      "[timestep: 1] [epoch: 2071] loss: 0.1566743553\n",
      "[timestep: 1] [epoch: 2101] loss: 0.1540334523\n",
      "[timestep: 1] [epoch: 2131] loss: 0.2350195646\n",
      "[timestep: 1] [epoch: 2161] loss: 0.1389739811\n",
      "[timestep: 1] [epoch: 2191] loss: 0.1729505658\n",
      "[timestep: 1] [epoch: 2221] loss: 0.0959620774\n",
      "[timestep: 1] [epoch: 2251] loss: 0.1228339374\n",
      "[timestep: 1] [epoch: 2281] loss: 0.1186893955\n",
      "[timestep: 1] [epoch: 2311] loss: 0.1707685888\n",
      "[timestep: 1] [epoch: 2341] loss: 0.1049143448\n",
      "[timestep: 1] [epoch: 2371] loss: 0.1026305407\n",
      "[timestep: 1] [epoch: 2401] loss: 0.1632934809\n",
      "[timestep: 1] [epoch: 2431] loss: 0.1232022420\n",
      "[timestep: 1] [epoch: 2461] loss: 0.1723781079\n",
      "[timestep: 1] [epoch: 2491] loss: 0.1882046759\n",
      "[timestep: 1] [epoch: 2521] loss: 0.1234108210\n",
      "[timestep: 1] [epoch: 2551] loss: 0.0741549805\n",
      "[timestep: 1] [epoch: 2581] loss: 0.1057006270\n",
      "[timestep: 1] [epoch: 2611] loss: 0.1274116039\n",
      "[timestep: 1] [epoch: 2641] loss: 0.1275535226\n",
      "[timestep: 1] [epoch: 2671] loss: 0.0868673176\n",
      "[timestep: 1] [epoch: 2701] loss: 0.1306175292\n",
      "[timestep: 1] [epoch: 2731] loss: 0.1518585384\n",
      "[timestep: 1] [epoch: 2761] loss: 0.0868774354\n",
      "[timestep: 1] [epoch: 2791] loss: 0.1313424706\n",
      "[timestep: 1] [epoch: 2821] loss: 0.1459079981\n",
      "[timestep: 1] [epoch: 2851] loss: 0.0916771293\n",
      "[timestep: 1] [epoch: 2881] loss: 0.0961615741\n",
      "[timestep: 1] [epoch: 2911] loss: 0.1091895849\n",
      "[timestep: 1] [epoch: 2941] loss: 0.0774610117\n",
      "[timestep: 1] [epoch: 2971] loss: 0.0908890292\n",
      "[timestep: 1] [epoch: 3001] loss: 0.0985060558\n",
      "[timestep: 1] [epoch: 3031] loss: 0.0873908475\n",
      "[timestep: 1] [epoch: 3061] loss: 0.1078098863\n",
      "[timestep: 1] [epoch: 3091] loss: 0.0859987065\n",
      "[timestep: 1] [epoch: 3121] loss: 0.0778333023\n",
      "[timestep: 1] [epoch: 3151] loss: 0.0926262662\n",
      "[timestep: 1] [epoch: 3181] loss: 0.0638720095\n",
      "[timestep: 1] [epoch: 3211] loss: 0.1346300542\n",
      "[timestep: 1] [epoch: 3241] loss: 0.0631316528\n",
      "[timestep: 1] [epoch: 3271] loss: 0.0731475204\n",
      "[timestep: 1] [epoch: 3301] loss: 0.0766139776\n",
      "[timestep: 1] [epoch: 3331] loss: 0.0899033546\n",
      "[timestep: 1] [epoch: 3361] loss: 0.0531500429\n",
      "[timestep: 1] [epoch: 3391] loss: 0.0663295984\n",
      "[timestep: 1] [epoch: 3421] loss: 0.0687981769\n",
      "[timestep: 1] [epoch: 3451] loss: 0.0616733953\n",
      "[timestep: 1] [epoch: 3481] loss: 0.1248744503\n",
      "[timestep: 1] [epoch: 3511] loss: 0.0843857899\n",
      "[timestep: 1] [epoch: 3541] loss: 0.0836753100\n",
      "[timestep: 1] [epoch: 3571] loss: 0.0826448500\n",
      "[timestep: 1] [epoch: 3601] loss: 0.0722603798\n",
      "[timestep: 1] [epoch: 3631] loss: 0.0688661486\n",
      "[timestep: 1] [epoch: 3661] loss: 0.1057151854\n",
      "[timestep: 1] [epoch: 3691] loss: 0.0947548077\n",
      "[timestep: 1] [epoch: 3721] loss: 0.0624829568\n",
      "[timestep: 1] [epoch: 3751] loss: 0.0806075335\n",
      "[timestep: 1] [epoch: 3781] loss: 0.0704605728\n",
      "[timestep: 1] [epoch: 3811] loss: 0.0656329542\n",
      "[timestep: 1] [epoch: 3841] loss: 0.1300050467\n",
      "[timestep: 1] [epoch: 3871] loss: 0.0705490559\n",
      "[timestep: 1] [epoch: 3901] loss: 0.0904409587\n",
      "[timestep: 1] [epoch: 3931] loss: 0.0621195138\n",
      "[timestep: 1] [epoch: 3961] loss: 0.0816157311\n",
      "[timestep: 1] [epoch: 3991] loss: 0.0596736297\n",
      "[timestep: 1] [epoch: 4021] loss: 0.0733990073\n",
      "[timestep: 1] [epoch: 4051] loss: 0.0760677978\n",
      "[timestep: 1] [epoch: 4081] loss: 0.0727425963\n",
      "[timestep: 1] [epoch: 4111] loss: 0.0668854266\n",
      "[timestep: 1] [epoch: 4141] loss: 0.0768338069\n",
      "[timestep: 1] [epoch: 4171] loss: 0.0568757020\n",
      "[timestep: 1] [epoch: 4201] loss: 0.1169749200\n",
      "[timestep: 1] [epoch: 4231] loss: 0.0382778756\n",
      "[timestep: 1] [epoch: 4261] loss: 0.0687419325\n",
      "[timestep: 1] [epoch: 4291] loss: 0.0733918697\n",
      "[timestep: 1] [epoch: 4321] loss: 0.0925380439\n",
      "[timestep: 1] [epoch: 4351] loss: 0.0498882011\n",
      "[timestep: 1] [epoch: 4381] loss: 0.0464375019\n",
      "[timestep: 1] [epoch: 4411] loss: 0.0550492853\n",
      "[timestep: 1] [epoch: 4441] loss: 0.0437611714\n",
      "[timestep: 1] [epoch: 4471] loss: 0.0785442889\n",
      "[timestep: 1] [epoch: 4501] loss: 0.0537559241\n",
      "[timestep: 1] [epoch: 4531] loss: 0.0549133606\n",
      "[timestep: 1] [epoch: 4561] loss: 0.0612787157\n",
      "[timestep: 1] [epoch: 4591] loss: 0.0595776103\n",
      "[timestep: 1] [epoch: 4621] loss: 0.0511050075\n",
      "[timestep: 1] [epoch: 4651] loss: 0.0373690650\n",
      "[timestep: 1] [epoch: 4681] loss: 0.0688367188\n",
      "[timestep: 1] [epoch: 4711] loss: 0.0746369213\n",
      "[timestep: 1] [epoch: 4741] loss: 0.0431549847\n",
      "[timestep: 1] [epoch: 4771] loss: 0.0382311940\n",
      "[timestep: 1] [epoch: 4801] loss: 0.0541293547\n",
      "[timestep: 1] [epoch: 4831] loss: 0.0640706345\n",
      "[timestep: 1] [epoch: 4861] loss: 0.1093906090\n",
      "[timestep: 1] [epoch: 4891] loss: 0.0653607696\n",
      "[timestep: 1] [epoch: 4921] loss: 0.0547466986\n",
      "[timestep: 1] [epoch: 4951] loss: 0.0533881634\n",
      "[timestep: 1] [epoch: 4981] loss: 0.0648299977\n",
      "[timestep: 1] [epoch: 5011] loss: 0.0353678726\n",
      "[timestep: 1] [epoch: 5041] loss: 0.0697930828\n",
      "[timestep: 1] [epoch: 5071] loss: 0.0313735604\n",
      "[timestep: 1] [epoch: 5101] loss: 0.0321898647\n",
      "[timestep: 1] [epoch: 5131] loss: 0.0628439933\n",
      "[timestep: 1] [epoch: 5161] loss: 0.0510142595\n",
      "[timestep: 1] [epoch: 5191] loss: 0.0438478887\n",
      "[timestep: 1] [epoch: 5221] loss: 0.0527864024\n",
      "[timestep: 1] [epoch: 5251] loss: 0.0511761494\n",
      "[timestep: 1] [epoch: 5281] loss: 0.0442955196\n",
      "[timestep: 1] [epoch: 5311] loss: 0.0792178661\n",
      "[timestep: 1] [epoch: 5341] loss: 0.1262686253\n",
      "[timestep: 1] [epoch: 5371] loss: 0.0406055152\n",
      "[timestep: 1] [epoch: 5401] loss: 0.1042735353\n",
      "[timestep: 1] [epoch: 5431] loss: 0.0709104240\n",
      "[timestep: 1] [epoch: 5461] loss: 0.0440670699\n",
      "[timestep: 1] [epoch: 5491] loss: 0.0438105613\n",
      "[timestep: 1] [epoch: 5521] loss: 0.0659208819\n",
      "[timestep: 1] [epoch: 5551] loss: 0.0442964844\n",
      "[timestep: 1] [epoch: 5581] loss: 0.0679768175\n",
      "[timestep: 1] [epoch: 5611] loss: 0.0492419861\n",
      "[timestep: 1] [epoch: 5641] loss: 0.0283555128\n",
      "[timestep: 1] [epoch: 5671] loss: 0.0402868986\n",
      "[timestep: 1] [epoch: 5701] loss: 0.0258586369\n",
      "[timestep: 1] [epoch: 5731] loss: 0.0334661379\n",
      "[timestep: 1] [epoch: 5761] loss: 0.0625252724\n",
      "[timestep: 1] [epoch: 5791] loss: 0.0429047868\n",
      "[timestep: 1] [epoch: 5821] loss: 0.0454110727\n",
      "[timestep: 1] [epoch: 5851] loss: 0.0329082608\n",
      "[timestep: 1] [epoch: 5881] loss: 0.0401828736\n",
      "[timestep: 1] [epoch: 5911] loss: 0.0675571114\n",
      "[timestep: 1] [epoch: 5941] loss: 0.0609298050\n",
      "[timestep: 1] [epoch: 5971] loss: 0.0506494418\n",
      "[timestep: 1] [epoch: 6001] loss: 0.0554866157\n",
      "[timestep: 1] [epoch: 6031] loss: 0.0298006460\n",
      "[timestep: 1] [epoch: 6061] loss: 0.0388179868\n",
      "[timestep: 1] [epoch: 6091] loss: 0.0432408936\n",
      "[timestep: 1] [epoch: 6121] loss: 0.0397226587\n",
      "[timestep: 1] [epoch: 6151] loss: 0.0379422531\n",
      "[timestep: 1] [epoch: 6181] loss: 0.0211139061\n",
      "[timestep: 1] [epoch: 6211] loss: 0.0440826491\n",
      "[timestep: 1] [epoch: 6241] loss: 0.0642346591\n",
      "[timestep: 1] [epoch: 6271] loss: 0.0507706925\n",
      "[timestep: 1] [epoch: 6301] loss: 0.0498523936\n",
      "[timestep: 1] [epoch: 6331] loss: 0.0611862019\n",
      "[timestep: 1] [epoch: 6361] loss: 0.0530042052\n",
      "[timestep: 1] [epoch: 6391] loss: 0.0728952810\n",
      "[timestep: 1] [epoch: 6421] loss: 0.0465118140\n",
      "[timestep: 1] [epoch: 6451] loss: 0.0263863280\n",
      "[timestep: 1] [epoch: 6481] loss: 0.0303859320\n",
      "[timestep: 1] [epoch: 6511] loss: 0.0416788198\n",
      "[timestep: 1] [epoch: 6541] loss: 0.0357750282\n",
      "[timestep: 1] [epoch: 6571] loss: 0.0312843584\n",
      "[timestep: 1] [epoch: 6601] loss: 0.0915652439\n",
      "[timestep: 1] [epoch: 6631] loss: 0.0496685877\n",
      "[timestep: 1] [epoch: 6661] loss: 0.0555613264\n",
      "[timestep: 1] [epoch: 6691] loss: 0.0182057172\n",
      "[timestep: 1] [epoch: 6721] loss: 0.0119994543\n",
      "[timestep: 1] [epoch: 6751] loss: 0.0304624978\n",
      "[timestep: 1] [epoch: 6781] loss: 0.0228725299\n",
      "[timestep: 1] [epoch: 6811] loss: 0.0363713019\n",
      "[timestep: 1] [epoch: 6841] loss: 0.0317027345\n",
      "[timestep: 1] [epoch: 6871] loss: 0.0224752855\n",
      "[timestep: 1] [epoch: 6901] loss: 0.0181285888\n",
      "[timestep: 1] [epoch: 6931] loss: 0.0397104770\n",
      "[timestep: 1] [epoch: 6961] loss: 0.0282459799\n",
      "[timestep: 1] [epoch: 6991] loss: 0.0254277717\n",
      "[timestep: 1] [epoch: 7021] loss: 0.0677630007\n",
      "[timestep: 1] [epoch: 7051] loss: 0.0299208649\n",
      "[timestep: 1] [epoch: 7081] loss: 0.0532671027\n",
      "[timestep: 1] [epoch: 7111] loss: 0.0606775433\n",
      "[timestep: 1] [epoch: 7141] loss: 0.0411802232\n",
      "[timestep: 1] [epoch: 7171] loss: 0.0415475368\n",
      "[timestep: 1] [epoch: 7201] loss: 0.0191140231\n",
      "[timestep: 1] [epoch: 7231] loss: 0.0306610931\n",
      "[timestep: 1] [epoch: 7261] loss: 0.0226735100\n",
      "[timestep: 1] [epoch: 7291] loss: 0.0607709773\n",
      "[timestep: 1] [epoch: 7321] loss: 0.0265954286\n",
      "[timestep: 1] [epoch: 7351] loss: 0.0503196567\n",
      "[timestep: 1] [epoch: 7381] loss: 0.0257684216\n",
      "[timestep: 1] [epoch: 7411] loss: 0.0587676316\n",
      "[timestep: 1] [epoch: 7441] loss: 0.0393216088\n",
      "[timestep: 1] [epoch: 7471] loss: 0.0475705117\n",
      "[timestep: 1] [epoch: 7501] loss: 0.0358093195\n",
      "[timestep: 1] [epoch: 7531] loss: 0.0465913303\n",
      "[timestep: 1] [epoch: 7561] loss: 0.0242709983\n",
      "[timestep: 1] [epoch: 7591] loss: 0.0238343999\n",
      "[timestep: 1] [epoch: 7621] loss: 0.0288269483\n",
      "[timestep: 1] [epoch: 7651] loss: 0.0198840275\n",
      "[timestep: 1] [epoch: 7681] loss: 0.0312463697\n",
      "[timestep: 1] [epoch: 7711] loss: 0.0319944210\n",
      "[timestep: 1] [epoch: 7741] loss: 0.0217899196\n",
      "[timestep: 1] [epoch: 7771] loss: 0.0338331461\n",
      "[timestep: 1] [epoch: 7801] loss: 0.0239661932\n",
      "[timestep: 1] [epoch: 7831] loss: 0.0427666456\n",
      "[timestep: 1] [epoch: 7861] loss: 0.0327321254\n",
      "[timestep: 1] [epoch: 7891] loss: 0.0583275072\n",
      "[timestep: 1] [epoch: 7921] loss: 0.0357619971\n",
      "[timestep: 1] [epoch: 7951] loss: 0.0173465684\n",
      "[timestep: 1] [epoch: 7981] loss: 0.0481740013\n",
      "[timestep: 1] [epoch: 8011] loss: 0.0345451087\n",
      "[timestep: 1] [epoch: 8041] loss: 0.0388846546\n",
      "[timestep: 1] [epoch: 8071] loss: 0.0353890732\n",
      "[timestep: 1] [epoch: 8101] loss: 0.0337420888\n",
      "[timestep: 1] [epoch: 8131] loss: 0.0331637077\n",
      "[timestep: 1] [epoch: 8161] loss: 0.0331630409\n",
      "[timestep: 1] [epoch: 8191] loss: 0.0263441429\n",
      "[timestep: 1] [epoch: 8221] loss: 0.0080583133\n",
      "[timestep: 1] [epoch: 8251] loss: 0.0335084125\n",
      "[timestep: 1] [epoch: 8281] loss: 0.0260023661\n",
      "[timestep: 1] [epoch: 8311] loss: 0.0536409542\n",
      "[timestep: 1] [epoch: 8341] loss: 0.0499429815\n",
      "[timestep: 1] [epoch: 8371] loss: 0.0383679084\n",
      "[timestep: 1] [epoch: 8401] loss: 0.0435581841\n",
      "[timestep: 1] [epoch: 8431] loss: 0.0362374596\n",
      "[timestep: 1] [epoch: 8461] loss: 0.0357961543\n",
      "[timestep: 1] [epoch: 8491] loss: 0.0265464354\n",
      "[timestep: 1] [epoch: 8521] loss: 0.0178719722\n",
      "[timestep: 1] [epoch: 8551] loss: 0.0324071422\n",
      "[timestep: 1] [epoch: 8581] loss: 0.0165149737\n",
      "[timestep: 1] [epoch: 8611] loss: 0.0375753939\n",
      "[timestep: 1] [epoch: 8641] loss: 0.0332804956\n",
      "[timestep: 1] [epoch: 8671] loss: 0.0332897566\n",
      "[timestep: 1] [epoch: 8701] loss: 0.0108243981\n",
      "[timestep: 1] [epoch: 8731] loss: 0.0142507572\n",
      "[timestep: 1] [epoch: 8761] loss: 0.0169320777\n",
      "[timestep: 1] [epoch: 8791] loss: 0.0263648182\n",
      "[timestep: 1] [epoch: 8821] loss: 0.0285047404\n",
      "[timestep: 1] [epoch: 8851] loss: 0.0626875758\n",
      "[timestep: 1] [epoch: 8881] loss: 0.0318038240\n",
      "[timestep: 1] [epoch: 8911] loss: 0.0340819359\n",
      "[timestep: 1] [epoch: 8941] loss: 0.0206426699\n",
      "[timestep: 1] [epoch: 8971] loss: 0.0304263607\n",
      "[timestep: 1] [epoch: 9001] loss: 0.0266960748\n",
      "[timestep: 1] [epoch: 9031] loss: 0.0371943824\n",
      "[timestep: 1] [epoch: 9061] loss: 0.0438157767\n",
      "[timestep: 1] [epoch: 9091] loss: 0.0400464237\n",
      "[timestep: 1] [epoch: 9121] loss: 0.0156631079\n",
      "[timestep: 1] [epoch: 9151] loss: 0.0163075216\n",
      "[timestep: 1] [epoch: 9181] loss: 0.0264041349\n",
      "[timestep: 1] [epoch: 9211] loss: 0.0388751477\n",
      "[timestep: 1] [epoch: 9241] loss: 0.0218617488\n",
      "[timestep: 1] [epoch: 9271] loss: 0.0087772878\n",
      "[timestep: 1] [epoch: 9301] loss: 0.0085017309\n",
      "[timestep: 1] [epoch: 9331] loss: 0.0096874461\n",
      "[timestep: 1] [epoch: 9361] loss: 0.0093452968\n",
      "[timestep: 1] [epoch: 9391] loss: 0.0120462934\n",
      "[timestep: 1] [epoch: 9421] loss: 0.0136569496\n",
      "[timestep: 1] [epoch: 9451] loss: 0.0257149078\n",
      "[timestep: 1] [epoch: 9481] loss: 0.0288872197\n",
      "[timestep: 1] [epoch: 9511] loss: 0.0302970409\n",
      "[timestep: 1] [epoch: 9541] loss: 0.0197780933\n",
      "[timestep: 1] [epoch: 9571] loss: 0.0115203112\n",
      "[timestep: 1] [epoch: 9601] loss: 0.0270906426\n",
      "[timestep: 1] [epoch: 9631] loss: 0.0181612652\n",
      "[timestep: 1] [epoch: 9661] loss: 0.0239686668\n",
      "[timestep: 1] [epoch: 9691] loss: 0.0215198137\n",
      "[timestep: 1] [epoch: 9721] loss: 0.0310155302\n",
      "[timestep: 1] [epoch: 9751] loss: 0.0331477597\n",
      "[timestep: 1] [epoch: 9781] loss: 0.0189644210\n",
      "[timestep: 1] [epoch: 9811] loss: 0.0169642568\n",
      "[timestep: 1] [epoch: 9841] loss: 0.0245284326\n",
      "[timestep: 1] [epoch: 9871] loss: 0.0167785063\n",
      "[timestep: 1] [epoch: 9901] loss: 0.0127502587\n",
      "[timestep: 1] [epoch: 9931] loss: 0.0237216726\n",
      "[timestep: 1] [epoch: 9961] loss: 0.0238868184\n",
      "[timestep: 1] [epoch: 9991] loss: 0.0266727842\n",
      "[timestep: 1] [epoch: 10021] loss: 0.0305184517\n",
      "[timestep: 1] [epoch: 10051] loss: 0.0184539668\n",
      "[timestep: 1] [epoch: 10081] loss: 0.0189112537\n",
      "[timestep: 1] [epoch: 10111] loss: 0.0078017670\n",
      "[timestep: 1] [epoch: 10141] loss: 0.0268180519\n",
      "[timestep: 1] [epoch: 10171] loss: 0.0150497546\n",
      "[timestep: 1] [epoch: 10201] loss: 0.0167549569\n",
      "[timestep: 1] [epoch: 10231] loss: 0.0122236563\n",
      "[timestep: 1] [epoch: 10261] loss: 0.0123681407\n",
      "[timestep: 1] [epoch: 10291] loss: 0.0142908171\n",
      "[timestep: 1] [epoch: 10321] loss: 0.0173002779\n",
      "[timestep: 1] [epoch: 10351] loss: 0.0183566809\n",
      "[timestep: 1] [epoch: 10381] loss: 0.0213923808\n",
      "[timestep: 1] [epoch: 10411] loss: 0.0272154547\n",
      "[timestep: 1] [epoch: 10441] loss: 0.0126903951\n",
      "[timestep: 1] [epoch: 10471] loss: 0.0253702290\n",
      "[timestep: 1] [epoch: 10501] loss: 0.0199286602\n",
      "[timestep: 1] [epoch: 10531] loss: 0.0135402298\n",
      "[timestep: 1] [epoch: 10561] loss: 0.0190777294\n",
      "[timestep: 1] [epoch: 10591] loss: 0.0212627836\n",
      "[timestep: 1] [epoch: 10621] loss: 0.0123067871\n",
      "[timestep: 1] [epoch: 10651] loss: 0.0089650620\n",
      "[timestep: 1] [epoch: 10681] loss: 0.0096174069\n",
      "[timestep: 1] [epoch: 10711] loss: 0.0272955112\n",
      "[timestep: 1] [epoch: 10741] loss: 0.0168282222\n",
      "[timestep: 1] [epoch: 10771] loss: 0.0410781279\n",
      "[timestep: 1] [epoch: 10801] loss: 0.0395388640\n",
      "[timestep: 1] [epoch: 10831] loss: 0.0078628734\n",
      "[timestep: 1] [epoch: 10861] loss: 0.0208953656\n",
      "[timestep: 1] [epoch: 10891] loss: 0.0189582817\n",
      "[timestep: 1] [epoch: 10921] loss: 0.0165203977\n",
      "[timestep: 1] [epoch: 10951] loss: 0.0122324154\n",
      "[timestep: 1] [epoch: 10981] loss: 0.0076582329\n",
      "[timestep: 1] [epoch: 11011] loss: 0.0085271075\n",
      "[timestep: 1] [epoch: 11041] loss: 0.0193559565\n",
      "[timestep: 1] [epoch: 11071] loss: 0.0081840726\n",
      "[timestep: 1] [epoch: 11101] loss: 0.0089084618\n",
      "[timestep: 1] [epoch: 11131] loss: 0.0117497891\n",
      "[timestep: 1] [epoch: 11161] loss: 0.0098875202\n",
      "[timestep: 1] [epoch: 11191] loss: 0.0136507349\n",
      "[timestep: 1] [epoch: 11221] loss: 0.0089576673\n",
      "[timestep: 1] [epoch: 11251] loss: 0.0210412405\n",
      "[timestep: 1] [epoch: 11281] loss: 0.0255986638\n",
      "[timestep: 1] [epoch: 11311] loss: 0.0192126986\n",
      "[timestep: 1] [epoch: 11341] loss: 0.0301642399\n",
      "[timestep: 1] [epoch: 11371] loss: 0.0035247768\n",
      "[timestep: 1] [epoch: 11401] loss: 0.0115793198\n",
      "[timestep: 1] [epoch: 11431] loss: 0.0270413794\n",
      "[timestep: 1] [epoch: 11461] loss: 0.0203258395\n",
      "[timestep: 1] [epoch: 11491] loss: 0.0067333123\n",
      "[timestep: 1] [epoch: 11521] loss: 0.0190600716\n",
      "[timestep: 1] [epoch: 11551] loss: 0.0141902547\n",
      "[timestep: 1] [epoch: 11581] loss: 0.0147537347\n",
      "[timestep: 1] [epoch: 11611] loss: 0.0196700469\n",
      "[timestep: 1] [epoch: 11641] loss: 0.0238200799\n",
      "[timestep: 1] [epoch: 11671] loss: 0.0169344544\n",
      "[timestep: 1] [epoch: 11701] loss: 0.0220550690\n",
      "[timestep: 1] [epoch: 11731] loss: 0.0196105689\n",
      "[timestep: 1] [epoch: 11761] loss: 0.0174896810\n",
      "[timestep: 1] [epoch: 11791] loss: 0.0135566182\n",
      "[timestep: 1] [epoch: 11821] loss: 0.0310964137\n",
      "[timestep: 1] [epoch: 11851] loss: 0.0074365446\n",
      "[timestep: 1] [epoch: 11881] loss: 0.0115509713\n",
      "[timestep: 1] [epoch: 11911] loss: 0.0056477794\n",
      "[timestep: 1] [epoch: 11941] loss: 0.0042886324\n",
      "[timestep: 1] [epoch: 11971] loss: 0.0180479847\n",
      "[timestep: 1] [epoch: 12001] loss: 0.0053930157\n",
      "[timestep: 1] [epoch: 12031] loss: 0.0069611678\n",
      "[timestep: 1] [epoch: 12061] loss: 0.0066598812\n",
      "[timestep: 1] [epoch: 12091] loss: 0.0087576136\n",
      "[timestep: 1] [epoch: 12121] loss: 0.0101899710\n",
      "[timestep: 1] [epoch: 12151] loss: 0.0160176642\n",
      "[timestep: 1] [epoch: 12181] loss: 0.0128208045\n",
      "[timestep: 1] [epoch: 12211] loss: 0.0154705700\n",
      "[timestep: 1] [epoch: 12241] loss: 0.0102253808\n",
      "[timestep: 1] [epoch: 12271] loss: 0.0229856595\n",
      "[timestep: 1] [epoch: 12301] loss: 0.0191689637\n",
      "[timestep: 1] [epoch: 12331] loss: 0.0282554664\n",
      "[timestep: 1] [epoch: 12361] loss: 0.0150994938\n",
      "[timestep: 1] [epoch: 12391] loss: 0.0065071248\n",
      "[timestep: 1] [epoch: 12421] loss: 0.0054360339\n",
      "[timestep: 1] [epoch: 12451] loss: 0.0049457033\n",
      "[timestep: 1] [epoch: 12481] loss: 0.0105336066\n",
      "[timestep: 1] [epoch: 12511] loss: 0.0205053408\n",
      "[timestep: 1] [epoch: 12541] loss: 0.0034063456\n",
      "[timestep: 1] [epoch: 12571] loss: 0.0227539372\n",
      "[timestep: 1] [epoch: 12601] loss: 0.0105570555\n",
      "[timestep: 1] [epoch: 12631] loss: 0.0100669954\n",
      "[timestep: 1] [epoch: 12661] loss: 0.0053751608\n",
      "[timestep: 1] [epoch: 12691] loss: 0.0072753485\n",
      "[timestep: 1] [epoch: 12721] loss: 0.0066361940\n",
      "[timestep: 1] [epoch: 12751] loss: 0.0058405474\n",
      "[timestep: 1] [epoch: 12781] loss: 0.0061513111\n",
      "[timestep: 1] [epoch: 12811] loss: 0.0119461212\n",
      "[timestep: 1] [epoch: 12841] loss: 0.0072216969\n",
      "[timestep: 1] [epoch: 12871] loss: 0.0052028624\n",
      "[timestep: 1] [epoch: 12901] loss: 0.0232316218\n",
      "[timestep: 1] [epoch: 12931] loss: 0.0134910746\n",
      "[timestep: 1] [epoch: 12961] loss: 0.0134590659\n",
      "[timestep: 1] [epoch: 12991] loss: 0.0115136784\n",
      "[timestep: 1] [epoch: 13021] loss: 0.0089002429\n",
      "[timestep: 1] [epoch: 13051] loss: 0.0086000795\n",
      "[timestep: 1] [epoch: 13081] loss: 0.0088807717\n",
      "[timestep: 1] [epoch: 13111] loss: 0.0122554824\n",
      "[timestep: 1] [epoch: 13141] loss: 0.0082855728\n",
      "[timestep: 1] [epoch: 13171] loss: 0.0064687342\n",
      "[timestep: 1] [epoch: 13201] loss: 0.0136519037\n",
      "[timestep: 1] [epoch: 13231] loss: 0.0085211806\n",
      "[timestep: 1] [epoch: 13261] loss: 0.0145231811\n",
      "[timestep: 1] [epoch: 13291] loss: 0.0134778339\n",
      "[timestep: 1] [epoch: 13321] loss: 0.0143157355\n",
      "[timestep: 1] [epoch: 13351] loss: 0.0469535552\n",
      "[timestep: 1] [epoch: 13381] loss: 0.0303413328\n",
      "[timestep: 1] [epoch: 13411] loss: 0.0150144296\n",
      "[timestep: 1] [epoch: 13441] loss: 0.0143422727\n",
      "[timestep: 1] [epoch: 13471] loss: 0.0125717819\n",
      "[timestep: 1] [epoch: 13501] loss: 0.0115337912\n",
      "[timestep: 1] [epoch: 13531] loss: 0.0100568719\n",
      "[timestep: 1] [epoch: 13561] loss: 0.0123918951\n",
      "[timestep: 1] [epoch: 13591] loss: 0.0079245362\n",
      "[timestep: 1] [epoch: 13621] loss: 0.0059741437\n",
      "[timestep: 1] [epoch: 13651] loss: 0.0155233247\n",
      "[timestep: 1] [epoch: 13681] loss: 0.0034519020\n",
      "[timestep: 1] [epoch: 13711] loss: 0.0059947437\n",
      "[timestep: 1] [epoch: 13741] loss: 0.0061948127\n",
      "[timestep: 1] [epoch: 13771] loss: 0.0160458963\n",
      "[timestep: 1] [epoch: 13801] loss: 0.0099197803\n",
      "[timestep: 1] [epoch: 13831] loss: 0.0028628714\n",
      "[timestep: 1] [epoch: 13861] loss: 0.0053201122\n",
      "[timestep: 1] [epoch: 13891] loss: 0.0094303703\n",
      "[timestep: 1] [epoch: 13921] loss: 0.0087303668\n",
      "[timestep: 1] [epoch: 13951] loss: 0.0053051682\n",
      "[timestep: 1] [epoch: 13981] loss: 0.0086585712\n",
      "[timestep: 1] [epoch: 14011] loss: 0.0068260059\n",
      "[timestep: 1] [epoch: 14041] loss: 0.0052336366\n",
      "[timestep: 1] [epoch: 14071] loss: 0.0031601768\n",
      "[timestep: 1] [epoch: 14101] loss: 0.0024505099\n",
      "[timestep: 1] [epoch: 14131] loss: 0.0156737510\n",
      "[timestep: 1] [epoch: 14161] loss: 0.0130953789\n",
      "[timestep: 1] [epoch: 14191] loss: 0.0105280075\n",
      "[timestep: 1] [epoch: 14221] loss: 0.0136932731\n",
      "[timestep: 1] [epoch: 14251] loss: 0.0035707667\n",
      "[timestep: 1] [epoch: 14281] loss: 0.0147043904\n",
      "[timestep: 1] [epoch: 14311] loss: 0.0102495626\n",
      "[timestep: 1] [epoch: 14341] loss: 0.0098313801\n",
      "[timestep: 1] [epoch: 14371] loss: 0.0113707511\n",
      "[timestep: 1] [epoch: 14401] loss: 0.0237742625\n",
      "[timestep: 1] [epoch: 14431] loss: 0.0146704288\n",
      "[timestep: 1] [epoch: 14461] loss: 0.0039578415\n",
      "[timestep: 1] [epoch: 14491] loss: 0.0059097121\n",
      "[timestep: 1] [epoch: 14521] loss: 0.0107365763\n",
      "[timestep: 1] [epoch: 14551] loss: 0.0049401792\n",
      "[timestep: 1] [epoch: 14581] loss: 0.0075506084\n",
      "[timestep: 1] [epoch: 14611] loss: 0.0069847899\n",
      "[timestep: 1] [epoch: 14641] loss: 0.0040282374\n",
      "[timestep: 1] [epoch: 14671] loss: 0.0071755983\n",
      "[timestep: 1] [epoch: 14701] loss: 0.0132826585\n",
      "[timestep: 1] [epoch: 14731] loss: 0.0176738147\n",
      "[timestep: 1] [epoch: 14761] loss: 0.0116138756\n",
      "[timestep: 1] [epoch: 14791] loss: 0.0096255541\n",
      "[timestep: 1] [epoch: 14821] loss: 0.0177740715\n",
      "[timestep: 1] [epoch: 14851] loss: 0.0107383495\n",
      "[timestep: 1] [epoch: 14881] loss: 0.0073823910\n",
      "[timestep: 1] [epoch: 14911] loss: 0.0134424828\n",
      "[timestep: 1] [epoch: 14941] loss: 0.0176618025\n",
      "[timestep: 1] [epoch: 14971] loss: 0.0078968089\n",
      "[timestep: 1] [epoch: 15001] loss: 0.0047441814\n",
      "[timestep: 1] [epoch: 15031] loss: 0.0086618643\n",
      "[timestep: 1] [epoch: 15061] loss: 0.0103107961\n",
      "[timestep: 1] [epoch: 15091] loss: 0.0032000544\n",
      "[timestep: 1] [epoch: 15121] loss: 0.0029670312\n",
      "[timestep: 1] [epoch: 15151] loss: 0.0047256332\n",
      "[timestep: 1] [epoch: 15181] loss: 0.0048813233\n",
      "[timestep: 1] [epoch: 15211] loss: 0.0044173957\n",
      "[timestep: 1] [epoch: 15241] loss: 0.0111126248\n",
      "[timestep: 1] [epoch: 15271] loss: 0.0084356535\n",
      "[timestep: 1] [epoch: 15301] loss: 0.0050971862\n",
      "[timestep: 1] [epoch: 15331] loss: 0.0042689508\n",
      "[timestep: 1] [epoch: 15361] loss: 0.0035572601\n",
      "[timestep: 1] [epoch: 15391] loss: 0.0124875614\n",
      "[timestep: 1] [epoch: 15421] loss: 0.0117090773\n",
      "[timestep: 1] [epoch: 15451] loss: 0.0119989486\n",
      "[timestep: 1] [epoch: 15481] loss: 0.0052346569\n",
      "[timestep: 1] [epoch: 15511] loss: 0.0103560090\n",
      "[timestep: 1] [epoch: 15541] loss: 0.0034725030\n",
      "[timestep: 1] [epoch: 15571] loss: 0.0041622650\n",
      "[timestep: 1] [epoch: 15601] loss: 0.0043982677\n",
      "[timestep: 1] [epoch: 15631] loss: 0.0021871985\n",
      "[timestep: 1] [epoch: 15661] loss: 0.0031657135\n",
      "[timestep: 1] [epoch: 15691] loss: 0.0027403184\n",
      "[timestep: 1] [epoch: 15721] loss: 0.0038437876\n",
      "[timestep: 1] [epoch: 15751] loss: 0.0135001205\n",
      "[timestep: 1] [epoch: 15781] loss: 0.0125565501\n",
      "[timestep: 1] [epoch: 15811] loss: 0.0081547555\n",
      "[timestep: 1] [epoch: 15841] loss: 0.0036617874\n",
      "[timestep: 1] [epoch: 15871] loss: 0.0049781259\n",
      "[timestep: 1] [epoch: 15901] loss: 0.0059791058\n",
      "[timestep: 1] [epoch: 15931] loss: 0.0069267587\n",
      "[timestep: 1] [epoch: 15961] loss: 0.0104474016\n",
      "[timestep: 1] [epoch: 15991] loss: 0.0036540267\n",
      "[timestep: 1] [epoch: 16021] loss: 0.0025204159\n",
      "[timestep: 1] [epoch: 16051] loss: 0.0031567172\n",
      "[timestep: 1] [epoch: 16081] loss: 0.0047986815\n",
      "[timestep: 1] [epoch: 16111] loss: 0.0042353617\n",
      "[timestep: 1] [epoch: 16141] loss: 0.0071946215\n",
      "[timestep: 1] [epoch: 16171] loss: 0.0063454993\n",
      "[timestep: 1] [epoch: 16201] loss: 0.0021819386\n",
      "[timestep: 1] [epoch: 16231] loss: 0.0059770262\n",
      "[timestep: 1] [epoch: 16261] loss: 0.0079492917\n",
      "[timestep: 1] [epoch: 16291] loss: 0.0082700625\n",
      "[timestep: 1] [epoch: 16321] loss: 0.0079914611\n",
      "[timestep: 1] [epoch: 16351] loss: 0.0063546887\n",
      "[timestep: 1] [epoch: 16381] loss: 0.0020724302\n",
      "[timestep: 1] [epoch: 16411] loss: 0.0043136096\n",
      "[timestep: 1] [epoch: 16441] loss: 0.0048470451\n",
      "[timestep: 1] [epoch: 16471] loss: 0.0118220486\n",
      "[timestep: 1] [epoch: 16501] loss: 0.0184974559\n",
      "[timestep: 1] [epoch: 16531] loss: 0.0050826771\n",
      "[timestep: 1] [epoch: 16561] loss: 0.0021262350\n",
      "[timestep: 1] [epoch: 16591] loss: 0.0027338294\n",
      "[timestep: 1] [epoch: 16621] loss: 0.0027946783\n",
      "[timestep: 1] [epoch: 16651] loss: 0.0021719774\n",
      "[timestep: 1] [epoch: 16681] loss: 0.0056990609\n",
      "[timestep: 1] [epoch: 16711] loss: 0.0041084103\n",
      "[timestep: 1] [epoch: 16741] loss: 0.0060579623\n",
      "[timestep: 1] [epoch: 16771] loss: 0.0073788962\n",
      "[timestep: 1] [epoch: 16801] loss: 0.0129518677\n",
      "[timestep: 1] [epoch: 16831] loss: 0.0087318327\n",
      "[timestep: 1] [epoch: 16861] loss: 0.0039651105\n",
      "[timestep: 1] [epoch: 16891] loss: 0.0155800078\n",
      "[timestep: 1] [epoch: 16921] loss: 0.0024974952\n",
      "[timestep: 1] [epoch: 16951] loss: 0.0028186094\n",
      "[timestep: 1] [epoch: 16981] loss: 0.0038393131\n",
      "[timestep: 1] [epoch: 17011] loss: 0.0057947598\n",
      "[timestep: 1] [epoch: 17041] loss: 0.0088916495\n",
      "[timestep: 1] [epoch: 17071] loss: 0.0063146725\n",
      "[timestep: 1] [epoch: 17101] loss: 0.0099143721\n",
      "[timestep: 1] [epoch: 17131] loss: 0.0099500697\n",
      "[timestep: 1] [epoch: 17161] loss: 0.0114524961\n",
      "[timestep: 1] [epoch: 17191] loss: 0.0043081786\n",
      "[timestep: 1] [epoch: 17221] loss: 0.0032166685\n",
      "[timestep: 1] [epoch: 17251] loss: 0.0089479415\n",
      "[timestep: 1] [epoch: 17281] loss: 0.0076295640\n",
      "[timestep: 1] [epoch: 17311] loss: 0.0061131977\n",
      "[timestep: 1] [epoch: 17341] loss: 0.0129760057\n",
      "[timestep: 1] [epoch: 17371] loss: 0.0143243885\n",
      "[timestep: 1] [epoch: 17401] loss: 0.0642045140\n",
      "[timestep: 1] [epoch: 17431] loss: 0.0106326565\n",
      "[timestep: 1] [epoch: 17461] loss: 0.0107595306\n",
      "[timestep: 1] [epoch: 17491] loss: 0.0040745903\n",
      "[timestep: 1] [epoch: 17521] loss: 0.0022177773\n",
      "[timestep: 1] [epoch: 17551] loss: 0.0015581844\n",
      "[timestep: 1] [epoch: 17581] loss: 0.0020259870\n",
      "[timestep: 1] [epoch: 17611] loss: 0.0020307677\n",
      "[timestep: 1] [epoch: 17641] loss: 0.0031702868\n",
      "[timestep: 1] [epoch: 17671] loss: 0.0022135526\n",
      "[timestep: 1] [epoch: 17701] loss: 0.0016808867\n",
      "[timestep: 1] [epoch: 17731] loss: 0.0090724248\n",
      "[timestep: 1] [epoch: 17761] loss: 0.0082317591\n",
      "[timestep: 1] [epoch: 17791] loss: 0.0052072285\n",
      "[timestep: 1] [epoch: 17821] loss: 0.0038790675\n",
      "[timestep: 1] [epoch: 17851] loss: 0.0052777315\n",
      "[timestep: 1] [epoch: 17881] loss: 0.0013202626\n",
      "[timestep: 1] [epoch: 17911] loss: 0.0016288909\n",
      "[timestep: 1] [epoch: 17941] loss: 0.0030198549\n",
      "[timestep: 1] [epoch: 17971] loss: 0.0015804662\n",
      "[timestep: 1] [epoch: 18001] loss: 0.0016912615\n",
      "[timestep: 1] [epoch: 18031] loss: 0.0022160453\n",
      "[timestep: 1] [epoch: 18061] loss: 0.0022841708\n",
      "[timestep: 1] [epoch: 18091] loss: 0.0024649792\n",
      "[timestep: 1] [epoch: 18121] loss: 0.0021289065\n",
      "[timestep: 1] [epoch: 18151] loss: 0.0023629547\n",
      "[timestep: 1] [epoch: 18181] loss: 0.0026155587\n",
      "[timestep: 1] [epoch: 18211] loss: 0.0028208606\n",
      "[timestep: 1] [epoch: 18241] loss: 0.0030489503\n",
      "[timestep: 1] [epoch: 18271] loss: 0.0018283739\n",
      "[timestep: 1] [epoch: 18301] loss: 0.0016497527\n",
      "[timestep: 1] [epoch: 18331] loss: 0.0020086423\n",
      "[timestep: 1] [epoch: 18361] loss: 0.0021582071\n",
      "[timestep: 1] [epoch: 18391] loss: 0.0035199439\n",
      "[timestep: 1] [epoch: 18421] loss: 0.0018804006\n",
      "[timestep: 1] [epoch: 18451] loss: 0.0014338780\n",
      "[timestep: 1] [epoch: 18481] loss: 0.0021994256\n",
      "[timestep: 1] [epoch: 18511] loss: 0.0099114319\n",
      "[timestep: 1] [epoch: 18541] loss: 0.0113394698\n",
      "[timestep: 1] [epoch: 18571] loss: 0.0045000622\n",
      "[timestep: 1] [epoch: 18601] loss: 0.0182131529\n",
      "[timestep: 1] [epoch: 18631] loss: 0.0161542371\n",
      "[timestep: 1] [epoch: 18661] loss: 0.0070752627\n",
      "[timestep: 1] [epoch: 18691] loss: 0.0032483945\n",
      "[timestep: 1] [epoch: 18721] loss: 0.0021006409\n",
      "[timestep: 1] [epoch: 18751] loss: 0.0037206807\n",
      "[timestep: 1] [epoch: 18781] loss: 0.0018785524\n",
      "[timestep: 1] [epoch: 18811] loss: 0.0029245419\n",
      "[timestep: 1] [epoch: 18841] loss: 0.0021949520\n",
      "[timestep: 1] [epoch: 18871] loss: 0.0016957214\n",
      "[timestep: 1] [epoch: 18901] loss: 0.0023609437\n",
      "[timestep: 1] [epoch: 18931] loss: 0.0028002583\n",
      "[timestep: 1] [epoch: 18961] loss: 0.0035057068\n",
      "[timestep: 1] [epoch: 18991] loss: 0.0047661313\n",
      "[timestep: 1] [epoch: 19021] loss: 0.0125553720\n",
      "[timestep: 1] [epoch: 19051] loss: 0.0031557274\n",
      "[timestep: 1] [epoch: 19081] loss: 0.0047409786\n",
      "[timestep: 1] [epoch: 19111] loss: 0.0022721405\n",
      "[timestep: 1] [epoch: 19141] loss: 0.0014560795\n",
      "[timestep: 1] [epoch: 19171] loss: 0.0011916552\n",
      "[timestep: 1] [epoch: 19201] loss: 0.0017944188\n",
      "[timestep: 1] [epoch: 19231] loss: 0.0022773952\n",
      "[timestep: 1] [epoch: 19261] loss: 0.0043785200\n",
      "[timestep: 1] [epoch: 19291] loss: 0.0025659266\n",
      "[timestep: 1] [epoch: 19321] loss: 0.0021415283\n",
      "[timestep: 1] [epoch: 19351] loss: 0.0016530821\n",
      "[timestep: 1] [epoch: 19381] loss: 0.0024361215\n",
      "[timestep: 1] [epoch: 19411] loss: 0.0024725255\n",
      "[timestep: 1] [epoch: 19441] loss: 0.0081239808\n",
      "[timestep: 1] [epoch: 19471] loss: 0.0022398296\n",
      "[timestep: 1] [epoch: 19501] loss: 0.0057022898\n",
      "[timestep: 1] [epoch: 19531] loss: 0.0016007381\n",
      "[timestep: 1] [epoch: 19561] loss: 0.0012105004\n",
      "[timestep: 1] [epoch: 19591] loss: 0.0017787642\n",
      "[timestep: 1] [epoch: 19621] loss: 0.0014965342\n",
      "[timestep: 1] [epoch: 19651] loss: 0.0021177127\n",
      "[timestep: 1] [epoch: 19681] loss: 0.0013581306\n",
      "[timestep: 1] [epoch: 19711] loss: 0.0068846932\n",
      "[timestep: 1] [epoch: 19741] loss: 0.0077119390\n",
      "[timestep: 1] [epoch: 19771] loss: 0.0044165491\n",
      "[timestep: 1] [epoch: 19801] loss: 0.0088109821\n",
      "[timestep: 1] [epoch: 19831] loss: 0.0025331033\n",
      "[timestep: 1] [epoch: 19861] loss: 0.0012210899\n",
      "[timestep: 1] [epoch: 19891] loss: 0.0011827452\n",
      "[timestep: 1] [epoch: 19921] loss: 0.0027827939\n",
      "[timestep: 1] [epoch: 19951] loss: 0.0016064367\n",
      "[timestep: 1] [epoch: 19981] loss: 0.0013094090\n",
      "[timestep: 1] [epoch: 20011] loss: 0.0033486083\n",
      "[timestep: 1] [epoch: 20041] loss: 0.0025005525\n",
      "[timestep: 1] [epoch: 20071] loss: 0.0015261503\n",
      "[timestep: 1] [epoch: 20101] loss: 0.0029321560\n",
      "[timestep: 1] [epoch: 20131] loss: 0.0011596254\n",
      "[timestep: 1] [epoch: 20161] loss: 0.0013509601\n",
      "[timestep: 1] [epoch: 20191] loss: 0.0019184869\n",
      "[timestep: 1] [epoch: 20221] loss: 0.0025525584\n",
      "[timestep: 1] [epoch: 20251] loss: 0.0019348526\n",
      "[timestep: 1] [epoch: 20281] loss: 0.0020265859\n",
      "[timestep: 1] [epoch: 20311] loss: 0.0016556911\n",
      "[timestep: 1] [epoch: 20341] loss: 0.0017812180\n",
      "[timestep: 1] [epoch: 20371] loss: 0.0014611095\n",
      "[timestep: 1] [epoch: 20401] loss: 0.0011477231\n",
      "[timestep: 1] [epoch: 20431] loss: 0.0021164799\n",
      "[timestep: 1] [epoch: 20461] loss: 0.0016727614\n",
      "[timestep: 1] [epoch: 20491] loss: 0.0022382198\n",
      "[timestep: 1] [epoch: 20521] loss: 0.0043419916\n",
      "[timestep: 1] [epoch: 20551] loss: 0.0049508484\n",
      "[timestep: 1] [epoch: 20581] loss: 0.0032469553\n",
      "[timestep: 1] [epoch: 20611] loss: 0.0017000659\n",
      "[timestep: 1] [epoch: 20641] loss: 0.0014998030\n",
      "[timestep: 1] [epoch: 20671] loss: 0.0016935727\n",
      "[timestep: 1] [epoch: 20701] loss: 0.0033537876\n",
      "[timestep: 1] [epoch: 20731] loss: 0.0028280052\n",
      "[timestep: 1] [epoch: 20761] loss: 0.0037569336\n",
      "[timestep: 1] [epoch: 20791] loss: 0.0026309341\n",
      "[timestep: 1] [epoch: 20821] loss: 0.0012434195\n",
      "[timestep: 1] [epoch: 20851] loss: 0.0011867161\n",
      "[timestep: 1] [epoch: 20881] loss: 0.0018310382\n",
      "[timestep: 1] [epoch: 20911] loss: 0.0080962684\n",
      "[timestep: 1] [epoch: 20941] loss: 0.0058926418\n",
      "[timestep: 1] [epoch: 20971] loss: 0.0080021918\n",
      "[timestep: 1] [epoch: 21001] loss: 0.0030392939\n",
      "[timestep: 1] [epoch: 21031] loss: 0.0021421593\n",
      "[timestep: 1] [epoch: 21061] loss: 0.0015842061\n",
      "[timestep: 1] [epoch: 21091] loss: 0.0024778801\n",
      "[timestep: 1] [epoch: 21121] loss: 0.0015088478\n",
      "[timestep: 1] [epoch: 21151] loss: 0.0014507066\n",
      "[timestep: 1] [epoch: 21181] loss: 0.0013117099\n",
      "[timestep: 1] [epoch: 21211] loss: 0.0015237930\n",
      "[timestep: 1] [epoch: 21241] loss: 0.0018144064\n",
      "[timestep: 1] [epoch: 21271] loss: 0.0029019667\n",
      "[timestep: 1] [epoch: 21301] loss: 0.0017897326\n",
      "[timestep: 1] [epoch: 21331] loss: 0.0015347297\n",
      "[timestep: 1] [epoch: 21361] loss: 0.0013078030\n",
      "[timestep: 1] [epoch: 21391] loss: 0.0010145828\n",
      "[timestep: 1] [epoch: 21421] loss: 0.0020235560\n",
      "[timestep: 1] [epoch: 21451] loss: 0.0013054906\n",
      "[timestep: 1] [epoch: 21481] loss: 0.0035629559\n",
      "[timestep: 1] [epoch: 21511] loss: 0.0027482989\n",
      "[timestep: 1] [epoch: 21541] loss: 0.0056808870\n",
      "[timestep: 1] [epoch: 21571] loss: 0.0070987125\n",
      "[timestep: 1] [epoch: 21601] loss: 0.0048498409\n",
      "[timestep: 1] [epoch: 21631] loss: 0.0022049763\n",
      "[timestep: 1] [epoch: 21661] loss: 0.0017306868\n",
      "[timestep: 1] [epoch: 21691] loss: 0.0014751351\n",
      "[timestep: 1] [epoch: 21721] loss: 0.0011945914\n",
      "0.01\n",
      "[timestep: 2] [epoch: 1] loss: 0.9667053223\n",
      "[timestep: 2] [epoch: 31] loss: 0.4341491461\n",
      "[timestep: 2] [epoch: 61] loss: 0.1951028109\n",
      "[timestep: 2] [epoch: 91] loss: 0.0622921810\n",
      "[timestep: 2] [epoch: 121] loss: 0.0524995402\n",
      "[timestep: 2] [epoch: 151] loss: 0.0399307795\n",
      "[timestep: 2] [epoch: 181] loss: 0.0257799309\n",
      "[timestep: 2] [epoch: 211] loss: 0.0255333297\n",
      "[timestep: 2] [epoch: 241] loss: 0.0173961483\n",
      "[timestep: 2] [epoch: 271] loss: 0.0147248106\n",
      "[timestep: 2] [epoch: 301] loss: 0.0231460948\n",
      "[timestep: 2] [epoch: 331] loss: 0.0258591976\n",
      "[timestep: 2] [epoch: 361] loss: 0.0348160118\n",
      "[timestep: 2] [epoch: 391] loss: 0.0172849130\n",
      "[timestep: 2] [epoch: 421] loss: 0.0235976800\n",
      "[timestep: 2] [epoch: 451] loss: 0.0353567190\n",
      "[timestep: 2] [epoch: 481] loss: 0.0232303124\n",
      "[timestep: 2] [epoch: 511] loss: 0.0184259228\n",
      "[timestep: 2] [epoch: 541] loss: 0.0102553274\n",
      "[timestep: 2] [epoch: 571] loss: 0.0091956016\n",
      "[timestep: 2] [epoch: 601] loss: 0.0052396171\n",
      "[timestep: 2] [epoch: 631] loss: 0.0062550940\n",
      "[timestep: 2] [epoch: 661] loss: 0.0059863185\n",
      "[timestep: 2] [epoch: 691] loss: 0.0218926556\n",
      "[timestep: 2] [epoch: 721] loss: 0.0181212183\n",
      "[timestep: 2] [epoch: 751] loss: 0.0181089714\n",
      "[timestep: 2] [epoch: 781] loss: 0.0135971243\n",
      "[timestep: 2] [epoch: 811] loss: 0.0131467097\n",
      "[timestep: 2] [epoch: 841] loss: 0.0112580638\n",
      "[timestep: 2] [epoch: 871] loss: 0.0094764903\n",
      "[timestep: 2] [epoch: 901] loss: 0.0052758623\n",
      "[timestep: 2] [epoch: 931] loss: 0.0084510073\n",
      "[timestep: 2] [epoch: 961] loss: 0.0174439661\n",
      "[timestep: 2] [epoch: 991] loss: 0.0146713238\n",
      "[timestep: 2] [epoch: 1021] loss: 0.0096760346\n",
      "[timestep: 2] [epoch: 1051] loss: 0.0213135909\n",
      "[timestep: 2] [epoch: 1081] loss: 0.0179953687\n",
      "[timestep: 2] [epoch: 1111] loss: 0.0067002997\n",
      "[timestep: 2] [epoch: 1141] loss: 0.0084825074\n",
      "[timestep: 2] [epoch: 1171] loss: 0.0125803128\n",
      "[timestep: 2] [epoch: 1201] loss: 0.0168319494\n",
      "[timestep: 2] [epoch: 1231] loss: 0.0100901211\n",
      "[timestep: 2] [epoch: 1261] loss: 0.0034053531\n",
      "[timestep: 2] [epoch: 1291] loss: 0.0103560099\n",
      "[timestep: 2] [epoch: 1321] loss: 0.0100880228\n",
      "[timestep: 2] [epoch: 1351] loss: 0.0188010000\n",
      "[timestep: 2] [epoch: 1381] loss: 0.0133398725\n",
      "[timestep: 2] [epoch: 1411] loss: 0.0096324887\n",
      "[timestep: 2] [epoch: 1441] loss: 0.0168723501\n",
      "[timestep: 2] [epoch: 1471] loss: 0.0173536837\n",
      "[timestep: 2] [epoch: 1501] loss: 0.0137962541\n",
      "[timestep: 2] [epoch: 1531] loss: 0.0160992220\n",
      "[timestep: 2] [epoch: 1561] loss: 0.0166278556\n",
      "[timestep: 2] [epoch: 1591] loss: 0.0102516711\n",
      "[timestep: 2] [epoch: 1621] loss: 0.0250006318\n",
      "[timestep: 2] [epoch: 1651] loss: 0.0058388072\n",
      "[timestep: 2] [epoch: 1681] loss: 0.0114999665\n",
      "[timestep: 2] [epoch: 1711] loss: 0.0034853357\n",
      "[timestep: 2] [epoch: 1741] loss: 0.0157524571\n",
      "[timestep: 2] [epoch: 1771] loss: 0.0084842807\n",
      "[timestep: 2] [epoch: 1801] loss: 0.0103183687\n",
      "[timestep: 2] [epoch: 1831] loss: 0.0104312487\n",
      "[timestep: 2] [epoch: 1861] loss: 0.0180171225\n",
      "[timestep: 2] [epoch: 1891] loss: 0.0107925627\n",
      "[timestep: 2] [epoch: 1921] loss: 0.0091071259\n",
      "[timestep: 2] [epoch: 1951] loss: 0.0068399189\n",
      "[timestep: 2] [epoch: 1981] loss: 0.0105204862\n",
      "[timestep: 2] [epoch: 2011] loss: 0.0115992557\n",
      "[timestep: 2] [epoch: 2041] loss: 0.0098167565\n",
      "[timestep: 2] [epoch: 2071] loss: 0.0074919825\n",
      "[timestep: 2] [epoch: 2101] loss: 0.0163833201\n",
      "[timestep: 2] [epoch: 2131] loss: 0.0070204632\n",
      "[timestep: 2] [epoch: 2161] loss: 0.0087798815\n",
      "[timestep: 2] [epoch: 2191] loss: 0.0088155596\n",
      "[timestep: 2] [epoch: 2221] loss: 0.0190910324\n",
      "[timestep: 2] [epoch: 2251] loss: 0.0150796687\n",
      "[timestep: 2] [epoch: 2281] loss: 0.0076630730\n",
      "[timestep: 2] [epoch: 2311] loss: 0.0106361611\n",
      "[timestep: 2] [epoch: 2341] loss: 0.0245103985\n",
      "[timestep: 2] [epoch: 2371] loss: 0.0111002186\n",
      "[timestep: 2] [epoch: 2401] loss: 0.0042080018\n",
      "[timestep: 2] [epoch: 2431] loss: 0.0064571397\n",
      "[timestep: 2] [epoch: 2461] loss: 0.0106436778\n",
      "[timestep: 2] [epoch: 2491] loss: 0.0117349979\n",
      "[timestep: 2] [epoch: 2521] loss: 0.0162010416\n",
      "[timestep: 2] [epoch: 2551] loss: 0.0075863535\n",
      "[timestep: 2] [epoch: 2581] loss: 0.0068248529\n",
      "[timestep: 2] [epoch: 2611] loss: 0.0058872653\n",
      "[timestep: 2] [epoch: 2641] loss: 0.0085877851\n",
      "[timestep: 2] [epoch: 2671] loss: 0.0129617713\n",
      "[timestep: 2] [epoch: 2701] loss: 0.0026754253\n",
      "[timestep: 2] [epoch: 2731] loss: 0.0026148881\n",
      "[timestep: 2] [epoch: 2761] loss: 0.0050416589\n",
      "[timestep: 2] [epoch: 2791] loss: 0.0048734006\n",
      "[timestep: 2] [epoch: 2821] loss: 0.0065337853\n",
      "[timestep: 2] [epoch: 2851] loss: 0.0081971176\n",
      "[timestep: 2] [epoch: 2881] loss: 0.0065613384\n",
      "[timestep: 2] [epoch: 2911] loss: 0.0091977380\n",
      "[timestep: 2] [epoch: 2941] loss: 0.0081921881\n",
      "[timestep: 2] [epoch: 2971] loss: 0.0217348430\n",
      "[timestep: 2] [epoch: 3001] loss: 0.0101089505\n",
      "[timestep: 2] [epoch: 3031] loss: 0.0296074003\n",
      "[timestep: 2] [epoch: 3061] loss: 0.0179572217\n",
      "[timestep: 2] [epoch: 3091] loss: 0.0037928992\n",
      "[timestep: 2] [epoch: 3121] loss: 0.0102335904\n",
      "[timestep: 2] [epoch: 3151] loss: 0.0052619376\n",
      "[timestep: 2] [epoch: 3181] loss: 0.0051055015\n",
      "[timestep: 2] [epoch: 3211] loss: 0.0042627733\n",
      "[timestep: 2] [epoch: 3241] loss: 0.0022509587\n",
      "[timestep: 2] [epoch: 3271] loss: 0.0041147992\n",
      "[timestep: 2] [epoch: 3301] loss: 0.0059498902\n",
      "[timestep: 2] [epoch: 3331] loss: 0.0055708773\n",
      "[timestep: 2] [epoch: 3361] loss: 0.0063952566\n",
      "[timestep: 2] [epoch: 3391] loss: 0.0144034624\n",
      "[timestep: 2] [epoch: 3421] loss: 0.0046780501\n",
      "[timestep: 2] [epoch: 3451] loss: 0.0040670829\n",
      "[timestep: 2] [epoch: 3481] loss: 0.0079293568\n",
      "[timestep: 2] [epoch: 3511] loss: 0.0044272402\n",
      "[timestep: 2] [epoch: 3541] loss: 0.0033428133\n",
      "[timestep: 2] [epoch: 3571] loss: 0.0009689340\n",
      "0.01\n",
      "[timestep: 3] [epoch: 1] loss: 0.9263536334\n",
      "[timestep: 3] [epoch: 31] loss: 0.1000710130\n",
      "[timestep: 3] [epoch: 61] loss: 0.1017887890\n",
      "[timestep: 3] [epoch: 91] loss: 0.0328718163\n",
      "[timestep: 3] [epoch: 121] loss: 0.0370165631\n",
      "[timestep: 3] [epoch: 151] loss: 0.0270547029\n",
      "[timestep: 3] [epoch: 181] loss: 0.0318351723\n",
      "[timestep: 3] [epoch: 211] loss: 0.0321600549\n",
      "[timestep: 3] [epoch: 241] loss: 0.0473250002\n",
      "[timestep: 3] [epoch: 271] loss: 0.0285938960\n",
      "[timestep: 3] [epoch: 301] loss: 0.0352930725\n",
      "[timestep: 3] [epoch: 331] loss: 0.0324535370\n",
      "[timestep: 3] [epoch: 361] loss: 0.0393532515\n",
      "[timestep: 3] [epoch: 391] loss: 0.0285983402\n",
      "[timestep: 3] [epoch: 421] loss: 0.0255647898\n",
      "[timestep: 3] [epoch: 451] loss: 0.0296165161\n",
      "[timestep: 3] [epoch: 481] loss: 0.0277001765\n",
      "[timestep: 3] [epoch: 511] loss: 0.0251673199\n",
      "[timestep: 3] [epoch: 541] loss: 0.0359347835\n",
      "[timestep: 3] [epoch: 571] loss: 0.0270215161\n",
      "[timestep: 3] [epoch: 601] loss: 0.0264841095\n",
      "[timestep: 3] [epoch: 631] loss: 0.0246207360\n",
      "[timestep: 3] [epoch: 661] loss: 0.0297664441\n",
      "[timestep: 3] [epoch: 691] loss: 0.0271675568\n",
      "[timestep: 3] [epoch: 721] loss: 0.0299227722\n",
      "[timestep: 3] [epoch: 751] loss: 0.0306553189\n",
      "[timestep: 3] [epoch: 781] loss: 0.0308422651\n",
      "[timestep: 3] [epoch: 811] loss: 0.0331419967\n",
      "[timestep: 3] [epoch: 841] loss: 0.0325742885\n",
      "[timestep: 3] [epoch: 871] loss: 0.0361947343\n",
      "[timestep: 3] [epoch: 901] loss: 0.0278105922\n",
      "[timestep: 3] [epoch: 931] loss: 0.0223381557\n",
      "[timestep: 3] [epoch: 961] loss: 0.0228360370\n",
      "[timestep: 3] [epoch: 991] loss: 0.0443735160\n",
      "[timestep: 3] [epoch: 1021] loss: 0.0485954024\n",
      "[timestep: 3] [epoch: 1051] loss: 0.0265648738\n",
      "[timestep: 3] [epoch: 1081] loss: 0.0309082605\n",
      "[timestep: 3] [epoch: 1111] loss: 0.0294589289\n",
      "[timestep: 3] [epoch: 1141] loss: 0.0504346639\n",
      "[timestep: 3] [epoch: 1171] loss: 0.0272398591\n",
      "[timestep: 3] [epoch: 1201] loss: 0.0233587269\n",
      "[timestep: 3] [epoch: 1231] loss: 0.0239518862\n",
      "[timestep: 3] [epoch: 1261] loss: 0.0278031658\n",
      "[timestep: 3] [epoch: 1291] loss: 0.0295443349\n",
      "[timestep: 3] [epoch: 1321] loss: 0.0253463313\n",
      "[timestep: 3] [epoch: 1351] loss: 0.0265343636\n",
      "[timestep: 3] [epoch: 1381] loss: 0.0226824470\n",
      "[timestep: 3] [epoch: 1411] loss: 0.0328442231\n",
      "[timestep: 3] [epoch: 1441] loss: 0.0233439766\n",
      "[timestep: 3] [epoch: 1471] loss: 0.0301885158\n",
      "[timestep: 3] [epoch: 1501] loss: 0.0250664055\n",
      "[timestep: 3] [epoch: 1531] loss: 0.0307704881\n",
      "[timestep: 3] [epoch: 1561] loss: 0.0212838128\n",
      "[timestep: 3] [epoch: 1591] loss: 0.0330141261\n",
      "[timestep: 3] [epoch: 1621] loss: 0.0244971514\n",
      "[timestep: 3] [epoch: 1651] loss: 0.0265246257\n",
      "[timestep: 3] [epoch: 1681] loss: 0.0397377461\n",
      "[timestep: 3] [epoch: 1711] loss: 0.0252660960\n",
      "[timestep: 3] [epoch: 1741] loss: 0.0235291421\n",
      "[timestep: 3] [epoch: 1771] loss: 0.0209418163\n",
      "[timestep: 3] [epoch: 1801] loss: 0.0216433015\n",
      "[timestep: 3] [epoch: 1831] loss: 0.0215189531\n",
      "[timestep: 3] [epoch: 1861] loss: 0.0202818401\n",
      "[timestep: 3] [epoch: 1891] loss: 0.0213328693\n",
      "[timestep: 3] [epoch: 1921] loss: 0.0282893814\n",
      "[timestep: 3] [epoch: 1951] loss: 0.0274237618\n",
      "[timestep: 3] [epoch: 1981] loss: 0.0281599872\n",
      "[timestep: 3] [epoch: 2011] loss: 0.0251616966\n",
      "[timestep: 3] [epoch: 2041] loss: 0.0263551660\n",
      "[timestep: 3] [epoch: 2071] loss: 0.0250023752\n",
      "[timestep: 3] [epoch: 2101] loss: 0.0239429530\n",
      "[timestep: 3] [epoch: 2131] loss: 0.0230319165\n",
      "[timestep: 3] [epoch: 2161] loss: 0.0248069614\n",
      "[timestep: 3] [epoch: 2191] loss: 0.0281072482\n",
      "[timestep: 3] [epoch: 2221] loss: 0.0239554048\n",
      "[timestep: 3] [epoch: 2251] loss: 0.0253977105\n",
      "[timestep: 3] [epoch: 2281] loss: 0.0250745937\n",
      "[timestep: 3] [epoch: 2311] loss: 0.0271618664\n",
      "[timestep: 3] [epoch: 2341] loss: 0.0274580512\n",
      "[timestep: 3] [epoch: 2371] loss: 0.0327721760\n",
      "[timestep: 3] [epoch: 2401] loss: 0.0374323279\n",
      "[timestep: 3] [epoch: 2431] loss: 0.0234924927\n",
      "[timestep: 3] [epoch: 2461] loss: 0.0234111268\n",
      "[timestep: 3] [epoch: 2491] loss: 0.0245438702\n",
      "[timestep: 3] [epoch: 2521] loss: 0.0253725816\n",
      "[timestep: 3] [epoch: 2551] loss: 0.0233837329\n",
      "[timestep: 3] [epoch: 2581] loss: 0.0256343633\n",
      "[timestep: 3] [epoch: 2611] loss: 0.0252535529\n",
      "[timestep: 3] [epoch: 2641] loss: 0.0240856744\n",
      "[timestep: 3] [epoch: 2671] loss: 0.0249115136\n",
      "[timestep: 3] [epoch: 2701] loss: 0.0255181119\n",
      "[timestep: 3] [epoch: 2731] loss: 0.0264078788\n",
      "[timestep: 3] [epoch: 2761] loss: 0.0218168646\n",
      "[timestep: 3] [epoch: 2791] loss: 0.0205011629\n",
      "[timestep: 3] [epoch: 2821] loss: 0.0208343863\n",
      "[timestep: 3] [epoch: 2851] loss: 0.0316929072\n",
      "[timestep: 3] [epoch: 2881] loss: 0.0198434964\n",
      "[timestep: 3] [epoch: 2911] loss: 0.0214609317\n",
      "[timestep: 3] [epoch: 2941] loss: 0.0208382681\n",
      "[timestep: 3] [epoch: 2971] loss: 0.0214444548\n",
      "[timestep: 3] [epoch: 3001] loss: 0.0221705046\n",
      "[timestep: 3] [epoch: 3031] loss: 0.0200350080\n",
      "[timestep: 3] [epoch: 3061] loss: 0.0210287757\n",
      "[timestep: 3] [epoch: 3091] loss: 0.0227669552\n",
      "[timestep: 3] [epoch: 3121] loss: 0.0239739567\n",
      "[timestep: 3] [epoch: 3151] loss: 0.0205208659\n",
      "[timestep: 3] [epoch: 3181] loss: 0.0201730281\n",
      "[timestep: 3] [epoch: 3211] loss: 0.0209626071\n",
      "[timestep: 3] [epoch: 3241] loss: 0.0198319349\n",
      "[timestep: 3] [epoch: 3271] loss: 0.0221787207\n",
      "[timestep: 3] [epoch: 3301] loss: 0.0221909359\n",
      "[timestep: 3] [epoch: 3331] loss: 0.0216998979\n",
      "[timestep: 3] [epoch: 3361] loss: 0.0280020498\n",
      "[timestep: 3] [epoch: 3391] loss: 0.0227424372\n",
      "[timestep: 3] [epoch: 3421] loss: 0.0202020947\n",
      "[timestep: 3] [epoch: 3451] loss: 0.0199395828\n",
      "[timestep: 3] [epoch: 3481] loss: 0.0207911618\n",
      "[timestep: 3] [epoch: 3511] loss: 0.0269135572\n",
      "[timestep: 3] [epoch: 3541] loss: 0.0212054849\n",
      "[timestep: 3] [epoch: 3571] loss: 0.0198881757\n",
      "[timestep: 3] [epoch: 3601] loss: 0.0203227177\n",
      "[timestep: 3] [epoch: 3631] loss: 0.0207508095\n",
      "[timestep: 3] [epoch: 3661] loss: 0.0206633247\n",
      "[timestep: 3] [epoch: 3691] loss: 0.0208727494\n",
      "[timestep: 3] [epoch: 3721] loss: 0.0204252489\n",
      "[timestep: 3] [epoch: 3751] loss: 0.0258769244\n",
      "[timestep: 3] [epoch: 3781] loss: 0.0839751810\n",
      "[timestep: 3] [epoch: 3811] loss: 0.1589498818\n",
      "[timestep: 3] [epoch: 3841] loss: 0.0686533526\n",
      "[timestep: 3] [epoch: 3871] loss: 0.0535442680\n",
      "[timestep: 3] [epoch: 3901] loss: 0.0259387288\n",
      "[timestep: 3] [epoch: 3931] loss: 0.0226564500\n",
      "[timestep: 3] [epoch: 3961] loss: 0.0214380082\n",
      "[timestep: 3] [epoch: 3991] loss: 0.0206812136\n",
      "[timestep: 3] [epoch: 4021] loss: 0.0200817287\n",
      "[timestep: 3] [epoch: 4051] loss: 0.0204335749\n",
      "[timestep: 3] [epoch: 4081] loss: 0.0211469866\n",
      "[timestep: 3] [epoch: 4111] loss: 0.0205449257\n",
      "[timestep: 3] [epoch: 4141] loss: 0.0201399215\n",
      "[timestep: 3] [epoch: 4171] loss: 0.0205957517\n",
      "[timestep: 3] [epoch: 4201] loss: 0.0214088149\n",
      "[timestep: 3] [epoch: 4231] loss: 0.0201880187\n",
      "[timestep: 3] [epoch: 4261] loss: 0.0205346774\n",
      "[timestep: 3] [epoch: 4291] loss: 0.0230951719\n",
      "[timestep: 3] [epoch: 4321] loss: 0.0205834974\n",
      "[timestep: 3] [epoch: 4351] loss: 0.0206485875\n",
      "[timestep: 3] [epoch: 4381] loss: 0.0218155310\n",
      "[timestep: 3] [epoch: 4411] loss: 0.0232921615\n",
      "[timestep: 3] [epoch: 4441] loss: 0.0215987917\n",
      "[timestep: 3] [epoch: 4471] loss: 0.0211429745\n",
      "[timestep: 3] [epoch: 4501] loss: 0.0210920051\n",
      "[timestep: 3] [epoch: 4531] loss: 0.0219840445\n",
      "[timestep: 3] [epoch: 4561] loss: 0.0206949860\n",
      "[timestep: 3] [epoch: 4591] loss: 0.0223129839\n",
      "[timestep: 3] [epoch: 4621] loss: 0.0285938978\n",
      "[timestep: 3] [epoch: 4651] loss: 0.0212275535\n",
      "[timestep: 3] [epoch: 4681] loss: 0.0279271957\n",
      "[timestep: 3] [epoch: 4711] loss: 0.0280758105\n",
      "[timestep: 3] [epoch: 4741] loss: 0.0279236287\n",
      "[timestep: 3] [epoch: 4771] loss: 0.0215488430\n",
      "[timestep: 3] [epoch: 4801] loss: 0.0247526988\n",
      "[timestep: 3] [epoch: 4831] loss: 0.0205936898\n",
      "[timestep: 3] [epoch: 4861] loss: 0.0210884418\n",
      "[timestep: 3] [epoch: 4891] loss: 0.0216407925\n",
      "[timestep: 3] [epoch: 4921] loss: 0.0248411410\n",
      "[timestep: 3] [epoch: 4951] loss: 0.0218481570\n",
      "[timestep: 3] [epoch: 4981] loss: 0.0210752375\n",
      "[timestep: 3] [epoch: 5011] loss: 0.0200715214\n",
      "[timestep: 3] [epoch: 5041] loss: 0.0206407513\n",
      "[timestep: 3] [epoch: 5071] loss: 0.0211477391\n",
      "[timestep: 3] [epoch: 5101] loss: 0.0244335588\n",
      "[timestep: 3] [epoch: 5131] loss: 0.0205367245\n",
      "[timestep: 3] [epoch: 5161] loss: 0.0201173294\n",
      "[timestep: 3] [epoch: 5191] loss: 0.0221691485\n",
      "[timestep: 3] [epoch: 5221] loss: 0.0207182355\n",
      "[timestep: 3] [epoch: 5251] loss: 0.0217735805\n",
      "[timestep: 3] [epoch: 5281] loss: 0.0212980770\n",
      "[timestep: 3] [epoch: 5311] loss: 0.0212277882\n",
      "[timestep: 3] [epoch: 5341] loss: 0.0256347191\n",
      "[timestep: 3] [epoch: 5371] loss: 0.0212181509\n",
      "[timestep: 3] [epoch: 5401] loss: 0.0226717517\n",
      "[timestep: 3] [epoch: 5431] loss: 0.0244313870\n",
      "[timestep: 3] [epoch: 5461] loss: 0.0199075975\n",
      "[timestep: 3] [epoch: 5491] loss: 0.0207064841\n",
      "[timestep: 3] [epoch: 5521] loss: 0.0210686848\n",
      "[timestep: 3] [epoch: 5551] loss: 0.0249118023\n",
      "[timestep: 3] [epoch: 5581] loss: 0.0220342465\n",
      "[timestep: 3] [epoch: 5611] loss: 0.0216597766\n",
      "[timestep: 3] [epoch: 5641] loss: 0.0199601203\n",
      "[timestep: 3] [epoch: 5671] loss: 0.0221139602\n",
      "[timestep: 3] [epoch: 5701] loss: 0.0202330835\n",
      "[timestep: 3] [epoch: 5731] loss: 0.0225230344\n",
      "[timestep: 3] [epoch: 5761] loss: 0.0212379284\n",
      "[timestep: 3] [epoch: 5791] loss: 0.0200346634\n",
      "[timestep: 3] [epoch: 5821] loss: 0.0216837227\n",
      "[timestep: 3] [epoch: 5851] loss: 0.0234250650\n",
      "[timestep: 3] [epoch: 5881] loss: 0.0357660018\n",
      "[timestep: 3] [epoch: 5911] loss: 0.0275884345\n",
      "[timestep: 3] [epoch: 5941] loss: 0.0213994458\n",
      "[timestep: 3] [epoch: 5971] loss: 0.0199486017\n",
      "[timestep: 3] [epoch: 6001] loss: 0.0205841977\n",
      "[timestep: 3] [epoch: 6031] loss: 0.0204455517\n",
      "[timestep: 3] [epoch: 6061] loss: 0.0208470896\n",
      "[timestep: 3] [epoch: 6091] loss: 0.0582249872\n",
      "[timestep: 3] [epoch: 6121] loss: 0.0543761738\n",
      "[timestep: 3] [epoch: 6151] loss: 0.0236395337\n",
      "[timestep: 3] [epoch: 6181] loss: 0.0213744305\n",
      "[timestep: 3] [epoch: 6211] loss: 0.0210699774\n",
      "[timestep: 3] [epoch: 6241] loss: 0.0195575170\n",
      "[timestep: 3] [epoch: 6271] loss: 0.0194614511\n",
      "[timestep: 3] [epoch: 6301] loss: 0.0193767622\n",
      "[timestep: 3] [epoch: 6331] loss: 0.0204622671\n",
      "[timestep: 3] [epoch: 6361] loss: 0.0225553177\n",
      "[timestep: 3] [epoch: 6391] loss: 0.0198460333\n",
      "[timestep: 3] [epoch: 6421] loss: 0.0196250789\n",
      "[timestep: 3] [epoch: 6451] loss: 0.0198207404\n",
      "[timestep: 3] [epoch: 6481] loss: 0.0211532786\n",
      "[timestep: 3] [epoch: 6511] loss: 0.0194554105\n",
      "[timestep: 3] [epoch: 6541] loss: 0.0281176455\n",
      "[timestep: 3] [epoch: 6571] loss: 0.0266183503\n",
      "[timestep: 3] [epoch: 6601] loss: 0.0264951140\n",
      "[timestep: 3] [epoch: 6631] loss: 0.0211486332\n",
      "[timestep: 3] [epoch: 6661] loss: 0.0230886545\n",
      "[timestep: 3] [epoch: 6691] loss: 0.0194287039\n",
      "[timestep: 3] [epoch: 6721] loss: 0.0203495827\n",
      "[timestep: 3] [epoch: 6751] loss: 0.0192858018\n",
      "[timestep: 3] [epoch: 6781] loss: 0.0193939283\n",
      "[timestep: 3] [epoch: 6811] loss: 0.0232465100\n",
      "[timestep: 3] [epoch: 6841] loss: 0.0206737518\n",
      "[timestep: 3] [epoch: 6871] loss: 0.0197760127\n",
      "[timestep: 3] [epoch: 6901] loss: 0.0197959095\n",
      "[timestep: 3] [epoch: 6931] loss: 0.0194172822\n",
      "[timestep: 3] [epoch: 6961] loss: 0.0207171813\n",
      "[timestep: 3] [epoch: 6991] loss: 0.0203726869\n",
      "[timestep: 3] [epoch: 7021] loss: 0.0201630201\n",
      "[timestep: 3] [epoch: 7051] loss: 0.0207949784\n",
      "[timestep: 3] [epoch: 7081] loss: 0.0194326118\n",
      "[timestep: 3] [epoch: 7111] loss: 0.0205565058\n",
      "[timestep: 3] [epoch: 7141] loss: 0.0196908079\n",
      "[timestep: 3] [epoch: 7171] loss: 0.0198668204\n",
      "[timestep: 3] [epoch: 7201] loss: 0.0188462008\n",
      "[timestep: 3] [epoch: 7231] loss: 0.0346724615\n",
      "[timestep: 3] [epoch: 7261] loss: 0.0268203989\n",
      "[timestep: 3] [epoch: 7291] loss: 0.0264559239\n",
      "[timestep: 3] [epoch: 7321] loss: 0.0218806863\n",
      "[timestep: 3] [epoch: 7351] loss: 0.0198978651\n",
      "[timestep: 3] [epoch: 7381] loss: 0.0213931594\n",
      "[timestep: 3] [epoch: 7411] loss: 0.0198592804\n",
      "[timestep: 3] [epoch: 7441] loss: 0.0199585371\n",
      "[timestep: 3] [epoch: 7471] loss: 0.0205325373\n",
      "[timestep: 3] [epoch: 7501] loss: 0.0199512467\n",
      "[timestep: 3] [epoch: 7531] loss: 0.0213750545\n",
      "[timestep: 3] [epoch: 7561] loss: 0.0203788113\n",
      "[timestep: 3] [epoch: 7591] loss: 0.0207010396\n",
      "[timestep: 3] [epoch: 7621] loss: 0.0206737928\n",
      "[timestep: 3] [epoch: 7651] loss: 0.0199802108\n",
      "[timestep: 3] [epoch: 7681] loss: 0.0196178481\n",
      "[timestep: 3] [epoch: 7711] loss: 0.0201958604\n",
      "[timestep: 3] [epoch: 7741] loss: 0.0200656801\n",
      "[timestep: 3] [epoch: 7771] loss: 0.0220881999\n",
      "[timestep: 3] [epoch: 7801] loss: 0.0218561534\n",
      "[timestep: 3] [epoch: 7831] loss: 0.0183552690\n",
      "[timestep: 3] [epoch: 7861] loss: 0.0161523093\n",
      "[timestep: 3] [epoch: 7891] loss: 0.0134383328\n",
      "[timestep: 3] [epoch: 7921] loss: 0.0124135315\n",
      "[timestep: 3] [epoch: 7951] loss: 0.0124333380\n",
      "[timestep: 3] [epoch: 7981] loss: 0.0120230950\n",
      "[timestep: 3] [epoch: 8011] loss: 0.0142485984\n",
      "[timestep: 3] [epoch: 8041] loss: 0.0140273608\n",
      "[timestep: 3] [epoch: 8071] loss: 0.0185702294\n",
      "[timestep: 3] [epoch: 8101] loss: 0.0118244793\n",
      "[timestep: 3] [epoch: 8131] loss: 0.0125876227\n",
      "[timestep: 3] [epoch: 8161] loss: 0.0143146943\n",
      "[timestep: 3] [epoch: 8191] loss: 0.0123937838\n",
      "[timestep: 3] [epoch: 8221] loss: 0.0121904174\n",
      "[timestep: 3] [epoch: 8251] loss: 0.0131193521\n",
      "[timestep: 3] [epoch: 8281] loss: 0.0122973267\n",
      "[timestep: 3] [epoch: 8311] loss: 0.0118850237\n",
      "[timestep: 3] [epoch: 8341] loss: 0.0133318938\n",
      "[timestep: 3] [epoch: 8371] loss: 0.0118796071\n",
      "[timestep: 3] [epoch: 8401] loss: 0.0167791061\n",
      "[timestep: 3] [epoch: 8431] loss: 0.0125006018\n",
      "[timestep: 3] [epoch: 8461] loss: 0.0127747282\n",
      "[timestep: 3] [epoch: 8491] loss: 0.0113705117\n",
      "[timestep: 3] [epoch: 8521] loss: 0.0075130863\n",
      "[timestep: 3] [epoch: 8551] loss: 0.0068337345\n",
      "[timestep: 3] [epoch: 8581] loss: 0.0068857628\n",
      "[timestep: 3] [epoch: 8611] loss: 0.0071457652\n",
      "[timestep: 3] [epoch: 8641] loss: 0.0066566584\n",
      "[timestep: 3] [epoch: 8671] loss: 0.0087977257\n",
      "[timestep: 3] [epoch: 8701] loss: 0.0079263207\n",
      "[timestep: 3] [epoch: 8731] loss: 0.0087333247\n",
      "[timestep: 3] [epoch: 8761] loss: 0.0092362538\n",
      "[timestep: 3] [epoch: 8791] loss: 0.0075765857\n",
      "[timestep: 3] [epoch: 8821] loss: 0.0071441848\n",
      "[timestep: 3] [epoch: 8851] loss: 0.0066867331\n",
      "[timestep: 3] [epoch: 8881] loss: 0.0067825494\n",
      "[timestep: 3] [epoch: 8911] loss: 0.0082240254\n",
      "[timestep: 3] [epoch: 8941] loss: 0.0090415888\n",
      "[timestep: 3] [epoch: 8971] loss: 0.0073346030\n",
      "[timestep: 3] [epoch: 9001] loss: 0.0079966560\n",
      "[timestep: 3] [epoch: 9031] loss: 0.0068291915\n",
      "[timestep: 3] [epoch: 9061] loss: 0.0094846776\n",
      "[timestep: 3] [epoch: 9091] loss: 0.0067782262\n",
      "[timestep: 3] [epoch: 9121] loss: 0.0080639767\n",
      "[timestep: 3] [epoch: 9151] loss: 0.0072928364\n",
      "[timestep: 3] [epoch: 9181] loss: 0.0092421230\n",
      "[timestep: 3] [epoch: 9211] loss: 0.0088951830\n",
      "[timestep: 3] [epoch: 9241] loss: 0.0068326509\n",
      "[timestep: 3] [epoch: 9271] loss: 0.0067841327\n",
      "[timestep: 3] [epoch: 9301] loss: 0.0070312675\n",
      "[timestep: 3] [epoch: 9331] loss: 0.0068389568\n",
      "[timestep: 3] [epoch: 9361] loss: 0.0081892274\n",
      "[timestep: 3] [epoch: 9391] loss: 0.0074201250\n",
      "[timestep: 3] [epoch: 9421] loss: 0.0073265522\n",
      "[timestep: 3] [epoch: 9451] loss: 0.0073512918\n",
      "[timestep: 3] [epoch: 9481] loss: 0.0081271157\n",
      "[timestep: 3] [epoch: 9511] loss: 0.0084388284\n",
      "[timestep: 3] [epoch: 9541] loss: 0.0075562550\n",
      "[timestep: 3] [epoch: 9571] loss: 0.0068128239\n",
      "[timestep: 3] [epoch: 9601] loss: 0.0067993701\n",
      "[timestep: 3] [epoch: 9631] loss: 0.0077739046\n",
      "[timestep: 3] [epoch: 9661] loss: 0.0071703186\n",
      "[timestep: 3] [epoch: 9691] loss: 0.0071742153\n",
      "[timestep: 3] [epoch: 9721] loss: 0.0068859458\n",
      "[timestep: 3] [epoch: 9751] loss: 0.0070286654\n",
      "[timestep: 3] [epoch: 9781] loss: 0.0082538622\n",
      "[timestep: 3] [epoch: 9811] loss: 0.0077914065\n",
      "[timestep: 3] [epoch: 9841] loss: 0.0069156708\n",
      "[timestep: 3] [epoch: 9871] loss: 0.0081562428\n",
      "[timestep: 3] [epoch: 9901] loss: 0.0071940841\n",
      "[timestep: 3] [epoch: 9931] loss: 0.0081789941\n",
      "[timestep: 3] [epoch: 9961] loss: 0.0083070472\n",
      "[timestep: 3] [epoch: 9991] loss: 0.0079344297\n",
      "[timestep: 3] [epoch: 10021] loss: 0.0076486166\n",
      "[timestep: 3] [epoch: 10051] loss: 0.0076208389\n",
      "[timestep: 3] [epoch: 10081] loss: 0.0080950046\n",
      "[timestep: 3] [epoch: 10111] loss: 0.0069862334\n",
      "[timestep: 3] [epoch: 10141] loss: 0.0089505240\n",
      "[timestep: 3] [epoch: 10171] loss: 0.0111458674\n",
      "[timestep: 3] [epoch: 10201] loss: 0.0120911608\n",
      "[timestep: 3] [epoch: 10231] loss: 0.0122776423\n",
      "[timestep: 3] [epoch: 10261] loss: 0.0126773044\n",
      "[timestep: 3] [epoch: 10291] loss: 0.0075570848\n",
      "[timestep: 3] [epoch: 10321] loss: 0.0066356994\n",
      "[timestep: 3] [epoch: 10351] loss: 0.0067564151\n",
      "[timestep: 3] [epoch: 10381] loss: 0.0069220625\n",
      "[timestep: 3] [epoch: 10411] loss: 0.0067246761\n",
      "[timestep: 3] [epoch: 10441] loss: 0.0066561266\n",
      "[timestep: 3] [epoch: 10471] loss: 0.0066053751\n",
      "[timestep: 3] [epoch: 10501] loss: 0.0066690673\n",
      "[timestep: 3] [epoch: 10531] loss: 0.0066809361\n",
      "[timestep: 3] [epoch: 10561] loss: 0.0065603647\n",
      "[timestep: 3] [epoch: 10591] loss: 0.0078388285\n",
      "[timestep: 3] [epoch: 10621] loss: 0.0111765359\n",
      "[timestep: 3] [epoch: 10651] loss: 0.0074996026\n",
      "[timestep: 3] [epoch: 10681] loss: 0.0071669491\n",
      "[timestep: 3] [epoch: 10711] loss: 0.0076493113\n",
      "[timestep: 3] [epoch: 10741] loss: 0.0067779301\n",
      "[timestep: 3] [epoch: 10771] loss: 0.0068077408\n",
      "[timestep: 3] [epoch: 10801] loss: 0.0066055711\n",
      "[timestep: 3] [epoch: 10831] loss: 0.0069969809\n",
      "[timestep: 3] [epoch: 10861] loss: 0.0065852841\n",
      "[timestep: 3] [epoch: 10891] loss: 0.0084013557\n",
      "[timestep: 3] [epoch: 10921] loss: 0.0085253622\n",
      "[timestep: 3] [epoch: 10951] loss: 0.0078266338\n",
      "[timestep: 3] [epoch: 10981] loss: 0.0068271416\n",
      "[timestep: 3] [epoch: 11011] loss: 0.0066663628\n",
      "[timestep: 3] [epoch: 11041] loss: 0.0088364985\n",
      "[timestep: 3] [epoch: 11071] loss: 0.0142509229\n",
      "[timestep: 3] [epoch: 11101] loss: 0.0097512919\n",
      "[timestep: 3] [epoch: 11131] loss: 0.0070285634\n",
      "[timestep: 3] [epoch: 11161] loss: 0.0069109518\n",
      "[timestep: 3] [epoch: 11191] loss: 0.0071793599\n",
      "[timestep: 3] [epoch: 11221] loss: 0.0075184801\n",
      "[timestep: 3] [epoch: 11251] loss: 0.0066227368\n",
      "[timestep: 3] [epoch: 11281] loss: 0.0074441927\n",
      "[timestep: 3] [epoch: 11311] loss: 0.0103307674\n",
      "[timestep: 3] [epoch: 11341] loss: 0.0086824140\n",
      "[timestep: 3] [epoch: 11371] loss: 0.0072396547\n",
      "[timestep: 3] [epoch: 11401] loss: 0.0070250398\n",
      "[timestep: 3] [epoch: 11431] loss: 0.0069557577\n",
      "[timestep: 3] [epoch: 11461] loss: 0.0067558084\n",
      "[timestep: 3] [epoch: 11491] loss: 0.0081028268\n",
      "[timestep: 3] [epoch: 11521] loss: 0.0070444602\n",
      "[timestep: 3] [epoch: 11551] loss: 0.0072648432\n",
      "[timestep: 3] [epoch: 11581] loss: 0.0070671807\n",
      "[timestep: 3] [epoch: 11611] loss: 0.0069956514\n",
      "[timestep: 3] [epoch: 11641] loss: 0.0068924879\n",
      "[timestep: 3] [epoch: 11671] loss: 0.0074070147\n",
      "[timestep: 3] [epoch: 11701] loss: 0.0090574864\n",
      "[timestep: 3] [epoch: 11731] loss: 0.0070975460\n",
      "[timestep: 3] [epoch: 11761] loss: 0.0090277474\n",
      "[timestep: 3] [epoch: 11791] loss: 0.0074536940\n",
      "[timestep: 3] [epoch: 11821] loss: 0.0066764392\n",
      "[timestep: 3] [epoch: 11851] loss: 0.0072858715\n",
      "[timestep: 3] [epoch: 11881] loss: 0.0068702935\n",
      "[timestep: 3] [epoch: 11911] loss: 0.0073680719\n",
      "[timestep: 3] [epoch: 11941] loss: 0.0067521818\n",
      "[timestep: 3] [epoch: 11971] loss: 0.0066461423\n",
      "[timestep: 3] [epoch: 12001] loss: 0.0066881129\n",
      "[timestep: 3] [epoch: 12031] loss: 0.0065955510\n",
      "[timestep: 3] [epoch: 12061] loss: 0.0066598011\n",
      "[timestep: 3] [epoch: 12091] loss: 0.0111365132\n",
      "[timestep: 3] [epoch: 12121] loss: 0.0119333472\n",
      "[timestep: 3] [epoch: 12151] loss: 0.0079998113\n",
      "[timestep: 3] [epoch: 12181] loss: 0.0072407499\n",
      "[timestep: 3] [epoch: 12211] loss: 0.0066857701\n",
      "[timestep: 3] [epoch: 12241] loss: 0.0072677890\n",
      "[timestep: 3] [epoch: 12271] loss: 0.0070884777\n",
      "[timestep: 3] [epoch: 12301] loss: 0.0078725107\n",
      "[timestep: 3] [epoch: 12331] loss: 0.0070147375\n",
      "[timestep: 3] [epoch: 12361] loss: 0.0070234463\n",
      "[timestep: 3] [epoch: 12391] loss: 0.0068666041\n",
      "[timestep: 3] [epoch: 12421] loss: 0.0068325382\n",
      "[timestep: 3] [epoch: 12451] loss: 0.0075377552\n",
      "[timestep: 3] [epoch: 12481] loss: 0.0092864409\n",
      "[timestep: 3] [epoch: 12511] loss: 0.0072903084\n",
      "[timestep: 3] [epoch: 12541] loss: 0.0102509046\n",
      "[timestep: 3] [epoch: 12571] loss: 0.0077705421\n",
      "[timestep: 3] [epoch: 12601] loss: 0.0071200673\n",
      "[timestep: 3] [epoch: 12631] loss: 0.0066761072\n",
      "[timestep: 3] [epoch: 12661] loss: 0.0071992632\n",
      "[timestep: 3] [epoch: 12691] loss: 0.0066013299\n",
      "[timestep: 3] [epoch: 12721] loss: 0.0066244854\n",
      "[timestep: 3] [epoch: 12751] loss: 0.0066742664\n",
      "[timestep: 3] [epoch: 12781] loss: 0.0087616760\n",
      "[timestep: 3] [epoch: 12811] loss: 0.0083141457\n",
      "[timestep: 3] [epoch: 12841] loss: 0.0079723280\n",
      "[timestep: 3] [epoch: 12871] loss: 0.0066963052\n",
      "[timestep: 3] [epoch: 12901] loss: 0.0065828064\n",
      "[timestep: 3] [epoch: 12931] loss: 0.0066275550\n",
      "[timestep: 3] [epoch: 12961] loss: 0.0067217178\n",
      "[timestep: 3] [epoch: 12991] loss: 0.0110578397\n",
      "[timestep: 3] [epoch: 13021] loss: 0.0069718976\n",
      "[timestep: 3] [epoch: 13051] loss: 0.0066610193\n",
      "[timestep: 3] [epoch: 13081] loss: 0.0066773621\n",
      "[timestep: 3] [epoch: 13111] loss: 0.0071930047\n",
      "[timestep: 3] [epoch: 13141] loss: 0.0068305177\n",
      "[timestep: 3] [epoch: 13171] loss: 0.0068841679\n",
      "[timestep: 3] [epoch: 13201] loss: 0.0072420323\n",
      "[timestep: 3] [epoch: 13231] loss: 0.0076666814\n",
      "[timestep: 3] [epoch: 13261] loss: 0.0080416193\n",
      "[timestep: 3] [epoch: 13291] loss: 0.0070695821\n",
      "[timestep: 3] [epoch: 13321] loss: 0.0086281747\n",
      "[timestep: 3] [epoch: 13351] loss: 0.0121062053\n",
      "[timestep: 3] [epoch: 13381] loss: 0.0068218769\n",
      "[timestep: 3] [epoch: 13411] loss: 0.0066019287\n",
      "[timestep: 3] [epoch: 13441] loss: 0.0066478499\n",
      "[timestep: 3] [epoch: 13471] loss: 0.0070265718\n",
      "[timestep: 3] [epoch: 13501] loss: 0.0073620956\n",
      "[timestep: 3] [epoch: 13531] loss: 0.0066287932\n",
      "[timestep: 3] [epoch: 13561] loss: 0.0066569014\n",
      "[timestep: 3] [epoch: 13591] loss: 0.0069915554\n",
      "[timestep: 3] [epoch: 13621] loss: 0.0075442144\n",
      "[timestep: 3] [epoch: 13651] loss: 0.0069419011\n",
      "[timestep: 3] [epoch: 13681] loss: 0.0068701748\n",
      "[timestep: 3] [epoch: 13711] loss: 0.0066027688\n",
      "[timestep: 3] [epoch: 13741] loss: 0.0077012945\n",
      "[timestep: 3] [epoch: 13771] loss: 0.0084451567\n",
      "[timestep: 3] [epoch: 13801] loss: 0.0069142738\n",
      "[timestep: 3] [epoch: 13831] loss: 0.0068801674\n",
      "[timestep: 3] [epoch: 13861] loss: 0.0066170539\n",
      "[timestep: 3] [epoch: 13891] loss: 0.0072117136\n",
      "[timestep: 3] [epoch: 13921] loss: 0.0066381479\n",
      "[timestep: 3] [epoch: 13951] loss: 0.0071023987\n",
      "[timestep: 3] [epoch: 13981] loss: 0.0070959660\n",
      "[timestep: 3] [epoch: 14011] loss: 0.0067822454\n",
      "[timestep: 3] [epoch: 14041] loss: 0.0076148645\n",
      "[timestep: 3] [epoch: 14071] loss: 0.0066210479\n",
      "[timestep: 3] [epoch: 14101] loss: 0.0124965040\n",
      "[timestep: 3] [epoch: 14131] loss: 0.0071555935\n",
      "[timestep: 3] [epoch: 14161] loss: 0.0066182218\n",
      "[timestep: 3] [epoch: 14191] loss: 0.0068621086\n",
      "[timestep: 3] [epoch: 14221] loss: 0.0066544195\n",
      "[timestep: 3] [epoch: 14251] loss: 0.0069867326\n",
      "[timestep: 3] [epoch: 14281] loss: 0.0070476495\n",
      "[timestep: 3] [epoch: 14311] loss: 0.0076889712\n",
      "[timestep: 3] [epoch: 14341] loss: 0.0066182343\n",
      "[timestep: 3] [epoch: 14371] loss: 0.0085484115\n",
      "[timestep: 3] [epoch: 14401] loss: 0.0067382129\n",
      "[timestep: 3] [epoch: 14431] loss: 0.0079712067\n",
      "[timestep: 3] [epoch: 14461] loss: 0.0066455659\n",
      "[timestep: 3] [epoch: 14491] loss: 0.0067098439\n",
      "[timestep: 3] [epoch: 14521] loss: 0.0081894249\n",
      "[timestep: 3] [epoch: 14551] loss: 0.0070198411\n",
      "[timestep: 3] [epoch: 14581] loss: 0.0069865743\n",
      "[timestep: 3] [epoch: 14611] loss: 0.0074592521\n",
      "[timestep: 3] [epoch: 14641] loss: 0.0069924523\n",
      "[timestep: 3] [epoch: 14671] loss: 0.0090762610\n",
      "[timestep: 3] [epoch: 14701] loss: 0.0067348792\n",
      "[timestep: 3] [epoch: 14731] loss: 0.0066165356\n",
      "[timestep: 3] [epoch: 14761] loss: 0.0068125511\n",
      "[timestep: 3] [epoch: 14791] loss: 0.0071638031\n",
      "[timestep: 3] [epoch: 14821] loss: 0.0068162261\n",
      "[timestep: 3] [epoch: 14851] loss: 0.0071144211\n",
      "[timestep: 3] [epoch: 14881] loss: 0.0066795824\n",
      "[timestep: 3] [epoch: 14911] loss: 0.0068056742\n",
      "[timestep: 3] [epoch: 14941] loss: 0.0065559717\n",
      "[timestep: 3] [epoch: 14971] loss: 0.0067207683\n",
      "[timestep: 3] [epoch: 15001] loss: 0.0066072163\n",
      "[timestep: 3] [epoch: 15031] loss: 0.0068274774\n",
      "[timestep: 3] [epoch: 15061] loss: 0.0073312838\n",
      "[timestep: 3] [epoch: 15091] loss: 0.0075006131\n",
      "[timestep: 3] [epoch: 15121] loss: 0.0068232054\n",
      "[timestep: 3] [epoch: 15151] loss: 0.0066410028\n",
      "[timestep: 3] [epoch: 15181] loss: 0.0071104188\n",
      "[timestep: 3] [epoch: 15211] loss: 0.0065569007\n",
      "[timestep: 3] [epoch: 15241] loss: 0.0065591685\n",
      "[timestep: 3] [epoch: 15271] loss: 0.0089864321\n",
      "[timestep: 3] [epoch: 15301] loss: 0.0082613593\n",
      "[timestep: 3] [epoch: 15331] loss: 0.0067862263\n",
      "[timestep: 3] [epoch: 15361] loss: 0.0077982801\n",
      "[timestep: 3] [epoch: 15391] loss: 0.0066470644\n",
      "[timestep: 3] [epoch: 15421] loss: 0.0070965197\n",
      "[timestep: 3] [epoch: 15451] loss: 0.0074406937\n",
      "[timestep: 3] [epoch: 15481] loss: 0.0069356970\n",
      "[timestep: 3] [epoch: 15511] loss: 0.0068434440\n",
      "[timestep: 3] [epoch: 15541] loss: 0.0067939679\n",
      "[timestep: 3] [epoch: 15571] loss: 0.0068006148\n",
      "[timestep: 3] [epoch: 15601] loss: 0.0065711024\n",
      "[timestep: 3] [epoch: 15631] loss: 0.0072253007\n",
      "[timestep: 3] [epoch: 15661] loss: 0.0070140120\n",
      "[timestep: 3] [epoch: 15691] loss: 0.0069809612\n",
      "[timestep: 3] [epoch: 15721] loss: 0.0071378369\n",
      "[timestep: 3] [epoch: 15751] loss: 0.0069501572\n",
      "[timestep: 3] [epoch: 15781] loss: 0.0068345028\n",
      "[timestep: 3] [epoch: 15811] loss: 0.0071044881\n",
      "[timestep: 3] [epoch: 15841] loss: 0.0068728481\n",
      "[timestep: 3] [epoch: 15871] loss: 0.0073955031\n",
      "[timestep: 3] [epoch: 15901] loss: 0.0089375861\n",
      "[timestep: 3] [epoch: 15931] loss: 0.0073664514\n",
      "[timestep: 3] [epoch: 15961] loss: 0.0067398143\n",
      "[timestep: 3] [epoch: 15991] loss: 0.0066126399\n",
      "[timestep: 3] [epoch: 16021] loss: 0.0067698983\n",
      "[timestep: 3] [epoch: 16051] loss: 0.0066722678\n",
      "[timestep: 3] [epoch: 16081] loss: 0.0069152275\n",
      "[timestep: 3] [epoch: 16111] loss: 0.0069821612\n",
      "[timestep: 3] [epoch: 16141] loss: 0.0067082858\n",
      "[timestep: 3] [epoch: 16171] loss: 0.0068717236\n",
      "[timestep: 3] [epoch: 16201] loss: 0.0072627617\n",
      "[timestep: 3] [epoch: 16231] loss: 0.0067432718\n",
      "[timestep: 3] [epoch: 16261] loss: 0.0066510988\n",
      "[timestep: 3] [epoch: 16291] loss: 0.0081439186\n",
      "[timestep: 3] [epoch: 16321] loss: 0.0066132257\n",
      "[timestep: 3] [epoch: 16351] loss: 0.0074337013\n",
      "[timestep: 3] [epoch: 16381] loss: 0.0066053178\n",
      "[timestep: 3] [epoch: 16411] loss: 0.0066686054\n",
      "[timestep: 3] [epoch: 16441] loss: 0.0077361218\n",
      "[timestep: 3] [epoch: 16471] loss: 0.0067916429\n",
      "[timestep: 3] [epoch: 16501] loss: 0.0069630528\n",
      "[timestep: 3] [epoch: 16531] loss: 0.0066708070\n",
      "[timestep: 3] [epoch: 16561] loss: 0.0066594612\n",
      "[timestep: 3] [epoch: 16591] loss: 0.0069605308\n",
      "[timestep: 3] [epoch: 16621] loss: 0.0069443034\n",
      "[timestep: 3] [epoch: 16651] loss: 0.0068766959\n",
      "[timestep: 3] [epoch: 16681] loss: 0.0065358141\n",
      "[timestep: 3] [epoch: 16711] loss: 0.0066331732\n",
      "[timestep: 3] [epoch: 16741] loss: 0.0067181839\n",
      "[timestep: 3] [epoch: 16771] loss: 0.0065669222\n",
      "[timestep: 3] [epoch: 16801] loss: 0.0084544867\n",
      "[timestep: 3] [epoch: 16831] loss: 0.0067759156\n",
      "[timestep: 3] [epoch: 16861] loss: 0.0066042114\n",
      "[timestep: 3] [epoch: 16891] loss: 0.0080044651\n",
      "[timestep: 3] [epoch: 16921] loss: 0.0069923690\n",
      "[timestep: 3] [epoch: 16951] loss: 0.0066456520\n",
      "[timestep: 3] [epoch: 16981] loss: 0.0066543510\n",
      "[timestep: 3] [epoch: 17011] loss: 0.0066235908\n",
      "[timestep: 3] [epoch: 17041] loss: 0.0073274709\n",
      "[timestep: 3] [epoch: 17071] loss: 0.0068158745\n",
      "[timestep: 3] [epoch: 17101] loss: 0.0069557149\n",
      "[timestep: 3] [epoch: 17131] loss: 0.0067141140\n",
      "[timestep: 3] [epoch: 17161] loss: 0.0065231007\n",
      "[timestep: 3] [epoch: 17191] loss: 0.0065671187\n",
      "[timestep: 3] [epoch: 17221] loss: 0.0067102239\n",
      "[timestep: 3] [epoch: 17251] loss: 0.0083061233\n",
      "[timestep: 3] [epoch: 17281] loss: 0.0075925542\n",
      "[timestep: 3] [epoch: 17311] loss: 0.0085170064\n",
      "[timestep: 3] [epoch: 17341] loss: 0.0066525443\n",
      "[timestep: 3] [epoch: 17371] loss: 0.0065042851\n",
      "[timestep: 3] [epoch: 17401] loss: 0.0065766191\n",
      "[timestep: 3] [epoch: 17431] loss: 0.0065314234\n",
      "[timestep: 3] [epoch: 17461] loss: 0.0065420731\n",
      "[timestep: 3] [epoch: 17491] loss: 0.0067077554\n",
      "[timestep: 3] [epoch: 17521] loss: 0.0065578306\n",
      "[timestep: 3] [epoch: 17551] loss: 0.0070209000\n",
      "[timestep: 3] [epoch: 17581] loss: 0.0065292250\n",
      "[timestep: 3] [epoch: 17611] loss: 0.0065640146\n",
      "[timestep: 3] [epoch: 17641] loss: 0.0065938411\n",
      "[timestep: 3] [epoch: 17671] loss: 0.0068655042\n",
      "[timestep: 3] [epoch: 17701] loss: 0.0066180546\n",
      "[timestep: 3] [epoch: 17731] loss: 0.0066835782\n",
      "[timestep: 3] [epoch: 17761] loss: 0.0067776786\n",
      "[timestep: 3] [epoch: 17791] loss: 0.0067725005\n",
      "[timestep: 3] [epoch: 17821] loss: 0.0070724012\n",
      "[timestep: 3] [epoch: 17851] loss: 0.0065577575\n",
      "[timestep: 3] [epoch: 17881] loss: 0.0068862103\n",
      "[timestep: 3] [epoch: 17911] loss: 0.0065696859\n",
      "[timestep: 3] [epoch: 17941] loss: 0.0065895161\n",
      "[timestep: 3] [epoch: 17971] loss: 0.0069571482\n",
      "[timestep: 3] [epoch: 18001] loss: 0.0066061821\n",
      "[timestep: 3] [epoch: 18031] loss: 0.0065123606\n",
      "[timestep: 3] [epoch: 18061] loss: 0.0065652858\n",
      "[timestep: 3] [epoch: 18091] loss: 0.0081143994\n",
      "[timestep: 3] [epoch: 18121] loss: 0.0067212726\n",
      "[timestep: 3] [epoch: 18151] loss: 0.0065026688\n",
      "[timestep: 3] [epoch: 18181] loss: 0.0065623149\n",
      "[timestep: 3] [epoch: 18211] loss: 0.0065332679\n",
      "[timestep: 3] [epoch: 18241] loss: 0.0065875985\n",
      "[timestep: 3] [epoch: 18271] loss: 0.0100926915\n",
      "[timestep: 3] [epoch: 18301] loss: 0.0075934851\n",
      "[timestep: 3] [epoch: 18331] loss: 0.0070338482\n",
      "[timestep: 3] [epoch: 18361] loss: 0.0066545112\n",
      "[timestep: 3] [epoch: 18391] loss: 0.0078787254\n",
      "[timestep: 3] [epoch: 18421] loss: 0.0066658487\n",
      "[timestep: 3] [epoch: 18451] loss: 0.0065861298\n",
      "[timestep: 3] [epoch: 18481] loss: 0.0071601602\n",
      "[timestep: 3] [epoch: 18511] loss: 0.0067790370\n",
      "[timestep: 3] [epoch: 18541] loss: 0.0067610396\n",
      "[timestep: 3] [epoch: 18571] loss: 0.0070030764\n",
      "[timestep: 3] [epoch: 18601] loss: 0.0066583557\n",
      "[timestep: 3] [epoch: 18631] loss: 0.0069070985\n",
      "[timestep: 3] [epoch: 18661] loss: 0.0084215049\n",
      "[timestep: 3] [epoch: 18691] loss: 0.0065599154\n",
      "[timestep: 3] [epoch: 18721] loss: 0.0077285361\n",
      "[timestep: 3] [epoch: 18751] loss: 0.0069435118\n",
      "[timestep: 3] [epoch: 18781] loss: 0.0067783473\n",
      "[timestep: 3] [epoch: 18811] loss: 0.0069319974\n",
      "[timestep: 3] [epoch: 18841] loss: 0.0066069420\n",
      "[timestep: 3] [epoch: 18871] loss: 0.0077587483\n",
      "[timestep: 3] [epoch: 18901] loss: 0.0072850054\n",
      "[timestep: 3] [epoch: 18931] loss: 0.0069312174\n",
      "[timestep: 3] [epoch: 18961] loss: 0.0065034963\n",
      "[timestep: 3] [epoch: 18991] loss: 0.0065082344\n",
      "[timestep: 3] [epoch: 19021] loss: 0.0065376312\n",
      "[timestep: 3] [epoch: 19051] loss: 0.0065281969\n",
      "[timestep: 3] [epoch: 19081] loss: 0.0067413338\n",
      "[timestep: 3] [epoch: 19111] loss: 0.0065420372\n",
      "[timestep: 3] [epoch: 19141] loss: 0.0067380830\n",
      "[timestep: 3] [epoch: 19171] loss: 0.0066396655\n",
      "[timestep: 3] [epoch: 19201] loss: 0.0067055644\n",
      "[timestep: 3] [epoch: 19231] loss: 0.0070814323\n",
      "[timestep: 3] [epoch: 19261] loss: 0.0066045793\n",
      "[timestep: 3] [epoch: 19291] loss: 0.0071955845\n",
      "[timestep: 3] [epoch: 19321] loss: 0.0067224987\n",
      "[timestep: 3] [epoch: 19351] loss: 0.0065941359\n",
      "[timestep: 3] [epoch: 19381] loss: 0.0067317057\n",
      "[timestep: 3] [epoch: 19411] loss: 0.0084268525\n",
      "[timestep: 3] [epoch: 19441] loss: 0.0065711006\n",
      "[timestep: 3] [epoch: 19471] loss: 0.0066193896\n",
      "[timestep: 3] [epoch: 19501] loss: 0.0065619512\n",
      "[timestep: 3] [epoch: 19531] loss: 0.0068653254\n",
      "[timestep: 3] [epoch: 19561] loss: 0.0065473239\n",
      "[timestep: 3] [epoch: 19591] loss: 0.0071778516\n",
      "[timestep: 3] [epoch: 19621] loss: 0.0067592156\n",
      "[timestep: 3] [epoch: 19651] loss: 0.0067490279\n",
      "[timestep: 3] [epoch: 19681] loss: 0.0065450324\n",
      "[timestep: 3] [epoch: 19711] loss: 0.0067261183\n",
      "[timestep: 3] [epoch: 19741] loss: 0.0070241163\n",
      "[timestep: 3] [epoch: 19771] loss: 0.0068933177\n",
      "[timestep: 3] [epoch: 19801] loss: 0.0065589407\n",
      "[timestep: 3] [epoch: 19831] loss: 0.0066246698\n",
      "[timestep: 3] [epoch: 19861] loss: 0.0065916511\n",
      "[timestep: 3] [epoch: 19891] loss: 0.0065684542\n",
      "[timestep: 3] [epoch: 19921] loss: 0.0067527303\n",
      "[timestep: 3] [epoch: 19951] loss: 0.0065101385\n",
      "[timestep: 3] [epoch: 19981] loss: 0.0066925776\n",
      "[timestep: 3] [epoch: 20011] loss: 0.0072230035\n",
      "[timestep: 3] [epoch: 20041] loss: 0.0092037451\n",
      "[timestep: 3] [epoch: 20071] loss: 0.0067250906\n",
      "[timestep: 3] [epoch: 20101] loss: 0.0065408289\n",
      "[timestep: 3] [epoch: 20131] loss: 0.0065854667\n",
      "[timestep: 3] [epoch: 20161] loss: 0.0068109105\n",
      "[timestep: 3] [epoch: 20191] loss: 0.0065555219\n",
      "[timestep: 3] [epoch: 20221] loss: 0.0065743173\n",
      "[timestep: 3] [epoch: 20251] loss: 0.0068714460\n",
      "[timestep: 3] [epoch: 20281] loss: 0.0066406047\n",
      "[timestep: 3] [epoch: 20311] loss: 0.0069190953\n",
      "[timestep: 3] [epoch: 20341] loss: 0.0068325568\n",
      "[timestep: 3] [epoch: 20371] loss: 0.0064814119\n",
      "[timestep: 3] [epoch: 20401] loss: 0.0065813940\n",
      "[timestep: 3] [epoch: 20431] loss: 0.0065127956\n",
      "[timestep: 3] [epoch: 20461] loss: 0.0073768338\n",
      "[timestep: 3] [epoch: 20491] loss: 0.0066241953\n",
      "[timestep: 3] [epoch: 20521] loss: 0.0065279882\n",
      "[timestep: 3] [epoch: 20551] loss: 0.0065327659\n",
      "[timestep: 3] [epoch: 20581] loss: 0.0067292210\n",
      "[timestep: 3] [epoch: 20611] loss: 0.0069824052\n",
      "[timestep: 3] [epoch: 20641] loss: 0.0068025766\n",
      "[timestep: 3] [epoch: 20671] loss: 0.0080338176\n",
      "[timestep: 3] [epoch: 20701] loss: 0.0068284394\n",
      "[timestep: 3] [epoch: 20731] loss: 0.0066447509\n",
      "[timestep: 3] [epoch: 20761] loss: 0.0067189508\n",
      "[timestep: 3] [epoch: 20791] loss: 0.0068978886\n",
      "[timestep: 3] [epoch: 20821] loss: 0.0072500799\n",
      "[timestep: 3] [epoch: 20851] loss: 0.0114653418\n",
      "[timestep: 3] [epoch: 20881] loss: 0.0132772839\n",
      "[timestep: 3] [epoch: 20911] loss: 0.0116024446\n",
      "[timestep: 3] [epoch: 20941] loss: 0.0070188860\n",
      "[timestep: 3] [epoch: 20971] loss: 0.0065151379\n",
      "[timestep: 3] [epoch: 21001] loss: 0.0064911023\n",
      "[timestep: 3] [epoch: 21031] loss: 0.0064393301\n",
      "[timestep: 3] [epoch: 21061] loss: 0.0064495830\n",
      "[timestep: 3] [epoch: 21091] loss: 0.0065364204\n",
      "[timestep: 3] [epoch: 21121] loss: 0.0064466521\n",
      "[timestep: 3] [epoch: 21151] loss: 0.0066014347\n",
      "[timestep: 3] [epoch: 21181] loss: 0.0065053143\n",
      "[timestep: 3] [epoch: 21211] loss: 0.0064540133\n",
      "[timestep: 3] [epoch: 21241] loss: 0.0065027718\n",
      "[timestep: 3] [epoch: 21271] loss: 0.0064818426\n",
      "[timestep: 3] [epoch: 21301] loss: 0.0070200879\n",
      "[timestep: 3] [epoch: 21331] loss: 0.0064957482\n",
      "[timestep: 3] [epoch: 21361] loss: 0.0067339535\n",
      "[timestep: 3] [epoch: 21391] loss: 0.0064645004\n",
      "[timestep: 3] [epoch: 21421] loss: 0.0067000929\n",
      "[timestep: 3] [epoch: 21451] loss: 0.0065558064\n",
      "[timestep: 3] [epoch: 21481] loss: 0.0068416367\n",
      "[timestep: 3] [epoch: 21511] loss: 0.0064651882\n",
      "[timestep: 3] [epoch: 21541] loss: 0.0064970008\n",
      "[timestep: 3] [epoch: 21571] loss: 0.0065216743\n",
      "[timestep: 3] [epoch: 21601] loss: 0.0066403649\n",
      "[timestep: 3] [epoch: 21631] loss: 0.0066955294\n",
      "[timestep: 3] [epoch: 21661] loss: 0.0066476990\n",
      "[timestep: 3] [epoch: 21691] loss: 0.0067301984\n",
      "[timestep: 3] [epoch: 21721] loss: 0.0065609803\n",
      "[timestep: 3] [epoch: 21751] loss: 0.0064875069\n",
      "[timestep: 3] [epoch: 21781] loss: 0.0085088322\n",
      "[timestep: 3] [epoch: 21811] loss: 0.0067750355\n",
      "[timestep: 3] [epoch: 21841] loss: 0.0065686721\n",
      "[timestep: 3] [epoch: 21871] loss: 0.0065380880\n",
      "[timestep: 3] [epoch: 21901] loss: 0.0065107793\n",
      "[timestep: 3] [epoch: 21931] loss: 0.0067222626\n",
      "[timestep: 3] [epoch: 21961] loss: 0.0065824385\n",
      "[timestep: 3] [epoch: 21991] loss: 0.0069074370\n",
      "[timestep: 3] [epoch: 22021] loss: 0.0065104892\n",
      "[timestep: 3] [epoch: 22051] loss: 0.0066573252\n",
      "[timestep: 3] [epoch: 22081] loss: 0.0066956356\n",
      "[timestep: 3] [epoch: 22111] loss: 0.0066189347\n",
      "[timestep: 3] [epoch: 22141] loss: 0.0065427395\n",
      "[timestep: 3] [epoch: 22171] loss: 0.0066558523\n",
      "[timestep: 3] [epoch: 22201] loss: 0.0065106107\n",
      "[timestep: 3] [epoch: 22231] loss: 0.0068136319\n",
      "[timestep: 3] [epoch: 22261] loss: 0.0070481463\n",
      "[timestep: 3] [epoch: 22291] loss: 0.0065362612\n",
      "[timestep: 3] [epoch: 22321] loss: 0.0064754821\n",
      "[timestep: 3] [epoch: 22351] loss: 0.0091455095\n",
      "[timestep: 3] [epoch: 22381] loss: 0.0066271834\n",
      "[timestep: 3] [epoch: 22411] loss: 0.0067026354\n",
      "[timestep: 3] [epoch: 22441] loss: 0.0066643422\n",
      "[timestep: 3] [epoch: 22471] loss: 0.0064956537\n",
      "[timestep: 3] [epoch: 22501] loss: 0.0065195076\n",
      "[timestep: 3] [epoch: 22531] loss: 0.0066607138\n",
      "[timestep: 3] [epoch: 22561] loss: 0.0068905568\n",
      "[timestep: 3] [epoch: 22591] loss: 0.0068183080\n",
      "[timestep: 3] [epoch: 22621] loss: 0.0066919243\n",
      "[timestep: 3] [epoch: 22651] loss: 0.0066439919\n",
      "[timestep: 3] [epoch: 22681] loss: 0.0064827399\n",
      "[timestep: 3] [epoch: 22711] loss: 0.0075767324\n",
      "[timestep: 3] [epoch: 22741] loss: 0.0065418719\n",
      "[timestep: 3] [epoch: 22771] loss: 0.0066044852\n",
      "[timestep: 3] [epoch: 22801] loss: 0.0065538269\n",
      "[timestep: 3] [epoch: 22831] loss: 0.0071383715\n",
      "[timestep: 3] [epoch: 22861] loss: 0.0075936359\n",
      "[timestep: 3] [epoch: 22891] loss: 0.0114781810\n",
      "[timestep: 3] [epoch: 22921] loss: 0.0076232310\n",
      "[timestep: 3] [epoch: 22951] loss: 0.0064783785\n",
      "[timestep: 3] [epoch: 22981] loss: 0.0064443974\n",
      "[timestep: 3] [epoch: 23011] loss: 0.0064553106\n",
      "[timestep: 3] [epoch: 23041] loss: 0.0064310315\n",
      "[timestep: 3] [epoch: 23071] loss: 0.0064711897\n",
      "[timestep: 3] [epoch: 23101] loss: 0.0064546722\n",
      "[timestep: 3] [epoch: 23131] loss: 0.0064426754\n",
      "[timestep: 3] [epoch: 23161] loss: 0.0064478330\n",
      "[timestep: 3] [epoch: 23191] loss: 0.0064587211\n",
      "[timestep: 3] [epoch: 23221] loss: 0.0065224636\n",
      "[timestep: 3] [epoch: 23251] loss: 0.0065006348\n",
      "[timestep: 3] [epoch: 23281] loss: 0.0065918383\n",
      "[timestep: 3] [epoch: 23311] loss: 0.0066571250\n",
      "[timestep: 3] [epoch: 23341] loss: 0.0064962786\n",
      "[timestep: 3] [epoch: 23371] loss: 0.0065069590\n",
      "[timestep: 3] [epoch: 23401] loss: 0.0064903991\n",
      "[timestep: 3] [epoch: 23431] loss: 0.0069563775\n",
      "[timestep: 3] [epoch: 23461] loss: 0.0068002450\n",
      "[timestep: 3] [epoch: 23491] loss: 0.0064563095\n",
      "[timestep: 3] [epoch: 23521] loss: 0.0065159462\n",
      "[timestep: 3] [epoch: 23551] loss: 0.0071782339\n",
      "[timestep: 3] [epoch: 23581] loss: 0.0067521995\n",
      "[timestep: 3] [epoch: 23611] loss: 0.0064884992\n",
      "[timestep: 3] [epoch: 23641] loss: 0.0066598719\n",
      "[timestep: 3] [epoch: 23671] loss: 0.0068093017\n",
      "[timestep: 3] [epoch: 23701] loss: 0.0067425915\n",
      "[timestep: 3] [epoch: 23731] loss: 0.0065358952\n",
      "[timestep: 3] [epoch: 23761] loss: 0.0070536095\n",
      "[timestep: 3] [epoch: 23791] loss: 0.0069971369\n",
      "[timestep: 3] [epoch: 23821] loss: 0.0065857926\n",
      "[timestep: 3] [epoch: 23851] loss: 0.0064874338\n",
      "[timestep: 3] [epoch: 23881] loss: 0.0064600082\n",
      "[timestep: 3] [epoch: 23911] loss: 0.0068810349\n",
      "[timestep: 3] [epoch: 23941] loss: 0.0064976085\n",
      "[timestep: 3] [epoch: 23971] loss: 0.0065011750\n",
      "[timestep: 3] [epoch: 24001] loss: 0.0067630382\n",
      "[timestep: 3] [epoch: 24031] loss: 0.0065208389\n",
      "[timestep: 3] [epoch: 24061] loss: 0.0067248913\n",
      "[timestep: 3] [epoch: 24091] loss: 0.0068105897\n",
      "[timestep: 3] [epoch: 24121] loss: 0.0064669750\n",
      "[timestep: 3] [epoch: 24151] loss: 0.0064699152\n",
      "[timestep: 3] [epoch: 24181] loss: 0.0064758626\n",
      "[timestep: 3] [epoch: 24211] loss: 0.0065147919\n",
      "[timestep: 3] [epoch: 24241] loss: 0.0067210980\n",
      "[timestep: 3] [epoch: 24271] loss: 0.0067059784\n",
      "[timestep: 3] [epoch: 24301] loss: 0.0065091327\n",
      "[timestep: 3] [epoch: 24331] loss: 0.0069044302\n",
      "[timestep: 3] [epoch: 24361] loss: 0.0065794997\n",
      "[timestep: 3] [epoch: 24391] loss: 0.0067525152\n",
      "[timestep: 3] [epoch: 24421] loss: 0.0064724777\n",
      "[timestep: 3] [epoch: 24451] loss: 0.0065716142\n",
      "[timestep: 3] [epoch: 24481] loss: 0.0073300898\n",
      "[timestep: 3] [epoch: 24511] loss: 0.0065559298\n",
      "[timestep: 3] [epoch: 24541] loss: 0.0065969485\n",
      "[timestep: 3] [epoch: 24571] loss: 0.0068960576\n",
      "[timestep: 3] [epoch: 24601] loss: 0.0064988509\n",
      "[timestep: 3] [epoch: 24631] loss: 0.0067930557\n",
      "[timestep: 3] [epoch: 24661] loss: 0.0068866438\n",
      "[timestep: 3] [epoch: 24691] loss: 0.0064669596\n",
      "[timestep: 3] [epoch: 24721] loss: 0.0064592273\n",
      "[timestep: 3] [epoch: 24751] loss: 0.0065106610\n",
      "[timestep: 3] [epoch: 24781] loss: 0.0065995464\n",
      "[timestep: 3] [epoch: 24811] loss: 0.0066810241\n",
      "[timestep: 3] [epoch: 24841] loss: 0.0066151349\n",
      "[timestep: 3] [epoch: 24871] loss: 0.0066500837\n",
      "[timestep: 3] [epoch: 24901] loss: 0.0066677756\n",
      "[timestep: 3] [epoch: 24931] loss: 0.0065729972\n",
      "[timestep: 3] [epoch: 24961] loss: 0.0065017003\n",
      "[timestep: 3] [epoch: 24991] loss: 0.0067842207\n",
      "[timestep: 3] [epoch: 25021] loss: 0.0066293865\n",
      "[timestep: 3] [epoch: 25051] loss: 0.0064491811\n",
      "[timestep: 3] [epoch: 25081] loss: 0.0066446676\n",
      "[timestep: 3] [epoch: 25111] loss: 0.0065395767\n",
      "[timestep: 3] [epoch: 25141] loss: 0.0065397527\n",
      "[timestep: 3] [epoch: 25171] loss: 0.0065356418\n",
      "[timestep: 3] [epoch: 25201] loss: 0.0067088660\n",
      "[timestep: 3] [epoch: 25231] loss: 0.0065325554\n",
      "[timestep: 3] [epoch: 25261] loss: 0.0064828512\n",
      "[timestep: 3] [epoch: 25291] loss: 0.0066319201\n",
      "[timestep: 3] [epoch: 25321] loss: 0.0066159172\n",
      "[timestep: 3] [epoch: 25351] loss: 0.0065587847\n",
      "[timestep: 3] [epoch: 25381] loss: 0.0065330910\n",
      "[timestep: 3] [epoch: 25411] loss: 0.0067800302\n",
      "[timestep: 3] [epoch: 25441] loss: 0.0067052599\n",
      "[timestep: 3] [epoch: 25471] loss: 0.0067031663\n",
      "[timestep: 3] [epoch: 25501] loss: 0.0066439989\n",
      "[timestep: 3] [epoch: 25531] loss: 0.0067243800\n",
      "[timestep: 3] [epoch: 25561] loss: 0.0067959120\n",
      "[timestep: 3] [epoch: 25591] loss: 0.0065488992\n",
      "[timestep: 3] [epoch: 25621] loss: 0.0065153115\n",
      "[timestep: 3] [epoch: 25651] loss: 0.0064708143\n",
      "[timestep: 3] [epoch: 25681] loss: 0.0065099658\n",
      "[timestep: 3] [epoch: 25711] loss: 0.0064990926\n",
      "[timestep: 3] [epoch: 25741] loss: 0.0065321652\n",
      "[timestep: 3] [epoch: 25771] loss: 0.0066060219\n",
      "[timestep: 3] [epoch: 25801] loss: 0.0066658682\n",
      "[timestep: 3] [epoch: 25831] loss: 0.0065160999\n",
      "[timestep: 3] [epoch: 25861] loss: 0.0066954149\n",
      "[timestep: 3] [epoch: 25891] loss: 0.0070192348\n",
      "[timestep: 3] [epoch: 25921] loss: 0.0066353627\n",
      "[timestep: 3] [epoch: 25951] loss: 0.0065141586\n",
      "[timestep: 3] [epoch: 25981] loss: 0.0064873328\n",
      "[timestep: 3] [epoch: 26011] loss: 0.0064939754\n",
      "[timestep: 3] [epoch: 26041] loss: 0.0065987506\n",
      "[timestep: 3] [epoch: 26071] loss: 0.0071929311\n",
      "[timestep: 3] [epoch: 26101] loss: 0.0066408967\n",
      "[timestep: 3] [epoch: 26131] loss: 0.0064856606\n",
      "[timestep: 3] [epoch: 26161] loss: 0.0064781569\n",
      "[timestep: 3] [epoch: 26191] loss: 0.0065212096\n",
      "[timestep: 3] [epoch: 26221] loss: 0.0069028609\n",
      "[timestep: 3] [epoch: 26251] loss: 0.0065533463\n",
      "[timestep: 3] [epoch: 26281] loss: 0.0066121118\n",
      "[timestep: 3] [epoch: 26311] loss: 0.0065227533\n",
      "[timestep: 3] [epoch: 26341] loss: 0.0064744586\n",
      "[timestep: 3] [epoch: 26371] loss: 0.0070005441\n",
      "[timestep: 3] [epoch: 26401] loss: 0.0066845370\n",
      "[timestep: 3] [epoch: 26431] loss: 0.0064842002\n",
      "[timestep: 3] [epoch: 26461] loss: 0.0065736291\n",
      "[timestep: 3] [epoch: 26491] loss: 0.0065635014\n",
      "[timestep: 3] [epoch: 26521] loss: 0.0065681757\n",
      "[timestep: 3] [epoch: 26551] loss: 0.0069271508\n",
      "[timestep: 3] [epoch: 26581] loss: 0.0065256078\n",
      "[timestep: 3] [epoch: 26611] loss: 0.0065743797\n",
      "[timestep: 3] [epoch: 26641] loss: 0.0075163832\n",
      "[timestep: 3] [epoch: 26671] loss: 0.0065098349\n",
      "[timestep: 3] [epoch: 26701] loss: 0.0064802086\n",
      "[timestep: 3] [epoch: 26731] loss: 0.0066274730\n",
      "[timestep: 3] [epoch: 26761] loss: 0.0065507144\n",
      "[timestep: 3] [epoch: 26791] loss: 0.0064788107\n",
      "[timestep: 3] [epoch: 26821] loss: 0.0065284204\n",
      "[timestep: 3] [epoch: 26851] loss: 0.0067732055\n",
      "[timestep: 3] [epoch: 26881] loss: 0.0066112876\n",
      "[timestep: 3] [epoch: 26911] loss: 0.0065021198\n",
      "[timestep: 3] [epoch: 26941] loss: 0.0066759242\n",
      "[timestep: 3] [epoch: 26971] loss: 0.0064960904\n",
      "[timestep: 3] [epoch: 27001] loss: 0.0071409210\n",
      "[timestep: 3] [epoch: 27031] loss: 0.0067772167\n",
      "[timestep: 3] [epoch: 27061] loss: 0.0123724798\n",
      "[timestep: 3] [epoch: 27091] loss: 0.0066009108\n",
      "[timestep: 3] [epoch: 27121] loss: 0.0064756772\n",
      "[timestep: 3] [epoch: 27151] loss: 0.0065226508\n",
      "[timestep: 3] [epoch: 27181] loss: 0.0064672865\n",
      "[timestep: 3] [epoch: 27211] loss: 0.0065334020\n",
      "[timestep: 3] [epoch: 27241] loss: 0.0065016146\n",
      "[timestep: 3] [epoch: 27271] loss: 0.0066455803\n",
      "[timestep: 3] [epoch: 27301] loss: 0.0065568020\n",
      "[timestep: 3] [epoch: 27331] loss: 0.0064610280\n",
      "[timestep: 3] [epoch: 27361] loss: 0.0066492278\n",
      "[timestep: 3] [epoch: 27391] loss: 0.0064678518\n",
      "[timestep: 3] [epoch: 27421] loss: 0.0065597892\n",
      "[timestep: 3] [epoch: 27451] loss: 0.0067352955\n",
      "[timestep: 3] [epoch: 27481] loss: 0.0064997328\n",
      "[timestep: 3] [epoch: 27511] loss: 0.0064726593\n",
      "[timestep: 3] [epoch: 27541] loss: 0.0066596963\n",
      "[timestep: 3] [epoch: 27571] loss: 0.0064656767\n",
      "[timestep: 3] [epoch: 27601] loss: 0.0065753935\n",
      "[timestep: 3] [epoch: 27631] loss: 0.0065827896\n",
      "[timestep: 3] [epoch: 27661] loss: 0.0066983560\n",
      "[timestep: 3] [epoch: 27691] loss: 0.0066396352\n",
      "[timestep: 3] [epoch: 27721] loss: 0.0064967973\n",
      "[timestep: 3] [epoch: 27751] loss: 0.0065798508\n",
      "[timestep: 3] [epoch: 27781] loss: 0.0065090382\n",
      "[timestep: 3] [epoch: 27811] loss: 0.0064508813\n",
      "[timestep: 3] [epoch: 27841] loss: 0.0064934324\n",
      "[timestep: 3] [epoch: 27871] loss: 0.0069916435\n",
      "[timestep: 3] [epoch: 27901] loss: 0.0064762160\n",
      "[timestep: 3] [epoch: 27931] loss: 0.0064340224\n",
      "[timestep: 3] [epoch: 27961] loss: 0.0067689391\n",
      "[timestep: 3] [epoch: 27991] loss: 0.0064707985\n",
      "[timestep: 3] [epoch: 28021] loss: 0.0065142065\n",
      "[timestep: 3] [epoch: 28051] loss: 0.0064575775\n",
      "[timestep: 3] [epoch: 28081] loss: 0.0068058381\n",
      "[timestep: 3] [epoch: 28111] loss: 0.0066076647\n",
      "[timestep: 3] [epoch: 28141] loss: 0.0064768763\n",
      "[timestep: 3] [epoch: 28171] loss: 0.0067529278\n",
      "[timestep: 3] [epoch: 28201] loss: 0.0065475698\n",
      "[timestep: 3] [epoch: 28231] loss: 0.0064430246\n",
      "[timestep: 3] [epoch: 28261] loss: 0.0065455101\n",
      "[timestep: 3] [epoch: 28291] loss: 0.0065071797\n",
      "[timestep: 3] [epoch: 28321] loss: 0.0066780839\n",
      "[timestep: 3] [epoch: 28351] loss: 0.0065197358\n",
      "[timestep: 3] [epoch: 28381] loss: 0.0065075122\n",
      "[timestep: 3] [epoch: 28411] loss: 0.0065034656\n",
      "[timestep: 3] [epoch: 28441] loss: 0.0065807253\n",
      "[timestep: 3] [epoch: 28471] loss: 0.0065075941\n",
      "[timestep: 3] [epoch: 28501] loss: 0.0064963698\n",
      "[timestep: 3] [epoch: 28531] loss: 0.0064950394\n",
      "[timestep: 3] [epoch: 28561] loss: 0.0064812303\n",
      "[timestep: 3] [epoch: 28591] loss: 0.0065281480\n",
      "[timestep: 3] [epoch: 28621] loss: 0.0065821856\n",
      "[timestep: 3] [epoch: 28651] loss: 0.0065164394\n",
      "[timestep: 3] [epoch: 28681] loss: 0.0064643370\n",
      "[timestep: 3] [epoch: 28711] loss: 0.0064570326\n",
      "[timestep: 3] [epoch: 28741] loss: 0.0072196890\n",
      "[timestep: 3] [epoch: 28771] loss: 0.0064301481\n",
      "[timestep: 3] [epoch: 28801] loss: 0.0064570303\n",
      "[timestep: 3] [epoch: 28831] loss: 0.0064450479\n",
      "[timestep: 3] [epoch: 28861] loss: 0.0065571270\n",
      "[timestep: 3] [epoch: 28891] loss: 0.0069493940\n",
      "[timestep: 3] [epoch: 28921] loss: 0.0064664753\n",
      "[timestep: 3] [epoch: 28951] loss: 0.0065779840\n",
      "[timestep: 3] [epoch: 28981] loss: 0.0066599431\n",
      "[timestep: 3] [epoch: 29011] loss: 0.0068341419\n",
      "[timestep: 3] [epoch: 29041] loss: 0.0064689955\n",
      "[timestep: 3] [epoch: 29071] loss: 0.0065084556\n",
      "[timestep: 3] [epoch: 29101] loss: 0.0065719434\n",
      "[timestep: 3] [epoch: 29131] loss: 0.0065031666\n",
      "[timestep: 3] [epoch: 29161] loss: 0.0065628085\n",
      "[timestep: 3] [epoch: 29191] loss: 0.0064857085\n",
      "[timestep: 3] [epoch: 29221] loss: 0.0065687401\n",
      "[timestep: 3] [epoch: 29251] loss: 0.0065402747\n",
      "[timestep: 3] [epoch: 29281] loss: 0.0065492569\n",
      "[timestep: 3] [epoch: 29311] loss: 0.0064469110\n",
      "[timestep: 3] [epoch: 29341] loss: 0.0065023587\n",
      "[timestep: 3] [epoch: 29371] loss: 0.0065681366\n",
      "[timestep: 3] [epoch: 29401] loss: 0.0064863539\n",
      "[timestep: 3] [epoch: 29431] loss: 0.0066242861\n",
      "[timestep: 3] [epoch: 29461] loss: 0.0066475067\n",
      "[timestep: 3] [epoch: 29491] loss: 0.0064950967\n",
      "[timestep: 3] [epoch: 29521] loss: 0.0065033422\n",
      "[timestep: 3] [epoch: 29551] loss: 0.0064613735\n",
      "[timestep: 3] [epoch: 29581] loss: 0.0065172524\n",
      "[timestep: 3] [epoch: 29611] loss: 0.0064467010\n",
      "[timestep: 3] [epoch: 29641] loss: 0.0067542791\n",
      "[timestep: 3] [epoch: 29671] loss: 0.0064502703\n",
      "[timestep: 3] [epoch: 29701] loss: 0.0064368276\n",
      "[timestep: 3] [epoch: 29731] loss: 0.0064971661\n",
      "[timestep: 3] [epoch: 29761] loss: 0.0066321576\n",
      "[timestep: 3] [epoch: 29791] loss: 0.0064883130\n",
      "[timestep: 3] [epoch: 29821] loss: 0.0065510180\n",
      "[timestep: 3] [epoch: 29851] loss: 0.0065778610\n",
      "[timestep: 3] [epoch: 29881] loss: 0.0065093073\n",
      "[timestep: 3] [epoch: 29911] loss: 0.0066059399\n",
      "[timestep: 3] [epoch: 29941] loss: 0.0064936262\n",
      "[timestep: 3] [epoch: 29971] loss: 0.0064932304\n",
      "[timestep: 3] [epoch: 30001] loss: 0.0065693278\n",
      "[timestep: 3] [epoch: 30031] loss: 0.0064672409\n",
      "[timestep: 3] [epoch: 30061] loss: 0.0066016251\n",
      "[timestep: 3] [epoch: 30091] loss: 0.0066302009\n",
      "[timestep: 3] [epoch: 30121] loss: 0.0066566607\n",
      "[timestep: 3] [epoch: 30151] loss: 0.0064536189\n",
      "[timestep: 3] [epoch: 30181] loss: 0.0064994479\n",
      "[timestep: 3] [epoch: 30211] loss: 0.0064790258\n",
      "[timestep: 3] [epoch: 30241] loss: 0.0066010552\n",
      "[timestep: 3] [epoch: 30271] loss: 0.0068263379\n",
      "[timestep: 3] [epoch: 30301] loss: 0.0065156012\n",
      "[timestep: 3] [epoch: 30331] loss: 0.0064381631\n",
      "[timestep: 3] [epoch: 30361] loss: 0.0064471806\n",
      "[timestep: 3] [epoch: 30391] loss: 0.0065543926\n",
      "[timestep: 3] [epoch: 30421] loss: 0.0065388107\n",
      "[timestep: 3] [epoch: 30451] loss: 0.0065270611\n",
      "[timestep: 3] [epoch: 30481] loss: 0.0065020928\n",
      "[timestep: 3] [epoch: 30511] loss: 0.0065225996\n",
      "[timestep: 3] [epoch: 30541] loss: 0.0065548844\n",
      "[timestep: 3] [epoch: 30571] loss: 0.0065093990\n",
      "[timestep: 3] [epoch: 30601] loss: 0.0064403387\n",
      "[timestep: 3] [epoch: 30631] loss: 0.0068296604\n",
      "[timestep: 3] [epoch: 30661] loss: 0.0065806066\n",
      "[timestep: 3] [epoch: 30691] loss: 0.0064454153\n",
      "[timestep: 3] [epoch: 30721] loss: 0.0065214089\n",
      "[timestep: 3] [epoch: 30751] loss: 0.0064553060\n",
      "[timestep: 3] [epoch: 30781] loss: 0.0064442982\n",
      "[timestep: 3] [epoch: 30811] loss: 0.0065315394\n",
      "[timestep: 3] [epoch: 30841] loss: 0.0065901778\n",
      "[timestep: 3] [epoch: 30871] loss: 0.0066515100\n",
      "[timestep: 3] [epoch: 30901] loss: 0.0065592262\n",
      "[timestep: 3] [epoch: 30931] loss: 0.0065540127\n",
      "[timestep: 3] [epoch: 30961] loss: 0.0064519844\n",
      "[timestep: 3] [epoch: 30991] loss: 0.0064499057\n",
      "[timestep: 3] [epoch: 31021] loss: 0.0065638376\n",
      "[timestep: 3] [epoch: 31051] loss: 0.0064633861\n",
      "[timestep: 3] [epoch: 31081] loss: 0.0065018022\n",
      "[timestep: 3] [epoch: 31111] loss: 0.0064374493\n",
      "[timestep: 3] [epoch: 31141] loss: 0.0064718495\n",
      "[timestep: 3] [epoch: 31171] loss: 0.0066811792\n",
      "[timestep: 3] [epoch: 31201] loss: 0.0064625368\n",
      "[timestep: 3] [epoch: 31231] loss: 0.0064759068\n",
      "[timestep: 3] [epoch: 31261] loss: 0.0065866164\n",
      "[timestep: 3] [epoch: 31291] loss: 0.0065307315\n",
      "[timestep: 3] [epoch: 31321] loss: 0.0064600641\n",
      "[timestep: 3] [epoch: 31351] loss: 0.0065584178\n",
      "[timestep: 3] [epoch: 31381] loss: 0.0066349143\n",
      "[timestep: 3] [epoch: 31411] loss: 0.0064811567\n",
      "[timestep: 3] [epoch: 31441] loss: 0.0065507405\n",
      "[timestep: 3] [epoch: 31471] loss: 0.0064332727\n",
      "[timestep: 3] [epoch: 31501] loss: 0.0067202081\n",
      "[timestep: 3] [epoch: 31531] loss: 0.0064800358\n",
      "[timestep: 3] [epoch: 31561] loss: 0.0064800638\n",
      "[timestep: 3] [epoch: 31591] loss: 0.0065916833\n",
      "[timestep: 3] [epoch: 31621] loss: 0.0064636539\n",
      "[timestep: 3] [epoch: 31651] loss: 0.0065550450\n",
      "[timestep: 3] [epoch: 31681] loss: 0.0065921480\n",
      "[timestep: 3] [epoch: 31711] loss: 0.0064778468\n",
      "[timestep: 3] [epoch: 31741] loss: 0.0064396476\n",
      "[timestep: 3] [epoch: 31771] loss: 0.0065200403\n",
      "[timestep: 3] [epoch: 31801] loss: 0.0064606220\n",
      "[timestep: 3] [epoch: 31831] loss: 0.0064937556\n",
      "[timestep: 3] [epoch: 31861] loss: 0.0068131224\n",
      "[timestep: 3] [epoch: 31891] loss: 0.0064660152\n",
      "[timestep: 3] [epoch: 31921] loss: 0.0064742370\n",
      "[timestep: 3] [epoch: 31951] loss: 0.0067725275\n",
      "[timestep: 3] [epoch: 31981] loss: 0.0065357992\n",
      "[timestep: 3] [epoch: 32011] loss: 0.0064603752\n",
      "[timestep: 3] [epoch: 32041] loss: 0.0064260536\n",
      "[timestep: 3] [epoch: 32071] loss: 0.0064462861\n",
      "[timestep: 3] [epoch: 32101] loss: 0.0064912550\n",
      "[timestep: 3] [epoch: 32131] loss: 0.0064280569\n",
      "[timestep: 3] [epoch: 32161] loss: 0.0065405746\n",
      "[timestep: 3] [epoch: 32191] loss: 0.0064738374\n",
      "[timestep: 3] [epoch: 32221] loss: 0.0066138878\n",
      "[timestep: 3] [epoch: 32251] loss: 0.0065474533\n",
      "[timestep: 3] [epoch: 32281] loss: 0.0065210243\n",
      "[timestep: 3] [epoch: 32311] loss: 0.0065964325\n",
      "[timestep: 3] [epoch: 32341] loss: 0.0064672180\n",
      "[timestep: 3] [epoch: 32371] loss: 0.0064155543\n",
      "[timestep: 3] [epoch: 32401] loss: 0.0064640949\n",
      "[timestep: 3] [epoch: 32431] loss: 0.0065340549\n",
      "[timestep: 3] [epoch: 32461] loss: 0.0064612846\n",
      "[timestep: 3] [epoch: 32491] loss: 0.0064896210\n",
      "[timestep: 3] [epoch: 32521] loss: 0.0064850803\n",
      "[timestep: 3] [epoch: 32551] loss: 0.0066792062\n",
      "[timestep: 3] [epoch: 32581] loss: 0.0065918267\n",
      "[timestep: 3] [epoch: 32611] loss: 0.0064954837\n",
      "[timestep: 3] [epoch: 32641] loss: 0.0065730680\n",
      "[timestep: 3] [epoch: 32671] loss: 0.0064192810\n",
      "[timestep: 3] [epoch: 32701] loss: 0.0064334525\n",
      "[timestep: 3] [epoch: 32731] loss: 0.0064647528\n",
      "[timestep: 3] [epoch: 32761] loss: 0.0064384406\n",
      "[timestep: 3] [epoch: 32791] loss: 0.0065413737\n",
      "[timestep: 3] [epoch: 32821] loss: 0.0064417738\n",
      "[timestep: 3] [epoch: 32851] loss: 0.0064030085\n",
      "[timestep: 3] [epoch: 32881] loss: 0.0064147720\n",
      "[timestep: 3] [epoch: 32911] loss: 0.0065481267\n",
      "[timestep: 3] [epoch: 32941] loss: 0.0064178524\n",
      "[timestep: 3] [epoch: 32971] loss: 0.0064213863\n",
      "[timestep: 3] [epoch: 33001] loss: 0.0064826575\n",
      "[timestep: 3] [epoch: 33031] loss: 0.0065398347\n",
      "[timestep: 3] [epoch: 33061] loss: 0.0065674512\n",
      "[timestep: 3] [epoch: 33091] loss: 0.0064837453\n",
      "[timestep: 3] [epoch: 33121] loss: 0.0064159865\n",
      "[timestep: 3] [epoch: 33151] loss: 0.0065193893\n",
      "[timestep: 3] [epoch: 33181] loss: 0.0066530285\n",
      "[timestep: 3] [epoch: 33211] loss: 0.0064100991\n",
      "[timestep: 3] [epoch: 33241] loss: 0.0064579397\n",
      "[timestep: 3] [epoch: 33271] loss: 0.0064754160\n",
      "[timestep: 3] [epoch: 33301] loss: 0.0064658653\n",
      "[timestep: 3] [epoch: 33331] loss: 0.0065278783\n",
      "[timestep: 3] [epoch: 33361] loss: 0.0065002060\n",
      "[timestep: 3] [epoch: 33391] loss: 0.0064388551\n",
      "[timestep: 3] [epoch: 33421] loss: 0.0064828922\n",
      "[timestep: 3] [epoch: 33451] loss: 0.0064919447\n",
      "[timestep: 3] [epoch: 33481] loss: 0.0064719571\n",
      "[timestep: 3] [epoch: 33511] loss: 0.0064659752\n",
      "[timestep: 3] [epoch: 33541] loss: 0.0065373103\n",
      "[timestep: 3] [epoch: 33571] loss: 0.0064966977\n",
      "[timestep: 3] [epoch: 33601] loss: 0.0065430193\n",
      "[timestep: 3] [epoch: 33631] loss: 0.0064672660\n",
      "[timestep: 3] [epoch: 33661] loss: 0.0065112994\n",
      "[timestep: 3] [epoch: 33691] loss: 0.0064745764\n",
      "[timestep: 3] [epoch: 33721] loss: 0.0064301402\n",
      "[timestep: 3] [epoch: 33751] loss: 0.0065136151\n",
      "[timestep: 3] [epoch: 33781] loss: 0.0064326078\n",
      "[timestep: 3] [epoch: 33811] loss: 0.0064213770\n",
      "[timestep: 3] [epoch: 33841] loss: 0.0064529935\n",
      "[timestep: 3] [epoch: 33871] loss: 0.0064470195\n",
      "[timestep: 3] [epoch: 33901] loss: 0.0065152459\n",
      "[timestep: 3] [epoch: 33931] loss: 0.0064482978\n",
      "[timestep: 3] [epoch: 33961] loss: 0.0064471019\n",
      "[timestep: 3] [epoch: 33991] loss: 0.0065257391\n",
      "[timestep: 3] [epoch: 34021] loss: 0.0064391573\n",
      "[timestep: 3] [epoch: 34051] loss: 0.0065186443\n",
      "[timestep: 3] [epoch: 34081] loss: 0.0064290995\n",
      "[timestep: 3] [epoch: 34111] loss: 0.0064813718\n",
      "[timestep: 3] [epoch: 34141] loss: 0.0066319271\n",
      "[timestep: 3] [epoch: 34171] loss: 0.0065901084\n",
      "[timestep: 3] [epoch: 34201] loss: 0.0064498438\n",
      "[timestep: 3] [epoch: 34231] loss: 0.0064349957\n",
      "[timestep: 3] [epoch: 34261] loss: 0.0064570336\n",
      "[timestep: 3] [epoch: 34291] loss: 0.0064259339\n",
      "[timestep: 3] [epoch: 34321] loss: 0.0064626774\n",
      "[timestep: 3] [epoch: 34351] loss: 0.0065425248\n",
      "[timestep: 3] [epoch: 34381] loss: 0.0064724972\n",
      "[timestep: 3] [epoch: 34411] loss: 0.0067136483\n",
      "[timestep: 3] [epoch: 34441] loss: 0.0064426269\n",
      "[timestep: 3] [epoch: 34471] loss: 0.0065665459\n",
      "[timestep: 3] [epoch: 34501] loss: 0.0064102625\n",
      "[timestep: 3] [epoch: 34531] loss: 0.0064154831\n",
      "[timestep: 3] [epoch: 34561] loss: 0.0064323461\n",
      "[timestep: 3] [epoch: 34591] loss: 0.0064656590\n",
      "[timestep: 3] [epoch: 34621] loss: 0.0064144367\n",
      "[timestep: 3] [epoch: 34651] loss: 0.0066543366\n",
      "[timestep: 3] [epoch: 34681] loss: 0.0064712917\n",
      "[timestep: 3] [epoch: 34711] loss: 0.0065069818\n",
      "[timestep: 3] [epoch: 34741] loss: 0.0064366655\n",
      "[timestep: 3] [epoch: 34771] loss: 0.0065291869\n",
      "[timestep: 3] [epoch: 34801] loss: 0.0066143880\n",
      "[timestep: 3] [epoch: 34831] loss: 0.0064227260\n",
      "[timestep: 3] [epoch: 34861] loss: 0.0064655044\n",
      "[timestep: 3] [epoch: 34891] loss: 0.0064156875\n",
      "[timestep: 3] [epoch: 34921] loss: 0.0064687133\n",
      "[timestep: 3] [epoch: 34951] loss: 0.0064376872\n",
      "[timestep: 3] [epoch: 34981] loss: 0.0064693694\n",
      "[timestep: 3] [epoch: 35011] loss: 0.0064682392\n",
      "[timestep: 3] [epoch: 35041] loss: 0.0064343303\n",
      "[timestep: 3] [epoch: 35071] loss: 0.0064357007\n",
      "[timestep: 3] [epoch: 35101] loss: 0.0064683422\n",
      "[timestep: 3] [epoch: 35131] loss: 0.0064582527\n",
      "[timestep: 3] [epoch: 35161] loss: 0.0065526841\n",
      "[timestep: 3] [epoch: 35191] loss: 0.0064688465\n",
      "[timestep: 3] [epoch: 35221] loss: 0.0064400085\n",
      "[timestep: 3] [epoch: 35251] loss: 0.0064183427\n",
      "[timestep: 3] [epoch: 35281] loss: 0.0064457292\n",
      "[timestep: 3] [epoch: 35311] loss: 0.0065275626\n",
      "[timestep: 3] [epoch: 35341] loss: 0.0064615938\n",
      "[timestep: 3] [epoch: 35371] loss: 0.0064380886\n",
      "[timestep: 3] [epoch: 35401] loss: 0.0064803734\n",
      "[timestep: 3] [epoch: 35431] loss: 0.0064682574\n",
      "[timestep: 3] [epoch: 35461] loss: 0.0065637529\n",
      "[timestep: 3] [epoch: 35491] loss: 0.0064274566\n",
      "[timestep: 3] [epoch: 35521] loss: 0.0064089629\n",
      "[timestep: 3] [epoch: 35551] loss: 0.0064320154\n",
      "[timestep: 3] [epoch: 35581] loss: 0.0065093031\n",
      "[timestep: 3] [epoch: 35611] loss: 0.0064166477\n",
      "[timestep: 3] [epoch: 35641] loss: 0.0064107087\n",
      "[timestep: 3] [epoch: 35671] loss: 0.0065059052\n",
      "[timestep: 3] [epoch: 35701] loss: 0.0064243358\n",
      "[timestep: 3] [epoch: 35731] loss: 0.0064260168\n",
      "[timestep: 3] [epoch: 35761] loss: 0.0066313194\n",
      "[timestep: 3] [epoch: 35791] loss: 0.0064297216\n",
      "[timestep: 3] [epoch: 35821] loss: 0.0064907521\n",
      "[timestep: 3] [epoch: 35851] loss: 0.0064586811\n",
      "[timestep: 3] [epoch: 35881] loss: 0.0064121187\n",
      "[timestep: 3] [epoch: 35911] loss: 0.0064652073\n",
      "[timestep: 3] [epoch: 35941] loss: 0.0064707329\n",
      "[timestep: 3] [epoch: 35971] loss: 0.0064218263\n",
      "[timestep: 3] [epoch: 36001] loss: 0.0064515080\n",
      "[timestep: 3] [epoch: 36031] loss: 0.0064351447\n",
      "[timestep: 3] [epoch: 36061] loss: 0.0064415336\n",
      "[timestep: 3] [epoch: 36091] loss: 0.0064108819\n",
      "[timestep: 3] [epoch: 36121] loss: 0.0064596650\n",
      "[timestep: 3] [epoch: 36151] loss: 0.0064146579\n",
      "[timestep: 3] [epoch: 36181] loss: 0.0064566452\n",
      "[timestep: 3] [epoch: 36211] loss: 0.0064180805\n",
      "[timestep: 3] [epoch: 36241] loss: 0.0064541381\n",
      "[timestep: 3] [epoch: 36271] loss: 0.0064202910\n",
      "[timestep: 3] [epoch: 36301] loss: 0.0064864657\n",
      "[timestep: 3] [epoch: 36331] loss: 0.0064348578\n",
      "[timestep: 3] [epoch: 36361] loss: 0.0064350227\n",
      "[timestep: 3] [epoch: 36391] loss: 0.0064369030\n",
      "[timestep: 3] [epoch: 36421] loss: 0.0064857565\n",
      "[timestep: 3] [epoch: 36451] loss: 0.0064722290\n",
      "[timestep: 3] [epoch: 36481] loss: 0.0064149513\n",
      "[timestep: 3] [epoch: 36511] loss: 0.0064024283\n",
      "[timestep: 3] [epoch: 36541] loss: 0.0064758174\n",
      "[timestep: 3] [epoch: 36571] loss: 0.0064174430\n",
      "[timestep: 3] [epoch: 36601] loss: 0.0063990499\n",
      "[timestep: 3] [epoch: 36631] loss: 0.0064428104\n",
      "[timestep: 3] [epoch: 36661] loss: 0.0064226752\n",
      "[timestep: 3] [epoch: 36691] loss: 0.0065261237\n",
      "[timestep: 3] [epoch: 36721] loss: 0.0064774975\n",
      "[timestep: 3] [epoch: 36751] loss: 0.0064103124\n",
      "[timestep: 3] [epoch: 36781] loss: 0.0065116659\n",
      "[timestep: 3] [epoch: 36811] loss: 0.0065049948\n",
      "[timestep: 3] [epoch: 36841] loss: 0.0064191907\n",
      "[timestep: 3] [epoch: 36871] loss: 0.0064690085\n",
      "[timestep: 3] [epoch: 36901] loss: 0.0064657805\n",
      "[timestep: 3] [epoch: 36931] loss: 0.0065133581\n",
      "[timestep: 3] [epoch: 36961] loss: 0.0064363182\n",
      "[timestep: 3] [epoch: 36991] loss: 0.0064234841\n",
      "[timestep: 3] [epoch: 37021] loss: 0.0064357249\n",
      "[timestep: 3] [epoch: 37051] loss: 0.0065749190\n",
      "[timestep: 3] [epoch: 37081] loss: 0.0064297435\n",
      "[timestep: 3] [epoch: 37111] loss: 0.0064816955\n",
      "[timestep: 3] [epoch: 37141] loss: 0.0065197698\n",
      "[timestep: 3] [epoch: 37171] loss: 0.0064554457\n",
      "[timestep: 3] [epoch: 37201] loss: 0.0064682383\n",
      "[timestep: 3] [epoch: 37231] loss: 0.0065069478\n",
      "[timestep: 3] [epoch: 37261] loss: 0.0064531071\n",
      "[timestep: 3] [epoch: 37291] loss: 0.0064337552\n",
      "[timestep: 3] [epoch: 37321] loss: 0.0064131352\n",
      "[timestep: 3] [epoch: 37351] loss: 0.0065146927\n",
      "[timestep: 3] [epoch: 37381] loss: 0.0065263985\n",
      "[timestep: 3] [epoch: 37411] loss: 0.0064676325\n",
      "[timestep: 3] [epoch: 37441] loss: 0.0064109704\n",
      "[timestep: 3] [epoch: 37471] loss: 0.0064045074\n",
      "[timestep: 3] [epoch: 37501] loss: 0.0064879498\n",
      "[timestep: 3] [epoch: 37531] loss: 0.0064487020\n",
      "[timestep: 3] [epoch: 37561] loss: 0.0064332476\n",
      "[timestep: 3] [epoch: 37591] loss: 0.0064540850\n",
      "[timestep: 3] [epoch: 37621] loss: 0.0064502452\n",
      "[timestep: 3] [epoch: 37651] loss: 0.0064762579\n",
      "[timestep: 3] [epoch: 37681] loss: 0.0064803506\n",
      "[timestep: 3] [epoch: 37711] loss: 0.0064852298\n",
      "[timestep: 3] [epoch: 37741] loss: 0.0064335605\n",
      "[timestep: 3] [epoch: 37771] loss: 0.0064590657\n",
      "[timestep: 3] [epoch: 37801] loss: 0.0064076101\n",
      "[timestep: 3] [epoch: 37831] loss: 0.0064691212\n",
      "[timestep: 3] [epoch: 37861] loss: 0.0064374278\n",
      "[timestep: 3] [epoch: 37891] loss: 0.0064238580\n",
      "[timestep: 3] [epoch: 37921] loss: 0.0064412728\n",
      "[timestep: 3] [epoch: 37951] loss: 0.0064309454\n",
      "[timestep: 3] [epoch: 37981] loss: 0.0064215064\n",
      "[timestep: 3] [epoch: 38011] loss: 0.0064679803\n",
      "[timestep: 3] [epoch: 38041] loss: 0.0064311037\n",
      "[timestep: 3] [epoch: 38071] loss: 0.0065520592\n",
      "[timestep: 3] [epoch: 38101] loss: 0.0064092111\n",
      "[timestep: 3] [epoch: 38131] loss: 0.0064509376\n",
      "[timestep: 3] [epoch: 38161] loss: 0.0065605715\n",
      "[timestep: 3] [epoch: 38191] loss: 0.0064371293\n",
      "[timestep: 3] [epoch: 38221] loss: 0.0065716496\n",
      "[timestep: 3] [epoch: 38251] loss: 0.0065551503\n",
      "[timestep: 3] [epoch: 38281] loss: 0.0064134835\n",
      "[timestep: 3] [epoch: 38311] loss: 0.0064216070\n",
      "[timestep: 3] [epoch: 38341] loss: 0.0064378483\n",
      "[timestep: 3] [epoch: 38371] loss: 0.0064962888\n",
      "[timestep: 3] [epoch: 38401] loss: 0.0064174123\n",
      "[timestep: 3] [epoch: 38431] loss: 0.0064324765\n",
      "[timestep: 3] [epoch: 38461] loss: 0.0064278832\n",
      "[timestep: 3] [epoch: 38491] loss: 0.0064736544\n",
      "[timestep: 3] [epoch: 38521] loss: 0.0065332446\n",
      "[timestep: 3] [epoch: 38551] loss: 0.0064348327\n",
      "[timestep: 3] [epoch: 38581] loss: 0.0064056707\n",
      "[timestep: 3] [epoch: 38611] loss: 0.0064214668\n",
      "[timestep: 3] [epoch: 38641] loss: 0.0065170666\n",
      "[timestep: 3] [epoch: 38671] loss: 0.0063969023\n",
      "[timestep: 3] [epoch: 38701] loss: 0.0064377235\n",
      "[timestep: 3] [epoch: 38731] loss: 0.0064480086\n",
      "[timestep: 3] [epoch: 38761] loss: 0.0064714793\n",
      "[timestep: 3] [epoch: 38791] loss: 0.0064657596\n",
      "[timestep: 3] [epoch: 38821] loss: 0.0064070504\n",
      "[timestep: 3] [epoch: 38851] loss: 0.0064219423\n",
      "[timestep: 3] [epoch: 38881] loss: 0.0064320010\n",
      "[timestep: 3] [epoch: 38911] loss: 0.0063948198\n",
      "[timestep: 3] [epoch: 38941] loss: 0.0064004343\n",
      "[timestep: 3] [epoch: 38971] loss: 0.0064355126\n",
      "[timestep: 3] [epoch: 39001] loss: 0.0064697601\n",
      "[timestep: 3] [epoch: 39031] loss: 0.0063934582\n",
      "[timestep: 3] [epoch: 39061] loss: 0.0064665121\n",
      "[timestep: 3] [epoch: 39091] loss: 0.0064639603\n",
      "[timestep: 3] [epoch: 39121] loss: 0.0064212177\n",
      "[timestep: 3] [epoch: 39151] loss: 0.0064018592\n",
      "[timestep: 3] [epoch: 39181] loss: 0.0066287974\n",
      "[timestep: 3] [epoch: 39211] loss: 0.0065056533\n",
      "[timestep: 3] [epoch: 39241] loss: 0.0064771613\n",
      "[timestep: 3] [epoch: 39271] loss: 0.0064422381\n",
      "[timestep: 3] [epoch: 39301] loss: 0.0064793429\n",
      "[timestep: 3] [epoch: 39331] loss: 0.0064522768\n",
      "[timestep: 3] [epoch: 39361] loss: 0.0064648250\n",
      "[timestep: 3] [epoch: 39391] loss: 0.0064630341\n",
      "[timestep: 3] [epoch: 39421] loss: 0.0064157788\n",
      "[timestep: 3] [epoch: 39451] loss: 0.0064276257\n",
      "[timestep: 3] [epoch: 39481] loss: 0.0064341114\n",
      "[timestep: 3] [epoch: 39511] loss: 0.0064790063\n",
      "[timestep: 3] [epoch: 39541] loss: 0.0064499388\n",
      "[timestep: 3] [epoch: 39571] loss: 0.0064459168\n",
      "[timestep: 3] [epoch: 39601] loss: 0.0064214701\n",
      "[timestep: 3] [epoch: 39631] loss: 0.0064707082\n",
      "[timestep: 3] [epoch: 39661] loss: 0.0064076311\n",
      "[timestep: 3] [epoch: 39691] loss: 0.0064384784\n",
      "[timestep: 3] [epoch: 39721] loss: 0.0064338297\n",
      "[timestep: 3] [epoch: 39751] loss: 0.0064867539\n",
      "[timestep: 3] [epoch: 39781] loss: 0.0064319968\n",
      "[timestep: 3] [epoch: 39811] loss: 0.0064845341\n",
      "[timestep: 3] [epoch: 39841] loss: 0.0064210556\n",
      "[timestep: 3] [epoch: 39871] loss: 0.0064268829\n",
      "[timestep: 3] [epoch: 39901] loss: 0.0063972175\n",
      "[timestep: 3] [epoch: 39931] loss: 0.0063910177\n",
      "[timestep: 3] [epoch: 39961] loss: 0.0064015975\n",
      "[timestep: 3] [epoch: 39991] loss: 0.0064221593\n",
      "[timestep: 3] [epoch: 40021] loss: 0.0064999331\n",
      "[timestep: 3] [epoch: 40051] loss: 0.0064350236\n",
      "[timestep: 3] [epoch: 40081] loss: 0.0064707389\n",
      "[timestep: 3] [epoch: 40111] loss: 0.0064050197\n",
      "[timestep: 3] [epoch: 40141] loss: 0.0064059128\n",
      "[timestep: 3] [epoch: 40171] loss: 0.0064774342\n",
      "[timestep: 3] [epoch: 40201] loss: 0.0064374227\n",
      "[timestep: 3] [epoch: 40231] loss: 0.0064111212\n",
      "[timestep: 3] [epoch: 40261] loss: 0.0064301025\n",
      "[timestep: 3] [epoch: 40291] loss: 0.0063967099\n",
      "[timestep: 3] [epoch: 40321] loss: 0.0064473362\n",
      "[timestep: 3] [epoch: 40351] loss: 0.0064377356\n",
      "[timestep: 3] [epoch: 40381] loss: 0.0064833323\n",
      "[timestep: 3] [epoch: 40411] loss: 0.0064403396\n",
      "[timestep: 3] [epoch: 40441] loss: 0.0064877486\n",
      "[timestep: 3] [epoch: 40471] loss: 0.0064019747\n",
      "[timestep: 3] [epoch: 40501] loss: 0.0064109769\n",
      "[timestep: 3] [epoch: 40531] loss: 0.0064168265\n",
      "[timestep: 3] [epoch: 40561] loss: 0.0064269602\n",
      "[timestep: 3] [epoch: 40591] loss: 0.0063964794\n",
      "[timestep: 3] [epoch: 40621] loss: 0.0064681168\n",
      "[timestep: 3] [epoch: 40651] loss: 0.0064038034\n",
      "[timestep: 3] [epoch: 40681] loss: 0.0065541784\n",
      "[timestep: 3] [epoch: 40711] loss: 0.0064022299\n",
      "[timestep: 3] [epoch: 40741] loss: 0.0065352377\n",
      "[timestep: 3] [epoch: 40771] loss: 0.0064438931\n",
      "[timestep: 3] [epoch: 40801] loss: 0.0064184587\n",
      "[timestep: 3] [epoch: 40831] loss: 0.0064384290\n",
      "[timestep: 3] [epoch: 40861] loss: 0.0065064342\n",
      "[timestep: 3] [epoch: 40891] loss: 0.0064149690\n",
      "[timestep: 3] [epoch: 40921] loss: 0.0063945921\n",
      "[timestep: 3] [epoch: 40951] loss: 0.0064037973\n",
      "[timestep: 3] [epoch: 40981] loss: 0.0063920836\n",
      "[timestep: 3] [epoch: 41011] loss: 0.0064302059\n",
      "[timestep: 3] [epoch: 41041] loss: 0.0064060306\n",
      "[timestep: 3] [epoch: 41071] loss: 0.0064199744\n",
      "[timestep: 3] [epoch: 41101] loss: 0.0063986755\n",
      "[timestep: 3] [epoch: 41131] loss: 0.0064111194\n",
      "[timestep: 3] [epoch: 41161] loss: 0.0064283884\n",
      "[timestep: 3] [epoch: 41191] loss: 0.0064116740\n",
      "[timestep: 3] [epoch: 41221] loss: 0.0064428123\n",
      "[timestep: 3] [epoch: 41251] loss: 0.0063959528\n",
      "[timestep: 3] [epoch: 41281] loss: 0.0064679822\n",
      "[timestep: 3] [epoch: 41311] loss: 0.0064857146\n",
      "[timestep: 3] [epoch: 41341] loss: 0.0064758235\n",
      "[timestep: 3] [epoch: 41371] loss: 0.0064456849\n",
      "[timestep: 3] [epoch: 41401] loss: 0.0064273938\n",
      "[timestep: 3] [epoch: 41431] loss: 0.0064303926\n",
      "[timestep: 3] [epoch: 41461] loss: 0.0064337198\n",
      "[timestep: 3] [epoch: 41491] loss: 0.0064090234\n",
      "[timestep: 3] [epoch: 41521] loss: 0.0064273239\n",
      "[timestep: 3] [epoch: 41551] loss: 0.0065634777\n",
      "[timestep: 3] [epoch: 41581] loss: 0.0064153736\n",
      "[timestep: 3] [epoch: 41611] loss: 0.0064071203\n",
      "[timestep: 3] [epoch: 41641] loss: 0.0064264475\n",
      "[timestep: 3] [epoch: 41671] loss: 0.0064264666\n",
      "[timestep: 3] [epoch: 41701] loss: 0.0064016813\n",
      "[timestep: 3] [epoch: 41731] loss: 0.0064164125\n",
      "[timestep: 3] [epoch: 41761] loss: 0.0065005813\n",
      "[timestep: 3] [epoch: 41791] loss: 0.0064723715\n",
      "[timestep: 3] [epoch: 41821] loss: 0.0063873488\n",
      "[timestep: 3] [epoch: 41851] loss: 0.0064253937\n",
      "[timestep: 3] [epoch: 41881] loss: 0.0064137555\n",
      "[timestep: 3] [epoch: 41911] loss: 0.0063989898\n",
      "[timestep: 3] [epoch: 41941] loss: 0.0064022974\n",
      "[timestep: 3] [epoch: 41971] loss: 0.0064139948\n",
      "[timestep: 3] [epoch: 42001] loss: 0.0063973558\n",
      "[timestep: 3] [epoch: 42031] loss: 0.0063875383\n",
      "[timestep: 3] [epoch: 42061] loss: 0.0064347987\n",
      "[timestep: 3] [epoch: 42091] loss: 0.0064856261\n",
      "[timestep: 3] [epoch: 42121] loss: 0.0063952236\n",
      "[timestep: 3] [epoch: 42151] loss: 0.0064685843\n",
      "[timestep: 3] [epoch: 42181] loss: 0.0064916639\n",
      "[timestep: 3] [epoch: 42211] loss: 0.0064079426\n",
      "[timestep: 3] [epoch: 42241] loss: 0.0064170365\n",
      "[timestep: 3] [epoch: 42271] loss: 0.0064293160\n",
      "[timestep: 3] [epoch: 42301] loss: 0.0064293491\n",
      "[timestep: 3] [epoch: 42331] loss: 0.0063952385\n",
      "[timestep: 3] [epoch: 42361] loss: 0.0064805411\n",
      "[timestep: 3] [epoch: 42391] loss: 0.0064310706\n",
      "[timestep: 3] [epoch: 42421] loss: 0.0063902666\n",
      "[timestep: 3] [epoch: 42451] loss: 0.0064279614\n",
      "[timestep: 3] [epoch: 42481] loss: 0.0064335773\n",
      "[timestep: 3] [epoch: 42511] loss: 0.0064284094\n",
      "[timestep: 3] [epoch: 42541] loss: 0.0064369179\n",
      "[timestep: 3] [epoch: 42571] loss: 0.0063946815\n",
      "[timestep: 3] [epoch: 42601] loss: 0.0064088115\n",
      "[timestep: 3] [epoch: 42631] loss: 0.0064783143\n",
      "[timestep: 3] [epoch: 42661] loss: 0.0064155627\n",
      "[timestep: 3] [epoch: 42691] loss: 0.0063953791\n",
      "[timestep: 3] [epoch: 42721] loss: 0.0065294090\n",
      "[timestep: 3] [epoch: 42751] loss: 0.0064275493\n",
      "[timestep: 3] [epoch: 42781] loss: 0.0064171166\n",
      "[timestep: 3] [epoch: 42811] loss: 0.0064189322\n",
      "[timestep: 3] [epoch: 42841] loss: 0.0064024865\n",
      "[timestep: 3] [epoch: 42871] loss: 0.0064023919\n",
      "[timestep: 3] [epoch: 42901] loss: 0.0064077182\n",
      "[timestep: 3] [epoch: 42931] loss: 0.0064265644\n",
      "[timestep: 3] [epoch: 42961] loss: 0.0063963193\n",
      "[timestep: 3] [epoch: 42991] loss: 0.0064306646\n",
      "[timestep: 3] [epoch: 43021] loss: 0.0063907364\n",
      "[timestep: 3] [epoch: 43051] loss: 0.0063932668\n",
      "[timestep: 3] [epoch: 43081] loss: 0.0064635812\n",
      "[timestep: 3] [epoch: 43111] loss: 0.0063974475\n",
      "[timestep: 3] [epoch: 43141] loss: 0.0064009279\n",
      "[timestep: 3] [epoch: 43171] loss: 0.0064473636\n",
      "[timestep: 3] [epoch: 43201] loss: 0.0064283535\n",
      "[timestep: 3] [epoch: 43231] loss: 0.0063983770\n",
      "[timestep: 3] [epoch: 43261] loss: 0.0064548803\n",
      "[timestep: 3] [epoch: 43291] loss: 0.0065203165\n",
      "[timestep: 3] [epoch: 43321] loss: 0.0063820696\n",
      "[timestep: 3] [epoch: 43351] loss: 0.0064111450\n",
      "[timestep: 3] [epoch: 43381] loss: 0.0064274035\n",
      "[timestep: 3] [epoch: 43411] loss: 0.0064102979\n",
      "[timestep: 3] [epoch: 43441] loss: 0.0063952450\n",
      "[timestep: 3] [epoch: 43471] loss: 0.0066192918\n",
      "[timestep: 3] [epoch: 43501] loss: 0.0063960552\n",
      "[timestep: 3] [epoch: 43531] loss: 0.0064157760\n",
      "[timestep: 3] [epoch: 43561] loss: 0.0063840030\n",
      "[timestep: 3] [epoch: 43591] loss: 0.0063989116\n",
      "[timestep: 3] [epoch: 43621] loss: 0.0064195213\n",
      "[timestep: 3] [epoch: 43651] loss: 0.0064063151\n",
      "[timestep: 3] [epoch: 43681] loss: 0.0064340867\n",
      "[timestep: 3] [epoch: 43711] loss: 0.0064117238\n",
      "[timestep: 3] [epoch: 43741] loss: 0.0063995123\n",
      "[timestep: 3] [epoch: 43771] loss: 0.0064179935\n",
      "[timestep: 3] [epoch: 43801] loss: 0.0064079561\n",
      "[timestep: 3] [epoch: 43831] loss: 0.0082768500\n",
      "[timestep: 3] [epoch: 43861] loss: 0.0053433506\n",
      "[timestep: 3] [epoch: 43891] loss: 0.0031200773\n",
      "[timestep: 3] [epoch: 43921] loss: 0.0030454481\n",
      "[timestep: 3] [epoch: 43951] loss: 0.0030454290\n",
      "[timestep: 3] [epoch: 43981] loss: 0.0030483941\n",
      "[timestep: 3] [epoch: 44011] loss: 0.0030410306\n",
      "[timestep: 3] [epoch: 44041] loss: 0.0030526957\n",
      "[timestep: 3] [epoch: 44071] loss: 0.0030549192\n",
      "[timestep: 3] [epoch: 44101] loss: 0.0030667612\n",
      "[timestep: 3] [epoch: 44131] loss: 0.0030562170\n",
      "[timestep: 3] [epoch: 44161] loss: 0.0030471326\n",
      "[timestep: 3] [epoch: 44191] loss: 0.0030468814\n",
      "[timestep: 3] [epoch: 44221] loss: 0.0030818004\n",
      "[timestep: 3] [epoch: 44251] loss: 0.0030667600\n",
      "[timestep: 3] [epoch: 44281] loss: 0.0030595579\n",
      "[timestep: 3] [epoch: 44311] loss: 0.0030377980\n",
      "[timestep: 3] [epoch: 44341] loss: 0.0030320305\n",
      "[timestep: 3] [epoch: 44371] loss: 0.0030685011\n",
      "[timestep: 3] [epoch: 44401] loss: 0.0030605872\n",
      "[timestep: 3] [epoch: 44431] loss: 0.0030521676\n",
      "[timestep: 3] [epoch: 44461] loss: 0.0030437740\n",
      "[timestep: 3] [epoch: 44491] loss: 0.0030552007\n",
      "[timestep: 3] [epoch: 44521] loss: 0.0030710357\n",
      "[timestep: 3] [epoch: 44551] loss: 0.0030616247\n",
      "[timestep: 3] [epoch: 44581] loss: 0.0030812381\n",
      "[timestep: 3] [epoch: 44611] loss: 0.0030429044\n",
      "[timestep: 3] [epoch: 44641] loss: 0.0030674238\n",
      "[timestep: 3] [epoch: 44671] loss: 0.0031262140\n",
      "[timestep: 3] [epoch: 44701] loss: 0.0030843010\n",
      "[timestep: 3] [epoch: 44731] loss: 0.0030486987\n",
      "[timestep: 3] [epoch: 44761] loss: 0.0030612620\n",
      "[timestep: 3] [epoch: 44791] loss: 0.0030722134\n",
      "[timestep: 3] [epoch: 44821] loss: 0.0030399589\n",
      "[timestep: 3] [epoch: 44851] loss: 0.0030442686\n",
      "[timestep: 3] [epoch: 44881] loss: 0.0030507201\n",
      "[timestep: 3] [epoch: 44911] loss: 0.0030749184\n",
      "[timestep: 3] [epoch: 44941] loss: 0.0030548007\n",
      "[timestep: 3] [epoch: 44971] loss: 0.0030783261\n",
      "[timestep: 3] [epoch: 45001] loss: 0.0030627463\n",
      "[timestep: 3] [epoch: 45031] loss: 0.0030409137\n",
      "[timestep: 3] [epoch: 45061] loss: 0.0030586203\n",
      "[timestep: 3] [epoch: 45091] loss: 0.0030786896\n",
      "[timestep: 3] [epoch: 45121] loss: 0.0030675929\n",
      "[timestep: 3] [epoch: 45151] loss: 0.0030615814\n",
      "[timestep: 3] [epoch: 45181] loss: 0.0030616752\n",
      "[timestep: 3] [epoch: 45211] loss: 0.0030363929\n",
      "[timestep: 3] [epoch: 45241] loss: 0.0030356648\n",
      "[timestep: 3] [epoch: 45271] loss: 0.0030687619\n",
      "[timestep: 3] [epoch: 45301] loss: 0.0030496481\n",
      "[timestep: 3] [epoch: 45331] loss: 0.0030533469\n",
      "[timestep: 3] [epoch: 45361] loss: 0.0030571774\n",
      "[timestep: 3] [epoch: 45391] loss: 0.0030682129\n",
      "[timestep: 3] [epoch: 45421] loss: 0.0030579222\n",
      "[timestep: 3] [epoch: 45451] loss: 0.0030846514\n",
      "[timestep: 3] [epoch: 45481] loss: 0.0030554642\n",
      "[timestep: 3] [epoch: 45511] loss: 0.0031089075\n",
      "[timestep: 3] [epoch: 45541] loss: 0.0030792316\n",
      "[timestep: 3] [epoch: 45571] loss: 0.0031343524\n",
      "[timestep: 3] [epoch: 45601] loss: 0.0030412688\n",
      "[timestep: 3] [epoch: 45631] loss: 0.0030477147\n",
      "[timestep: 3] [epoch: 45661] loss: 0.0030446898\n",
      "[timestep: 3] [epoch: 45691] loss: 0.0031242562\n",
      "[timestep: 3] [epoch: 45721] loss: 0.0030712474\n",
      "[timestep: 3] [epoch: 45751] loss: 0.0030954990\n",
      "[timestep: 3] [epoch: 45781] loss: 0.0030887704\n",
      "[timestep: 3] [epoch: 45811] loss: 0.0030694660\n",
      "[timestep: 3] [epoch: 45841] loss: 0.0031004727\n",
      "[timestep: 3] [epoch: 45871] loss: 0.0030599497\n",
      "[timestep: 3] [epoch: 45901] loss: 0.0030604294\n",
      "[timestep: 3] [epoch: 45931] loss: 0.0030631092\n",
      "[timestep: 3] [epoch: 45961] loss: 0.0030423380\n",
      "[timestep: 3] [epoch: 45991] loss: 0.0030531546\n",
      "[timestep: 3] [epoch: 46021] loss: 0.0030571925\n",
      "[timestep: 3] [epoch: 46051] loss: 0.0030844957\n",
      "[timestep: 3] [epoch: 46081] loss: 0.0031015386\n",
      "[timestep: 3] [epoch: 46111] loss: 0.0030540195\n",
      "[timestep: 3] [epoch: 46141] loss: 0.0030701309\n",
      "[timestep: 3] [epoch: 46171] loss: 0.0030521876\n",
      "[timestep: 3] [epoch: 46201] loss: 0.0030454104\n",
      "[timestep: 3] [epoch: 46231] loss: 0.0030385500\n",
      "[timestep: 3] [epoch: 46261] loss: 0.0030531231\n",
      "[timestep: 3] [epoch: 46291] loss: 0.0030571220\n",
      "[timestep: 3] [epoch: 46321] loss: 0.0030444807\n",
      "[timestep: 3] [epoch: 46351] loss: 0.0030493368\n",
      "[timestep: 3] [epoch: 46381] loss: 0.0030533290\n",
      "[timestep: 3] [epoch: 46411] loss: 0.0030925958\n",
      "[timestep: 3] [epoch: 46441] loss: 0.0030662443\n",
      "[timestep: 3] [epoch: 46471] loss: 0.0030641754\n",
      "[timestep: 3] [epoch: 46501] loss: 0.0030671088\n",
      "[timestep: 3] [epoch: 46531] loss: 0.0030656604\n",
      "[timestep: 3] [epoch: 46561] loss: 0.0030723710\n",
      "[timestep: 3] [epoch: 46591] loss: 0.0030416264\n",
      "[timestep: 3] [epoch: 46621] loss: 0.0030358122\n",
      "[timestep: 3] [epoch: 46651] loss: 0.0030517159\n",
      "[timestep: 3] [epoch: 46681] loss: 0.0030477212\n",
      "[timestep: 3] [epoch: 46711] loss: 0.0030871797\n",
      "[timestep: 3] [epoch: 46741] loss: 0.0030517990\n",
      "[timestep: 3] [epoch: 46771] loss: 0.0030587746\n",
      "[timestep: 3] [epoch: 46801] loss: 0.0030802449\n",
      "[timestep: 3] [epoch: 46831] loss: 0.0030653197\n",
      "[timestep: 3] [epoch: 46861] loss: 0.0030408269\n",
      "[timestep: 3] [epoch: 46891] loss: 0.0031280473\n",
      "[timestep: 3] [epoch: 46921] loss: 0.0030953807\n",
      "[timestep: 3] [epoch: 46951] loss: 0.0031327289\n",
      "[timestep: 3] [epoch: 46981] loss: 0.0030655239\n",
      "[timestep: 3] [epoch: 47011] loss: 0.0030682480\n",
      "[timestep: 3] [epoch: 47041] loss: 0.0030739952\n",
      "[timestep: 3] [epoch: 47071] loss: 0.0030473063\n",
      "[timestep: 3] [epoch: 47101] loss: 0.0030694627\n",
      "[timestep: 3] [epoch: 47131] loss: 0.0030481359\n",
      "[timestep: 3] [epoch: 47161] loss: 0.0030639060\n",
      "[timestep: 3] [epoch: 47191] loss: 0.0030512442\n",
      "[timestep: 3] [epoch: 47221] loss: 0.0030532375\n",
      "[timestep: 3] [epoch: 47251] loss: 0.0031122840\n",
      "[timestep: 3] [epoch: 47281] loss: 0.0030434071\n",
      "[timestep: 3] [epoch: 47311] loss: 0.0030421806\n",
      "[timestep: 3] [epoch: 47341] loss: 0.0030719340\n",
      "[timestep: 3] [epoch: 47371] loss: 0.0030624652\n",
      "[timestep: 3] [epoch: 47401] loss: 0.0030652850\n",
      "[timestep: 3] [epoch: 47431] loss: 0.0030734956\n",
      "[timestep: 3] [epoch: 47461] loss: 0.0030500046\n",
      "[timestep: 3] [epoch: 47491] loss: 0.0030526300\n",
      "[timestep: 3] [epoch: 47521] loss: 0.0030499450\n",
      "[timestep: 3] [epoch: 47551] loss: 0.0030745885\n",
      "[timestep: 3] [epoch: 47581] loss: 0.0030861406\n",
      "[timestep: 3] [epoch: 47611] loss: 0.0031195707\n",
      "[timestep: 3] [epoch: 47641] loss: 0.0030303502\n",
      "[timestep: 3] [epoch: 47671] loss: 0.0030620892\n",
      "[timestep: 3] [epoch: 47701] loss: 0.0031139392\n",
      "[timestep: 3] [epoch: 47731] loss: 0.0030536673\n",
      "[timestep: 3] [epoch: 47761] loss: 0.0030374255\n",
      "[timestep: 3] [epoch: 47791] loss: 0.0031151159\n",
      "[timestep: 3] [epoch: 47821] loss: 0.0030403365\n",
      "[timestep: 3] [epoch: 47851] loss: 0.0030372068\n",
      "[timestep: 3] [epoch: 47881] loss: 0.0030591942\n",
      "[timestep: 3] [epoch: 47911] loss: 0.0030445256\n",
      "[timestep: 3] [epoch: 47941] loss: 0.0030457384\n",
      "[timestep: 3] [epoch: 47971] loss: 0.0030340133\n",
      "[timestep: 3] [epoch: 48001] loss: 0.0030479378\n",
      "[timestep: 3] [epoch: 48031] loss: 0.0030397666\n",
      "[timestep: 3] [epoch: 48061] loss: 0.0030526761\n",
      "[timestep: 3] [epoch: 48091] loss: 0.0030449026\n",
      "[timestep: 3] [epoch: 48121] loss: 0.0030313330\n",
      "[timestep: 3] [epoch: 48151] loss: 0.0030495443\n",
      "[timestep: 3] [epoch: 48181] loss: 0.0030456705\n",
      "[timestep: 3] [epoch: 48211] loss: 0.0030491361\n",
      "[timestep: 3] [epoch: 48241] loss: 0.0030441782\n",
      "[timestep: 3] [epoch: 48271] loss: 0.0030694050\n",
      "[timestep: 3] [epoch: 48301] loss: 0.0030335875\n",
      "[timestep: 3] [epoch: 48331] loss: 0.0030525827\n",
      "[timestep: 3] [epoch: 48361] loss: 0.0030444250\n",
      "[timestep: 3] [epoch: 48391] loss: 0.0030746721\n",
      "[timestep: 3] [epoch: 48421] loss: 0.0030468244\n",
      "[timestep: 3] [epoch: 48451] loss: 0.0030912957\n",
      "[timestep: 3] [epoch: 48481] loss: 0.0030391179\n",
      "[timestep: 3] [epoch: 48511] loss: 0.0030700394\n",
      "[timestep: 3] [epoch: 48541] loss: 0.0030423761\n",
      "[timestep: 3] [epoch: 48571] loss: 0.0031263190\n",
      "[timestep: 3] [epoch: 48601] loss: 0.0030598268\n",
      "[timestep: 3] [epoch: 48631] loss: 0.0030897646\n",
      "[timestep: 3] [epoch: 48661] loss: 0.0030927840\n",
      "[timestep: 3] [epoch: 48691] loss: 0.0030694909\n",
      "[timestep: 3] [epoch: 48721] loss: 0.0030337516\n",
      "[timestep: 3] [epoch: 48751] loss: 0.0030398685\n",
      "[timestep: 3] [epoch: 48781] loss: 0.0030312780\n",
      "[timestep: 3] [epoch: 48811] loss: 0.0030392506\n",
      "[timestep: 3] [epoch: 48841] loss: 0.0030339570\n",
      "[timestep: 3] [epoch: 48871] loss: 0.0030582538\n",
      "[timestep: 3] [epoch: 48901] loss: 0.0030883655\n",
      "[timestep: 3] [epoch: 48931] loss: 0.0030603861\n",
      "[timestep: 3] [epoch: 48961] loss: 0.0030404765\n",
      "[timestep: 3] [epoch: 48991] loss: 0.0030491995\n",
      "[timestep: 3] [epoch: 49021] loss: 0.0030428097\n",
      "[timestep: 3] [epoch: 49051] loss: 0.0031111205\n",
      "[timestep: 3] [epoch: 49081] loss: 0.0030411750\n",
      "[timestep: 3] [epoch: 49111] loss: 0.0030393440\n",
      "[timestep: 3] [epoch: 49141] loss: 0.0030419233\n",
      "[timestep: 3] [epoch: 49171] loss: 0.0030550337\n",
      "[timestep: 3] [epoch: 49201] loss: 0.0030628811\n",
      "[timestep: 3] [epoch: 49231] loss: 0.0030457855\n",
      "[timestep: 3] [epoch: 49261] loss: 0.0030334296\n",
      "[timestep: 3] [epoch: 49291] loss: 0.0030392725\n",
      "[timestep: 3] [epoch: 49321] loss: 0.0030401933\n",
      "[timestep: 3] [epoch: 49351] loss: 0.0031023514\n",
      "[timestep: 3] [epoch: 49381] loss: 0.0030618536\n",
      "[timestep: 3] [epoch: 49411] loss: 0.0030615702\n",
      "[timestep: 3] [epoch: 49441] loss: 0.0030886428\n",
      "[timestep: 3] [epoch: 49471] loss: 0.0030933339\n",
      "[timestep: 3] [epoch: 49501] loss: 0.0030984085\n",
      "[timestep: 3] [epoch: 49531] loss: 0.0030445270\n",
      "[timestep: 3] [epoch: 49561] loss: 0.0030720346\n",
      "[timestep: 3] [epoch: 49591] loss: 0.0030449596\n",
      "[timestep: 3] [epoch: 49621] loss: 0.0030408809\n",
      "[timestep: 3] [epoch: 49651] loss: 0.0031120183\n",
      "[timestep: 3] [epoch: 49681] loss: 0.0030531695\n",
      "[timestep: 3] [epoch: 49711] loss: 0.0030652015\n",
      "[timestep: 3] [epoch: 49741] loss: 0.0030318904\n",
      "[timestep: 3] [epoch: 49771] loss: 0.0030383361\n",
      "[timestep: 3] [epoch: 49801] loss: 0.0030990504\n",
      "[timestep: 3] [epoch: 49831] loss: 0.0030686988\n",
      "[timestep: 3] [epoch: 49861] loss: 0.0030472425\n",
      "[timestep: 3] [epoch: 49891] loss: 0.0030405300\n",
      "[timestep: 3] [epoch: 49921] loss: 0.0030437424\n",
      "[timestep: 3] [epoch: 49951] loss: 0.0030285253\n",
      "[timestep: 3] [epoch: 49981] loss: 0.0030373342\n",
      "0.01\n",
      "[timestep: 4] [epoch: 1] loss: 0.8989127874\n",
      "[timestep: 4] [epoch: 31] loss: 0.0332482085\n",
      "[timestep: 4] [epoch: 61] loss: 0.0104822498\n",
      "[timestep: 4] [epoch: 91] loss: 0.0135929473\n",
      "[timestep: 4] [epoch: 121] loss: 0.0095023587\n",
      "[timestep: 4] [epoch: 151] loss: 0.0090776253\n",
      "[timestep: 4] [epoch: 181] loss: 0.0138052180\n",
      "[timestep: 4] [epoch: 211] loss: 0.0088192644\n",
      "[timestep: 4] [epoch: 241] loss: 0.0087569850\n",
      "[timestep: 4] [epoch: 271] loss: 0.0109980647\n",
      "[timestep: 4] [epoch: 301] loss: 0.0094238035\n",
      "[timestep: 4] [epoch: 331] loss: 0.0129439905\n",
      "[timestep: 4] [epoch: 361] loss: 0.0081507247\n",
      "[timestep: 4] [epoch: 391] loss: 0.0129875466\n",
      "[timestep: 4] [epoch: 421] loss: 0.0091755698\n",
      "[timestep: 4] [epoch: 451] loss: 0.0082618864\n",
      "[timestep: 4] [epoch: 481] loss: 0.0091159102\n",
      "[timestep: 4] [epoch: 511] loss: 0.0101329349\n",
      "[timestep: 4] [epoch: 541] loss: 0.0082177082\n",
      "[timestep: 4] [epoch: 571] loss: 0.0111676361\n",
      "[timestep: 4] [epoch: 601] loss: 0.0125821475\n",
      "[timestep: 4] [epoch: 631] loss: 0.0076858518\n",
      "[timestep: 4] [epoch: 661] loss: 0.0081227031\n",
      "[timestep: 4] [epoch: 691] loss: 0.0091147572\n",
      "[timestep: 4] [epoch: 721] loss: 0.0099075725\n",
      "[timestep: 4] [epoch: 751] loss: 0.0071409722\n",
      "[timestep: 4] [epoch: 781] loss: 0.0104041239\n",
      "[timestep: 4] [epoch: 811] loss: 0.0090960450\n",
      "[timestep: 4] [epoch: 841] loss: 0.0080961026\n",
      "[timestep: 4] [epoch: 871] loss: 0.0096705202\n",
      "[timestep: 4] [epoch: 901] loss: 0.0107039399\n",
      "[timestep: 4] [epoch: 931] loss: 0.0111115668\n",
      "[timestep: 4] [epoch: 961] loss: 0.0074840840\n",
      "[timestep: 4] [epoch: 991] loss: 0.0125487521\n",
      "[timestep: 4] [epoch: 1021] loss: 0.0201665945\n",
      "[timestep: 4] [epoch: 1051] loss: 0.0317488462\n",
      "[timestep: 4] [epoch: 1081] loss: 0.0159992054\n",
      "[timestep: 4] [epoch: 1111] loss: 0.0221707709\n",
      "[timestep: 4] [epoch: 1141] loss: 0.0126018282\n",
      "[timestep: 4] [epoch: 1171] loss: 0.0117776217\n",
      "[timestep: 4] [epoch: 1201] loss: 0.0155937066\n",
      "[timestep: 4] [epoch: 1231] loss: 0.0137775503\n",
      "[timestep: 4] [epoch: 1261] loss: 0.0119180772\n",
      "[timestep: 4] [epoch: 1291] loss: 0.0122425733\n",
      "[timestep: 4] [epoch: 1321] loss: 0.0076697939\n",
      "[timestep: 4] [epoch: 1351] loss: 0.0071386183\n",
      "[timestep: 4] [epoch: 1381] loss: 0.0110187624\n",
      "[timestep: 4] [epoch: 1411] loss: 0.0077217314\n",
      "[timestep: 4] [epoch: 1441] loss: 0.0076607438\n",
      "[timestep: 4] [epoch: 1471] loss: 0.0073625413\n",
      "[timestep: 4] [epoch: 1501] loss: 0.0077301194\n",
      "[timestep: 4] [epoch: 1531] loss: 0.0090438202\n",
      "[timestep: 4] [epoch: 1561] loss: 0.0082087927\n",
      "[timestep: 4] [epoch: 1591] loss: 0.0108606741\n",
      "[timestep: 4] [epoch: 1621] loss: 0.0076920353\n",
      "[timestep: 4] [epoch: 1651] loss: 0.0076036127\n",
      "[timestep: 4] [epoch: 1681] loss: 0.0082674865\n",
      "[timestep: 4] [epoch: 1711] loss: 0.0078896917\n",
      "[timestep: 4] [epoch: 1741] loss: 0.0079806326\n",
      "[timestep: 4] [epoch: 1771] loss: 0.0076492662\n",
      "[timestep: 4] [epoch: 1801] loss: 0.0107784038\n",
      "[timestep: 4] [epoch: 1831] loss: 0.0086064516\n",
      "[timestep: 4] [epoch: 1861] loss: 0.0074462723\n",
      "[timestep: 4] [epoch: 1891] loss: 0.0073479116\n",
      "[timestep: 4] [epoch: 1921] loss: 0.0084526446\n",
      "[timestep: 4] [epoch: 1951] loss: 0.0097010219\n",
      "[timestep: 4] [epoch: 1981] loss: 0.0091357296\n",
      "[timestep: 4] [epoch: 2011] loss: 0.0074832086\n",
      "[timestep: 4] [epoch: 2041] loss: 0.0102613168\n",
      "[timestep: 4] [epoch: 2071] loss: 0.0125814183\n",
      "[timestep: 4] [epoch: 2101] loss: 0.0092043141\n",
      "[timestep: 4] [epoch: 2131] loss: 0.0086282529\n",
      "[timestep: 4] [epoch: 2161] loss: 0.0087796403\n",
      "[timestep: 4] [epoch: 2191] loss: 0.0104066506\n",
      "[timestep: 4] [epoch: 2221] loss: 0.0074528907\n",
      "[timestep: 4] [epoch: 2251] loss: 0.0079817194\n",
      "[timestep: 4] [epoch: 2281] loss: 0.0071518118\n",
      "[timestep: 4] [epoch: 2311] loss: 0.0085247522\n",
      "[timestep: 4] [epoch: 2341] loss: 0.0105604595\n",
      "[timestep: 4] [epoch: 2371] loss: 0.0093207043\n",
      "[timestep: 4] [epoch: 2401] loss: 0.0125487857\n",
      "[timestep: 4] [epoch: 2431] loss: 0.0095732855\n",
      "[timestep: 4] [epoch: 2461] loss: 0.0071381698\n",
      "[timestep: 4] [epoch: 2491] loss: 0.0112733198\n",
      "[timestep: 4] [epoch: 2521] loss: 0.0071932822\n",
      "[timestep: 4] [epoch: 2551] loss: 0.0086422786\n",
      "[timestep: 4] [epoch: 2581] loss: 0.0088898335\n",
      "[timestep: 4] [epoch: 2611] loss: 0.0080587268\n",
      "[timestep: 4] [epoch: 2641] loss: 0.0073814341\n",
      "[timestep: 4] [epoch: 2671] loss: 0.0089315921\n",
      "[timestep: 4] [epoch: 2701] loss: 0.0083288075\n",
      "[timestep: 4] [epoch: 2731] loss: 0.0077711139\n",
      "[timestep: 4] [epoch: 2761] loss: 0.0113011319\n",
      "[timestep: 4] [epoch: 2791] loss: 0.0082357964\n",
      "[timestep: 4] [epoch: 2821] loss: 0.0098834895\n",
      "[timestep: 4] [epoch: 2851] loss: 0.0109036174\n",
      "[timestep: 4] [epoch: 2881] loss: 0.0074357558\n",
      "[timestep: 4] [epoch: 2911] loss: 0.0076670428\n",
      "[timestep: 4] [epoch: 2941] loss: 0.0105337240\n",
      "[timestep: 4] [epoch: 2971] loss: 0.0074249026\n",
      "[timestep: 4] [epoch: 3001] loss: 0.0086424937\n",
      "[timestep: 4] [epoch: 3031] loss: 0.0074507948\n",
      "[timestep: 4] [epoch: 3061] loss: 0.0084897466\n",
      "[timestep: 4] [epoch: 3091] loss: 0.0087631308\n",
      "[timestep: 4] [epoch: 3121] loss: 0.0081497924\n",
      "[timestep: 4] [epoch: 3151] loss: 0.0103210751\n",
      "[timestep: 4] [epoch: 3181] loss: 0.0076588928\n",
      "[timestep: 4] [epoch: 3211] loss: 0.0073280432\n",
      "[timestep: 4] [epoch: 3241] loss: 0.0078710243\n",
      "[timestep: 4] [epoch: 3271] loss: 0.0080478331\n",
      "[timestep: 4] [epoch: 3301] loss: 0.0083340788\n",
      "[timestep: 4] [epoch: 3331] loss: 0.0109979678\n",
      "[timestep: 4] [epoch: 3361] loss: 0.0133961774\n",
      "[timestep: 4] [epoch: 3391] loss: 0.0140209030\n",
      "[timestep: 4] [epoch: 3421] loss: 0.0080381650\n",
      "[timestep: 4] [epoch: 3451] loss: 0.0071136379\n",
      "[timestep: 4] [epoch: 3481] loss: 0.0081492634\n",
      "[timestep: 4] [epoch: 3511] loss: 0.0075193513\n",
      "[timestep: 4] [epoch: 3541] loss: 0.0143491831\n",
      "[timestep: 4] [epoch: 3571] loss: 0.0089463685\n",
      "[timestep: 4] [epoch: 3601] loss: 0.0085521145\n",
      "[timestep: 4] [epoch: 3631] loss: 0.0071618133\n",
      "[timestep: 4] [epoch: 3661] loss: 0.0071174535\n",
      "[timestep: 4] [epoch: 3691] loss: 0.0150072807\n",
      "[timestep: 4] [epoch: 3721] loss: 0.0078376047\n",
      "[timestep: 4] [epoch: 3751] loss: 0.0086503439\n",
      "[timestep: 4] [epoch: 3781] loss: 0.0075304173\n",
      "[timestep: 4] [epoch: 3811] loss: 0.0074299257\n",
      "[timestep: 4] [epoch: 3841] loss: 0.0077214614\n",
      "[timestep: 4] [epoch: 3871] loss: 0.0097779576\n",
      "[timestep: 4] [epoch: 3901] loss: 0.0079856329\n",
      "[timestep: 4] [epoch: 3931] loss: 0.0084607657\n",
      "[timestep: 4] [epoch: 3961] loss: 0.0073886313\n",
      "[timestep: 4] [epoch: 3991] loss: 0.0093899192\n",
      "[timestep: 4] [epoch: 4021] loss: 0.0086700907\n",
      "[timestep: 4] [epoch: 4051] loss: 0.0287603848\n",
      "[timestep: 4] [epoch: 4081] loss: 0.0192211308\n",
      "[timestep: 4] [epoch: 4111] loss: 0.0108057549\n",
      "[timestep: 4] [epoch: 4141] loss: 0.0077646868\n",
      "[timestep: 4] [epoch: 4171] loss: 0.0071029477\n",
      "[timestep: 4] [epoch: 4201] loss: 0.0071806554\n",
      "[timestep: 4] [epoch: 4231] loss: 0.0072480696\n",
      "[timestep: 4] [epoch: 4261] loss: 0.0073541305\n",
      "[timestep: 4] [epoch: 4291] loss: 0.0076660090\n",
      "[timestep: 4] [epoch: 4321] loss: 0.0074908002\n",
      "[timestep: 4] [epoch: 4351] loss: 0.0070945607\n",
      "[timestep: 4] [epoch: 4381] loss: 0.0098268213\n",
      "[timestep: 4] [epoch: 4411] loss: 0.0078374436\n",
      "[timestep: 4] [epoch: 4441] loss: 0.0073015145\n",
      "[timestep: 4] [epoch: 4471] loss: 0.0072739720\n",
      "[timestep: 4] [epoch: 4501] loss: 0.0073885545\n",
      "[timestep: 4] [epoch: 4531] loss: 0.0096165109\n",
      "[timestep: 4] [epoch: 4561] loss: 0.0090937819\n",
      "[timestep: 4] [epoch: 4591] loss: 0.0084398026\n",
      "[timestep: 4] [epoch: 4621] loss: 0.0088431397\n",
      "[timestep: 4] [epoch: 4651] loss: 0.0093692522\n",
      "[timestep: 4] [epoch: 4681] loss: 0.0087243039\n",
      "[timestep: 4] [epoch: 4711] loss: 0.0093687437\n",
      "[timestep: 4] [epoch: 4741] loss: 0.0131089389\n",
      "[timestep: 4] [epoch: 4771] loss: 0.0132513940\n",
      "[timestep: 4] [epoch: 4801] loss: 0.0076717022\n",
      "[timestep: 4] [epoch: 4831] loss: 0.0070722578\n",
      "[timestep: 4] [epoch: 4861] loss: 0.0070328498\n",
      "[timestep: 4] [epoch: 4891] loss: 0.0074068578\n",
      "[timestep: 4] [epoch: 4921] loss: 0.0074740569\n",
      "[timestep: 4] [epoch: 4951] loss: 0.0107979244\n",
      "[timestep: 4] [epoch: 4981] loss: 0.0075183176\n",
      "[timestep: 4] [epoch: 5011] loss: 0.0123363407\n",
      "[timestep: 4] [epoch: 5041] loss: 0.0073134792\n",
      "[timestep: 4] [epoch: 5071] loss: 0.0071168337\n",
      "[timestep: 4] [epoch: 5101] loss: 0.0083068721\n",
      "[timestep: 4] [epoch: 5131] loss: 0.0073619601\n",
      "[timestep: 4] [epoch: 5161] loss: 0.0071537690\n",
      "[timestep: 4] [epoch: 5191] loss: 0.0103164557\n",
      "[timestep: 4] [epoch: 5221] loss: 0.0083490489\n",
      "[timestep: 4] [epoch: 5251] loss: 0.0071638878\n",
      "[timestep: 4] [epoch: 5281] loss: 0.0073451470\n",
      "[timestep: 4] [epoch: 5311] loss: 0.0073347855\n",
      "[timestep: 4] [epoch: 5341] loss: 0.0094505455\n",
      "[timestep: 4] [epoch: 5371] loss: 0.0196622051\n",
      "[timestep: 4] [epoch: 5401] loss: 0.0074834921\n",
      "[timestep: 4] [epoch: 5431] loss: 0.0083841821\n",
      "[timestep: 4] [epoch: 5461] loss: 0.0072490228\n",
      "[timestep: 4] [epoch: 5491] loss: 0.0072853207\n",
      "[timestep: 4] [epoch: 5521] loss: 0.0074335961\n",
      "[timestep: 4] [epoch: 5551] loss: 0.0089051966\n",
      "[timestep: 4] [epoch: 5581] loss: 0.0073843375\n",
      "[timestep: 4] [epoch: 5611] loss: 0.0101455813\n",
      "[timestep: 4] [epoch: 5641] loss: 0.0078106509\n",
      "[timestep: 4] [epoch: 5671] loss: 0.0186097901\n",
      "[timestep: 4] [epoch: 5701] loss: 0.0125244129\n",
      "[timestep: 4] [epoch: 5731] loss: 0.0079587046\n",
      "[timestep: 4] [epoch: 5761] loss: 0.0072345180\n",
      "[timestep: 4] [epoch: 5791] loss: 0.0070795985\n",
      "[timestep: 4] [epoch: 5821] loss: 0.0071748579\n",
      "[timestep: 4] [epoch: 5851] loss: 0.0089449752\n",
      "[timestep: 4] [epoch: 5881] loss: 0.0076465253\n",
      "[timestep: 4] [epoch: 5911] loss: 0.0071902610\n",
      "[timestep: 4] [epoch: 5941] loss: 0.0076696193\n",
      "[timestep: 4] [epoch: 5971] loss: 0.0072890529\n",
      "[timestep: 4] [epoch: 6001] loss: 0.0101256976\n",
      "[timestep: 4] [epoch: 6031] loss: 0.0105052516\n",
      "[timestep: 4] [epoch: 6061] loss: 0.0078405011\n",
      "[timestep: 4] [epoch: 6091] loss: 0.0073783295\n",
      "[timestep: 4] [epoch: 6121] loss: 0.0082171988\n",
      "[timestep: 4] [epoch: 6151] loss: 0.0076303575\n",
      "[timestep: 4] [epoch: 6181] loss: 0.0109534627\n",
      "[timestep: 4] [epoch: 6211] loss: 0.0085701458\n",
      "[timestep: 4] [epoch: 6241] loss: 0.0079015084\n",
      "[timestep: 4] [epoch: 6271] loss: 0.0081214327\n",
      "[timestep: 4] [epoch: 6301] loss: 0.0075436793\n",
      "[timestep: 4] [epoch: 6331] loss: 0.0146792959\n",
      "[timestep: 4] [epoch: 6361] loss: 0.0074834968\n",
      "[timestep: 4] [epoch: 6391] loss: 0.0080596544\n",
      "[timestep: 4] [epoch: 6421] loss: 0.0073721334\n",
      "[timestep: 4] [epoch: 6451] loss: 0.0074573820\n",
      "[timestep: 4] [epoch: 6481] loss: 0.0096429233\n",
      "[timestep: 4] [epoch: 6511] loss: 0.0101181474\n",
      "[timestep: 4] [epoch: 6541] loss: 0.0075121541\n",
      "[timestep: 4] [epoch: 6571] loss: 0.0070932182\n",
      "[timestep: 4] [epoch: 6601] loss: 0.0071428348\n",
      "[timestep: 4] [epoch: 6631] loss: 0.0081226137\n",
      "[timestep: 4] [epoch: 6661] loss: 0.0077567729\n",
      "[timestep: 4] [epoch: 6691] loss: 0.0090802386\n",
      "[timestep: 4] [epoch: 6721] loss: 0.0086111426\n",
      "[timestep: 4] [epoch: 6751] loss: 0.0077170664\n",
      "[timestep: 4] [epoch: 6781] loss: 0.0074077654\n",
      "[timestep: 4] [epoch: 6811] loss: 0.0075634471\n",
      "[timestep: 4] [epoch: 6841] loss: 0.0072411597\n",
      "[timestep: 4] [epoch: 6871] loss: 0.0122265164\n",
      "[timestep: 4] [epoch: 6901] loss: 0.0097812451\n",
      "[timestep: 4] [epoch: 6931] loss: 0.0082278838\n",
      "[timestep: 4] [epoch: 6961] loss: 0.0080975480\n",
      "[timestep: 4] [epoch: 6991] loss: 0.0091973161\n",
      "[timestep: 4] [epoch: 7021] loss: 0.0071776430\n",
      "[timestep: 4] [epoch: 7051] loss: 0.0072962027\n",
      "[timestep: 4] [epoch: 7081] loss: 0.0072569321\n",
      "[timestep: 4] [epoch: 7111] loss: 0.0074618906\n",
      "[timestep: 4] [epoch: 7141] loss: 0.0072323764\n",
      "[timestep: 4] [epoch: 7171] loss: 0.0076695946\n",
      "[timestep: 4] [epoch: 7201] loss: 0.0251910724\n",
      "[timestep: 4] [epoch: 7231] loss: 0.0181846134\n",
      "[timestep: 4] [epoch: 7261] loss: 0.0119835865\n",
      "[timestep: 4] [epoch: 7291] loss: 0.0079153366\n",
      "[timestep: 4] [epoch: 7321] loss: 0.0070699807\n",
      "[timestep: 4] [epoch: 7351] loss: 0.0070735253\n",
      "[timestep: 4] [epoch: 7381] loss: 0.0070656422\n",
      "[timestep: 4] [epoch: 7411] loss: 0.0070508653\n",
      "[timestep: 4] [epoch: 7441] loss: 0.0074602515\n",
      "[timestep: 4] [epoch: 7471] loss: 0.0070688636\n",
      "[timestep: 4] [epoch: 7501] loss: 0.0070477873\n",
      "[timestep: 4] [epoch: 7531] loss: 0.0075499155\n",
      "[timestep: 4] [epoch: 7561] loss: 0.0071387640\n",
      "[timestep: 4] [epoch: 7591] loss: 0.0081112282\n",
      "[timestep: 4] [epoch: 7621] loss: 0.0076985974\n",
      "[timestep: 4] [epoch: 7651] loss: 0.0078338170\n",
      "[timestep: 4] [epoch: 7681] loss: 0.0071224347\n",
      "[timestep: 4] [epoch: 7711] loss: 0.0080787428\n",
      "[timestep: 4] [epoch: 7741] loss: 0.0074248551\n",
      "[timestep: 4] [epoch: 7771] loss: 0.0081827845\n",
      "[timestep: 4] [epoch: 7801] loss: 0.0080758855\n",
      "[timestep: 4] [epoch: 7831] loss: 0.0081980769\n",
      "[timestep: 4] [epoch: 7861] loss: 0.0081226546\n",
      "[timestep: 4] [epoch: 7891] loss: 0.0075540133\n",
      "[timestep: 4] [epoch: 7921] loss: 0.0077128187\n",
      "[timestep: 4] [epoch: 7951] loss: 0.0071954369\n",
      "[timestep: 4] [epoch: 7981] loss: 0.0072059883\n",
      "[timestep: 4] [epoch: 8011] loss: 0.0074480241\n",
      "[timestep: 4] [epoch: 8041] loss: 0.0080287643\n",
      "[timestep: 4] [epoch: 8071] loss: 0.0073091690\n",
      "[timestep: 4] [epoch: 8101] loss: 0.0080648959\n",
      "[timestep: 4] [epoch: 8131] loss: 0.0078422660\n",
      "[timestep: 4] [epoch: 8161] loss: 0.0072290227\n",
      "[timestep: 4] [epoch: 8191] loss: 0.0154304644\n",
      "[timestep: 4] [epoch: 8221] loss: 0.0081284950\n",
      "[timestep: 4] [epoch: 8251] loss: 0.0077421647\n",
      "[timestep: 4] [epoch: 8281] loss: 0.0070745097\n",
      "[timestep: 4] [epoch: 8311] loss: 0.0072169257\n",
      "[timestep: 4] [epoch: 8341] loss: 0.0071369577\n",
      "[timestep: 4] [epoch: 8371] loss: 0.0076392493\n",
      "[timestep: 4] [epoch: 8401] loss: 0.0080836201\n",
      "[timestep: 4] [epoch: 8431] loss: 0.0075514917\n",
      "[timestep: 4] [epoch: 8461] loss: 0.0070448406\n",
      "[timestep: 4] [epoch: 8491] loss: 0.0073378505\n",
      "[timestep: 4] [epoch: 8521] loss: 0.0072264676\n",
      "[timestep: 4] [epoch: 8551] loss: 0.0071984744\n",
      "[timestep: 4] [epoch: 8581] loss: 0.0082052760\n",
      "[timestep: 4] [epoch: 8611] loss: 0.0072796224\n",
      "[timestep: 4] [epoch: 8641] loss: 0.0073525268\n",
      "[timestep: 4] [epoch: 8671] loss: 0.0083537735\n",
      "[timestep: 4] [epoch: 8701] loss: 0.0077418541\n",
      "[timestep: 4] [epoch: 8731] loss: 0.0092475787\n",
      "[timestep: 4] [epoch: 8761] loss: 0.0150467465\n",
      "[timestep: 4] [epoch: 8791] loss: 0.0154091073\n",
      "[timestep: 4] [epoch: 8821] loss: 0.0074268747\n",
      "[timestep: 4] [epoch: 8851] loss: 0.0070945569\n",
      "[timestep: 4] [epoch: 8881] loss: 0.0071016313\n",
      "[timestep: 4] [epoch: 8911] loss: 0.0071969032\n",
      "[timestep: 4] [epoch: 8941] loss: 0.0070596901\n",
      "[timestep: 4] [epoch: 8971] loss: 0.0070527121\n",
      "[timestep: 4] [epoch: 9001] loss: 0.0071401745\n",
      "[timestep: 4] [epoch: 9031] loss: 0.0074763172\n",
      "[timestep: 4] [epoch: 9061] loss: 0.0072419066\n",
      "[timestep: 4] [epoch: 9091] loss: 0.0071246689\n",
      "[timestep: 4] [epoch: 9121] loss: 0.0036216676\n",
      "[timestep: 4] [epoch: 9151] loss: 0.0035274036\n",
      "0.01\n",
      "[timestep: 5] [epoch: 1] loss: 0.8821480274\n",
      "[timestep: 5] [epoch: 31] loss: 0.0222399421\n",
      "[timestep: 5] [epoch: 61] loss: 0.0020756614\n",
      "0.01\n",
      "[timestep: 6] [epoch: 1] loss: 0.8843950629\n",
      "[timestep: 6] [epoch: 31] loss: 0.0260846112\n",
      "[timestep: 6] [epoch: 61] loss: 0.0027411960\n",
      "0.01\n",
      "[timestep: 7] [epoch: 1] loss: 0.8870840073\n",
      "[timestep: 7] [epoch: 31] loss: 0.0266849864\n",
      "[timestep: 7] [epoch: 61] loss: 0.0025543210\n",
      "[timestep: 7] [epoch: 91] loss: 0.0092043392\n",
      "[timestep: 7] [epoch: 121] loss: 0.0008506390\n",
      "0.01\n",
      "[timestep: 8] [epoch: 1] loss: 0.8716939688\n",
      "[timestep: 8] [epoch: 31] loss: 0.0380615592\n",
      "[timestep: 8] [epoch: 61] loss: 0.0103201866\n",
      "[timestep: 8] [epoch: 91] loss: 0.0052931579\n",
      "[timestep: 8] [epoch: 121] loss: 0.0054191500\n",
      "[timestep: 8] [epoch: 151] loss: 0.0034027048\n",
      "[timestep: 8] [epoch: 181] loss: 0.0110639716\n",
      "[timestep: 8] [epoch: 211] loss: 0.0086305300\n",
      "[timestep: 8] [epoch: 241] loss: 0.0040405546\n",
      "[timestep: 8] [epoch: 271] loss: 0.0143795069\n",
      "[timestep: 8] [epoch: 301] loss: 0.0087586865\n",
      "[timestep: 8] [epoch: 331] loss: 0.0034826337\n",
      "[timestep: 8] [epoch: 361] loss: 0.0106954109\n",
      "[timestep: 8] [epoch: 391] loss: 0.0041564624\n",
      "[timestep: 8] [epoch: 421] loss: 0.0042187683\n",
      "[timestep: 8] [epoch: 451] loss: 0.0055345828\n",
      "[timestep: 8] [epoch: 481] loss: 0.0032272157\n",
      "[timestep: 8] [epoch: 511] loss: 0.0100730602\n",
      "[timestep: 8] [epoch: 541] loss: 0.0031354118\n",
      "[timestep: 8] [epoch: 571] loss: 0.0029719574\n",
      "[timestep: 8] [epoch: 601] loss: 0.0034029591\n",
      "[timestep: 8] [epoch: 631] loss: 0.0071207304\n",
      "[timestep: 8] [epoch: 661] loss: 0.0078942198\n",
      "[timestep: 8] [epoch: 691] loss: 0.0132680107\n",
      "[timestep: 8] [epoch: 721] loss: 0.0045092506\n",
      "[timestep: 8] [epoch: 751] loss: 0.0141339405\n",
      "[timestep: 8] [epoch: 781] loss: 0.0081666466\n",
      "[timestep: 8] [epoch: 811] loss: 0.0049534142\n",
      "[timestep: 8] [epoch: 841] loss: 0.0075633554\n",
      "[timestep: 8] [epoch: 871] loss: 0.0031775211\n",
      "[timestep: 8] [epoch: 901] loss: 0.0106210001\n",
      "[timestep: 8] [epoch: 931] loss: 0.0043887543\n",
      "[timestep: 8] [epoch: 961] loss: 0.0243821926\n",
      "[timestep: 8] [epoch: 991] loss: 0.0043712184\n",
      "[timestep: 8] [epoch: 1021] loss: 0.0037717773\n",
      "[timestep: 8] [epoch: 1051] loss: 0.0092096012\n",
      "[timestep: 8] [epoch: 1081] loss: 0.0046993978\n",
      "[timestep: 8] [epoch: 1111] loss: 0.0065835835\n",
      "[timestep: 8] [epoch: 1141] loss: 0.0038934471\n",
      "[timestep: 8] [epoch: 1171] loss: 0.0042198626\n",
      "[timestep: 8] [epoch: 1201] loss: 0.0097250650\n",
      "[timestep: 8] [epoch: 1231] loss: 0.0032668912\n",
      "[timestep: 8] [epoch: 1261] loss: 0.0107770748\n",
      "[timestep: 8] [epoch: 1291] loss: 0.0039723627\n",
      "[timestep: 8] [epoch: 1321] loss: 0.0064753932\n",
      "[timestep: 8] [epoch: 1351] loss: 0.0071990630\n",
      "[timestep: 8] [epoch: 1381] loss: 0.0036843792\n",
      "[timestep: 8] [epoch: 1411] loss: 0.0037616459\n",
      "[timestep: 8] [epoch: 1441] loss: 0.0077848206\n",
      "[timestep: 8] [epoch: 1471] loss: 0.0051860767\n",
      "[timestep: 8] [epoch: 1501] loss: 0.0048347265\n",
      "[timestep: 8] [epoch: 1531] loss: 0.0034313668\n",
      "[timestep: 8] [epoch: 1561] loss: 0.0155236367\n",
      "[timestep: 8] [epoch: 1591] loss: 0.0083364844\n",
      "[timestep: 8] [epoch: 1621] loss: 0.0044094753\n",
      "[timestep: 8] [epoch: 1651] loss: 0.0063105002\n",
      "[timestep: 8] [epoch: 1681] loss: 0.0038955624\n",
      "[timestep: 8] [epoch: 1711] loss: 0.0042198547\n",
      "[timestep: 8] [epoch: 1741] loss: 0.0041387351\n",
      "[timestep: 8] [epoch: 1771] loss: 0.0030445266\n",
      "[timestep: 8] [epoch: 1801] loss: 0.0077709048\n",
      "[timestep: 8] [epoch: 1831] loss: 0.0099218450\n",
      "[timestep: 8] [epoch: 1861] loss: 0.0141161149\n",
      "[timestep: 8] [epoch: 1891] loss: 0.0073153879\n",
      "[timestep: 8] [epoch: 1921] loss: 0.0038272736\n",
      "[timestep: 8] [epoch: 1951] loss: 0.0027385110\n",
      "[timestep: 8] [epoch: 1981] loss: 0.0034092451\n",
      "[timestep: 8] [epoch: 2011] loss: 0.0043170601\n",
      "[timestep: 8] [epoch: 2041] loss: 0.0047854586\n",
      "[timestep: 8] [epoch: 2071] loss: 0.0041090855\n",
      "[timestep: 8] [epoch: 2101] loss: 0.0028593885\n",
      "[timestep: 8] [epoch: 2131] loss: 0.0031985447\n",
      "[timestep: 8] [epoch: 2161] loss: 0.0223251674\n",
      "[timestep: 8] [epoch: 2191] loss: 0.0050093923\n",
      "[timestep: 8] [epoch: 2221] loss: 0.0029885450\n",
      "[timestep: 8] [epoch: 2251] loss: 0.0028799938\n",
      "[timestep: 8] [epoch: 2281] loss: 0.0034100674\n",
      "[timestep: 8] [epoch: 2311] loss: 0.0063838772\n",
      "[timestep: 8] [epoch: 2341] loss: 0.0108309137\n",
      "[timestep: 8] [epoch: 2371] loss: 0.0039554411\n",
      "[timestep: 8] [epoch: 2401] loss: 0.0026396846\n",
      "[timestep: 8] [epoch: 2431] loss: 0.0026114353\n",
      "[timestep: 8] [epoch: 2461] loss: 0.0033640247\n",
      "[timestep: 8] [epoch: 2491] loss: 0.0113371136\n",
      "[timestep: 8] [epoch: 2521] loss: 0.0089240465\n",
      "[timestep: 8] [epoch: 2551] loss: 0.0034180242\n",
      "[timestep: 8] [epoch: 2581] loss: 0.0038110605\n",
      "[timestep: 8] [epoch: 2611] loss: 0.0034994767\n",
      "[timestep: 8] [epoch: 2641] loss: 0.0033339714\n",
      "[timestep: 8] [epoch: 2671] loss: 0.0057691867\n",
      "[timestep: 8] [epoch: 2701] loss: 0.0027863239\n",
      "[timestep: 8] [epoch: 2731] loss: 0.0060533220\n",
      "[timestep: 8] [epoch: 2761] loss: 0.0072557926\n",
      "[timestep: 8] [epoch: 2791] loss: 0.0032401904\n",
      "[timestep: 8] [epoch: 2821] loss: 0.0081051979\n",
      "[timestep: 8] [epoch: 2851] loss: 0.0030513611\n",
      "[timestep: 8] [epoch: 2881] loss: 0.0045578424\n",
      "[timestep: 8] [epoch: 2911] loss: 0.0032617990\n",
      "[timestep: 8] [epoch: 2941] loss: 0.0033153750\n",
      "[timestep: 8] [epoch: 2971] loss: 0.0060568433\n",
      "[timestep: 8] [epoch: 3001] loss: 0.0028601694\n",
      "[timestep: 8] [epoch: 3031] loss: 0.0032789081\n",
      "[timestep: 8] [epoch: 3061] loss: 0.0037880931\n",
      "[timestep: 8] [epoch: 3091] loss: 0.0066848574\n",
      "[timestep: 8] [epoch: 3121] loss: 0.0042207800\n",
      "[timestep: 8] [epoch: 3151] loss: 0.0051127626\n",
      "[timestep: 8] [epoch: 3181] loss: 0.0027327633\n",
      "[timestep: 8] [epoch: 3211] loss: 0.0045576310\n",
      "[timestep: 8] [epoch: 3241] loss: 0.0057741781\n",
      "[timestep: 8] [epoch: 3271] loss: 0.0039470065\n",
      "[timestep: 8] [epoch: 3301] loss: 0.0027715596\n",
      "[timestep: 8] [epoch: 3331] loss: 0.0057746340\n",
      "[timestep: 8] [epoch: 3361] loss: 0.0062836800\n",
      "[timestep: 8] [epoch: 3391] loss: 0.0031820876\n",
      "[timestep: 8] [epoch: 3421] loss: 0.0035348525\n",
      "[timestep: 8] [epoch: 3451] loss: 0.0035335019\n",
      "[timestep: 8] [epoch: 3481] loss: 0.0035351408\n",
      "[timestep: 8] [epoch: 3511] loss: 0.0036313578\n",
      "[timestep: 8] [epoch: 3541] loss: 0.0028215647\n",
      "[timestep: 8] [epoch: 3571] loss: 0.0031009139\n",
      "[timestep: 8] [epoch: 3601] loss: 0.0097694956\n",
      "[timestep: 8] [epoch: 3631] loss: 0.0079482449\n",
      "[timestep: 8] [epoch: 3661] loss: 0.0029056272\n",
      "[timestep: 8] [epoch: 3691] loss: 0.0032612260\n",
      "[timestep: 8] [epoch: 3721] loss: 0.0061913054\n",
      "[timestep: 8] [epoch: 3751] loss: 0.0054105720\n",
      "[timestep: 8] [epoch: 3781] loss: 0.0028698384\n",
      "[timestep: 8] [epoch: 3811] loss: 0.0030259844\n",
      "[timestep: 8] [epoch: 3841] loss: 0.0034230300\n",
      "[timestep: 8] [epoch: 3871] loss: 0.0031128130\n",
      "[timestep: 8] [epoch: 3901] loss: 0.0035745883\n",
      "[timestep: 8] [epoch: 3931] loss: 0.0054727923\n",
      "[timestep: 8] [epoch: 3961] loss: 0.0025439246\n",
      "[timestep: 8] [epoch: 3991] loss: 0.0033475284\n",
      "[timestep: 8] [epoch: 4021] loss: 0.0034583805\n",
      "[timestep: 8] [epoch: 4051] loss: 0.0063344436\n",
      "[timestep: 8] [epoch: 4081] loss: 0.0027210270\n",
      "[timestep: 8] [epoch: 4111] loss: 0.0025185179\n",
      "[timestep: 8] [epoch: 4141] loss: 0.0025058917\n",
      "[timestep: 8] [epoch: 4171] loss: 0.0029353667\n",
      "[timestep: 8] [epoch: 4201] loss: 0.0040079905\n",
      "[timestep: 8] [epoch: 4231] loss: 0.0025740359\n",
      "[timestep: 8] [epoch: 4261] loss: 0.0037443608\n",
      "[timestep: 8] [epoch: 4291] loss: 0.0026313069\n",
      "[timestep: 8] [epoch: 4321] loss: 0.0101376427\n",
      "[timestep: 8] [epoch: 4351] loss: 0.0044341851\n",
      "[timestep: 8] [epoch: 4381] loss: 0.0121208252\n",
      "[timestep: 8] [epoch: 4411] loss: 0.0153420325\n",
      "[timestep: 8] [epoch: 4441] loss: 0.0041049188\n",
      "[timestep: 8] [epoch: 4471] loss: 0.0118802395\n",
      "[timestep: 8] [epoch: 4501] loss: 0.0046877395\n",
      "[timestep: 8] [epoch: 4531] loss: 0.0030432893\n",
      "[timestep: 8] [epoch: 4561] loss: 0.0025111702\n",
      "[timestep: 8] [epoch: 4591] loss: 0.0024558848\n",
      "[timestep: 8] [epoch: 4621] loss: 0.0043754489\n",
      "[timestep: 8] [epoch: 4651] loss: 0.0028427718\n",
      "[timestep: 8] [epoch: 4681] loss: 0.0080356272\n",
      "[timestep: 8] [epoch: 4711] loss: 0.0055773323\n",
      "[timestep: 8] [epoch: 4741] loss: 0.0028351680\n",
      "[timestep: 8] [epoch: 4771] loss: 0.0028556469\n",
      "[timestep: 8] [epoch: 4801] loss: 0.0038582138\n",
      "[timestep: 8] [epoch: 4831] loss: 0.0032596979\n",
      "[timestep: 8] [epoch: 4861] loss: 0.0028412491\n",
      "[timestep: 8] [epoch: 4891] loss: 0.0025372636\n",
      "[timestep: 8] [epoch: 4921] loss: 0.0030861374\n",
      "[timestep: 8] [epoch: 4951] loss: 0.0029062396\n",
      "[timestep: 8] [epoch: 4981] loss: 0.0026244367\n",
      "[timestep: 8] [epoch: 5011] loss: 0.0026633842\n",
      "[timestep: 8] [epoch: 5041] loss: 0.0035650476\n",
      "[timestep: 8] [epoch: 5071] loss: 0.0039805723\n",
      "[timestep: 8] [epoch: 5101] loss: 0.0032480960\n",
      "[timestep: 8] [epoch: 5131] loss: 0.0033356627\n",
      "[timestep: 8] [epoch: 5161] loss: 0.0032787682\n",
      "[timestep: 8] [epoch: 5191] loss: 0.0343874246\n",
      "[timestep: 8] [epoch: 5221] loss: 0.0034975489\n",
      "[timestep: 8] [epoch: 5251] loss: 0.0024744901\n",
      "[timestep: 8] [epoch: 5281] loss: 0.0027305400\n",
      "[timestep: 8] [epoch: 5311] loss: 0.0025303015\n",
      "[timestep: 8] [epoch: 5341] loss: 0.0024481120\n",
      "[timestep: 8] [epoch: 5371] loss: 0.0025985921\n",
      "[timestep: 8] [epoch: 5401] loss: 0.0025386992\n",
      "[timestep: 8] [epoch: 5431] loss: 0.0025198627\n",
      "[timestep: 8] [epoch: 5461] loss: 0.0052449550\n",
      "[timestep: 8] [epoch: 5491] loss: 0.0043995227\n",
      "[timestep: 8] [epoch: 5521] loss: 0.0038682611\n",
      "[timestep: 8] [epoch: 5551] loss: 0.0033271695\n",
      "[timestep: 8] [epoch: 5581] loss: 0.0031923822\n",
      "[timestep: 8] [epoch: 5611] loss: 0.0035176419\n",
      "[timestep: 8] [epoch: 5641] loss: 0.0060466602\n",
      "[timestep: 8] [epoch: 5671] loss: 0.0026408848\n",
      "[timestep: 8] [epoch: 5701] loss: 0.0028088340\n",
      "[timestep: 8] [epoch: 5731] loss: 0.0030445431\n",
      "[timestep: 8] [epoch: 5761] loss: 0.0030451631\n",
      "[timestep: 8] [epoch: 5791] loss: 0.0045474665\n",
      "[timestep: 8] [epoch: 5821] loss: 0.0027978728\n",
      "[timestep: 8] [epoch: 5851] loss: 0.0034760900\n",
      "[timestep: 8] [epoch: 5881] loss: 0.0036164657\n",
      "[timestep: 8] [epoch: 5911] loss: 0.0052846773\n",
      "[timestep: 8] [epoch: 5941] loss: 0.0025026759\n",
      "[timestep: 8] [epoch: 5971] loss: 0.0026363004\n",
      "[timestep: 8] [epoch: 6001] loss: 0.0026188008\n",
      "[timestep: 8] [epoch: 6031] loss: 0.0029018987\n",
      "[timestep: 8] [epoch: 6061] loss: 0.0025978261\n",
      "[timestep: 8] [epoch: 6091] loss: 0.0049790386\n",
      "[timestep: 8] [epoch: 6121] loss: 0.0027997745\n",
      "[timestep: 8] [epoch: 6151] loss: 0.0030271029\n",
      "[timestep: 8] [epoch: 6181] loss: 0.0029799510\n",
      "[timestep: 8] [epoch: 6211] loss: 0.0030118884\n",
      "[timestep: 8] [epoch: 6241] loss: 0.0038072998\n",
      "[timestep: 8] [epoch: 6271] loss: 0.0045223786\n",
      "[timestep: 8] [epoch: 6301] loss: 0.0026466446\n",
      "[timestep: 8] [epoch: 6331] loss: 0.0039802194\n",
      "[timestep: 8] [epoch: 6361] loss: 0.0026108571\n",
      "[timestep: 8] [epoch: 6391] loss: 0.0038483890\n",
      "[timestep: 8] [epoch: 6421] loss: 0.0029659923\n",
      "[timestep: 8] [epoch: 6451] loss: 0.0028022928\n",
      "[timestep: 8] [epoch: 6481] loss: 0.0064082942\n",
      "[timestep: 8] [epoch: 6511] loss: 0.0033660769\n",
      "[timestep: 8] [epoch: 6541] loss: 0.0029873946\n",
      "[timestep: 8] [epoch: 6571] loss: 0.0024677189\n",
      "[timestep: 8] [epoch: 6601] loss: 0.0027777022\n",
      "[timestep: 8] [epoch: 6631] loss: 0.0050550546\n",
      "[timestep: 8] [epoch: 6661] loss: 0.0074492106\n",
      "[timestep: 8] [epoch: 6691] loss: 0.0041357563\n",
      "[timestep: 8] [epoch: 6721] loss: 0.0026157191\n",
      "[timestep: 8] [epoch: 6751] loss: 0.0026990322\n",
      "[timestep: 8] [epoch: 6781] loss: 0.0026188903\n",
      "[timestep: 8] [epoch: 6811] loss: 0.0040624849\n",
      "[timestep: 8] [epoch: 6841] loss: 0.0030592126\n",
      "[timestep: 8] [epoch: 6871] loss: 0.0034022550\n",
      "[timestep: 8] [epoch: 6901] loss: 0.0042324760\n",
      "[timestep: 8] [epoch: 6931] loss: 0.0067541962\n",
      "[timestep: 8] [epoch: 6961] loss: 0.0033944272\n",
      "[timestep: 8] [epoch: 6991] loss: 0.0033278598\n",
      "[timestep: 8] [epoch: 7021] loss: 0.0030103708\n",
      "[timestep: 8] [epoch: 7051] loss: 0.0050704805\n",
      "[timestep: 8] [epoch: 7081] loss: 0.0034501797\n",
      "[timestep: 8] [epoch: 7111] loss: 0.0052658976\n",
      "[timestep: 8] [epoch: 7141] loss: 0.0033617266\n",
      "[timestep: 8] [epoch: 7171] loss: 0.0026048827\n",
      "[timestep: 8] [epoch: 7201] loss: 0.0042093443\n",
      "[timestep: 8] [epoch: 7231] loss: 0.0029676117\n",
      "[timestep: 8] [epoch: 7261] loss: 0.0028345836\n",
      "[timestep: 8] [epoch: 7291] loss: 0.0171036981\n",
      "[timestep: 8] [epoch: 7321] loss: 0.0041190051\n",
      "[timestep: 8] [epoch: 7351] loss: 0.0027742465\n",
      "[timestep: 8] [epoch: 7381] loss: 0.0028871652\n",
      "[timestep: 8] [epoch: 7411] loss: 0.0029738909\n",
      "[timestep: 8] [epoch: 7441] loss: 0.0025494897\n",
      "[timestep: 8] [epoch: 7471] loss: 0.0029463214\n",
      "[timestep: 8] [epoch: 7501] loss: 0.0048492332\n",
      "[timestep: 8] [epoch: 7531] loss: 0.0027864480\n",
      "[timestep: 8] [epoch: 7561] loss: 0.0025521223\n",
      "[timestep: 8] [epoch: 7591] loss: 0.0025200779\n",
      "[timestep: 8] [epoch: 7621] loss: 0.0035551679\n",
      "[timestep: 8] [epoch: 7651] loss: 0.0025698908\n",
      "[timestep: 8] [epoch: 7681] loss: 0.0044611888\n",
      "[timestep: 8] [epoch: 7711] loss: 0.0107422406\n",
      "[timestep: 8] [epoch: 7741] loss: 0.0033822195\n",
      "[timestep: 8] [epoch: 7771] loss: 0.0026857245\n",
      "[timestep: 8] [epoch: 7801] loss: 0.0029200355\n",
      "[timestep: 8] [epoch: 7831] loss: 0.0024932793\n",
      "[timestep: 8] [epoch: 7861] loss: 0.0042193374\n",
      "[timestep: 8] [epoch: 7891] loss: 0.0035461299\n",
      "[timestep: 8] [epoch: 7921] loss: 0.0028964709\n",
      "[timestep: 8] [epoch: 7951] loss: 0.0087065231\n",
      "[timestep: 8] [epoch: 7981] loss: 0.0035319827\n",
      "[timestep: 8] [epoch: 8011] loss: 0.0108799562\n",
      "[timestep: 8] [epoch: 8041] loss: 0.0035047005\n",
      "[timestep: 8] [epoch: 8071] loss: 0.0028363871\n",
      "[timestep: 8] [epoch: 8101] loss: 0.0025598868\n",
      "[timestep: 8] [epoch: 8131] loss: 0.0081078727\n",
      "[timestep: 8] [epoch: 8161] loss: 0.0031256867\n",
      "[timestep: 8] [epoch: 8191] loss: 0.0029133041\n",
      "[timestep: 8] [epoch: 8221] loss: 0.0027629267\n",
      "[timestep: 8] [epoch: 8251] loss: 0.0027266834\n",
      "[timestep: 8] [epoch: 8281] loss: 0.0030243897\n",
      "[timestep: 8] [epoch: 8311] loss: 0.0039645694\n",
      "[timestep: 8] [epoch: 8341] loss: 0.0036795170\n",
      "[timestep: 8] [epoch: 8371] loss: 0.0035188321\n",
      "[timestep: 8] [epoch: 8401] loss: 0.0047061150\n",
      "[timestep: 8] [epoch: 8431] loss: 0.0026596827\n",
      "[timestep: 8] [epoch: 8461] loss: 0.0052751182\n",
      "[timestep: 8] [epoch: 8491] loss: 0.0031203525\n",
      "[timestep: 8] [epoch: 8521] loss: 0.0025386363\n",
      "[timestep: 8] [epoch: 8551] loss: 0.0046943203\n",
      "[timestep: 8] [epoch: 8581] loss: 0.0029380168\n",
      "[timestep: 8] [epoch: 8611] loss: 0.0083442442\n",
      "[timestep: 8] [epoch: 8641] loss: 0.0027312180\n",
      "[timestep: 8] [epoch: 8671] loss: 0.0025678538\n",
      "[timestep: 8] [epoch: 8701] loss: 0.0025093555\n",
      "[timestep: 8] [epoch: 8731] loss: 0.0029514662\n",
      "[timestep: 8] [epoch: 8761] loss: 0.0025995206\n",
      "[timestep: 8] [epoch: 8791] loss: 0.0029429318\n",
      "[timestep: 8] [epoch: 8821] loss: 0.0024875035\n",
      "[timestep: 8] [epoch: 8851] loss: 0.0045813415\n",
      "[timestep: 8] [epoch: 8881] loss: 0.0027685738\n",
      "[timestep: 8] [epoch: 8911] loss: 0.0026912000\n",
      "[timestep: 8] [epoch: 8941] loss: 0.0048474413\n",
      "[timestep: 8] [epoch: 8971] loss: 0.0034928424\n",
      "[timestep: 8] [epoch: 9001] loss: 0.0031668367\n",
      "[timestep: 8] [epoch: 9031] loss: 0.0067286370\n",
      "[timestep: 8] [epoch: 9061] loss: 0.0039888434\n",
      "[timestep: 8] [epoch: 9091] loss: 0.0026125228\n",
      "[timestep: 8] [epoch: 9121] loss: 0.0028763334\n",
      "[timestep: 8] [epoch: 9151] loss: 0.0033701854\n",
      "[timestep: 8] [epoch: 9181] loss: 0.0027939100\n",
      "[timestep: 8] [epoch: 9211] loss: 0.0025877338\n",
      "[timestep: 8] [epoch: 9241] loss: 0.0029058938\n",
      "[timestep: 8] [epoch: 9271] loss: 0.0056449948\n",
      "[timestep: 8] [epoch: 9301] loss: 0.0039917482\n",
      "[timestep: 8] [epoch: 9331] loss: 0.0027179029\n",
      "[timestep: 8] [epoch: 9361] loss: 0.0026001665\n",
      "[timestep: 8] [epoch: 9391] loss: 0.0027682995\n",
      "[timestep: 8] [epoch: 9421] loss: 0.0032520620\n",
      "[timestep: 8] [epoch: 9451] loss: 0.0025597210\n",
      "[timestep: 8] [epoch: 9481] loss: 0.0157900900\n",
      "[timestep: 8] [epoch: 9511] loss: 0.0050966628\n",
      "[timestep: 8] [epoch: 9541] loss: 0.0025008451\n",
      "[timestep: 8] [epoch: 9571] loss: 0.0028080568\n",
      "[timestep: 8] [epoch: 9601] loss: 0.0026506269\n",
      "[timestep: 8] [epoch: 9631] loss: 0.0028843551\n",
      "[timestep: 8] [epoch: 9661] loss: 0.0024985031\n",
      "[timestep: 8] [epoch: 9691] loss: 0.0028111851\n",
      "[timestep: 8] [epoch: 9721] loss: 0.0040044691\n",
      "[timestep: 8] [epoch: 9751] loss: 0.0047781081\n",
      "[timestep: 8] [epoch: 9781] loss: 0.0059338538\n",
      "[timestep: 8] [epoch: 9811] loss: 0.0033118571\n",
      "[timestep: 8] [epoch: 9841] loss: 0.0025376489\n",
      "[timestep: 8] [epoch: 9871] loss: 0.0027869137\n",
      "[timestep: 8] [epoch: 9901] loss: 0.0028518829\n",
      "[timestep: 8] [epoch: 9931] loss: 0.0054190084\n",
      "[timestep: 8] [epoch: 9961] loss: 0.0028672079\n",
      "[timestep: 8] [epoch: 9991] loss: 0.0026125410\n",
      "[timestep: 8] [epoch: 10021] loss: 0.0026936901\n",
      "[timestep: 8] [epoch: 10051] loss: 0.0062809214\n",
      "[timestep: 8] [epoch: 10081] loss: 0.0034039337\n",
      "[timestep: 8] [epoch: 10111] loss: 0.0033170460\n",
      "[timestep: 8] [epoch: 10141] loss: 0.0032942074\n",
      "[timestep: 8] [epoch: 10171] loss: 0.0026818984\n",
      "[timestep: 8] [epoch: 10201] loss: 0.0024029352\n",
      "[timestep: 8] [epoch: 10231] loss: 0.0079209181\n",
      "[timestep: 8] [epoch: 10261] loss: 0.0026187513\n",
      "[timestep: 8] [epoch: 10291] loss: 0.0042762649\n",
      "[timestep: 8] [epoch: 10321] loss: 0.0025038263\n",
      "[timestep: 8] [epoch: 10351] loss: 0.0025555375\n",
      "[timestep: 8] [epoch: 10381] loss: 0.0024416079\n",
      "[timestep: 8] [epoch: 10411] loss: 0.0027470393\n",
      "[timestep: 8] [epoch: 10441] loss: 0.0024217519\n",
      "[timestep: 8] [epoch: 10471] loss: 0.0024329117\n",
      "[timestep: 8] [epoch: 10501] loss: 0.0025268262\n",
      "[timestep: 8] [epoch: 10531] loss: 0.0049154256\n",
      "[timestep: 8] [epoch: 10561] loss: 0.0025058663\n",
      "[timestep: 8] [epoch: 10591] loss: 0.0024704554\n",
      "[timestep: 8] [epoch: 10621] loss: 0.0028394982\n",
      "[timestep: 8] [epoch: 10651] loss: 0.0028779197\n",
      "[timestep: 8] [epoch: 10681] loss: 0.0025648891\n",
      "[timestep: 8] [epoch: 10711] loss: 0.0028717383\n",
      "[timestep: 8] [epoch: 10741] loss: 0.0024467667\n",
      "[timestep: 8] [epoch: 10771] loss: 0.0034078178\n",
      "[timestep: 8] [epoch: 10801] loss: 0.0038476253\n",
      "[timestep: 8] [epoch: 10831] loss: 0.0030700709\n",
      "[timestep: 8] [epoch: 10861] loss: 0.0045769936\n",
      "[timestep: 8] [epoch: 10891] loss: 0.0024825996\n",
      "[timestep: 8] [epoch: 10921] loss: 0.0026227660\n",
      "[timestep: 8] [epoch: 10951] loss: 0.0024166103\n",
      "[timestep: 8] [epoch: 10981] loss: 0.0058827647\n",
      "[timestep: 8] [epoch: 11011] loss: 0.0033710683\n",
      "[timestep: 8] [epoch: 11041] loss: 0.0027713811\n",
      "[timestep: 8] [epoch: 11071] loss: 0.0025467747\n",
      "[timestep: 8] [epoch: 11101] loss: 0.0026872708\n",
      "[timestep: 8] [epoch: 11131] loss: 0.0025491458\n",
      "[timestep: 8] [epoch: 11161] loss: 0.0028819987\n",
      "[timestep: 8] [epoch: 11191] loss: 0.0027946308\n",
      "[timestep: 8] [epoch: 11221] loss: 0.0029318603\n",
      "[timestep: 8] [epoch: 11251] loss: 0.0026744609\n",
      "[timestep: 8] [epoch: 11281] loss: 0.0032294793\n",
      "[timestep: 8] [epoch: 11311] loss: 0.0033275804\n",
      "[timestep: 8] [epoch: 11341] loss: 0.0031141350\n",
      "[timestep: 8] [epoch: 11371] loss: 0.0054542283\n",
      "[timestep: 8] [epoch: 11401] loss: 0.0034779115\n",
      "[timestep: 8] [epoch: 11431] loss: 0.0025923683\n",
      "[timestep: 8] [epoch: 11461] loss: 0.0024488622\n",
      "[timestep: 8] [epoch: 11491] loss: 0.0024971715\n",
      "[timestep: 8] [epoch: 11521] loss: 0.0024460610\n",
      "[timestep: 8] [epoch: 11551] loss: 0.0030197091\n",
      "[timestep: 8] [epoch: 11581] loss: 0.0025035290\n",
      "[timestep: 8] [epoch: 11611] loss: 0.0023832661\n",
      "[timestep: 8] [epoch: 11641] loss: 0.0029768064\n",
      "[timestep: 8] [epoch: 11671] loss: 0.0084566548\n",
      "[timestep: 8] [epoch: 11701] loss: 0.0033274409\n",
      "[timestep: 8] [epoch: 11731] loss: 0.0024702947\n",
      "[timestep: 8] [epoch: 11761] loss: 0.0025398964\n",
      "[timestep: 8] [epoch: 11791] loss: 0.0025866721\n",
      "[timestep: 8] [epoch: 11821] loss: 0.0032754855\n",
      "[timestep: 8] [epoch: 11851] loss: 0.0025040496\n",
      "[timestep: 8] [epoch: 11881] loss: 0.0025788061\n",
      "[timestep: 8] [epoch: 11911] loss: 0.0027761036\n",
      "[timestep: 8] [epoch: 11941] loss: 0.0025935448\n",
      "[timestep: 8] [epoch: 11971] loss: 0.0041759387\n",
      "[timestep: 8] [epoch: 12001] loss: 0.0053814342\n",
      "[timestep: 8] [epoch: 12031] loss: 0.0023958259\n",
      "[timestep: 8] [epoch: 12061] loss: 0.0025250579\n",
      "[timestep: 8] [epoch: 12091] loss: 0.0024124556\n",
      "[timestep: 8] [epoch: 12121] loss: 0.0024472410\n",
      "[timestep: 8] [epoch: 12151] loss: 0.0024492936\n",
      "[timestep: 8] [epoch: 12181] loss: 0.0026375288\n",
      "[timestep: 8] [epoch: 12211] loss: 0.0025838381\n",
      "[timestep: 8] [epoch: 12241] loss: 0.0026665339\n",
      "[timestep: 8] [epoch: 12271] loss: 0.0026188232\n",
      "[timestep: 8] [epoch: 12301] loss: 0.0029961141\n",
      "[timestep: 8] [epoch: 12331] loss: 0.0029612898\n",
      "[timestep: 8] [epoch: 12361] loss: 0.0040200553\n",
      "[timestep: 8] [epoch: 12391] loss: 0.0024750368\n",
      "[timestep: 8] [epoch: 12421] loss: 0.0024740715\n",
      "[timestep: 8] [epoch: 12451] loss: 0.0025833575\n",
      "[timestep: 8] [epoch: 12481] loss: 0.0026165526\n",
      "[timestep: 8] [epoch: 12511] loss: 0.0025860702\n",
      "[timestep: 8] [epoch: 12541] loss: 0.0024469492\n",
      "[timestep: 8] [epoch: 12571] loss: 0.0024480186\n",
      "[timestep: 8] [epoch: 12601] loss: 0.0024666106\n",
      "[timestep: 8] [epoch: 12631] loss: 0.0040349038\n",
      "[timestep: 8] [epoch: 12661] loss: 0.0035539011\n",
      "[timestep: 8] [epoch: 12691] loss: 0.0033608649\n",
      "[timestep: 8] [epoch: 12721] loss: 0.0033682969\n",
      "[timestep: 8] [epoch: 12751] loss: 0.0024706661\n",
      "[timestep: 8] [epoch: 12781] loss: 0.0028112496\n",
      "[timestep: 8] [epoch: 12811] loss: 0.0025558071\n",
      "[timestep: 8] [epoch: 12841] loss: 0.0024624460\n",
      "[timestep: 8] [epoch: 12871] loss: 0.0030835662\n",
      "[timestep: 8] [epoch: 12901] loss: 0.0027649393\n",
      "[timestep: 8] [epoch: 12931] loss: 0.0029042820\n",
      "[timestep: 8] [epoch: 12961] loss: 0.0035517975\n",
      "[timestep: 8] [epoch: 12991] loss: 0.0026166085\n",
      "[timestep: 8] [epoch: 13021] loss: 0.0024711736\n",
      "[timestep: 8] [epoch: 13051] loss: 0.0026381800\n",
      "[timestep: 8] [epoch: 13081] loss: 0.0028461097\n",
      "[timestep: 8] [epoch: 13111] loss: 0.0027184351\n",
      "[timestep: 8] [epoch: 13141] loss: 0.0026657297\n",
      "[timestep: 8] [epoch: 13171] loss: 0.0029095900\n",
      "[timestep: 8] [epoch: 13201] loss: 0.0033944037\n",
      "[timestep: 8] [epoch: 13231] loss: 0.0026690934\n",
      "[timestep: 8] [epoch: 13261] loss: 0.0025398675\n",
      "[timestep: 8] [epoch: 13291] loss: 0.0025428715\n",
      "[timestep: 8] [epoch: 13321] loss: 0.0028979634\n",
      "[timestep: 8] [epoch: 13351] loss: 0.0024896171\n",
      "[timestep: 8] [epoch: 13381] loss: 0.0025415113\n",
      "[timestep: 8] [epoch: 13411] loss: 0.0061535807\n",
      "[timestep: 8] [epoch: 13441] loss: 0.0026181308\n",
      "[timestep: 8] [epoch: 13471] loss: 0.0025488592\n",
      "[timestep: 8] [epoch: 13501] loss: 0.0025204364\n",
      "[timestep: 8] [epoch: 13531] loss: 0.0063547445\n",
      "[timestep: 8] [epoch: 13561] loss: 0.0026211049\n",
      "[timestep: 8] [epoch: 13591] loss: 0.0025926209\n",
      "[timestep: 8] [epoch: 13621] loss: 0.0027247074\n",
      "[timestep: 8] [epoch: 13651] loss: 0.0027587090\n",
      "[timestep: 8] [epoch: 13681] loss: 0.0024258238\n",
      "[timestep: 8] [epoch: 13711] loss: 0.0124163358\n",
      "[timestep: 8] [epoch: 13741] loss: 0.0027529893\n",
      "[timestep: 8] [epoch: 13771] loss: 0.0025220113\n",
      "[timestep: 8] [epoch: 13801] loss: 0.0029776187\n",
      "[timestep: 8] [epoch: 13831] loss: 0.0027999245\n",
      "[timestep: 8] [epoch: 13861] loss: 0.0031463422\n",
      "[timestep: 8] [epoch: 13891] loss: 0.0026726709\n",
      "[timestep: 8] [epoch: 13921] loss: 0.0027025142\n",
      "[timestep: 8] [epoch: 13951] loss: 0.0025130045\n",
      "[timestep: 8] [epoch: 13981] loss: 0.0046403352\n",
      "[timestep: 8] [epoch: 14011] loss: 0.0051107425\n",
      "[timestep: 8] [epoch: 14041] loss: 0.0039734165\n",
      "[timestep: 8] [epoch: 14071] loss: 0.0024053799\n",
      "[timestep: 8] [epoch: 14101] loss: 0.0025231973\n",
      "[timestep: 8] [epoch: 14131] loss: 0.0024892557\n",
      "[timestep: 8] [epoch: 14161] loss: 0.0024409289\n",
      "[timestep: 8] [epoch: 14191] loss: 0.0024955692\n",
      "[timestep: 8] [epoch: 14221] loss: 0.0025675157\n",
      "[timestep: 8] [epoch: 14251] loss: 0.0027228545\n",
      "[timestep: 8] [epoch: 14281] loss: 0.0042527523\n",
      "[timestep: 8] [epoch: 14311] loss: 0.0028496482\n",
      "[timestep: 8] [epoch: 14341] loss: 0.0023873376\n",
      "[timestep: 8] [epoch: 14371] loss: 0.0024776328\n",
      "[timestep: 8] [epoch: 14401] loss: 0.0031931933\n",
      "[timestep: 8] [epoch: 14431] loss: 0.0027237334\n",
      "[timestep: 8] [epoch: 14461] loss: 0.0035297978\n",
      "[timestep: 8] [epoch: 14491] loss: 0.0029796218\n",
      "[timestep: 8] [epoch: 14521] loss: 0.0026276074\n",
      "[timestep: 8] [epoch: 14551] loss: 0.0031361124\n",
      "[timestep: 8] [epoch: 14581] loss: 0.0026161247\n",
      "[timestep: 8] [epoch: 14611] loss: 0.0027771927\n",
      "[timestep: 8] [epoch: 14641] loss: 0.0024528292\n",
      "[timestep: 8] [epoch: 14671] loss: 0.0025249477\n",
      "[timestep: 8] [epoch: 14701] loss: 0.0038325302\n",
      "[timestep: 8] [epoch: 14731] loss: 0.0035447278\n",
      "[timestep: 8] [epoch: 14761] loss: 0.0028613196\n",
      "[timestep: 8] [epoch: 14791] loss: 0.0025575552\n",
      "[timestep: 8] [epoch: 14821] loss: 0.0025919154\n",
      "[timestep: 8] [epoch: 14851] loss: 0.0030545075\n",
      "[timestep: 8] [epoch: 14881] loss: 0.0026965323\n",
      "[timestep: 8] [epoch: 14911] loss: 0.0026588915\n",
      "[timestep: 8] [epoch: 14941] loss: 0.0027176663\n",
      "[timestep: 8] [epoch: 14971] loss: 0.0054047983\n",
      "[timestep: 8] [epoch: 15001] loss: 0.0056157699\n",
      "[timestep: 8] [epoch: 15031] loss: 0.0024311170\n",
      "[timestep: 8] [epoch: 15061] loss: 0.0024807556\n",
      "[timestep: 8] [epoch: 15091] loss: 0.0023645619\n",
      "[timestep: 8] [epoch: 15121] loss: 0.0025866367\n",
      "[timestep: 8] [epoch: 15151] loss: 0.0028502038\n",
      "[timestep: 8] [epoch: 15181] loss: 0.0025316412\n",
      "[timestep: 8] [epoch: 15211] loss: 0.0025084636\n",
      "[timestep: 8] [epoch: 15241] loss: 0.0031674746\n",
      "[timestep: 8] [epoch: 15271] loss: 0.0026451796\n",
      "[timestep: 8] [epoch: 15301] loss: 0.0030164693\n",
      "[timestep: 8] [epoch: 15331] loss: 0.0049077012\n",
      "[timestep: 8] [epoch: 15361] loss: 0.0029495999\n",
      "[timestep: 8] [epoch: 15391] loss: 0.0023979249\n",
      "[timestep: 8] [epoch: 15421] loss: 0.0024104209\n",
      "[timestep: 8] [epoch: 15451] loss: 0.0039953068\n",
      "[timestep: 8] [epoch: 15481] loss: 0.0025751777\n",
      "[timestep: 8] [epoch: 15511] loss: 0.0035324413\n",
      "[timestep: 8] [epoch: 15541] loss: 0.0027887798\n",
      "[timestep: 8] [epoch: 15571] loss: 0.0028758652\n",
      "[timestep: 8] [epoch: 15601] loss: 0.0025279974\n",
      "[timestep: 8] [epoch: 15631] loss: 0.0027010893\n",
      "[timestep: 8] [epoch: 15661] loss: 0.0025660687\n",
      "[timestep: 8] [epoch: 15691] loss: 0.0026032301\n",
      "[timestep: 8] [epoch: 15721] loss: 0.0024102549\n",
      "[timestep: 8] [epoch: 15751] loss: 0.0026613465\n",
      "[timestep: 8] [epoch: 15781] loss: 0.0057205260\n",
      "[timestep: 8] [epoch: 15811] loss: 0.0027919279\n",
      "[timestep: 8] [epoch: 15841] loss: 0.0028156647\n",
      "[timestep: 8] [epoch: 15871] loss: 0.0036343520\n",
      "[timestep: 8] [epoch: 15901] loss: 0.0025619024\n",
      "[timestep: 8] [epoch: 15931] loss: 0.0024587412\n",
      "[timestep: 8] [epoch: 15961] loss: 0.0027466835\n",
      "[timestep: 8] [epoch: 15991] loss: 0.0027660450\n",
      "[timestep: 8] [epoch: 16021] loss: 0.0026987242\n",
      "[timestep: 8] [epoch: 16051] loss: 0.0028840625\n",
      "[timestep: 8] [epoch: 16081] loss: 0.0026433307\n",
      "[timestep: 8] [epoch: 16111] loss: 0.0027253907\n",
      "[timestep: 8] [epoch: 16141] loss: 0.0024795579\n",
      "[timestep: 8] [epoch: 16171] loss: 0.0026191263\n",
      "[timestep: 8] [epoch: 16201] loss: 0.0024557973\n",
      "[timestep: 8] [epoch: 16231] loss: 0.0027712276\n",
      "[timestep: 8] [epoch: 16261] loss: 0.0024903689\n",
      "[timestep: 8] [epoch: 16291] loss: 0.0067625139\n",
      "[timestep: 8] [epoch: 16321] loss: 0.0026174511\n",
      "[timestep: 8] [epoch: 16351] loss: 0.0031693159\n",
      "[timestep: 8] [epoch: 16381] loss: 0.0029245233\n",
      "[timestep: 8] [epoch: 16411] loss: 0.0026784197\n",
      "[timestep: 8] [epoch: 16441] loss: 0.0025878120\n",
      "[timestep: 8] [epoch: 16471] loss: 0.0026143393\n",
      "[timestep: 8] [epoch: 16501] loss: 0.0026631602\n",
      "[timestep: 8] [epoch: 16531] loss: 0.0040529557\n",
      "[timestep: 8] [epoch: 16561] loss: 0.0029302784\n",
      "[timestep: 8] [epoch: 16591] loss: 0.0024646115\n",
      "[timestep: 8] [epoch: 16621] loss: 0.0028715499\n",
      "[timestep: 8] [epoch: 16651] loss: 0.0027628355\n",
      "[timestep: 8] [epoch: 16681] loss: 0.0040576742\n",
      "[timestep: 8] [epoch: 16711] loss: 0.0031096772\n",
      "[timestep: 8] [epoch: 16741] loss: 0.0024176463\n",
      "[timestep: 8] [epoch: 16771] loss: 0.0026693512\n",
      "[timestep: 8] [epoch: 16801] loss: 0.0025109090\n",
      "[timestep: 8] [epoch: 16831] loss: 0.0055825654\n",
      "[timestep: 8] [epoch: 16861] loss: 0.0025378061\n",
      "[timestep: 8] [epoch: 16891] loss: 0.0029132643\n",
      "[timestep: 8] [epoch: 16921] loss: 0.0026608771\n",
      "[timestep: 8] [epoch: 16951] loss: 0.0024107539\n",
      "[timestep: 8] [epoch: 16981] loss: 0.0030655435\n",
      "[timestep: 8] [epoch: 17011] loss: 0.0024955650\n",
      "[timestep: 8] [epoch: 17041] loss: 0.0030542996\n",
      "[timestep: 8] [epoch: 17071] loss: 0.0027971584\n",
      "[timestep: 8] [epoch: 17101] loss: 0.0024685671\n",
      "[timestep: 8] [epoch: 17131] loss: 0.0027609039\n",
      "[timestep: 8] [epoch: 17161] loss: 0.0035577230\n",
      "[timestep: 8] [epoch: 17191] loss: 0.0024886366\n",
      "[timestep: 8] [epoch: 17221] loss: 0.0024731951\n",
      "[timestep: 8] [epoch: 17251] loss: 0.0026527303\n",
      "[timestep: 8] [epoch: 17281] loss: 0.0026738378\n",
      "[timestep: 8] [epoch: 17311] loss: 0.0026632608\n",
      "[timestep: 8] [epoch: 17341] loss: 0.0024503334\n",
      "[timestep: 8] [epoch: 17371] loss: 0.0023832184\n",
      "[timestep: 8] [epoch: 17401] loss: 0.0024046886\n",
      "[timestep: 8] [epoch: 17431] loss: 0.0028425090\n",
      "[timestep: 8] [epoch: 17461] loss: 0.0024295165\n",
      "[timestep: 8] [epoch: 17491] loss: 0.0024361012\n",
      "[timestep: 8] [epoch: 17521] loss: 0.0030134250\n",
      "[timestep: 8] [epoch: 17551] loss: 0.0027893190\n",
      "[timestep: 8] [epoch: 17581] loss: 0.0024206932\n",
      "[timestep: 8] [epoch: 17611] loss: 0.0030952119\n",
      "[timestep: 8] [epoch: 17641] loss: 0.0027283914\n",
      "[timestep: 8] [epoch: 17671] loss: 0.0025055085\n",
      "[timestep: 8] [epoch: 17701] loss: 0.0026060953\n",
      "[timestep: 8] [epoch: 17731] loss: 0.0025695311\n",
      "[timestep: 8] [epoch: 17761] loss: 0.0027363352\n",
      "[timestep: 8] [epoch: 17791] loss: 0.0031479911\n",
      "[timestep: 8] [epoch: 17821] loss: 0.0024535591\n",
      "[timestep: 8] [epoch: 17851] loss: 0.0025991849\n",
      "[timestep: 8] [epoch: 17881] loss: 0.0023920946\n",
      "[timestep: 8] [epoch: 17911] loss: 0.0026392005\n",
      "[timestep: 8] [epoch: 17941] loss: 0.0082200542\n",
      "[timestep: 8] [epoch: 17971] loss: 0.0026179203\n",
      "[timestep: 8] [epoch: 18001] loss: 0.0029573881\n",
      "[timestep: 8] [epoch: 18031] loss: 0.0025005019\n",
      "[timestep: 8] [epoch: 18061] loss: 0.0026085291\n",
      "[timestep: 8] [epoch: 18091] loss: 0.0023671954\n",
      "[timestep: 8] [epoch: 18121] loss: 0.0027429927\n",
      "[timestep: 8] [epoch: 18151] loss: 0.0028806250\n",
      "[timestep: 8] [epoch: 18181] loss: 0.0028074691\n",
      "[timestep: 8] [epoch: 18211] loss: 0.0024214943\n",
      "[timestep: 8] [epoch: 18241] loss: 0.0025708443\n",
      "[timestep: 8] [epoch: 18271] loss: 0.0027247858\n",
      "[timestep: 8] [epoch: 18301] loss: 0.0027313363\n",
      "[timestep: 8] [epoch: 18331] loss: 0.0024716118\n",
      "[timestep: 8] [epoch: 18361] loss: 0.0026644114\n",
      "[timestep: 8] [epoch: 18391] loss: 0.0027043098\n",
      "[timestep: 8] [epoch: 18421] loss: 0.0026323292\n",
      "[timestep: 8] [epoch: 18451] loss: 0.0026701565\n",
      "[timestep: 8] [epoch: 18481] loss: 0.0030071018\n",
      "[timestep: 8] [epoch: 18511] loss: 0.0026307958\n",
      "[timestep: 8] [epoch: 18541] loss: 0.0024895400\n",
      "[timestep: 8] [epoch: 18571] loss: 0.0029121051\n",
      "[timestep: 8] [epoch: 18601] loss: 0.0028688502\n",
      "[timestep: 8] [epoch: 18631] loss: 0.0023964993\n",
      "[timestep: 8] [epoch: 18661] loss: 0.0024338367\n",
      "[timestep: 8] [epoch: 18691] loss: 0.0029856949\n",
      "[timestep: 8] [epoch: 18721] loss: 0.0024612087\n",
      "[timestep: 8] [epoch: 18751] loss: 0.0026302133\n",
      "[timestep: 8] [epoch: 18781] loss: 0.0026029241\n",
      "[timestep: 8] [epoch: 18811] loss: 0.0028264506\n",
      "[timestep: 8] [epoch: 18841] loss: 0.0027276254\n",
      "[timestep: 8] [epoch: 18871] loss: 0.0046788352\n",
      "[timestep: 8] [epoch: 18901] loss: 0.0024696556\n",
      "[timestep: 8] [epoch: 18931] loss: 0.0026191617\n",
      "[timestep: 8] [epoch: 18961] loss: 0.0024342779\n",
      "[timestep: 8] [epoch: 18991] loss: 0.0025189607\n",
      "[timestep: 8] [epoch: 19021] loss: 0.0025052470\n",
      "[timestep: 8] [epoch: 19051] loss: 0.0024532219\n",
      "[timestep: 8] [epoch: 19081] loss: 0.0024856334\n",
      "[timestep: 8] [epoch: 19111] loss: 0.0024451704\n",
      "[timestep: 8] [epoch: 19141] loss: 0.0025848914\n",
      "[timestep: 8] [epoch: 19171] loss: 0.0024077781\n",
      "[timestep: 8] [epoch: 19201] loss: 0.0043994868\n",
      "[timestep: 8] [epoch: 19231] loss: 0.0024539272\n",
      "[timestep: 8] [epoch: 19261] loss: 0.0025040873\n",
      "[timestep: 8] [epoch: 19291] loss: 0.0024412507\n",
      "[timestep: 8] [epoch: 19321] loss: 0.0029820795\n",
      "[timestep: 8] [epoch: 19351] loss: 0.0027912674\n",
      "[timestep: 8] [epoch: 19381] loss: 0.0027239928\n",
      "[timestep: 8] [epoch: 19411] loss: 0.0024406477\n",
      "[timestep: 8] [epoch: 19441] loss: 0.0025287417\n",
      "[timestep: 8] [epoch: 19471] loss: 0.0026177075\n",
      "[timestep: 8] [epoch: 19501] loss: 0.0035364935\n",
      "[timestep: 8] [epoch: 19531] loss: 0.0026697339\n",
      "[timestep: 8] [epoch: 19561] loss: 0.0024462743\n",
      "[timestep: 8] [epoch: 19591] loss: 0.0028405851\n",
      "[timestep: 8] [epoch: 19621] loss: 0.0023824661\n",
      "[timestep: 8] [epoch: 19651] loss: 0.0024324059\n",
      "[timestep: 8] [epoch: 19681] loss: 0.0024006045\n",
      "[timestep: 8] [epoch: 19711] loss: 0.0024904218\n",
      "[timestep: 8] [epoch: 19741] loss: 0.0025381325\n",
      "[timestep: 8] [epoch: 19771] loss: 0.0026109265\n",
      "[timestep: 8] [epoch: 19801] loss: 0.0024661939\n",
      "[timestep: 8] [epoch: 19831] loss: 0.0023900524\n",
      "[timestep: 8] [epoch: 19861] loss: 0.0026847823\n",
      "[timestep: 8] [epoch: 19891] loss: 0.0025026419\n",
      "[timestep: 8] [epoch: 19921] loss: 0.0034308820\n",
      "[timestep: 8] [epoch: 19951] loss: 0.0024482347\n",
      "[timestep: 8] [epoch: 19981] loss: 0.0024283761\n",
      "[timestep: 8] [epoch: 20011] loss: 0.0031080197\n",
      "[timestep: 8] [epoch: 20041] loss: 0.0025972321\n",
      "[timestep: 8] [epoch: 20071] loss: 0.0026064022\n",
      "[timestep: 8] [epoch: 20101] loss: 0.0024820955\n",
      "[timestep: 8] [epoch: 20131] loss: 0.0024158028\n",
      "[timestep: 8] [epoch: 20161] loss: 0.0025772275\n",
      "[timestep: 8] [epoch: 20191] loss: 0.0027409527\n",
      "[timestep: 8] [epoch: 20221] loss: 0.0024511691\n",
      "[timestep: 8] [epoch: 20251] loss: 0.0024959799\n",
      "[timestep: 8] [epoch: 20281] loss: 0.0024221996\n",
      "[timestep: 8] [epoch: 20311] loss: 0.0026415791\n",
      "[timestep: 8] [epoch: 20341] loss: 0.0027658897\n",
      "[timestep: 8] [epoch: 20371] loss: 0.0024576522\n",
      "[timestep: 8] [epoch: 20401] loss: 0.0025454564\n",
      "[timestep: 8] [epoch: 20431] loss: 0.0025315047\n",
      "[timestep: 8] [epoch: 20461] loss: 0.0024636264\n",
      "[timestep: 8] [epoch: 20491] loss: 0.0024073205\n",
      "[timestep: 8] [epoch: 20521] loss: 0.0033206488\n",
      "[timestep: 8] [epoch: 20551] loss: 0.0030644736\n",
      "[timestep: 8] [epoch: 20581] loss: 0.0023741699\n",
      "[timestep: 8] [epoch: 20611] loss: 0.0075290995\n",
      "[timestep: 8] [epoch: 20641] loss: 0.0039772214\n",
      "[timestep: 8] [epoch: 20671] loss: 0.1592282206\n",
      "[timestep: 8] [epoch: 20701] loss: 0.1216312647\n",
      "[timestep: 8] [epoch: 20731] loss: 0.1151400059\n",
      "[timestep: 8] [epoch: 20761] loss: 0.1136645451\n",
      "[timestep: 8] [epoch: 20791] loss: 0.1135750487\n",
      "[timestep: 8] [epoch: 20821] loss: 0.1135404855\n",
      "[timestep: 8] [epoch: 20851] loss: 0.1135480702\n",
      "[timestep: 8] [epoch: 20881] loss: 0.1135233790\n",
      "[timestep: 8] [epoch: 20911] loss: 0.1135599762\n",
      "[timestep: 8] [epoch: 20941] loss: 0.1134749502\n",
      "[timestep: 8] [epoch: 20971] loss: 0.1134352610\n",
      "[timestep: 8] [epoch: 21001] loss: 0.1133898944\n",
      "[timestep: 8] [epoch: 21031] loss: 0.1134015843\n",
      "[timestep: 8] [epoch: 21061] loss: 0.1134040952\n",
      "[timestep: 8] [epoch: 21091] loss: 0.1134432927\n",
      "[timestep: 8] [epoch: 21121] loss: 0.1133690402\n",
      "[timestep: 8] [epoch: 21151] loss: 0.1134867966\n",
      "[timestep: 8] [epoch: 21181] loss: 0.1133849621\n",
      "[timestep: 8] [epoch: 21211] loss: 0.1135021001\n",
      "[timestep: 8] [epoch: 21241] loss: 0.1134472936\n",
      "[timestep: 8] [epoch: 21271] loss: 0.1134860963\n",
      "[timestep: 8] [epoch: 21301] loss: 0.1134596616\n",
      "[timestep: 8] [epoch: 21331] loss: 0.1133616567\n",
      "[timestep: 8] [epoch: 21361] loss: 0.1137018427\n",
      "[timestep: 8] [epoch: 21391] loss: 0.1134419888\n",
      "[timestep: 8] [epoch: 21421] loss: 0.1136502773\n",
      "[timestep: 8] [epoch: 21451] loss: 0.1145105660\n",
      "[timestep: 8] [epoch: 21481] loss: 0.1135044694\n",
      "[timestep: 8] [epoch: 21511] loss: 0.1134629101\n",
      "[timestep: 8] [epoch: 21541] loss: 0.1137194633\n",
      "[timestep: 8] [epoch: 21571] loss: 0.1133540124\n",
      "[timestep: 8] [epoch: 21601] loss: 0.1135263443\n",
      "[timestep: 8] [epoch: 21631] loss: 0.1135911793\n",
      "[timestep: 8] [epoch: 21661] loss: 0.1133682355\n",
      "[timestep: 8] [epoch: 21691] loss: 0.1134372950\n",
      "[timestep: 8] [epoch: 21721] loss: 0.1134455800\n",
      "[timestep: 8] [epoch: 21751] loss: 0.1135727987\n",
      "[timestep: 8] [epoch: 21781] loss: 0.1135895476\n",
      "[timestep: 8] [epoch: 21811] loss: 0.1133571863\n",
      "[timestep: 8] [epoch: 21841] loss: 0.1135752499\n",
      "[timestep: 8] [epoch: 21871] loss: 0.1134129614\n",
      "[timestep: 8] [epoch: 21901] loss: 0.1143773422\n",
      "[timestep: 8] [epoch: 21931] loss: 0.1134106368\n",
      "[timestep: 8] [epoch: 21961] loss: 0.1136358827\n",
      "[timestep: 8] [epoch: 21991] loss: 0.1135233194\n",
      "[timestep: 8] [epoch: 22021] loss: 0.1141827106\n",
      "[timestep: 8] [epoch: 22051] loss: 0.1134502888\n",
      "[timestep: 8] [epoch: 22081] loss: 0.1135297045\n",
      "[timestep: 8] [epoch: 22111] loss: 0.1134540141\n",
      "[timestep: 8] [epoch: 22141] loss: 0.1134817600\n",
      "[timestep: 8] [epoch: 22171] loss: 0.1136322767\n",
      "[timestep: 8] [epoch: 22201] loss: 0.1133610159\n",
      "[timestep: 8] [epoch: 22231] loss: 0.1135286838\n",
      "[timestep: 8] [epoch: 22261] loss: 0.1138154268\n",
      "[timestep: 8] [epoch: 22291] loss: 0.1135266423\n",
      "[timestep: 8] [epoch: 22321] loss: 0.1133821309\n",
      "[timestep: 8] [epoch: 22351] loss: 0.1147225201\n",
      "[timestep: 8] [epoch: 22381] loss: 0.1140163764\n",
      "[timestep: 8] [epoch: 22411] loss: 0.1136267781\n",
      "[timestep: 8] [epoch: 22441] loss: 0.1133862585\n",
      "[timestep: 8] [epoch: 22471] loss: 0.1135189533\n",
      "[timestep: 8] [epoch: 22501] loss: 0.1137920469\n",
      "[timestep: 8] [epoch: 22531] loss: 0.1147563905\n",
      "[timestep: 8] [epoch: 22561] loss: 0.1135260910\n",
      "[timestep: 8] [epoch: 22591] loss: 0.1133759618\n",
      "[timestep: 8] [epoch: 22621] loss: 0.1137192547\n",
      "[timestep: 8] [epoch: 22651] loss: 0.1134047508\n",
      "[timestep: 8] [epoch: 22681] loss: 0.1133686602\n",
      "[timestep: 8] [epoch: 22711] loss: 0.1134053096\n",
      "[timestep: 8] [epoch: 22741] loss: 0.1133805662\n",
      "[timestep: 8] [epoch: 22771] loss: 0.1136257946\n",
      "[timestep: 8] [epoch: 22801] loss: 0.1139285043\n",
      "[timestep: 8] [epoch: 22831] loss: 0.1136992276\n",
      "[timestep: 8] [epoch: 22861] loss: 0.1137411147\n",
      "[timestep: 8] [epoch: 22891] loss: 0.1134169325\n",
      "[timestep: 8] [epoch: 22921] loss: 0.1134570390\n",
      "[timestep: 8] [epoch: 22951] loss: 0.1134621948\n",
      "[timestep: 8] [epoch: 22981] loss: 0.1134014577\n",
      "[timestep: 8] [epoch: 23011] loss: 0.1137637347\n",
      "[timestep: 8] [epoch: 23041] loss: 0.1133970991\n",
      "[timestep: 8] [epoch: 23071] loss: 0.1135320067\n",
      "[timestep: 8] [epoch: 23101] loss: 0.1134422943\n",
      "[timestep: 8] [epoch: 23131] loss: 0.1135339141\n",
      "[timestep: 8] [epoch: 23161] loss: 0.1133393049\n",
      "[timestep: 8] [epoch: 23191] loss: 0.1134846285\n",
      "[timestep: 8] [epoch: 23221] loss: 0.1134003773\n",
      "[timestep: 8] [epoch: 23251] loss: 0.1134506837\n",
      "[timestep: 8] [epoch: 23281] loss: 0.1136924028\n",
      "[timestep: 8] [epoch: 23311] loss: 0.1133834124\n",
      "[timestep: 8] [epoch: 23341] loss: 0.1157804579\n",
      "[timestep: 8] [epoch: 23371] loss: 0.1134181917\n",
      "[timestep: 8] [epoch: 23401] loss: 0.1136050969\n",
      "[timestep: 8] [epoch: 23431] loss: 0.1133560911\n",
      "[timestep: 8] [epoch: 23461] loss: 0.1139606610\n",
      "[timestep: 8] [epoch: 23491] loss: 0.1133856475\n",
      "[timestep: 8] [epoch: 23521] loss: 0.1138271913\n",
      "[timestep: 8] [epoch: 23551] loss: 0.1135331318\n",
      "[timestep: 8] [epoch: 23581] loss: 0.1134104952\n",
      "[timestep: 8] [epoch: 23611] loss: 0.1137192547\n",
      "[timestep: 8] [epoch: 23641] loss: 0.1133839339\n",
      "[timestep: 8] [epoch: 23671] loss: 0.1135877520\n",
      "[timestep: 8] [epoch: 23701] loss: 0.1133554801\n",
      "[timestep: 8] [epoch: 23731] loss: 0.1139043570\n",
      "[timestep: 8] [epoch: 23761] loss: 0.1144869179\n",
      "[timestep: 8] [epoch: 23791] loss: 0.1140489653\n",
      "[timestep: 8] [epoch: 23821] loss: 0.1135225743\n",
      "[timestep: 8] [epoch: 23851] loss: 0.1133860797\n",
      "[timestep: 8] [epoch: 23881] loss: 0.1134529710\n",
      "[timestep: 8] [epoch: 23911] loss: 0.1135405749\n",
      "[timestep: 8] [epoch: 23941] loss: 0.1134577096\n",
      "[timestep: 8] [epoch: 23971] loss: 0.1146371663\n",
      "[timestep: 8] [epoch: 24001] loss: 0.1136950552\n",
      "[timestep: 8] [epoch: 24031] loss: 0.1133982018\n",
      "[timestep: 8] [epoch: 24061] loss: 0.1134894937\n",
      "[timestep: 8] [epoch: 24091] loss: 0.1135117263\n",
      "[timestep: 8] [epoch: 24121] loss: 0.1134210974\n",
      "[timestep: 8] [epoch: 24151] loss: 0.1139699370\n",
      "[timestep: 8] [epoch: 24181] loss: 0.1137983352\n",
      "[timestep: 8] [epoch: 24211] loss: 0.1135602742\n",
      "[timestep: 8] [epoch: 24241] loss: 0.1136054024\n",
      "[timestep: 8] [epoch: 24271] loss: 0.1136580482\n",
      "[timestep: 8] [epoch: 24301] loss: 0.1137283295\n",
      "[timestep: 8] [epoch: 24331] loss: 0.1135881320\n",
      "[timestep: 8] [epoch: 24361] loss: 0.1137098819\n",
      "[timestep: 8] [epoch: 24391] loss: 0.1136357486\n",
      "[timestep: 8] [epoch: 24421] loss: 0.1133853495\n",
      "[timestep: 8] [epoch: 24451] loss: 0.1134835184\n",
      "[timestep: 8] [epoch: 24481] loss: 0.1137346327\n",
      "[timestep: 8] [epoch: 24511] loss: 0.1139961034\n",
      "[timestep: 8] [epoch: 24541] loss: 0.1133870184\n",
      "[timestep: 8] [epoch: 24571] loss: 0.1136836857\n",
      "[timestep: 8] [epoch: 24601] loss: 0.1138720959\n",
      "[timestep: 8] [epoch: 24631] loss: 0.1136608720\n",
      "[timestep: 8] [epoch: 24661] loss: 0.1133889183\n",
      "[timestep: 8] [epoch: 24691] loss: 0.1138942540\n",
      "[timestep: 8] [epoch: 24721] loss: 0.1133730412\n",
      "[timestep: 8] [epoch: 24751] loss: 0.1137199700\n",
      "[timestep: 8] [epoch: 24781] loss: 0.1133817285\n",
      "[timestep: 8] [epoch: 24811] loss: 0.1134709641\n",
      "[timestep: 8] [epoch: 24841] loss: 0.1136135608\n",
      "[timestep: 8] [epoch: 24871] loss: 0.1134983301\n",
      "[timestep: 8] [epoch: 24901] loss: 0.1133858114\n",
      "[timestep: 8] [epoch: 24931] loss: 0.1142516360\n",
      "[timestep: 8] [epoch: 24961] loss: 0.1139136851\n",
      "[timestep: 8] [epoch: 24991] loss: 0.1134885550\n",
      "[timestep: 8] [epoch: 25021] loss: 0.1135854274\n",
      "[timestep: 8] [epoch: 25051] loss: 0.1134354249\n",
      "[timestep: 8] [epoch: 25081] loss: 0.1135649681\n",
      "[timestep: 8] [epoch: 25111] loss: 0.1136255041\n",
      "[timestep: 8] [epoch: 25141] loss: 0.1139174849\n",
      "[timestep: 8] [epoch: 25171] loss: 0.1134500057\n",
      "[timestep: 8] [epoch: 25201] loss: 0.1133354753\n",
      "[timestep: 8] [epoch: 25231] loss: 0.1134239212\n",
      "[timestep: 8] [epoch: 25261] loss: 0.1135694087\n",
      "[timestep: 8] [epoch: 25291] loss: 0.1139259860\n",
      "[timestep: 8] [epoch: 25321] loss: 0.1133413017\n",
      "[timestep: 8] [epoch: 25351] loss: 0.1133706570\n",
      "[timestep: 8] [epoch: 25381] loss: 0.1136262566\n",
      "[timestep: 8] [epoch: 25411] loss: 0.1134118587\n",
      "[timestep: 8] [epoch: 25441] loss: 0.1137531847\n",
      "[timestep: 8] [epoch: 25471] loss: 0.1138548627\n",
      "[timestep: 8] [epoch: 25501] loss: 0.1135602742\n",
      "[timestep: 8] [epoch: 25531] loss: 0.1135822460\n",
      "[timestep: 8] [epoch: 25561] loss: 0.1137964651\n",
      "[timestep: 8] [epoch: 25591] loss: 0.1134342700\n",
      "[timestep: 8] [epoch: 25621] loss: 0.1133729517\n",
      "[timestep: 8] [epoch: 25651] loss: 0.1133762896\n",
      "[timestep: 8] [epoch: 25681] loss: 0.1134260297\n",
      "[timestep: 8] [epoch: 25711] loss: 0.1133687198\n",
      "[timestep: 8] [epoch: 25741] loss: 0.1135967970\n",
      "[timestep: 8] [epoch: 25771] loss: 0.1134570539\n",
      "[timestep: 8] [epoch: 25801] loss: 0.1134066954\n",
      "[timestep: 8] [epoch: 25831] loss: 0.1133217812\n",
      "[timestep: 8] [epoch: 25861] loss: 0.1133772805\n",
      "[timestep: 8] [epoch: 25891] loss: 0.1135243475\n",
      "[timestep: 8] [epoch: 25921] loss: 0.1133813858\n",
      "[timestep: 8] [epoch: 25951] loss: 0.1135558635\n",
      "[timestep: 8] [epoch: 25981] loss: 0.1134109199\n",
      "[timestep: 8] [epoch: 26011] loss: 0.1134750694\n",
      "[timestep: 8] [epoch: 26041] loss: 0.1133787557\n",
      "[timestep: 8] [epoch: 26071] loss: 0.1135228425\n",
      "[timestep: 8] [epoch: 26101] loss: 0.1133837849\n",
      "[timestep: 8] [epoch: 26131] loss: 0.1134160012\n",
      "[timestep: 8] [epoch: 26161] loss: 0.1134477928\n",
      "[timestep: 8] [epoch: 26191] loss: 0.1136950478\n",
      "[timestep: 8] [epoch: 26221] loss: 0.1133770272\n",
      "[timestep: 8] [epoch: 26251] loss: 0.1133936495\n",
      "[timestep: 8] [epoch: 26281] loss: 0.1133260727\n",
      "[timestep: 8] [epoch: 26311] loss: 0.1133854240\n",
      "[timestep: 8] [epoch: 26341] loss: 0.1133635715\n",
      "[timestep: 8] [epoch: 26371] loss: 0.1135998741\n",
      "[timestep: 8] [epoch: 26401] loss: 0.1135303229\n",
      "[timestep: 8] [epoch: 26431] loss: 0.1135352999\n",
      "[timestep: 8] [epoch: 26461] loss: 0.1133679077\n",
      "[timestep: 8] [epoch: 26491] loss: 0.1133967042\n",
      "[timestep: 8] [epoch: 26521] loss: 0.1133551151\n",
      "[timestep: 8] [epoch: 26551] loss: 0.1134864241\n",
      "[timestep: 8] [epoch: 26581] loss: 0.1134469956\n",
      "[timestep: 8] [epoch: 26611] loss: 0.1133463234\n",
      "[timestep: 8] [epoch: 26641] loss: 0.1136128902\n",
      "[timestep: 8] [epoch: 26671] loss: 0.1137908101\n",
      "[timestep: 8] [epoch: 26701] loss: 0.1133305877\n",
      "[timestep: 8] [epoch: 26731] loss: 0.1133477390\n",
      "[timestep: 8] [epoch: 26761] loss: 0.1134458780\n",
      "[timestep: 8] [epoch: 26791] loss: 0.1133960485\n",
      "[timestep: 8] [epoch: 26821] loss: 0.1133946627\n",
      "[timestep: 8] [epoch: 26851] loss: 0.1134149805\n",
      "[timestep: 8] [epoch: 26881] loss: 0.1134255603\n",
      "[timestep: 8] [epoch: 26911] loss: 0.1134497970\n",
      "[timestep: 8] [epoch: 26941] loss: 0.1137554348\n",
      "[timestep: 8] [epoch: 26971] loss: 0.1135159433\n",
      "[timestep: 8] [epoch: 27001] loss: 0.1134876385\n",
      "[timestep: 8] [epoch: 27031] loss: 0.1136249155\n",
      "[timestep: 8] [epoch: 27061] loss: 0.1134436727\n",
      "[timestep: 8] [epoch: 27091] loss: 0.1136079282\n",
      "[timestep: 8] [epoch: 27121] loss: 0.1133902147\n",
      "[timestep: 8] [epoch: 27151] loss: 0.1136053056\n",
      "[timestep: 8] [epoch: 27181] loss: 0.1133534610\n",
      "[timestep: 8] [epoch: 27211] loss: 0.1134991050\n",
      "[timestep: 8] [epoch: 27241] loss: 0.1133560985\n",
      "[timestep: 8] [epoch: 27271] loss: 0.1133950353\n",
      "[timestep: 8] [epoch: 27301] loss: 0.1134222001\n",
      "[timestep: 8] [epoch: 27331] loss: 0.1133778989\n",
      "[timestep: 8] [epoch: 27361] loss: 0.1133975163\n",
      "[timestep: 8] [epoch: 27391] loss: 0.1136018187\n",
      "[timestep: 8] [epoch: 27421] loss: 0.1133853346\n",
      "[timestep: 8] [epoch: 27451] loss: 0.1133369952\n",
      "[timestep: 8] [epoch: 27481] loss: 0.1135159284\n",
      "[timestep: 8] [epoch: 27511] loss: 0.1133827269\n",
      "[timestep: 8] [epoch: 27541] loss: 0.1141614318\n",
      "[timestep: 8] [epoch: 27571] loss: 0.1133635640\n",
      "[timestep: 8] [epoch: 27601] loss: 0.1133583486\n",
      "[timestep: 8] [epoch: 27631] loss: 0.1134362966\n",
      "[timestep: 8] [epoch: 27661] loss: 0.1133302450\n",
      "[timestep: 8] [epoch: 27691] loss: 0.1134138182\n",
      "[timestep: 8] [epoch: 27721] loss: 0.1133956388\n",
      "[timestep: 8] [epoch: 27751] loss: 0.1136191487\n",
      "[timestep: 8] [epoch: 27781] loss: 0.1134765968\n",
      "[timestep: 8] [epoch: 27811] loss: 0.1134620309\n",
      "[timestep: 8] [epoch: 27841] loss: 0.1134495735\n",
      "[timestep: 8] [epoch: 27871] loss: 0.1137659848\n",
      "[timestep: 8] [epoch: 27901] loss: 0.1133958474\n",
      "[timestep: 8] [epoch: 27931] loss: 0.1133315265\n",
      "[timestep: 8] [epoch: 27961] loss: 0.1135775149\n",
      "[timestep: 8] [epoch: 27991] loss: 0.1134013087\n",
      "[timestep: 8] [epoch: 28021] loss: 0.1133280993\n",
      "[timestep: 8] [epoch: 28051] loss: 0.1134911478\n",
      "[timestep: 8] [epoch: 28081] loss: 0.1133394018\n",
      "[timestep: 8] [epoch: 28111] loss: 0.1134370118\n",
      "[timestep: 8] [epoch: 28141] loss: 0.1133399159\n",
      "[timestep: 8] [epoch: 28171] loss: 0.1133505851\n",
      "[timestep: 8] [epoch: 28201] loss: 0.1134931594\n",
      "[timestep: 8] [epoch: 28231] loss: 0.1140723675\n",
      "[timestep: 8] [epoch: 28261] loss: 0.1134278178\n",
      "[timestep: 8] [epoch: 28291] loss: 0.1135151237\n",
      "[timestep: 8] [epoch: 28321] loss: 0.1137816682\n",
      "[timestep: 8] [epoch: 28351] loss: 0.1134187579\n",
      "[timestep: 8] [epoch: 28381] loss: 0.1134129912\n",
      "[timestep: 8] [epoch: 28411] loss: 0.1133377850\n",
      "[timestep: 8] [epoch: 28441] loss: 0.1134368181\n",
      "[timestep: 8] [epoch: 28471] loss: 0.1137053743\n",
      "[timestep: 8] [epoch: 28501] loss: 0.1133815721\n",
      "[timestep: 8] [epoch: 28531] loss: 0.1133307964\n",
      "[timestep: 8] [epoch: 28561] loss: 0.1133581996\n",
      "[timestep: 8] [epoch: 28591] loss: 0.1133461595\n",
      "[timestep: 8] [epoch: 28621] loss: 0.1135839522\n",
      "[timestep: 8] [epoch: 28651] loss: 0.1134359986\n",
      "[timestep: 8] [epoch: 28681] loss: 0.1135329977\n",
      "[timestep: 8] [epoch: 28711] loss: 0.1134128049\n",
      "[timestep: 8] [epoch: 28741] loss: 0.1135235801\n",
      "[timestep: 8] [epoch: 28771] loss: 0.1133784354\n",
      "[timestep: 8] [epoch: 28801] loss: 0.1133314073\n",
      "[timestep: 8] [epoch: 28831] loss: 0.1134738326\n",
      "[timestep: 8] [epoch: 28861] loss: 0.1135586724\n",
      "[timestep: 8] [epoch: 28891] loss: 0.1133459359\n",
      "[timestep: 8] [epoch: 28921] loss: 0.1133601665\n",
      "[timestep: 8] [epoch: 28951] loss: 0.1134075075\n",
      "[timestep: 8] [epoch: 28981] loss: 0.1134929806\n",
      "[timestep: 8] [epoch: 29011] loss: 0.1134771109\n",
      "[timestep: 8] [epoch: 29041] loss: 0.1135935113\n",
      "[timestep: 8] [epoch: 29071] loss: 0.1135563031\n",
      "[timestep: 8] [epoch: 29101] loss: 0.1133800149\n",
      "[timestep: 8] [epoch: 29131] loss: 0.1133644283\n",
      "[timestep: 8] [epoch: 29161] loss: 0.1135359854\n",
      "[timestep: 8] [epoch: 29191] loss: 0.1133830398\n",
      "[timestep: 8] [epoch: 29221] loss: 0.1135059297\n",
      "[timestep: 8] [epoch: 29251] loss: 0.1134430096\n",
      "[timestep: 8] [epoch: 29281] loss: 0.1134537682\n",
      "[timestep: 8] [epoch: 29311] loss: 0.1134819388\n",
      "[timestep: 8] [epoch: 29341] loss: 0.1133962646\n",
      "[timestep: 8] [epoch: 29371] loss: 0.1134651825\n",
      "[timestep: 8] [epoch: 29401] loss: 0.1134786755\n",
      "[timestep: 8] [epoch: 29431] loss: 0.1133419275\n",
      "[timestep: 8] [epoch: 29461] loss: 0.1133654937\n",
      "[timestep: 8] [epoch: 29491] loss: 0.1134723723\n",
      "[timestep: 8] [epoch: 29521] loss: 0.1133998632\n",
      "[timestep: 8] [epoch: 29551] loss: 0.1133210808\n",
      "[timestep: 8] [epoch: 29581] loss: 0.1134974211\n",
      "[timestep: 8] [epoch: 29611] loss: 0.1133179441\n",
      "[timestep: 8] [epoch: 29641] loss: 0.1133638769\n",
      "[timestep: 8] [epoch: 29671] loss: 0.1134015098\n",
      "[timestep: 8] [epoch: 29701] loss: 0.1133329794\n",
      "[timestep: 8] [epoch: 29731] loss: 0.1134449244\n",
      "[timestep: 8] [epoch: 29761] loss: 0.1134501249\n",
      "[timestep: 8] [epoch: 29791] loss: 0.1135251746\n",
      "[timestep: 8] [epoch: 29821] loss: 0.1136803180\n",
      "[timestep: 8] [epoch: 29851] loss: 0.1135131940\n",
      "[timestep: 8] [epoch: 29881] loss: 0.1137637347\n",
      "[timestep: 8] [epoch: 29911] loss: 0.1133386642\n",
      "[timestep: 8] [epoch: 29941] loss: 0.1134067029\n",
      "[timestep: 8] [epoch: 29971] loss: 0.1135979146\n",
      "[timestep: 8] [epoch: 30001] loss: 0.1134980768\n",
      "[timestep: 8] [epoch: 30031] loss: 0.1134047359\n",
      "[timestep: 8] [epoch: 30061] loss: 0.1134086847\n",
      "[timestep: 8] [epoch: 30091] loss: 0.1133717969\n",
      "[timestep: 8] [epoch: 30121] loss: 0.1133804172\n",
      "[timestep: 8] [epoch: 30151] loss: 0.1133950651\n",
      "[timestep: 8] [epoch: 30181] loss: 0.1134418994\n",
      "[timestep: 8] [epoch: 30211] loss: 0.1133511066\n",
      "[timestep: 8] [epoch: 30241] loss: 0.1134677082\n",
      "[timestep: 8] [epoch: 30271] loss: 0.1134059057\n",
      "[timestep: 8] [epoch: 30301] loss: 0.1133347005\n",
      "[timestep: 8] [epoch: 30331] loss: 0.1135179549\n",
      "[timestep: 8] [epoch: 30361] loss: 0.1133966893\n",
      "[timestep: 8] [epoch: 30391] loss: 0.1137490943\n",
      "[timestep: 8] [epoch: 30421] loss: 0.1133652180\n",
      "[timestep: 8] [epoch: 30451] loss: 0.1134368256\n",
      "[timestep: 8] [epoch: 30481] loss: 0.1135836989\n",
      "[timestep: 8] [epoch: 30511] loss: 0.1134499460\n",
      "[timestep: 8] [epoch: 30541] loss: 0.1135989875\n",
      "[timestep: 8] [epoch: 30571] loss: 0.1133957356\n",
      "[timestep: 8] [epoch: 30601] loss: 0.1133437902\n",
      "[timestep: 8] [epoch: 30631] loss: 0.1136435270\n",
      "[timestep: 8] [epoch: 30661] loss: 0.1134105772\n",
      "[timestep: 8] [epoch: 30691] loss: 0.1133525893\n",
      "[timestep: 8] [epoch: 30721] loss: 0.1133337617\n",
      "[timestep: 8] [epoch: 30751] loss: 0.1135984063\n",
      "[timestep: 8] [epoch: 30781] loss: 0.1133228391\n",
      "[timestep: 8] [epoch: 30811] loss: 0.1133530885\n",
      "[timestep: 8] [epoch: 30841] loss: 0.0694387183\n",
      "[timestep: 8] [epoch: 30871] loss: 0.0660339072\n",
      "[timestep: 8] [epoch: 30901] loss: 0.0642645955\n",
      "[timestep: 8] [epoch: 30931] loss: 0.0639348850\n",
      "[timestep: 8] [epoch: 30961] loss: 0.0626482069\n",
      "[timestep: 8] [epoch: 30991] loss: 0.0154127963\n",
      "[timestep: 8] [epoch: 31021] loss: 0.0031583589\n",
      "[timestep: 8] [epoch: 31051] loss: 0.0025290712\n",
      "[timestep: 8] [epoch: 31081] loss: 0.0024832706\n",
      "[timestep: 8] [epoch: 31111] loss: 0.0024719606\n",
      "[timestep: 8] [epoch: 31141] loss: 0.0024655522\n",
      "[timestep: 8] [epoch: 31171] loss: 0.0024895468\n",
      "[timestep: 8] [epoch: 31201] loss: 0.0024641955\n",
      "[timestep: 8] [epoch: 31231] loss: 0.0024631256\n",
      "[timestep: 8] [epoch: 31261] loss: 0.0024596965\n",
      "[timestep: 8] [epoch: 31291] loss: 0.0025152662\n",
      "[timestep: 8] [epoch: 31321] loss: 0.0024558192\n",
      "[timestep: 8] [epoch: 31351] loss: 0.0024933168\n",
      "[timestep: 8] [epoch: 31381] loss: 0.0024262161\n",
      "[timestep: 8] [epoch: 31411] loss: 0.0024728125\n",
      "[timestep: 8] [epoch: 31441] loss: 0.0024183900\n",
      "[timestep: 8] [epoch: 31471] loss: 0.0024430896\n",
      "[timestep: 8] [epoch: 31501] loss: 0.0024184999\n",
      "[timestep: 8] [epoch: 31531] loss: 0.0026236784\n",
      "[timestep: 8] [epoch: 31561] loss: 0.0025718524\n",
      "[timestep: 8] [epoch: 31591] loss: 0.0024443276\n",
      "[timestep: 8] [epoch: 31621] loss: 0.0024334514\n",
      "[timestep: 8] [epoch: 31651] loss: 0.0024209849\n",
      "[timestep: 8] [epoch: 31681] loss: 0.0025462208\n",
      "[timestep: 8] [epoch: 31711] loss: 0.0024773681\n",
      "[timestep: 8] [epoch: 31741] loss: 0.0025163409\n",
      "[timestep: 8] [epoch: 31771] loss: 0.0025189936\n",
      "[timestep: 8] [epoch: 31801] loss: 0.0024978886\n",
      "[timestep: 8] [epoch: 31831] loss: 0.0024395748\n",
      "[timestep: 8] [epoch: 31861] loss: 0.0024425110\n",
      "[timestep: 8] [epoch: 31891] loss: 0.0024807202\n",
      "[timestep: 8] [epoch: 31921] loss: 0.0020239602\n",
      "[timestep: 8] [epoch: 31951] loss: 0.0017914232\n",
      "[timestep: 8] [epoch: 31981] loss: 0.0019845637\n",
      "[timestep: 8] [epoch: 32011] loss: 0.0017623338\n",
      "[timestep: 8] [epoch: 32041] loss: 0.0017532532\n",
      "[timestep: 8] [epoch: 32071] loss: 0.0018164419\n",
      "[timestep: 8] [epoch: 32101] loss: 0.0017265929\n",
      "[timestep: 8] [epoch: 32131] loss: 0.0020278154\n",
      "[timestep: 8] [epoch: 32161] loss: 0.0018807484\n",
      "[timestep: 8] [epoch: 32191] loss: 0.0017162404\n",
      "[timestep: 8] [epoch: 32221] loss: 0.0017823263\n",
      "[timestep: 8] [epoch: 32251] loss: 0.0017640993\n",
      "[timestep: 8] [epoch: 32281] loss: 0.0017369321\n",
      "[timestep: 8] [epoch: 32311] loss: 0.0017406599\n",
      "[timestep: 8] [epoch: 32341] loss: 0.0017285142\n",
      "[timestep: 8] [epoch: 32371] loss: 0.0019561299\n",
      "[timestep: 8] [epoch: 32401] loss: 0.0017454115\n",
      "[timestep: 8] [epoch: 32431] loss: 0.0018007816\n",
      "[timestep: 8] [epoch: 32461] loss: 0.0018527469\n",
      "[timestep: 8] [epoch: 32491] loss: 0.0018660536\n",
      "[timestep: 8] [epoch: 32521] loss: 0.0018215663\n",
      "[timestep: 8] [epoch: 32551] loss: 0.0017565462\n",
      "[timestep: 8] [epoch: 32581] loss: 0.0018793285\n",
      "[timestep: 8] [epoch: 32611] loss: 0.0017734568\n",
      "[timestep: 8] [epoch: 32641] loss: 0.0017639260\n",
      "[timestep: 8] [epoch: 32671] loss: 0.0017991078\n",
      "[timestep: 8] [epoch: 32701] loss: 0.0017448242\n",
      "[timestep: 8] [epoch: 32731] loss: 0.0018167018\n",
      "[timestep: 8] [epoch: 32761] loss: 0.0017310751\n",
      "[timestep: 8] [epoch: 32791] loss: 0.0018454383\n",
      "[timestep: 8] [epoch: 32821] loss: 0.0019243506\n",
      "[timestep: 8] [epoch: 32851] loss: 0.0017893914\n",
      "[timestep: 8] [epoch: 32881] loss: 0.0017806903\n",
      "[timestep: 8] [epoch: 32911] loss: 0.0019027742\n",
      "[timestep: 8] [epoch: 32941] loss: 0.0017899704\n",
      "[timestep: 8] [epoch: 32971] loss: 0.0017544450\n",
      "[timestep: 8] [epoch: 33001] loss: 0.0019423134\n",
      "[timestep: 8] [epoch: 33031] loss: 0.0019359818\n",
      "[timestep: 8] [epoch: 33061] loss: 0.0018835836\n",
      "[timestep: 8] [epoch: 33091] loss: 0.0017623032\n",
      "[timestep: 8] [epoch: 33121] loss: 0.0018843226\n",
      "[timestep: 8] [epoch: 33151] loss: 0.0017967052\n",
      "[timestep: 8] [epoch: 33181] loss: 0.0017499194\n",
      "[timestep: 8] [epoch: 33211] loss: 0.0018425680\n",
      "[timestep: 8] [epoch: 33241] loss: 0.0017191309\n",
      "[timestep: 8] [epoch: 33271] loss: 0.0017143635\n",
      "[timestep: 8] [epoch: 33301] loss: 0.0017678230\n",
      "[timestep: 8] [epoch: 33331] loss: 0.0017397667\n",
      "[timestep: 8] [epoch: 33361] loss: 0.0018697404\n",
      "[timestep: 8] [epoch: 33391] loss: 0.0017456297\n",
      "[timestep: 8] [epoch: 33421] loss: 0.0017316514\n",
      "[timestep: 8] [epoch: 33451] loss: 0.0017256616\n",
      "[timestep: 8] [epoch: 33481] loss: 0.0017121995\n",
      "[timestep: 8] [epoch: 33511] loss: 0.0018063083\n",
      "[timestep: 8] [epoch: 33541] loss: 0.0017717495\n",
      "[timestep: 8] [epoch: 33571] loss: 0.0018560039\n",
      "[timestep: 8] [epoch: 33601] loss: 0.0018160155\n",
      "[timestep: 8] [epoch: 33631] loss: 0.0017399034\n",
      "[timestep: 8] [epoch: 33661] loss: 0.0018046880\n",
      "[timestep: 8] [epoch: 33691] loss: 0.0018676468\n",
      "[timestep: 8] [epoch: 33721] loss: 0.0017641804\n",
      "[timestep: 8] [epoch: 33751] loss: 0.0017549202\n",
      "[timestep: 8] [epoch: 33781] loss: 0.0017527936\n",
      "[timestep: 8] [epoch: 33811] loss: 0.0017714397\n",
      "[timestep: 8] [epoch: 33841] loss: 0.0018157518\n",
      "[timestep: 8] [epoch: 33871] loss: 0.0017895708\n",
      "[timestep: 8] [epoch: 33901] loss: 0.0018465584\n",
      "[timestep: 8] [epoch: 33931] loss: 0.0017409362\n",
      "[timestep: 8] [epoch: 33961] loss: 0.0017398335\n",
      "[timestep: 8] [epoch: 33991] loss: 0.0017210623\n",
      "[timestep: 8] [epoch: 34021] loss: 0.0018485673\n",
      "[timestep: 8] [epoch: 34051] loss: 0.0019746164\n",
      "[timestep: 8] [epoch: 34081] loss: 0.0019268626\n",
      "[timestep: 8] [epoch: 34111] loss: 0.0017370782\n",
      "[timestep: 8] [epoch: 34141] loss: 0.0018278264\n",
      "[timestep: 8] [epoch: 34171] loss: 0.0018633612\n",
      "[timestep: 8] [epoch: 34201] loss: 0.0017469956\n",
      "[timestep: 8] [epoch: 34231] loss: 0.0017571832\n",
      "[timestep: 8] [epoch: 34261] loss: 0.0017202558\n",
      "[timestep: 8] [epoch: 34291] loss: 0.0017675960\n",
      "[timestep: 8] [epoch: 34321] loss: 0.0017495444\n",
      "[timestep: 8] [epoch: 34351] loss: 0.0018030371\n",
      "[timestep: 8] [epoch: 34381] loss: 0.0018031588\n",
      "[timestep: 8] [epoch: 34411] loss: 0.0019140409\n",
      "[timestep: 8] [epoch: 34441] loss: 0.0017579886\n",
      "[timestep: 8] [epoch: 34471] loss: 0.0020640793\n",
      "[timestep: 8] [epoch: 34501] loss: 0.0017798622\n",
      "[timestep: 8] [epoch: 34531] loss: 0.0019154728\n",
      "[timestep: 8] [epoch: 34561] loss: 0.0018103597\n",
      "[timestep: 8] [epoch: 34591] loss: 0.0017982441\n",
      "[timestep: 8] [epoch: 34621] loss: 0.0017789527\n",
      "[timestep: 8] [epoch: 34651] loss: 0.0017949238\n",
      "[timestep: 8] [epoch: 34681] loss: 0.0018996797\n",
      "[timestep: 8] [epoch: 34711] loss: 0.0018367420\n",
      "[timestep: 8] [epoch: 34741] loss: 0.0018423147\n",
      "[timestep: 8] [epoch: 34771] loss: 0.0017739066\n",
      "[timestep: 8] [epoch: 34801] loss: 0.0017261012\n",
      "[timestep: 8] [epoch: 34831] loss: 0.0017754547\n",
      "[timestep: 8] [epoch: 34861] loss: 0.0017202087\n",
      "[timestep: 8] [epoch: 34891] loss: 0.0017193260\n",
      "[timestep: 8] [epoch: 34921] loss: 0.0017528184\n",
      "[timestep: 8] [epoch: 34951] loss: 0.0019954164\n",
      "[timestep: 8] [epoch: 34981] loss: 0.0017479174\n",
      "[timestep: 8] [epoch: 35011] loss: 0.0017535528\n",
      "[timestep: 8] [epoch: 35041] loss: 0.0018702736\n",
      "[timestep: 8] [epoch: 35071] loss: 0.0017164100\n",
      "[timestep: 8] [epoch: 35101] loss: 0.0018243564\n",
      "[timestep: 8] [epoch: 35131] loss: 0.0017628227\n",
      "[timestep: 8] [epoch: 35161] loss: 0.0017355047\n",
      "[timestep: 8] [epoch: 35191] loss: 0.0017808678\n",
      "[timestep: 8] [epoch: 35221] loss: 0.0017146685\n",
      "[timestep: 8] [epoch: 35251] loss: 0.0019324187\n",
      "[timestep: 8] [epoch: 35281] loss: 0.0018354347\n",
      "[timestep: 8] [epoch: 35311] loss: 0.0017310141\n",
      "[timestep: 8] [epoch: 35341] loss: 0.0019133331\n",
      "[timestep: 8] [epoch: 35371] loss: 0.0017483772\n",
      "[timestep: 8] [epoch: 35401] loss: 0.0017558151\n",
      "[timestep: 8] [epoch: 35431] loss: 0.0017902885\n",
      "[timestep: 8] [epoch: 35461] loss: 0.0018004081\n",
      "[timestep: 8] [epoch: 35491] loss: 0.0019535422\n",
      "[timestep: 8] [epoch: 35521] loss: 0.0017688368\n",
      "[timestep: 8] [epoch: 35551] loss: 0.0017245533\n",
      "[timestep: 8] [epoch: 35581] loss: 0.0017119783\n",
      "[timestep: 8] [epoch: 35611] loss: 0.0017939976\n",
      "[timestep: 8] [epoch: 35641] loss: 0.0017744318\n",
      "[timestep: 8] [epoch: 35671] loss: 0.0019124431\n",
      "[timestep: 8] [epoch: 35701] loss: 0.0017346934\n",
      "[timestep: 8] [epoch: 35731] loss: 0.0018230550\n",
      "[timestep: 8] [epoch: 35761] loss: 0.0017765480\n",
      "[timestep: 8] [epoch: 35791] loss: 0.0017698314\n",
      "[timestep: 8] [epoch: 35821] loss: 0.0017290841\n",
      "[timestep: 8] [epoch: 35851] loss: 0.0017365300\n",
      "[timestep: 8] [epoch: 35881] loss: 0.0017660356\n",
      "[timestep: 8] [epoch: 35911] loss: 0.0018557090\n",
      "[timestep: 8] [epoch: 35941] loss: 0.0017304053\n",
      "[timestep: 8] [epoch: 35971] loss: 0.0017192576\n",
      "[timestep: 8] [epoch: 36001] loss: 0.0017414147\n",
      "[timestep: 8] [epoch: 36031] loss: 0.0017883196\n",
      "[timestep: 8] [epoch: 36061] loss: 0.0017490569\n",
      "[timestep: 8] [epoch: 36091] loss: 0.0018280214\n",
      "[timestep: 8] [epoch: 36121] loss: 0.0017918900\n",
      "[timestep: 8] [epoch: 36151] loss: 0.0018000004\n",
      "[timestep: 8] [epoch: 36181] loss: 0.0017593580\n",
      "[timestep: 8] [epoch: 36211] loss: 0.0017145905\n",
      "[timestep: 8] [epoch: 36241] loss: 0.0016831968\n",
      "[timestep: 8] [epoch: 36271] loss: 0.0016986176\n",
      "[timestep: 8] [epoch: 36301] loss: 0.0018413763\n",
      "[timestep: 8] [epoch: 36331] loss: 0.0016715999\n",
      "[timestep: 8] [epoch: 36361] loss: 0.0017181060\n",
      "[timestep: 8] [epoch: 36391] loss: 0.0018451269\n",
      "[timestep: 8] [epoch: 36421] loss: 0.0017153971\n",
      "[timestep: 8] [epoch: 36451] loss: 0.0016970278\n",
      "[timestep: 8] [epoch: 36481] loss: 0.0017509700\n",
      "[timestep: 8] [epoch: 36511] loss: 0.0017516760\n",
      "[timestep: 8] [epoch: 36541] loss: 0.0016922217\n",
      "[timestep: 8] [epoch: 36571] loss: 0.0016900070\n",
      "[timestep: 8] [epoch: 36601] loss: 0.0016869112\n",
      "[timestep: 8] [epoch: 36631] loss: 0.0017136763\n",
      "[timestep: 8] [epoch: 36661] loss: 0.0017045056\n",
      "[timestep: 8] [epoch: 36691] loss: 0.0017341229\n",
      "[timestep: 8] [epoch: 36721] loss: 0.0017581331\n",
      "[timestep: 8] [epoch: 36751] loss: 0.0017175020\n",
      "[timestep: 8] [epoch: 36781] loss: 0.0017220706\n",
      "[timestep: 8] [epoch: 36811] loss: 0.0017984601\n",
      "[timestep: 8] [epoch: 36841] loss: 0.0017405640\n",
      "[timestep: 8] [epoch: 36871] loss: 0.0017592391\n",
      "[timestep: 8] [epoch: 36901] loss: 0.0018078001\n",
      "[timestep: 8] [epoch: 36931] loss: 0.0017369727\n",
      "[timestep: 8] [epoch: 36961] loss: 0.0016947160\n",
      "[timestep: 8] [epoch: 36991] loss: 0.0017652675\n",
      "[timestep: 8] [epoch: 37021] loss: 0.0017116703\n",
      "[timestep: 8] [epoch: 37051] loss: 0.0018074131\n",
      "[timestep: 8] [epoch: 37081] loss: 0.0016994234\n",
      "[timestep: 8] [epoch: 37111] loss: 0.0018063434\n",
      "[timestep: 8] [epoch: 37141] loss: 0.0017203500\n",
      "[timestep: 8] [epoch: 37171] loss: 0.0016989538\n",
      "[timestep: 8] [epoch: 37201] loss: 0.0018027214\n",
      "[timestep: 8] [epoch: 37231] loss: 0.0017907758\n",
      "[timestep: 8] [epoch: 37261] loss: 0.0017485346\n",
      "[timestep: 8] [epoch: 37291] loss: 0.0018092431\n",
      "[timestep: 8] [epoch: 37321] loss: 0.0017068582\n",
      "[timestep: 8] [epoch: 37351] loss: 0.0018448179\n",
      "[timestep: 8] [epoch: 37381] loss: 0.0017925717\n",
      "[timestep: 8] [epoch: 37411] loss: 0.0017193739\n",
      "[timestep: 8] [epoch: 37441] loss: 0.0015483091\n",
      "[timestep: 8] [epoch: 37471] loss: 0.0011686722\n",
      "[timestep: 8] [epoch: 37501] loss: 0.0011108576\n",
      "[timestep: 8] [epoch: 37531] loss: 0.0012399002\n",
      "[timestep: 8] [epoch: 37561] loss: 0.0012423713\n",
      "[timestep: 8] [epoch: 37591] loss: 0.0012168527\n",
      "[timestep: 8] [epoch: 37621] loss: 0.0011828931\n",
      "[timestep: 8] [epoch: 37651] loss: 0.0012116762\n",
      "0.01\n",
      "[timestep: 9] [epoch: 1] loss: 0.8733338118\n",
      "[timestep: 9] [epoch: 31] loss: 0.0338325873\n",
      "[timestep: 9] [epoch: 61] loss: 0.0109544666\n",
      "[timestep: 9] [epoch: 91] loss: 0.0101342760\n",
      "[timestep: 9] [epoch: 121] loss: 0.0117169358\n",
      "[timestep: 9] [epoch: 151] loss: 0.0099200308\n",
      "[timestep: 9] [epoch: 181] loss: 0.0084388200\n",
      "[timestep: 9] [epoch: 211] loss: 0.0077143628\n",
      "[timestep: 9] [epoch: 241] loss: 0.0160041563\n",
      "[timestep: 9] [epoch: 271] loss: 0.0047580460\n",
      "[timestep: 9] [epoch: 301] loss: 0.0042875437\n",
      "[timestep: 9] [epoch: 331] loss: 0.0022488991\n",
      "[timestep: 9] [epoch: 361] loss: 0.0118445726\n",
      "[timestep: 9] [epoch: 391] loss: 0.0030641449\n",
      "[timestep: 9] [epoch: 421] loss: 0.0047148080\n",
      "0.01\n",
      "[timestep: 10] [epoch: 1] loss: 0.8586877584\n",
      "[timestep: 10] [epoch: 31] loss: 0.0409040004\n",
      "[timestep: 10] [epoch: 61] loss: 0.0029559336\n",
      "0.01\n",
      "[timestep: 11] [epoch: 1] loss: 0.8621681929\n",
      "[timestep: 11] [epoch: 31] loss: 0.0442636609\n",
      "[timestep: 11] [epoch: 61] loss: 0.0065864874\n",
      "0.01\n",
      "[timestep: 12] [epoch: 1] loss: 0.8461179733\n",
      "[timestep: 12] [epoch: 31] loss: 0.0400669128\n",
      "[timestep: 12] [epoch: 61] loss: 0.0118671563\n",
      "[timestep: 12] [epoch: 91] loss: 0.0100605506\n",
      "[timestep: 12] [epoch: 121] loss: 0.0027093545\n",
      "[timestep: 12] [epoch: 151] loss: 0.0214605369\n",
      "[timestep: 12] [epoch: 181] loss: 0.0022111950\n",
      "[timestep: 12] [epoch: 211] loss: 0.0030316887\n",
      "[timestep: 12] [epoch: 241] loss: 0.0015987067\n",
      "[timestep: 12] [epoch: 271] loss: 0.0058843079\n",
      "[timestep: 12] [epoch: 301] loss: 0.0185910910\n",
      "[timestep: 12] [epoch: 331] loss: 0.0026769151\n",
      "0.01\n",
      "[timestep: 13] [epoch: 1] loss: 0.8472467661\n",
      "[timestep: 13] [epoch: 31] loss: 0.0438063107\n",
      "[timestep: 13] [epoch: 61] loss: 0.0042297509\n",
      "[timestep: 13] [epoch: 91] loss: 0.0024059913\n",
      "[timestep: 13] [epoch: 121] loss: 0.0022773468\n",
      "[timestep: 13] [epoch: 151] loss: 0.0072783423\n",
      "[timestep: 13] [epoch: 181] loss: 0.0027791900\n",
      "[timestep: 13] [epoch: 211] loss: 0.0030592836\n",
      "[timestep: 13] [epoch: 241] loss: 0.0061646188\n",
      "[timestep: 13] [epoch: 271] loss: 0.0019199733\n",
      "[timestep: 13] [epoch: 301] loss: 0.0153589491\n",
      "[timestep: 13] [epoch: 331] loss: 0.0022995761\n",
      "0.01\n",
      "[timestep: 14] [epoch: 1] loss: 0.8428708315\n",
      "[timestep: 14] [epoch: 31] loss: 0.0362045020\n",
      "[timestep: 14] [epoch: 61] loss: 0.0057286480\n",
      "[timestep: 14] [epoch: 91] loss: 0.0021813780\n",
      "[timestep: 14] [epoch: 121] loss: 0.0026098674\n",
      "[timestep: 14] [epoch: 151] loss: 0.0036706447\n",
      "[timestep: 14] [epoch: 181] loss: 0.0030385694\n",
      "[timestep: 14] [epoch: 211] loss: 0.0101744793\n",
      "[timestep: 14] [epoch: 241] loss: 0.0029081856\n",
      "[timestep: 14] [epoch: 271] loss: 0.0056074550\n",
      "[timestep: 14] [epoch: 301] loss: 0.0114451516\n",
      "[timestep: 14] [epoch: 331] loss: 0.0074251359\n",
      "[timestep: 14] [epoch: 361] loss: 0.0027055668\n",
      "[timestep: 14] [epoch: 391] loss: 0.0132644139\n",
      "[timestep: 14] [epoch: 421] loss: 0.0037271571\n",
      "[timestep: 14] [epoch: 451] loss: 0.0169591717\n",
      "[timestep: 14] [epoch: 481] loss: 0.0068262173\n",
      "[timestep: 14] [epoch: 511] loss: 0.0051619187\n",
      "[timestep: 14] [epoch: 541] loss: 0.0079663135\n",
      "[timestep: 14] [epoch: 571] loss: 0.0065999581\n",
      "[timestep: 14] [epoch: 601] loss: 0.0033888654\n",
      "[timestep: 14] [epoch: 631] loss: 0.0032557887\n",
      "[timestep: 14] [epoch: 661] loss: 0.0266164020\n",
      "[timestep: 14] [epoch: 691] loss: 0.0052988664\n",
      "[timestep: 14] [epoch: 721] loss: 0.0049796985\n",
      "[timestep: 14] [epoch: 751] loss: 0.0028992458\n",
      "[timestep: 14] [epoch: 781] loss: 0.0119745061\n",
      "[timestep: 14] [epoch: 811] loss: 0.0026075270\n",
      "[timestep: 14] [epoch: 841] loss: 0.0043523321\n",
      "[timestep: 14] [epoch: 871] loss: 0.0041679386\n",
      "[timestep: 14] [epoch: 901] loss: 0.0017485728\n",
      "[timestep: 14] [epoch: 931] loss: 0.0130803827\n",
      "[timestep: 14] [epoch: 961] loss: 0.0021897112\n",
      "[timestep: 14] [epoch: 991] loss: 0.0031744698\n",
      "[timestep: 14] [epoch: 1021] loss: 0.0019909218\n",
      "[timestep: 14] [epoch: 1051] loss: 0.0068348530\n",
      "[timestep: 14] [epoch: 1081] loss: 0.0036880770\n",
      "[timestep: 14] [epoch: 1111] loss: 0.0061022956\n",
      "[timestep: 14] [epoch: 1141] loss: 0.0046923854\n",
      "[timestep: 14] [epoch: 1171] loss: 0.0102827121\n",
      "[timestep: 14] [epoch: 1201] loss: 0.0122914612\n",
      "[timestep: 14] [epoch: 1231] loss: 0.0028784606\n",
      "[timestep: 14] [epoch: 1261] loss: 0.0173155721\n",
      "[timestep: 14] [epoch: 1291] loss: 0.0024177819\n",
      "[timestep: 14] [epoch: 1321] loss: 0.0047255270\n",
      "[timestep: 14] [epoch: 1351] loss: 0.0056263069\n",
      "[timestep: 14] [epoch: 1381] loss: 0.0024352404\n",
      "[timestep: 14] [epoch: 1411] loss: 0.0037283148\n",
      "[timestep: 14] [epoch: 1441] loss: 0.0036600058\n",
      "[timestep: 14] [epoch: 1471] loss: 0.0217906237\n",
      "[timestep: 14] [epoch: 1501] loss: 0.0031381494\n",
      "[timestep: 14] [epoch: 1531] loss: 0.0022967202\n",
      "[timestep: 14] [epoch: 1561] loss: 0.0051727062\n",
      "[timestep: 14] [epoch: 1591] loss: 0.0063544880\n",
      "[timestep: 14] [epoch: 1621] loss: 0.0099484064\n",
      "[timestep: 14] [epoch: 1651] loss: 0.0086621959\n",
      "[timestep: 14] [epoch: 1681] loss: 0.0024341594\n",
      "[timestep: 14] [epoch: 1711] loss: 0.0045940205\n",
      "[timestep: 14] [epoch: 1741] loss: 0.0025358195\n",
      "[timestep: 14] [epoch: 1771] loss: 0.0023190300\n",
      "[timestep: 14] [epoch: 1801] loss: 0.0022850928\n",
      "[timestep: 14] [epoch: 1831] loss: 0.0034245839\n",
      "[timestep: 14] [epoch: 1861] loss: 0.0056820624\n",
      "[timestep: 14] [epoch: 1891] loss: 0.0025956675\n",
      "[timestep: 14] [epoch: 1921] loss: 0.0016173513\n",
      "[timestep: 14] [epoch: 1951] loss: 0.0142855588\n",
      "[timestep: 14] [epoch: 1981] loss: 0.0026100497\n",
      "[timestep: 14] [epoch: 2011] loss: 0.0017395150\n",
      "[timestep: 14] [epoch: 2041] loss: 0.0039820713\n",
      "[timestep: 14] [epoch: 2071] loss: 0.0032680300\n",
      "[timestep: 14] [epoch: 2101] loss: 0.0032652044\n",
      "[timestep: 14] [epoch: 2131] loss: 0.0044670380\n",
      "[timestep: 14] [epoch: 2161] loss: 0.0026816314\n",
      "[timestep: 14] [epoch: 2191] loss: 0.0024728149\n",
      "[timestep: 14] [epoch: 2221] loss: 0.0023356322\n",
      "[timestep: 14] [epoch: 2251] loss: 0.0082739927\n",
      "[timestep: 14] [epoch: 2281] loss: 0.0050139772\n",
      "[timestep: 14] [epoch: 2311] loss: 0.0026367288\n",
      "[timestep: 14] [epoch: 2341] loss: 0.0019272418\n",
      "[timestep: 14] [epoch: 2371] loss: 0.0047541009\n",
      "[timestep: 14] [epoch: 2401] loss: 0.0062337643\n",
      "[timestep: 14] [epoch: 2431] loss: 0.0089401612\n",
      "[timestep: 14] [epoch: 2461] loss: 0.0024940278\n",
      "[timestep: 14] [epoch: 2491] loss: 0.0019248734\n",
      "[timestep: 14] [epoch: 2521] loss: 0.0192053393\n",
      "[timestep: 14] [epoch: 2551] loss: 0.0031639552\n",
      "[timestep: 14] [epoch: 2581] loss: 0.0043758657\n",
      "[timestep: 14] [epoch: 2611] loss: 0.0080452487\n",
      "[timestep: 14] [epoch: 2641] loss: 0.0025292188\n",
      "[timestep: 14] [epoch: 2671] loss: 0.0072871251\n",
      "[timestep: 14] [epoch: 2701] loss: 0.0032297620\n",
      "[timestep: 14] [epoch: 2731] loss: 0.0055713356\n",
      "[timestep: 14] [epoch: 2761] loss: 0.0025050216\n",
      "[timestep: 14] [epoch: 2791] loss: 0.0022615809\n",
      "[timestep: 14] [epoch: 2821] loss: 0.0025105597\n",
      "[timestep: 14] [epoch: 2851] loss: 0.0023992909\n",
      "[timestep: 14] [epoch: 2881] loss: 0.0065488676\n",
      "[timestep: 14] [epoch: 2911] loss: 0.0021658307\n",
      "[timestep: 14] [epoch: 2941] loss: 0.0033598565\n",
      "[timestep: 14] [epoch: 2971] loss: 0.0038459853\n",
      "[timestep: 14] [epoch: 3001] loss: 0.0025562765\n",
      "[timestep: 14] [epoch: 3031] loss: 0.0041011591\n",
      "[timestep: 14] [epoch: 3061] loss: 0.0052508670\n",
      "[timestep: 14] [epoch: 3091] loss: 0.0048765065\n",
      "[timestep: 14] [epoch: 3121] loss: 0.0019708325\n",
      "[timestep: 14] [epoch: 3151] loss: 0.0147897070\n",
      "[timestep: 14] [epoch: 3181] loss: 0.0049984758\n",
      "[timestep: 14] [epoch: 3211] loss: 0.0021317457\n",
      "[timestep: 14] [epoch: 3241] loss: 0.0023800298\n",
      "[timestep: 14] [epoch: 3271] loss: 0.0020982393\n",
      "[timestep: 14] [epoch: 3301] loss: 0.0145088360\n",
      "[timestep: 14] [epoch: 3331] loss: 0.0025996747\n",
      "[timestep: 14] [epoch: 3361] loss: 0.0015786886\n",
      "[timestep: 14] [epoch: 3391] loss: 0.0011257838\n",
      "[timestep: 14] [epoch: 3421] loss: 0.0019685661\n",
      "[timestep: 14] [epoch: 3451] loss: 0.0126917474\n",
      "[timestep: 14] [epoch: 3481] loss: 0.0017531037\n",
      "[timestep: 14] [epoch: 3511] loss: 0.0018598496\n",
      "[timestep: 14] [epoch: 3541] loss: 0.0025707930\n",
      "[timestep: 14] [epoch: 3571] loss: 0.0027303763\n",
      "[timestep: 14] [epoch: 3601] loss: 0.0024388467\n",
      "[timestep: 14] [epoch: 3631] loss: 0.0017399704\n",
      "[timestep: 14] [epoch: 3661] loss: 0.0024939887\n",
      "[timestep: 14] [epoch: 3691] loss: 0.0019913139\n",
      "[timestep: 14] [epoch: 3721] loss: 0.0024166214\n",
      "[timestep: 14] [epoch: 3751] loss: 0.0020897938\n",
      "[timestep: 14] [epoch: 3781] loss: 0.0017158603\n",
      "[timestep: 14] [epoch: 3811] loss: 0.0037592580\n",
      "[timestep: 14] [epoch: 3841] loss: 0.0048562600\n",
      "[timestep: 14] [epoch: 3871] loss: 0.0018077786\n",
      "[timestep: 14] [epoch: 3901] loss: 0.0029508332\n",
      "[timestep: 14] [epoch: 3931] loss: 0.0018970498\n",
      "[timestep: 14] [epoch: 3961] loss: 0.0041552829\n",
      "[timestep: 14] [epoch: 3991] loss: 0.0023991247\n",
      "[timestep: 14] [epoch: 4021] loss: 0.0016575706\n",
      "[timestep: 14] [epoch: 4051] loss: 0.0012320143\n",
      "[timestep: 14] [epoch: 4081] loss: 0.0029617494\n",
      "[timestep: 14] [epoch: 4111] loss: 0.0021991613\n",
      "[timestep: 14] [epoch: 4141] loss: 0.0015543153\n",
      "[timestep: 14] [epoch: 4171] loss: 0.0028147458\n",
      "[timestep: 14] [epoch: 4201] loss: 0.0045339707\n",
      "[timestep: 14] [epoch: 4231] loss: 0.0014619299\n",
      "[timestep: 14] [epoch: 4261] loss: 0.0018892457\n",
      "0.01\n",
      "[timestep: 15] [epoch: 1] loss: 0.8476511240\n",
      "[timestep: 15] [epoch: 31] loss: 0.0270160548\n",
      "[timestep: 15] [epoch: 61] loss: 0.0029418273\n",
      "0.01\n",
      "[timestep: 16] [epoch: 1] loss: 0.8380701542\n",
      "[timestep: 16] [epoch: 31] loss: 0.0346093886\n",
      "[timestep: 16] [epoch: 61] loss: 0.0072571458\n",
      "[timestep: 16] [epoch: 91] loss: 0.0033969572\n",
      "0.01\n",
      "[timestep: 17] [epoch: 1] loss: 0.8179737329\n",
      "[timestep: 17] [epoch: 31] loss: 0.0542551950\n",
      "[timestep: 17] [epoch: 61] loss: 0.0090209562\n",
      "[timestep: 17] [epoch: 91] loss: 0.0030610752\n",
      "[timestep: 17] [epoch: 121] loss: 0.0073141912\n",
      "[timestep: 17] [epoch: 151] loss: 0.0162985157\n",
      "0.01\n",
      "[timestep: 18] [epoch: 1] loss: 0.8287886381\n",
      "[timestep: 18] [epoch: 31] loss: 0.0330685899\n",
      "[timestep: 18] [epoch: 61] loss: 0.0038984516\n",
      "[timestep: 18] [epoch: 91] loss: 0.0024186641\n",
      "[timestep: 18] [epoch: 121] loss: 0.0033274072\n",
      "[timestep: 18] [epoch: 151] loss: 0.0032975834\n",
      "[timestep: 18] [epoch: 181] loss: 0.0178445578\n",
      "[timestep: 18] [epoch: 211] loss: 0.0059071174\n",
      "[timestep: 18] [epoch: 241] loss: 0.0050761192\n",
      "[timestep: 18] [epoch: 271] loss: 0.0077367532\n",
      "[timestep: 18] [epoch: 301] loss: 0.0037865192\n",
      "[timestep: 18] [epoch: 331] loss: 0.0067147277\n",
      "[timestep: 18] [epoch: 361] loss: 0.0087954495\n",
      "[timestep: 18] [epoch: 391] loss: 0.0082428828\n",
      "[timestep: 18] [epoch: 421] loss: 0.0056793583\n",
      "[timestep: 18] [epoch: 451] loss: 0.0080954321\n",
      "[timestep: 18] [epoch: 481] loss: 0.0202029180\n",
      "[timestep: 18] [epoch: 511] loss: 0.0019536715\n",
      "[timestep: 18] [epoch: 541] loss: 0.0048072292\n",
      "[timestep: 18] [epoch: 571] loss: 0.0179082919\n",
      "[timestep: 18] [epoch: 601] loss: 0.0096326200\n",
      "[timestep: 18] [epoch: 631] loss: 0.0042684437\n",
      "[timestep: 18] [epoch: 661] loss: 0.0030568945\n",
      "[timestep: 18] [epoch: 691] loss: 0.0262948349\n",
      "[timestep: 18] [epoch: 721] loss: 0.0211980492\n",
      "[timestep: 18] [epoch: 751] loss: 0.0077820909\n",
      "[timestep: 18] [epoch: 781] loss: 0.0055177612\n",
      "[timestep: 18] [epoch: 811] loss: 0.0183680244\n",
      "0.01\n",
      "[timestep: 19] [epoch: 1] loss: 0.8209803104\n",
      "[timestep: 19] [epoch: 31] loss: 0.0295384247\n",
      "[timestep: 19] [epoch: 61] loss: 0.0036168699\n",
      "[timestep: 19] [epoch: 91] loss: 0.0139532890\n",
      "[timestep: 19] [epoch: 121] loss: 0.0097772889\n",
      "[timestep: 19] [epoch: 151] loss: 0.0024470449\n",
      "[timestep: 19] [epoch: 181] loss: 0.0064355582\n",
      "[timestep: 19] [epoch: 211] loss: 0.0102204485\n",
      "[timestep: 19] [epoch: 241] loss: 0.0024119634\n",
      "[timestep: 19] [epoch: 271] loss: 0.0086462069\n",
      "[timestep: 19] [epoch: 301] loss: 0.0149460053\n",
      "[timestep: 19] [epoch: 331] loss: 0.0076810513\n",
      "[timestep: 19] [epoch: 361] loss: 0.0047615906\n",
      "[timestep: 19] [epoch: 391] loss: 0.0027123368\n",
      "[timestep: 19] [epoch: 421] loss: 0.0021491880\n",
      "[timestep: 19] [epoch: 451] loss: 0.0057236189\n",
      "[timestep: 19] [epoch: 481] loss: 0.0037776779\n",
      "[timestep: 19] [epoch: 511] loss: 0.0052332650\n",
      "[timestep: 19] [epoch: 541] loss: 0.0057237744\n",
      "[timestep: 19] [epoch: 571] loss: 0.0042586457\n",
      "[timestep: 19] [epoch: 601] loss: 0.0014171244\n",
      "[timestep: 19] [epoch: 631] loss: 0.0222007371\n",
      "[timestep: 19] [epoch: 661] loss: 0.0053783446\n",
      "[timestep: 19] [epoch: 691] loss: 0.0067942827\n",
      "0.01\n",
      "[timestep: 20] [epoch: 1] loss: 0.8155797720\n",
      "[timestep: 20] [epoch: 31] loss: 0.0372343957\n",
      "[timestep: 20] [epoch: 61] loss: 0.0047142101\n",
      "[timestep: 20] [epoch: 91] loss: 0.0106000602\n",
      "[timestep: 20] [epoch: 121] loss: 0.0028650099\n",
      "[timestep: 20] [epoch: 151] loss: 0.0019980159\n",
      "[timestep: 20] [epoch: 181] loss: 0.0077186138\n",
      "[timestep: 20] [epoch: 211] loss: 0.0089082597\n",
      "[timestep: 20] [epoch: 241] loss: 0.0029744145\n",
      "[timestep: 20] [epoch: 271] loss: 0.0033280284\n",
      "[timestep: 20] [epoch: 301] loss: 0.0097324345\n",
      "[timestep: 20] [epoch: 331] loss: 0.0020694749\n",
      "0.01\n",
      "[timestep: 21] [epoch: 1] loss: 0.8372201920\n",
      "[timestep: 21] [epoch: 31] loss: 0.0436847173\n",
      "[timestep: 21] [epoch: 61] loss: 0.0043736035\n",
      "[timestep: 21] [epoch: 91] loss: 0.0074304137\n",
      "0.01\n",
      "[timestep: 22] [epoch: 1] loss: 0.8170777559\n",
      "[timestep: 22] [epoch: 31] loss: 0.0622689389\n",
      "[timestep: 22] [epoch: 61] loss: 0.0054029478\n",
      "[timestep: 22] [epoch: 91] loss: 0.0059194556\n",
      "[timestep: 22] [epoch: 121] loss: 0.0121369846\n",
      "0.01\n",
      "[timestep: 23] [epoch: 1] loss: 0.8152722716\n",
      "[timestep: 23] [epoch: 31] loss: 0.0961635113\n",
      "[timestep: 23] [epoch: 61] loss: 0.0077686817\n",
      "[timestep: 23] [epoch: 91] loss: 0.0020320124\n",
      "[timestep: 23] [epoch: 121] loss: 0.0032758710\n",
      "[timestep: 23] [epoch: 151] loss: 0.0028132598\n",
      "[timestep: 23] [epoch: 181] loss: 0.0251815841\n",
      "[timestep: 23] [epoch: 211] loss: 0.0018119256\n",
      "[timestep: 23] [epoch: 241] loss: 0.0139138913\n",
      "[timestep: 23] [epoch: 271] loss: 0.0094710179\n",
      "[timestep: 23] [epoch: 301] loss: 0.0426015705\n",
      "0.01\n",
      "[timestep: 24] [epoch: 1] loss: 0.7906920314\n",
      "[timestep: 24] [epoch: 31] loss: 0.0748438686\n",
      "[timestep: 24] [epoch: 61] loss: 0.0069629466\n",
      "[timestep: 24] [epoch: 91] loss: 0.0108476449\n",
      "[timestep: 24] [epoch: 121] loss: 0.0062412838\n",
      "[timestep: 24] [epoch: 151] loss: 0.0091221081\n",
      "[timestep: 24] [epoch: 181] loss: 0.0105182836\n",
      "[timestep: 24] [epoch: 211] loss: 0.0246108063\n",
      "0.01\n",
      "[timestep: 25] [epoch: 1] loss: 0.8005335331\n",
      "[timestep: 25] [epoch: 31] loss: 0.1034958512\n",
      "[timestep: 25] [epoch: 61] loss: 0.0077656922\n",
      "[timestep: 25] [epoch: 91] loss: 0.0242631622\n",
      "[timestep: 25] [epoch: 121] loss: 0.0191865303\n",
      "[timestep: 25] [epoch: 151] loss: 0.0122834444\n",
      "[timestep: 25] [epoch: 181] loss: 0.0045269886\n",
      "[timestep: 25] [epoch: 211] loss: 0.0039718030\n",
      "[timestep: 25] [epoch: 241] loss: 0.0287587307\n",
      "[timestep: 25] [epoch: 271] loss: 0.0120093236\n",
      "[timestep: 25] [epoch: 301] loss: 0.0121568916\n",
      "[timestep: 25] [epoch: 331] loss: 0.0131033380\n",
      "[timestep: 25] [epoch: 361] loss: 0.0065171411\n",
      "[timestep: 25] [epoch: 391] loss: 0.0141645800\n",
      "[timestep: 25] [epoch: 421] loss: 0.0062200688\n",
      "[timestep: 25] [epoch: 451] loss: 0.0046687420\n",
      "[timestep: 25] [epoch: 481] loss: 0.0079418095\n",
      "[timestep: 25] [epoch: 511] loss: 0.0077239824\n",
      "[timestep: 25] [epoch: 541] loss: 0.0255975183\n",
      "[timestep: 25] [epoch: 571] loss: 0.0063423663\n",
      "[timestep: 25] [epoch: 601] loss: 0.0076136217\n",
      "[timestep: 25] [epoch: 631] loss: 0.0116994400\n",
      "[timestep: 25] [epoch: 661] loss: 0.0073070489\n",
      "[timestep: 25] [epoch: 691] loss: 0.0137176067\n",
      "[timestep: 25] [epoch: 721] loss: 0.0051142592\n",
      "[timestep: 25] [epoch: 751] loss: 0.0085487757\n",
      "[timestep: 25] [epoch: 781] loss: 0.0099462466\n",
      "[timestep: 25] [epoch: 811] loss: 0.0039677918\n",
      "[timestep: 25] [epoch: 841] loss: 0.0024903491\n",
      "[timestep: 25] [epoch: 871] loss: 0.0131924693\n",
      "[timestep: 25] [epoch: 901] loss: 0.0021400191\n",
      "[timestep: 25] [epoch: 931] loss: 0.0074714003\n",
      "[timestep: 25] [epoch: 961] loss: 0.0083976164\n",
      "[timestep: 25] [epoch: 991] loss: 0.0047498867\n",
      "[timestep: 25] [epoch: 1021] loss: 0.0029182113\n",
      "[timestep: 25] [epoch: 1051] loss: 0.0148856007\n",
      "[timestep: 25] [epoch: 1081] loss: 0.0113858841\n",
      "[timestep: 25] [epoch: 1111] loss: 0.0104857311\n",
      "[timestep: 25] [epoch: 1141] loss: 0.0031562238\n",
      "[timestep: 25] [epoch: 1171] loss: 0.0085201133\n",
      "[timestep: 25] [epoch: 1201] loss: 0.0106945382\n",
      "[timestep: 25] [epoch: 1231] loss: 0.0032643797\n",
      "[timestep: 25] [epoch: 1261] loss: 0.0085731475\n",
      "[timestep: 25] [epoch: 1291] loss: 0.0140772555\n",
      "[timestep: 25] [epoch: 1321] loss: 0.0138714891\n",
      "0.01\n",
      "[timestep: 26] [epoch: 1] loss: 0.8195934296\n",
      "[timestep: 26] [epoch: 31] loss: 0.0730756968\n",
      "[timestep: 26] [epoch: 61] loss: 0.0109976809\n",
      "[timestep: 26] [epoch: 91] loss: 0.0039302055\n",
      "[timestep: 26] [epoch: 121] loss: 0.0044208858\n",
      "[timestep: 26] [epoch: 151] loss: 0.0025178050\n",
      "[timestep: 26] [epoch: 181] loss: 0.0100953998\n",
      "[timestep: 26] [epoch: 211] loss: 0.0136589771\n",
      "[timestep: 26] [epoch: 241] loss: 0.0025489153\n",
      "[timestep: 26] [epoch: 271] loss: 0.0096450523\n",
      "[timestep: 26] [epoch: 301] loss: 0.0018470297\n",
      "[timestep: 26] [epoch: 331] loss: 0.0027289819\n",
      "[timestep: 26] [epoch: 361] loss: 0.0024224538\n",
      "[timestep: 26] [epoch: 391] loss: 0.0358094871\n",
      "[timestep: 26] [epoch: 421] loss: 0.0021974102\n",
      "[timestep: 26] [epoch: 451] loss: 0.0042923843\n",
      "[timestep: 26] [epoch: 481] loss: 0.0079221819\n",
      "[timestep: 26] [epoch: 511] loss: 0.0109006586\n",
      "[timestep: 26] [epoch: 541] loss: 0.0084666237\n",
      "[timestep: 26] [epoch: 571] loss: 0.0213543717\n",
      "[timestep: 26] [epoch: 601] loss: 0.0142077887\n",
      "[timestep: 26] [epoch: 631] loss: 0.0115189608\n",
      "[timestep: 26] [epoch: 661] loss: 0.0101861944\n",
      "[timestep: 26] [epoch: 691] loss: 0.0071167666\n",
      "[timestep: 26] [epoch: 721] loss: 0.0170158818\n",
      "[timestep: 26] [epoch: 751] loss: 0.0197510682\n",
      "[timestep: 26] [epoch: 781] loss: 0.0113817696\n",
      "[timestep: 26] [epoch: 811] loss: 0.0041057244\n",
      "[timestep: 26] [epoch: 841] loss: 0.0024135225\n",
      "[timestep: 26] [epoch: 871] loss: 0.0043150401\n",
      "[timestep: 26] [epoch: 901] loss: 0.0220439341\n",
      "[timestep: 26] [epoch: 931] loss: 0.0023874929\n",
      "[timestep: 26] [epoch: 961] loss: 0.0035820166\n",
      "[timestep: 26] [epoch: 991] loss: 0.0074437475\n",
      "[timestep: 26] [epoch: 1021] loss: 0.0084646968\n",
      "[timestep: 26] [epoch: 1051] loss: 0.0068643671\n",
      "[timestep: 26] [epoch: 1081] loss: 0.0018501718\n",
      "[timestep: 26] [epoch: 1111] loss: 0.0102251656\n",
      "[timestep: 26] [epoch: 1141] loss: 0.0128241573\n",
      "[timestep: 26] [epoch: 1171] loss: 0.0062094233\n",
      "[timestep: 26] [epoch: 1201] loss: 0.0036572728\n",
      "[timestep: 26] [epoch: 1231] loss: 0.0026509117\n",
      "[timestep: 26] [epoch: 1261] loss: 0.0118270796\n",
      "[timestep: 26] [epoch: 1291] loss: 0.0129413009\n",
      "[timestep: 26] [epoch: 1321] loss: 0.0021872167\n",
      "[timestep: 26] [epoch: 1351] loss: 0.0346829370\n",
      "[timestep: 26] [epoch: 1381] loss: 0.0132971685\n",
      "[timestep: 26] [epoch: 1411] loss: 0.0040844027\n",
      "[timestep: 26] [epoch: 1441] loss: 0.0038986467\n",
      "[timestep: 26] [epoch: 1471] loss: 0.0170038957\n",
      "[timestep: 26] [epoch: 1501] loss: 0.0013825094\n",
      "[timestep: 26] [epoch: 1531] loss: 0.0264427289\n",
      "[timestep: 26] [epoch: 1561] loss: 0.0026966513\n",
      "[timestep: 26] [epoch: 1591] loss: 0.0033638903\n",
      "[timestep: 26] [epoch: 1621] loss: 0.0076224804\n",
      "[timestep: 26] [epoch: 1651] loss: 0.0220188797\n",
      "[timestep: 26] [epoch: 1681] loss: 0.0066067036\n",
      "[timestep: 26] [epoch: 1711] loss: 0.0033642005\n",
      "[timestep: 26] [epoch: 1741] loss: 0.0206788294\n",
      "[timestep: 26] [epoch: 1771] loss: 0.0056390846\n",
      "[timestep: 26] [epoch: 1801] loss: 0.0089138616\n",
      "[timestep: 26] [epoch: 1831] loss: 0.0039340630\n",
      "[timestep: 26] [epoch: 1861] loss: 0.0080002658\n",
      "[timestep: 26] [epoch: 1891] loss: 0.0040608803\n",
      "[timestep: 26] [epoch: 1921] loss: 0.0024028141\n",
      "[timestep: 26] [epoch: 1951] loss: 0.0044084513\n",
      "[timestep: 26] [epoch: 1981] loss: 0.0082099428\n",
      "[timestep: 26] [epoch: 2011] loss: 0.0023255073\n",
      "[timestep: 26] [epoch: 2041] loss: 0.0010978568\n",
      "[timestep: 26] [epoch: 2071] loss: 0.0095646977\n",
      "[timestep: 26] [epoch: 2101] loss: 0.0026946012\n",
      "[timestep: 26] [epoch: 2131] loss: 0.0018857764\n",
      "[timestep: 26] [epoch: 2161] loss: 0.0105408970\n",
      "[timestep: 26] [epoch: 2191] loss: 0.0032826243\n",
      "[timestep: 26] [epoch: 2221] loss: 0.0074781165\n",
      "[timestep: 26] [epoch: 2251] loss: 0.0048946934\n",
      "[timestep: 26] [epoch: 2281] loss: 0.0024568029\n",
      "[timestep: 26] [epoch: 2311] loss: 0.0072477590\n",
      "[timestep: 26] [epoch: 2341] loss: 0.0033054410\n",
      "[timestep: 26] [epoch: 2371] loss: 0.0052312235\n",
      "[timestep: 26] [epoch: 2401] loss: 0.0158306304\n",
      "[timestep: 26] [epoch: 2431] loss: 0.0059939558\n",
      "[timestep: 26] [epoch: 2461] loss: 0.0011339481\n",
      "[timestep: 26] [epoch: 2491] loss: 0.0045493403\n",
      "[timestep: 26] [epoch: 2521] loss: 0.0076354886\n",
      "[timestep: 26] [epoch: 2551] loss: 0.0033507897\n",
      "[timestep: 26] [epoch: 2581] loss: 0.0099447630\n",
      "[timestep: 26] [epoch: 2611] loss: 0.0031728279\n",
      "0.01\n",
      "[timestep: 27] [epoch: 1] loss: 0.8198062778\n",
      "[timestep: 27] [epoch: 31] loss: 0.0595998280\n",
      "[timestep: 27] [epoch: 61] loss: 0.0052861404\n",
      "[timestep: 27] [epoch: 91] loss: 0.0015721164\n",
      "[timestep: 27] [epoch: 121] loss: 0.0019187253\n",
      "[timestep: 27] [epoch: 151] loss: 0.0095916940\n",
      "[timestep: 27] [epoch: 181] loss: 0.0041048867\n",
      "[timestep: 27] [epoch: 211] loss: 0.0029349392\n",
      "[timestep: 27] [epoch: 241] loss: 0.0128152128\n",
      "[timestep: 27] [epoch: 271] loss: 0.0039285328\n",
      "[timestep: 27] [epoch: 301] loss: 0.0098409820\n",
      "[timestep: 27] [epoch: 331] loss: 0.0267379321\n",
      "[timestep: 27] [epoch: 361] loss: 0.0043856837\n",
      "[timestep: 27] [epoch: 391] loss: 0.0055185650\n",
      "[timestep: 27] [epoch: 421] loss: 0.0122102341\n",
      "[timestep: 27] [epoch: 451] loss: 0.0098654162\n",
      "[timestep: 27] [epoch: 481] loss: 0.0052585327\n",
      "[timestep: 27] [epoch: 511] loss: 0.0082661901\n",
      "[timestep: 27] [epoch: 541] loss: 0.0084663974\n",
      "[timestep: 27] [epoch: 571] loss: 0.0125624659\n",
      "[timestep: 27] [epoch: 601] loss: 0.0041672699\n",
      "[timestep: 27] [epoch: 631] loss: 0.0076462002\n",
      "[timestep: 27] [epoch: 661] loss: 0.0060804999\n",
      "[timestep: 27] [epoch: 691] loss: 0.0262865070\n",
      "[timestep: 27] [epoch: 721] loss: 0.0041108029\n",
      "[timestep: 27] [epoch: 751] loss: 0.0079060635\n",
      "[timestep: 27] [epoch: 781] loss: 0.0047620945\n",
      "[timestep: 27] [epoch: 811] loss: 0.0054148976\n",
      "0.01\n",
      "[timestep: 28] [epoch: 1] loss: 0.8181576729\n",
      "[timestep: 28] [epoch: 31] loss: 0.0559774749\n",
      "[timestep: 28] [epoch: 61] loss: 0.0052659446\n",
      "[timestep: 28] [epoch: 91] loss: 0.0022043306\n",
      "[timestep: 28] [epoch: 121] loss: 0.0028428813\n",
      "[timestep: 28] [epoch: 151] loss: 0.0044921525\n",
      "[timestep: 28] [epoch: 181] loss: 0.0042308355\n",
      "[timestep: 28] [epoch: 211] loss: 0.0078528738\n",
      "[timestep: 28] [epoch: 241] loss: 0.0054952851\n",
      "[timestep: 28] [epoch: 271] loss: 0.0113970991\n",
      "[timestep: 28] [epoch: 301] loss: 0.0073809018\n",
      "[timestep: 28] [epoch: 331] loss: 0.0173384026\n",
      "[timestep: 28] [epoch: 361] loss: 0.0136389900\n",
      "[timestep: 28] [epoch: 391] loss: 0.0074669505\n",
      "[timestep: 28] [epoch: 421] loss: 0.0073694619\n",
      "[timestep: 28] [epoch: 451] loss: 0.0185556300\n",
      "[timestep: 28] [epoch: 481] loss: 0.0186733603\n",
      "[timestep: 28] [epoch: 511] loss: 0.0119423866\n",
      "[timestep: 28] [epoch: 541] loss: 0.0075593740\n",
      "[timestep: 28] [epoch: 571] loss: 0.0079582054\n",
      "[timestep: 28] [epoch: 601] loss: 0.0076047308\n",
      "[timestep: 28] [epoch: 631] loss: 0.0115417643\n",
      "[timestep: 28] [epoch: 661] loss: 0.0030455869\n",
      "[timestep: 28] [epoch: 691] loss: 0.0280921664\n",
      "[timestep: 28] [epoch: 721] loss: 0.0043989657\n",
      "[timestep: 28] [epoch: 751] loss: 0.0120465104\n",
      "[timestep: 28] [epoch: 781] loss: 0.0042059300\n",
      "[timestep: 28] [epoch: 811] loss: 0.0061468799\n",
      "[timestep: 28] [epoch: 841] loss: 0.0028654952\n",
      "[timestep: 28] [epoch: 871] loss: 0.0092653437\n",
      "[timestep: 28] [epoch: 901] loss: 0.0106438436\n",
      "[timestep: 28] [epoch: 931] loss: 0.0081805009\n",
      "[timestep: 28] [epoch: 961] loss: 0.0016813397\n",
      "[timestep: 28] [epoch: 991] loss: 0.0038591058\n",
      "0.01\n",
      "[timestep: 29] [epoch: 1] loss: 0.8148525953\n",
      "[timestep: 29] [epoch: 31] loss: 0.0599000417\n",
      "[timestep: 29] [epoch: 61] loss: 0.0038313246\n",
      "[timestep: 29] [epoch: 91] loss: 0.0088648945\n",
      "0.01\n",
      "[timestep: 30] [epoch: 1] loss: 0.7999279499\n",
      "[timestep: 30] [epoch: 31] loss: 0.0790474117\n",
      "[timestep: 30] [epoch: 61] loss: 0.0043225577\n",
      "[timestep: 30] [epoch: 91] loss: 0.0038719212\n",
      "0.01\n",
      "[timestep: 31] [epoch: 1] loss: 0.8061946630\n",
      "[timestep: 31] [epoch: 31] loss: 0.0671629757\n",
      "[timestep: 31] [epoch: 61] loss: 0.0060733240\n",
      "[timestep: 31] [epoch: 91] loss: 0.0040552355\n",
      "[timestep: 31] [epoch: 121] loss: 0.0024343317\n",
      "[timestep: 31] [epoch: 151] loss: 0.0065219775\n",
      "0.01\n",
      "[timestep: 32] [epoch: 1] loss: 0.7755298615\n",
      "[timestep: 32] [epoch: 31] loss: 0.0796248689\n",
      "[timestep: 32] [epoch: 61] loss: 0.0071660988\n",
      "[timestep: 32] [epoch: 91] loss: 0.0044689830\n",
      "[timestep: 32] [epoch: 121] loss: 0.0023769701\n",
      "[timestep: 32] [epoch: 151] loss: 0.0106771467\n",
      "0.01\n",
      "[timestep: 33] [epoch: 1] loss: 0.7850727439\n",
      "[timestep: 33] [epoch: 31] loss: 0.0720184445\n",
      "[timestep: 33] [epoch: 61] loss: 0.0054673124\n",
      "[timestep: 33] [epoch: 91] loss: 0.0030716183\n",
      "[timestep: 33] [epoch: 121] loss: 0.0130762439\n",
      "[timestep: 33] [epoch: 151] loss: 0.0081191845\n",
      "[timestep: 33] [epoch: 181] loss: 0.0197093822\n",
      "[timestep: 33] [epoch: 211] loss: 0.0033604300\n",
      "[timestep: 33] [epoch: 241] loss: 0.0060650054\n",
      "[timestep: 33] [epoch: 271] loss: 0.0051113525\n",
      "[timestep: 33] [epoch: 301] loss: 0.0025554586\n",
      "[timestep: 33] [epoch: 331] loss: 0.0016326689\n",
      "[timestep: 33] [epoch: 361] loss: 0.0050859293\n",
      "[timestep: 33] [epoch: 391] loss: 0.0031210778\n",
      "[timestep: 33] [epoch: 421] loss: 0.0026786849\n",
      "[timestep: 33] [epoch: 451] loss: 0.0043387897\n",
      "[timestep: 33] [epoch: 481] loss: 0.0069676028\n",
      "[timestep: 33] [epoch: 511] loss: 0.0038499362\n",
      "0.01\n",
      "[timestep: 34] [epoch: 1] loss: 0.8082879186\n",
      "[timestep: 34] [epoch: 31] loss: 0.0742470250\n",
      "[timestep: 34] [epoch: 61] loss: 0.0056927335\n",
      "[timestep: 34] [epoch: 91] loss: 0.0013530066\n",
      "[timestep: 34] [epoch: 121] loss: 0.0038299556\n",
      "[timestep: 34] [epoch: 151] loss: 0.0048549091\n",
      "[timestep: 34] [epoch: 181] loss: 0.0084101763\n",
      "[timestep: 34] [epoch: 211] loss: 0.0195007585\n",
      "[timestep: 34] [epoch: 241] loss: 0.0016856218\n",
      "[timestep: 34] [epoch: 271] loss: 0.0065736677\n",
      "[timestep: 34] [epoch: 301] loss: 0.0244334806\n",
      "[timestep: 34] [epoch: 331] loss: 0.0044693202\n",
      "[timestep: 34] [epoch: 361] loss: 0.0036330493\n",
      "[timestep: 34] [epoch: 391] loss: 0.0019952809\n",
      "[timestep: 34] [epoch: 421] loss: 0.0032594781\n",
      "[timestep: 34] [epoch: 451] loss: 0.0182267074\n",
      "[timestep: 34] [epoch: 481] loss: 0.0088350642\n",
      "[timestep: 34] [epoch: 511] loss: 0.0050590169\n",
      "[timestep: 34] [epoch: 541] loss: 0.0327553451\n",
      "[timestep: 34] [epoch: 571] loss: 0.0139100160\n",
      "[timestep: 34] [epoch: 601] loss: 0.0016392216\n",
      "[timestep: 34] [epoch: 631] loss: 0.0361635722\n",
      "[timestep: 34] [epoch: 661] loss: 0.0130431298\n",
      "[timestep: 34] [epoch: 691] loss: 0.0147164371\n",
      "[timestep: 34] [epoch: 721] loss: 0.0145725897\n",
      "[timestep: 34] [epoch: 751] loss: 0.0119518479\n",
      "[timestep: 34] [epoch: 781] loss: 0.0280263815\n",
      "[timestep: 34] [epoch: 811] loss: 0.0065751756\n",
      "[timestep: 34] [epoch: 841] loss: 0.0195031390\n",
      "[timestep: 34] [epoch: 871] loss: 0.0093624778\n",
      "[timestep: 34] [epoch: 901] loss: 0.0153315822\n",
      "[timestep: 34] [epoch: 931] loss: 0.0193477459\n",
      "[timestep: 34] [epoch: 961] loss: 0.0036406619\n",
      "[timestep: 34] [epoch: 991] loss: 0.0063559692\n",
      "[timestep: 34] [epoch: 1021] loss: 0.0051233112\n",
      "[timestep: 34] [epoch: 1051] loss: 0.0151206218\n",
      "[timestep: 34] [epoch: 1081] loss: 0.0024618404\n",
      "[timestep: 34] [epoch: 1111] loss: 0.0036756345\n",
      "[timestep: 34] [epoch: 1141] loss: 0.0084634656\n",
      "[timestep: 34] [epoch: 1171] loss: 0.0048803687\n",
      "[timestep: 34] [epoch: 1201] loss: 0.0035568085\n",
      "[timestep: 34] [epoch: 1231] loss: 0.0068415133\n",
      "[timestep: 34] [epoch: 1261] loss: 0.0061507113\n",
      "[timestep: 34] [epoch: 1291] loss: 0.0104646133\n",
      "[timestep: 34] [epoch: 1321] loss: 0.0054105869\n",
      "[timestep: 34] [epoch: 1351] loss: 0.0041471589\n",
      "[timestep: 34] [epoch: 1381] loss: 0.0109843947\n",
      "[timestep: 34] [epoch: 1411] loss: 0.0031356390\n",
      "[timestep: 34] [epoch: 1441] loss: 0.0073501235\n",
      "[timestep: 34] [epoch: 1471] loss: 0.0196514837\n",
      "[timestep: 34] [epoch: 1501] loss: 0.0028155700\n",
      "[timestep: 34] [epoch: 1531] loss: 0.0039121644\n",
      "[timestep: 34] [epoch: 1561] loss: 0.0269456916\n",
      "[timestep: 34] [epoch: 1591] loss: 0.0036771349\n",
      "[timestep: 34] [epoch: 1621] loss: 0.0042072521\n",
      "[timestep: 34] [epoch: 1651] loss: 0.0223529469\n",
      "[timestep: 34] [epoch: 1681] loss: 0.0050410079\n",
      "[timestep: 34] [epoch: 1711] loss: 0.0031275547\n",
      "[timestep: 34] [epoch: 1741] loss: 0.0028743199\n",
      "[timestep: 34] [epoch: 1771] loss: 0.0029253871\n",
      "[timestep: 34] [epoch: 1801] loss: 0.0022236905\n",
      "[timestep: 34] [epoch: 1831] loss: 0.0064354297\n",
      "[timestep: 34] [epoch: 1861] loss: 0.0099336123\n",
      "[timestep: 34] [epoch: 1891] loss: 0.0089279367\n",
      "[timestep: 34] [epoch: 1921] loss: 0.0043213367\n",
      "[timestep: 34] [epoch: 1951] loss: 0.0224021934\n",
      "[timestep: 34] [epoch: 1981] loss: 0.0071072010\n",
      "[timestep: 34] [epoch: 2011] loss: 0.0079098102\n",
      "[timestep: 34] [epoch: 2041] loss: 0.0034256121\n",
      "[timestep: 34] [epoch: 2071] loss: 0.0042178119\n",
      "[timestep: 34] [epoch: 2101] loss: 0.0061084465\n",
      "[timestep: 34] [epoch: 2131] loss: 0.0046729222\n",
      "[timestep: 34] [epoch: 2161] loss: 0.0031151446\n",
      "[timestep: 34] [epoch: 2191] loss: 0.0056320047\n",
      "[timestep: 34] [epoch: 2221] loss: 0.0013037648\n",
      "[timestep: 34] [epoch: 2251] loss: 0.0294707958\n",
      "[timestep: 34] [epoch: 2281] loss: 0.0077345483\n",
      "[timestep: 34] [epoch: 2311] loss: 0.0046449453\n",
      "[timestep: 34] [epoch: 2341] loss: 0.0036233473\n",
      "[timestep: 34] [epoch: 2371] loss: 0.0082347123\n",
      "[timestep: 34] [epoch: 2401] loss: 0.0068901321\n",
      "[timestep: 34] [epoch: 2431] loss: 0.0046276199\n",
      "[timestep: 34] [epoch: 2461] loss: 0.0024198787\n",
      "[timestep: 34] [epoch: 2491] loss: 0.0127543136\n",
      "[timestep: 34] [epoch: 2521] loss: 0.0087439194\n",
      "0.01\n",
      "[timestep: 35] [epoch: 1] loss: 0.7903690338\n",
      "[timestep: 35] [epoch: 31] loss: 0.0657869726\n",
      "[timestep: 35] [epoch: 61] loss: 0.0038671747\n",
      "[timestep: 35] [epoch: 91] loss: 0.0008946097\n",
      "0.01\n",
      "[timestep: 36] [epoch: 1] loss: 0.7917569280\n",
      "[timestep: 36] [epoch: 31] loss: 0.0798371285\n",
      "[timestep: 36] [epoch: 61] loss: 0.0047448799\n",
      "[timestep: 36] [epoch: 91] loss: 0.0014701670\n",
      "[timestep: 36] [epoch: 121] loss: 0.0055722110\n",
      "0.01\n",
      "[timestep: 37] [epoch: 1] loss: 0.7808892727\n",
      "[timestep: 37] [epoch: 31] loss: 0.0589123853\n",
      "[timestep: 37] [epoch: 61] loss: 0.0047111819\n",
      "[timestep: 37] [epoch: 91] loss: 0.0138288951\n",
      "[timestep: 37] [epoch: 121] loss: 0.0060495823\n",
      "0.01\n",
      "[timestep: 38] [epoch: 1] loss: 0.7825236917\n",
      "[timestep: 38] [epoch: 31] loss: 0.0926791802\n",
      "[timestep: 38] [epoch: 61] loss: 0.0049694488\n",
      "[timestep: 38] [epoch: 91] loss: 0.0178758241\n",
      "[timestep: 38] [epoch: 121] loss: 0.0054378686\n",
      "[timestep: 38] [epoch: 151] loss: 0.0252601523\n",
      "[timestep: 38] [epoch: 181] loss: 0.0022222647\n",
      "[timestep: 38] [epoch: 211] loss: 0.0265803672\n",
      "[timestep: 38] [epoch: 241] loss: 0.0041765124\n",
      "[timestep: 38] [epoch: 271] loss: 0.0062610796\n",
      "[timestep: 38] [epoch: 301] loss: 0.0073661003\n",
      "[timestep: 38] [epoch: 331] loss: 0.0044323877\n",
      "[timestep: 38] [epoch: 361] loss: 0.0155529808\n",
      "[timestep: 38] [epoch: 391] loss: 0.0042860629\n",
      "[timestep: 38] [epoch: 421] loss: 0.0164538547\n",
      "[timestep: 38] [epoch: 451] loss: 0.0027528484\n",
      "[timestep: 38] [epoch: 481] loss: 0.0076627438\n",
      "[timestep: 38] [epoch: 511] loss: 0.0384796709\n",
      "[timestep: 38] [epoch: 541] loss: 0.0164185744\n",
      "[timestep: 38] [epoch: 571] loss: 0.0176508222\n",
      "[timestep: 38] [epoch: 601] loss: 0.0025205510\n",
      "[timestep: 38] [epoch: 631] loss: 0.0065547517\n",
      "[timestep: 38] [epoch: 661] loss: 0.0027364045\n",
      "[timestep: 38] [epoch: 691] loss: 0.0039638621\n",
      "[timestep: 38] [epoch: 721] loss: 0.0050358502\n",
      "[timestep: 38] [epoch: 751] loss: 0.0262459554\n",
      "[timestep: 38] [epoch: 781] loss: 0.0078248158\n",
      "[timestep: 38] [epoch: 811] loss: 0.0076096863\n",
      "[timestep: 38] [epoch: 841] loss: 0.0034017530\n",
      "[timestep: 38] [epoch: 871] loss: 0.0190703347\n",
      "[timestep: 38] [epoch: 901] loss: 0.0053558080\n",
      "[timestep: 38] [epoch: 931] loss: 0.0437590331\n",
      "[timestep: 38] [epoch: 961] loss: 0.0025362493\n",
      "[timestep: 38] [epoch: 991] loss: 0.0063743433\n",
      "[timestep: 38] [epoch: 1021] loss: 0.0024804336\n",
      "[timestep: 38] [epoch: 1051] loss: 0.0105127934\n",
      "[timestep: 38] [epoch: 1081] loss: 0.0123348348\n",
      "[timestep: 38] [epoch: 1111] loss: 0.0042220722\n",
      "[timestep: 38] [epoch: 1141] loss: 0.0202514529\n",
      "[timestep: 38] [epoch: 1171] loss: 0.0152498418\n",
      "[timestep: 38] [epoch: 1201] loss: 0.0121911578\n",
      "[timestep: 38] [epoch: 1231] loss: 0.0076248744\n",
      "[timestep: 38] [epoch: 1261] loss: 0.0021532604\n",
      "[timestep: 38] [epoch: 1291] loss: 0.0028014625\n",
      "[timestep: 38] [epoch: 1321] loss: 0.0042367736\n",
      "[timestep: 38] [epoch: 1351] loss: 0.0257149991\n",
      "[timestep: 38] [epoch: 1381] loss: 0.0076574394\n",
      "0.01\n",
      "[timestep: 39] [epoch: 1] loss: 0.7836703062\n",
      "[timestep: 39] [epoch: 31] loss: 0.0807446092\n",
      "[timestep: 39] [epoch: 61] loss: 0.0060212682\n",
      "[timestep: 39] [epoch: 91] loss: 0.0013580672\n",
      "[timestep: 39] [epoch: 121] loss: 0.0040491503\n",
      "0.01\n",
      "[timestep: 40] [epoch: 1] loss: 0.7701102495\n",
      "[timestep: 40] [epoch: 31] loss: 0.1138972193\n",
      "[timestep: 40] [epoch: 61] loss: 0.0077165836\n",
      "[timestep: 40] [epoch: 91] loss: 0.0014765159\n",
      "[timestep: 40] [epoch: 121] loss: 0.0237572789\n",
      "[timestep: 40] [epoch: 151] loss: 0.0039406219\n",
      "[timestep: 40] [epoch: 181] loss: 0.0157302022\n",
      "[timestep: 40] [epoch: 211] loss: 0.0125843100\n",
      "[timestep: 40] [epoch: 241] loss: 0.0142842084\n",
      "[timestep: 40] [epoch: 271] loss: 0.0125913937\n",
      "[timestep: 40] [epoch: 301] loss: 0.0015784379\n",
      "[timestep: 40] [epoch: 331] loss: 0.0280585103\n",
      "[timestep: 40] [epoch: 361] loss: 0.0265401546\n",
      "[timestep: 40] [epoch: 391] loss: 0.0066995891\n",
      "[timestep: 40] [epoch: 421] loss: 0.0022643548\n",
      "[timestep: 40] [epoch: 451] loss: 0.0024020332\n",
      "[timestep: 40] [epoch: 481] loss: 0.0046148403\n",
      "[timestep: 40] [epoch: 511] loss: 0.0165377371\n",
      "[timestep: 40] [epoch: 541] loss: 0.0063872198\n",
      "[timestep: 40] [epoch: 571] loss: 0.0051298491\n",
      "[timestep: 40] [epoch: 601] loss: 0.0044791931\n",
      "[timestep: 40] [epoch: 631] loss: 0.0035208301\n",
      "[timestep: 40] [epoch: 661] loss: 0.0113907121\n",
      "[timestep: 40] [epoch: 691] loss: 0.0212281644\n",
      "[timestep: 40] [epoch: 721] loss: 0.0029266898\n",
      "[timestep: 40] [epoch: 751] loss: 0.0438160896\n",
      "[timestep: 40] [epoch: 781] loss: 0.0037487489\n",
      "[timestep: 40] [epoch: 811] loss: 0.0034618892\n",
      "[timestep: 40] [epoch: 841] loss: 0.0070196767\n",
      "[timestep: 40] [epoch: 871] loss: 0.0025531235\n",
      "[timestep: 40] [epoch: 901] loss: 0.0236907899\n",
      "[timestep: 40] [epoch: 931] loss: 0.0086608361\n",
      "[timestep: 40] [epoch: 961] loss: 0.0040812893\n",
      "[timestep: 40] [epoch: 991] loss: 0.0246649031\n",
      "[timestep: 40] [epoch: 1021] loss: 0.0069482652\n",
      "[timestep: 40] [epoch: 1051] loss: 0.0065140189\n",
      "[timestep: 40] [epoch: 1081] loss: 0.0035625231\n",
      "[timestep: 40] [epoch: 1111] loss: 0.0042912057\n",
      "[timestep: 40] [epoch: 1141] loss: 0.0055403588\n",
      "[timestep: 40] [epoch: 1171] loss: 0.0104235681\n",
      "[timestep: 40] [epoch: 1201] loss: 0.0262319744\n",
      "[timestep: 40] [epoch: 1231] loss: 0.0059099188\n",
      "[timestep: 40] [epoch: 1261] loss: 0.0170505010\n",
      "[timestep: 40] [epoch: 1291] loss: 0.0030164206\n",
      "[timestep: 40] [epoch: 1321] loss: 0.0122276349\n",
      "[timestep: 40] [epoch: 1351] loss: 0.0107649937\n",
      "[timestep: 40] [epoch: 1381] loss: 0.0063057244\n",
      "[timestep: 40] [epoch: 1411] loss: 0.0025237538\n",
      "[timestep: 40] [epoch: 1441] loss: 0.0045882370\n",
      "[timestep: 40] [epoch: 1471] loss: 0.0058260188\n",
      "[timestep: 40] [epoch: 1501] loss: 0.0049147224\n",
      "[timestep: 40] [epoch: 1531] loss: 0.0048701437\n",
      "[timestep: 40] [epoch: 1561] loss: 0.0578247085\n",
      "[timestep: 40] [epoch: 1591] loss: 0.0082569178\n",
      "[timestep: 40] [epoch: 1621] loss: 0.0051409341\n",
      "[timestep: 40] [epoch: 1651] loss: 0.0088779265\n",
      "[timestep: 40] [epoch: 1681] loss: 0.0062362887\n",
      "[timestep: 40] [epoch: 1711] loss: 0.0128600970\n",
      "[timestep: 40] [epoch: 1741] loss: 0.0040082904\n",
      "[timestep: 40] [epoch: 1771] loss: 0.0237561204\n",
      "[timestep: 40] [epoch: 1801] loss: 0.0043562255\n",
      "[timestep: 40] [epoch: 1831] loss: 0.0063454793\n",
      "[timestep: 40] [epoch: 1861] loss: 0.0036467658\n",
      "[timestep: 40] [epoch: 1891] loss: 0.0601388142\n",
      "[timestep: 40] [epoch: 1921] loss: 0.0043069636\n",
      "[timestep: 40] [epoch: 1951] loss: 0.0068136165\n",
      "[timestep: 40] [epoch: 1981] loss: 0.0043413574\n",
      "[timestep: 40] [epoch: 2011] loss: 0.0039770762\n",
      "[timestep: 40] [epoch: 2041] loss: 0.0033348780\n",
      "[timestep: 40] [epoch: 2071] loss: 0.0203046948\n",
      "[timestep: 40] [epoch: 2101] loss: 0.0028325589\n",
      "[timestep: 40] [epoch: 2131] loss: 0.0128234290\n",
      "[timestep: 40] [epoch: 2161] loss: 0.0031949854\n",
      "[timestep: 40] [epoch: 2191] loss: 0.0492423214\n",
      "[timestep: 40] [epoch: 2221] loss: 0.0064433739\n",
      "[timestep: 40] [epoch: 2251] loss: 0.0036087167\n",
      "[timestep: 40] [epoch: 2281] loss: 0.0196548551\n",
      "[timestep: 40] [epoch: 2311] loss: 0.0123513183\n",
      "[timestep: 40] [epoch: 2341] loss: 0.0034878547\n",
      "[timestep: 40] [epoch: 2371] loss: 0.0025004921\n",
      "[timestep: 40] [epoch: 2401] loss: 0.0052238596\n",
      "[timestep: 40] [epoch: 2431] loss: 0.0026360361\n",
      "[timestep: 40] [epoch: 2461] loss: 0.0033366047\n",
      "[timestep: 40] [epoch: 2491] loss: 0.0233331956\n",
      "[timestep: 40] [epoch: 2521] loss: 0.0038042800\n",
      "[timestep: 40] [epoch: 2551] loss: 0.0029486464\n",
      "[timestep: 40] [epoch: 2581] loss: 0.0215630066\n",
      "[timestep: 40] [epoch: 2611] loss: 0.0078911409\n",
      "[timestep: 40] [epoch: 2641] loss: 0.0111863036\n",
      "[timestep: 40] [epoch: 2671] loss: 0.0113436077\n",
      "[timestep: 40] [epoch: 2701] loss: 0.0074111484\n",
      "[timestep: 40] [epoch: 2731] loss: 0.0043912008\n",
      "[timestep: 40] [epoch: 2761] loss: 0.0143404854\n",
      "[timestep: 40] [epoch: 2791] loss: 0.0029846635\n",
      "[timestep: 40] [epoch: 2821] loss: 0.0032401260\n",
      "[timestep: 40] [epoch: 2851] loss: 0.0013177671\n",
      "[timestep: 40] [epoch: 2881] loss: 0.0099111889\n",
      "[timestep: 40] [epoch: 2911] loss: 0.0088468865\n",
      "[timestep: 40] [epoch: 2941] loss: 0.0021637154\n",
      "[timestep: 40] [epoch: 2971] loss: 0.0128595084\n",
      "[timestep: 40] [epoch: 3001] loss: 0.0051449933\n",
      "[timestep: 40] [epoch: 3031] loss: 0.0025454063\n",
      "[timestep: 40] [epoch: 3061] loss: 0.0041867476\n",
      "[timestep: 40] [epoch: 3091] loss: 0.0021255235\n",
      "[timestep: 40] [epoch: 3121] loss: 0.0020895284\n",
      "[timestep: 40] [epoch: 3151] loss: 0.0098430905\n",
      "[timestep: 40] [epoch: 3181] loss: 0.0041924827\n",
      "[timestep: 40] [epoch: 3211] loss: 0.0195482709\n",
      "[timestep: 40] [epoch: 3241] loss: 0.0026129973\n",
      "[timestep: 40] [epoch: 3271] loss: 0.0049069817\n",
      "[timestep: 40] [epoch: 3301] loss: 0.0313834921\n",
      "[timestep: 40] [epoch: 3331] loss: 0.0042821318\n",
      "[timestep: 40] [epoch: 3361] loss: 0.0055028945\n",
      "[timestep: 40] [epoch: 3391] loss: 0.0135878026\n",
      "[timestep: 40] [epoch: 3421] loss: 0.0053697210\n",
      "[timestep: 40] [epoch: 3451] loss: 0.0094378702\n",
      "[timestep: 40] [epoch: 3481] loss: 0.0041779699\n",
      "[timestep: 40] [epoch: 3511] loss: 0.0050067790\n",
      "[timestep: 40] [epoch: 3541] loss: 0.0095336791\n",
      "[timestep: 40] [epoch: 3571] loss: 0.0118095893\n",
      "0.01\n",
      "[timestep: 41] [epoch: 1] loss: 0.7677422166\n",
      "[timestep: 41] [epoch: 31] loss: 0.0756637380\n",
      "[timestep: 41] [epoch: 61] loss: 0.0054332968\n",
      "[timestep: 41] [epoch: 91] loss: 0.0012474242\n",
      "[timestep: 41] [epoch: 121] loss: 0.0011046021\n",
      "[timestep: 41] [epoch: 151] loss: 0.0024828985\n",
      "[timestep: 41] [epoch: 181] loss: 0.0093701696\n",
      "[timestep: 41] [epoch: 211] loss: 0.0010629389\n",
      "[timestep: 41] [epoch: 241] loss: 0.0152388513\n",
      "[timestep: 41] [epoch: 271] loss: 0.0169457048\n",
      "[timestep: 41] [epoch: 301] loss: 0.0228975639\n",
      "[timestep: 41] [epoch: 331] loss: 0.0034304210\n",
      "[timestep: 41] [epoch: 361] loss: 0.0476258770\n",
      "[timestep: 41] [epoch: 391] loss: 0.0090388600\n",
      "[timestep: 41] [epoch: 421] loss: 0.0081517799\n",
      "[timestep: 41] [epoch: 451] loss: 0.0073124235\n",
      "[timestep: 41] [epoch: 481] loss: 0.0111333299\n",
      "[timestep: 41] [epoch: 511] loss: 0.0055308137\n",
      "[timestep: 41] [epoch: 541] loss: 0.0016883984\n",
      "[timestep: 41] [epoch: 571] loss: 0.0026333388\n",
      "[timestep: 41] [epoch: 601] loss: 0.0239156708\n",
      "[timestep: 41] [epoch: 631] loss: 0.0017520536\n",
      "[timestep: 41] [epoch: 661] loss: 0.0115710786\n",
      "[timestep: 41] [epoch: 691] loss: 0.0147616453\n",
      "[timestep: 41] [epoch: 721] loss: 0.0038970863\n",
      "[timestep: 41] [epoch: 751] loss: 0.0604560673\n",
      "[timestep: 41] [epoch: 781] loss: 0.0083951429\n",
      "[timestep: 41] [epoch: 811] loss: 0.0037818467\n",
      "[timestep: 41] [epoch: 841] loss: 0.0157093406\n",
      "[timestep: 41] [epoch: 871] loss: 0.0090110004\n",
      "[timestep: 41] [epoch: 901] loss: 0.0109158270\n",
      "[timestep: 41] [epoch: 931] loss: 0.0032867840\n",
      "[timestep: 41] [epoch: 961] loss: 0.0104684960\n",
      "[timestep: 41] [epoch: 991] loss: 0.0142282862\n",
      "[timestep: 41] [epoch: 1021] loss: 0.0049840007\n",
      "[timestep: 41] [epoch: 1051] loss: 0.0429203287\n",
      "[timestep: 41] [epoch: 1081] loss: 0.0034538100\n",
      "[timestep: 41] [epoch: 1111] loss: 0.0025980044\n",
      "[timestep: 41] [epoch: 1141] loss: 0.0078469561\n",
      "[timestep: 41] [epoch: 1171] loss: 0.0017087687\n",
      "[timestep: 41] [epoch: 1201] loss: 0.0209165588\n",
      "[timestep: 41] [epoch: 1231] loss: 0.0093045905\n",
      "[timestep: 41] [epoch: 1261] loss: 0.0037014466\n",
      "[timestep: 41] [epoch: 1291] loss: 0.0577040389\n",
      "[timestep: 41] [epoch: 1321] loss: 0.0034088478\n",
      "[timestep: 41] [epoch: 1351] loss: 0.0237299390\n",
      "[timestep: 41] [epoch: 1381] loss: 0.0052905688\n",
      "[timestep: 41] [epoch: 1411] loss: 0.0022463189\n",
      "[timestep: 41] [epoch: 1441] loss: 0.0030265902\n",
      "[timestep: 41] [epoch: 1471] loss: 0.0230862126\n",
      "[timestep: 41] [epoch: 1501] loss: 0.0030305674\n",
      "[timestep: 41] [epoch: 1531] loss: 0.0095453663\n",
      "[timestep: 41] [epoch: 1561] loss: 0.0078565553\n",
      "[timestep: 41] [epoch: 1591] loss: 0.0057024602\n",
      "[timestep: 41] [epoch: 1621] loss: 0.0029987912\n",
      "[timestep: 41] [epoch: 1651] loss: 0.0064695743\n",
      "[timestep: 41] [epoch: 1681] loss: 0.0021422568\n",
      "[timestep: 41] [epoch: 1711] loss: 0.0032943620\n",
      "[timestep: 41] [epoch: 1741] loss: 0.0348309167\n",
      "[timestep: 41] [epoch: 1771] loss: 0.0048687058\n",
      "[timestep: 41] [epoch: 1801] loss: 0.0065815113\n",
      "[timestep: 41] [epoch: 1831] loss: 0.0027121017\n",
      "[timestep: 41] [epoch: 1861] loss: 0.0040694033\n",
      "[timestep: 41] [epoch: 1891] loss: 0.0030410122\n",
      "[timestep: 41] [epoch: 1921] loss: 0.0024463322\n",
      "[timestep: 41] [epoch: 1951] loss: 0.0029336549\n",
      "[timestep: 41] [epoch: 1981] loss: 0.0108600529\n",
      "[timestep: 41] [epoch: 2011] loss: 0.0017787390\n",
      "[timestep: 41] [epoch: 2041] loss: 0.0049444493\n",
      "[timestep: 41] [epoch: 2071] loss: 0.0108314501\n",
      "[timestep: 41] [epoch: 2101] loss: 0.0074219042\n",
      "[timestep: 41] [epoch: 2131] loss: 0.0066326307\n",
      "[timestep: 41] [epoch: 2161] loss: 0.0395909473\n",
      "[timestep: 41] [epoch: 2191] loss: 0.0038141953\n",
      "[timestep: 41] [epoch: 2221] loss: 0.0044023544\n",
      "[timestep: 41] [epoch: 2251] loss: 0.0087314015\n",
      "[timestep: 41] [epoch: 2281] loss: 0.0023173550\n",
      "[timestep: 41] [epoch: 2311] loss: 0.0251380168\n",
      "[timestep: 41] [epoch: 2341] loss: 0.0032486150\n",
      "[timestep: 41] [epoch: 2371] loss: 0.0045437883\n",
      "[timestep: 41] [epoch: 2401] loss: 0.0014111968\n",
      "[timestep: 41] [epoch: 2431] loss: 0.0153952986\n",
      "[timestep: 41] [epoch: 2461] loss: 0.0032186983\n",
      "[timestep: 41] [epoch: 2491] loss: 0.0071023004\n",
      "[timestep: 41] [epoch: 2521] loss: 0.0052010850\n",
      "[timestep: 41] [epoch: 2551] loss: 0.0044878954\n",
      "[timestep: 41] [epoch: 2581] loss: 0.0070949057\n",
      "[timestep: 41] [epoch: 2611] loss: 0.0030478798\n",
      "[timestep: 41] [epoch: 2641] loss: 0.0037127100\n",
      "[timestep: 41] [epoch: 2671] loss: 0.0319338627\n",
      "[timestep: 41] [epoch: 2701] loss: 0.0048328992\n",
      "[timestep: 41] [epoch: 2731] loss: 0.0034252000\n",
      "[timestep: 41] [epoch: 2761] loss: 0.0051374109\n",
      "[timestep: 41] [epoch: 2791] loss: 0.0043368340\n",
      "[timestep: 41] [epoch: 2821] loss: 0.0069832942\n",
      "[timestep: 41] [epoch: 2851] loss: 0.0141529366\n",
      "[timestep: 41] [epoch: 2881] loss: 0.0035875810\n",
      "[timestep: 41] [epoch: 2911] loss: 0.0027372926\n",
      "[timestep: 41] [epoch: 2941] loss: 0.0212628208\n",
      "[timestep: 41] [epoch: 2971] loss: 0.0034278901\n",
      "[timestep: 41] [epoch: 3001] loss: 0.0081776250\n",
      "[timestep: 41] [epoch: 3031] loss: 0.0017085751\n",
      "[timestep: 41] [epoch: 3061] loss: 0.0118342713\n",
      "[timestep: 41] [epoch: 3091] loss: 0.0077500823\n",
      "[timestep: 41] [epoch: 3121] loss: 0.0017877707\n",
      "[timestep: 41] [epoch: 3151] loss: 0.0052149035\n",
      "[timestep: 41] [epoch: 3181] loss: 0.0070881671\n",
      "[timestep: 41] [epoch: 3211] loss: 0.0036548143\n",
      "[timestep: 41] [epoch: 3241] loss: 0.0071098292\n",
      "[timestep: 41] [epoch: 3271] loss: 0.0054823938\n",
      "[timestep: 41] [epoch: 3301] loss: 0.0082609262\n",
      "[timestep: 41] [epoch: 3331] loss: 0.0015538349\n",
      "[timestep: 41] [epoch: 3361] loss: 0.0066193123\n",
      "[timestep: 41] [epoch: 3391] loss: 0.0029232160\n",
      "[timestep: 41] [epoch: 3421] loss: 0.0026645837\n",
      "[timestep: 41] [epoch: 3451] loss: 0.0043249456\n",
      "[timestep: 41] [epoch: 3481] loss: 0.0201113392\n",
      "[timestep: 41] [epoch: 3511] loss: 0.0032491528\n",
      "[timestep: 41] [epoch: 3541] loss: 0.0058873501\n",
      "[timestep: 41] [epoch: 3571] loss: 0.0030347616\n",
      "[timestep: 41] [epoch: 3601] loss: 0.0038374588\n",
      "[timestep: 41] [epoch: 3631] loss: 0.0023912974\n",
      "[timestep: 41] [epoch: 3661] loss: 0.0095051564\n",
      "[timestep: 41] [epoch: 3691] loss: 0.0068320232\n",
      "[timestep: 41] [epoch: 3721] loss: 0.0052233171\n",
      "[timestep: 41] [epoch: 3751] loss: 0.0024977983\n",
      "[timestep: 41] [epoch: 3781] loss: 0.0050571705\n",
      "[timestep: 41] [epoch: 3811] loss: 0.0030408478\n",
      "[timestep: 41] [epoch: 3841] loss: 0.0228514969\n",
      "[timestep: 41] [epoch: 3871] loss: 0.0026415824\n",
      "[timestep: 41] [epoch: 3901] loss: 0.0047031180\n",
      "[timestep: 41] [epoch: 3931] loss: 0.0018905937\n",
      "[timestep: 41] [epoch: 3961] loss: 0.0047772205\n",
      "[timestep: 41] [epoch: 3991] loss: 0.0041049859\n",
      "[timestep: 41] [epoch: 4021] loss: 0.0026885448\n",
      "[timestep: 41] [epoch: 4051] loss: 0.0026184148\n",
      "[timestep: 41] [epoch: 4081] loss: 0.0038410295\n",
      "[timestep: 41] [epoch: 4111] loss: 0.0021192103\n",
      "[timestep: 41] [epoch: 4141] loss: 0.0061667114\n",
      "[timestep: 41] [epoch: 4171] loss: 0.0076112752\n",
      "[timestep: 41] [epoch: 4201] loss: 0.0023843972\n",
      "[timestep: 41] [epoch: 4231] loss: 0.0040508327\n",
      "[timestep: 41] [epoch: 4261] loss: 0.0181072466\n",
      "[timestep: 41] [epoch: 4291] loss: 0.0035963296\n",
      "[timestep: 41] [epoch: 4321] loss: 0.0041728020\n",
      "[timestep: 41] [epoch: 4351] loss: 0.0043003857\n",
      "[timestep: 41] [epoch: 4381] loss: 0.0016346495\n",
      "[timestep: 41] [epoch: 4411] loss: 0.0090811215\n",
      "[timestep: 41] [epoch: 4441] loss: 0.0074605253\n",
      "[timestep: 41] [epoch: 4471] loss: 0.0041085863\n",
      "[timestep: 41] [epoch: 4501] loss: 0.0020435576\n",
      "[timestep: 41] [epoch: 4531] loss: 0.0131005775\n",
      "[timestep: 41] [epoch: 4561] loss: 0.0074598258\n",
      "[timestep: 41] [epoch: 4591] loss: 0.0044843024\n",
      "[timestep: 41] [epoch: 4621] loss: 0.0028082735\n",
      "[timestep: 41] [epoch: 4651] loss: 0.0030622340\n",
      "[timestep: 41] [epoch: 4681] loss: 0.0016906566\n",
      "[timestep: 41] [epoch: 4711] loss: 0.0081417784\n",
      "[timestep: 41] [epoch: 4741] loss: 0.0082164565\n",
      "[timestep: 41] [epoch: 4771] loss: 0.0032071036\n",
      "[timestep: 41] [epoch: 4801] loss: 0.0025963658\n",
      "[timestep: 41] [epoch: 4831] loss: 0.0027630902\n",
      "[timestep: 41] [epoch: 4861] loss: 0.0019660471\n",
      "[timestep: 41] [epoch: 4891] loss: 0.0137854842\n",
      "[timestep: 41] [epoch: 4921] loss: 0.0052149827\n",
      "[timestep: 41] [epoch: 4951] loss: 0.0044009825\n",
      "[timestep: 41] [epoch: 4981] loss: 0.0033486765\n",
      "[timestep: 41] [epoch: 5011] loss: 0.0013615742\n",
      "[timestep: 41] [epoch: 5041] loss: 0.0077480292\n",
      "[timestep: 41] [epoch: 5071] loss: 0.0013923002\n",
      "[timestep: 41] [epoch: 5101] loss: 0.0025377851\n",
      "[timestep: 41] [epoch: 5131] loss: 0.0262619238\n",
      "[timestep: 41] [epoch: 5161] loss: 0.0034650224\n",
      "[timestep: 41] [epoch: 5191] loss: 0.0036499377\n",
      "[timestep: 41] [epoch: 5221] loss: 0.0056871679\n",
      "[timestep: 41] [epoch: 5251] loss: 0.0015579171\n",
      "[timestep: 41] [epoch: 5281] loss: 0.0079525001\n",
      "[timestep: 41] [epoch: 5311] loss: 0.0043715946\n",
      "[timestep: 41] [epoch: 5341] loss: 0.0030463370\n",
      "[timestep: 41] [epoch: 5371] loss: 0.0128342677\n",
      "[timestep: 41] [epoch: 5401] loss: 0.0024347368\n",
      "[timestep: 41] [epoch: 5431] loss: 0.0035679112\n",
      "[timestep: 41] [epoch: 5461] loss: 0.0011427158\n",
      "[timestep: 41] [epoch: 5491] loss: 0.0031934436\n",
      "[timestep: 41] [epoch: 5521] loss: 0.0017185155\n",
      "[timestep: 41] [epoch: 5551] loss: 0.0042122500\n",
      "[timestep: 41] [epoch: 5581] loss: 0.0048911627\n",
      "[timestep: 41] [epoch: 5611] loss: 0.0069533670\n",
      "[timestep: 41] [epoch: 5641] loss: 0.0029736289\n",
      "[timestep: 41] [epoch: 5671] loss: 0.0038704812\n",
      "[timestep: 41] [epoch: 5701] loss: 0.0013336460\n",
      "[timestep: 41] [epoch: 5731] loss: 0.0014874658\n",
      "[timestep: 41] [epoch: 5761] loss: 0.0043922211\n",
      "[timestep: 41] [epoch: 5791] loss: 0.0029610381\n",
      "[timestep: 41] [epoch: 5821] loss: 0.0015318892\n",
      "[timestep: 41] [epoch: 5851] loss: 0.0033249105\n",
      "[timestep: 41] [epoch: 5881] loss: 0.0041644382\n",
      "[timestep: 41] [epoch: 5911] loss: 0.0022056901\n",
      "[timestep: 41] [epoch: 5941] loss: 0.0017730176\n",
      "[timestep: 41] [epoch: 5971] loss: 0.0047545191\n",
      "[timestep: 41] [epoch: 6001] loss: 0.0027847118\n",
      "[timestep: 41] [epoch: 6031] loss: 0.0033050678\n",
      "[timestep: 41] [epoch: 6061] loss: 0.0073482450\n",
      "[timestep: 41] [epoch: 6091] loss: 0.0051035234\n",
      "[timestep: 41] [epoch: 6121] loss: 0.0021947809\n",
      "[timestep: 41] [epoch: 6151] loss: 0.0024128736\n",
      "[timestep: 41] [epoch: 6181] loss: 0.0021760338\n",
      "[timestep: 41] [epoch: 6211] loss: 0.0099625587\n",
      "[timestep: 41] [epoch: 6241] loss: 0.0024685194\n",
      "[timestep: 41] [epoch: 6271] loss: 0.0315000415\n",
      "[timestep: 41] [epoch: 6301] loss: 0.0588654429\n",
      "[timestep: 41] [epoch: 6331] loss: 0.0047204522\n",
      "[timestep: 41] [epoch: 6361] loss: 0.0012671992\n",
      "0.01\n",
      "[timestep: 42] [epoch: 1] loss: 0.7739880681\n",
      "[timestep: 42] [epoch: 31] loss: 0.0623483397\n",
      "[timestep: 42] [epoch: 61] loss: 0.0070236698\n",
      "[timestep: 42] [epoch: 91] loss: 0.0025507237\n",
      "[timestep: 42] [epoch: 121] loss: 0.0012723510\n",
      "[timestep: 42] [epoch: 151] loss: 0.0017368559\n",
      "[timestep: 42] [epoch: 181] loss: 0.0036677970\n",
      "[timestep: 42] [epoch: 211] loss: 0.0022934168\n",
      "[timestep: 42] [epoch: 241] loss: 0.0176840797\n",
      "[timestep: 42] [epoch: 271] loss: 0.0041125338\n",
      "[timestep: 42] [epoch: 301] loss: 0.0109202387\n",
      "[timestep: 42] [epoch: 331] loss: 0.0018112110\n",
      "[timestep: 42] [epoch: 361] loss: 0.0128912404\n",
      "[timestep: 42] [epoch: 391] loss: 0.0080284439\n",
      "[timestep: 42] [epoch: 421] loss: 0.0039910553\n",
      "[timestep: 42] [epoch: 451] loss: 0.0034926797\n",
      "[timestep: 42] [epoch: 481] loss: 0.0538489260\n",
      "[timestep: 42] [epoch: 511] loss: 0.0024438882\n",
      "[timestep: 42] [epoch: 541] loss: 0.0033639628\n",
      "[timestep: 42] [epoch: 571] loss: 0.0077354531\n",
      "[timestep: 42] [epoch: 601] loss: 0.0088424720\n",
      "[timestep: 42] [epoch: 631] loss: 0.0157562383\n",
      "[timestep: 42] [epoch: 661] loss: 0.0225909166\n",
      "[timestep: 42] [epoch: 691] loss: 0.0064480091\n",
      "[timestep: 42] [epoch: 721] loss: 0.0029092950\n",
      "[timestep: 42] [epoch: 751] loss: 0.0026794598\n",
      "[timestep: 42] [epoch: 781] loss: 0.0044543054\n",
      "[timestep: 42] [epoch: 811] loss: 0.0168275535\n",
      "[timestep: 42] [epoch: 841] loss: 0.0034775040\n",
      "[timestep: 42] [epoch: 871] loss: 0.0078985523\n",
      "[timestep: 42] [epoch: 901] loss: 0.0017017706\n",
      "[timestep: 42] [epoch: 931] loss: 0.0082843881\n",
      "[timestep: 42] [epoch: 961] loss: 0.0041111289\n",
      "[timestep: 42] [epoch: 991] loss: 0.0021818492\n",
      "[timestep: 42] [epoch: 1021] loss: 0.0154981017\n",
      "[timestep: 42] [epoch: 1051] loss: 0.0071880799\n",
      "[timestep: 42] [epoch: 1081] loss: 0.0054973988\n",
      "[timestep: 42] [epoch: 1111] loss: 0.0094461236\n",
      "[timestep: 42] [epoch: 1141] loss: 0.0031972332\n",
      "[timestep: 42] [epoch: 1171] loss: 0.0129671358\n",
      "[timestep: 42] [epoch: 1201] loss: 0.0086341863\n",
      "[timestep: 42] [epoch: 1231] loss: 0.0121523757\n",
      "[timestep: 42] [epoch: 1261] loss: 0.0083391573\n",
      "[timestep: 42] [epoch: 1291] loss: 0.0124690160\n",
      "[timestep: 42] [epoch: 1321] loss: 0.0044881040\n",
      "[timestep: 42] [epoch: 1351] loss: 0.0415223613\n",
      "[timestep: 42] [epoch: 1381] loss: 0.0042473120\n",
      "[timestep: 42] [epoch: 1411] loss: 0.0028799027\n",
      "[timestep: 42] [epoch: 1441] loss: 0.0047468129\n",
      "[timestep: 42] [epoch: 1471] loss: 0.0124534043\n",
      "[timestep: 42] [epoch: 1501] loss: 0.0022850891\n",
      "[timestep: 42] [epoch: 1531] loss: 0.0028146128\n",
      "[timestep: 42] [epoch: 1561] loss: 0.0059861429\n",
      "[timestep: 42] [epoch: 1591] loss: 0.0044827182\n",
      "[timestep: 42] [epoch: 1621] loss: 0.0023624669\n",
      "[timestep: 42] [epoch: 1651] loss: 0.0093697067\n",
      "[timestep: 42] [epoch: 1681] loss: 0.0026008890\n",
      "[timestep: 42] [epoch: 1711] loss: 0.0022064587\n",
      "[timestep: 42] [epoch: 1741] loss: 0.0253418833\n",
      "[timestep: 42] [epoch: 1771] loss: 0.0039273826\n",
      "[timestep: 42] [epoch: 1801] loss: 0.0096299890\n",
      "[timestep: 42] [epoch: 1831] loss: 0.0023692693\n",
      "[timestep: 42] [epoch: 1861] loss: 0.0015246350\n",
      "[timestep: 42] [epoch: 1891] loss: 0.0076188259\n",
      "[timestep: 42] [epoch: 1921] loss: 0.0042513642\n",
      "[timestep: 42] [epoch: 1951] loss: 0.0035592769\n",
      "[timestep: 42] [epoch: 1981] loss: 0.0032421635\n",
      "[timestep: 42] [epoch: 2011] loss: 0.0020045042\n",
      "[timestep: 42] [epoch: 2041] loss: 0.0029914184\n",
      "[timestep: 42] [epoch: 2071] loss: 0.0434423983\n",
      "[timestep: 42] [epoch: 2101] loss: 0.0029848360\n",
      "[timestep: 42] [epoch: 2131] loss: 0.0033789533\n",
      "[timestep: 42] [epoch: 2161] loss: 0.0132127423\n",
      "[timestep: 42] [epoch: 2191] loss: 0.0028071904\n",
      "[timestep: 42] [epoch: 2221] loss: 0.0059254551\n",
      "[timestep: 42] [epoch: 2251] loss: 0.0018777788\n",
      "[timestep: 42] [epoch: 2281] loss: 0.0050660530\n",
      "[timestep: 42] [epoch: 2311] loss: 0.0208143480\n",
      "[timestep: 42] [epoch: 2341] loss: 0.0042166929\n",
      "[timestep: 42] [epoch: 2371] loss: 0.0136454273\n",
      "[timestep: 42] [epoch: 2401] loss: 0.0062452154\n",
      "[timestep: 42] [epoch: 2431] loss: 0.0035889675\n",
      "[timestep: 42] [epoch: 2461] loss: 0.0025507091\n",
      "[timestep: 42] [epoch: 2491] loss: 0.0050719865\n",
      "[timestep: 42] [epoch: 2521] loss: 0.0091567058\n",
      "[timestep: 42] [epoch: 2551] loss: 0.0049411869\n",
      "[timestep: 42] [epoch: 2581] loss: 0.0024360740\n",
      "[timestep: 42] [epoch: 2611] loss: 0.0048923041\n",
      "[timestep: 42] [epoch: 2641] loss: 0.0114761377\n",
      "[timestep: 42] [epoch: 2671] loss: 0.0030637817\n",
      "[timestep: 42] [epoch: 2701] loss: 0.0021182527\n",
      "[timestep: 42] [epoch: 2731] loss: 0.0061649024\n",
      "[timestep: 42] [epoch: 2761] loss: 0.0084031001\n",
      "[timestep: 42] [epoch: 2791] loss: 0.0046008178\n",
      "[timestep: 42] [epoch: 2821] loss: 0.0018900357\n",
      "[timestep: 42] [epoch: 2851] loss: 0.0110798217\n",
      "[timestep: 42] [epoch: 2881] loss: 0.0064286022\n",
      "[timestep: 42] [epoch: 2911] loss: 0.0038229371\n",
      "[timestep: 42] [epoch: 2941] loss: 0.0037738900\n",
      "[timestep: 42] [epoch: 2971] loss: 0.0107070338\n",
      "[timestep: 42] [epoch: 3001] loss: 0.0020295773\n",
      "[timestep: 42] [epoch: 3031] loss: 0.0063129505\n",
      "[timestep: 42] [epoch: 3061] loss: 0.0017535499\n",
      "[timestep: 42] [epoch: 3091] loss: 0.0543918386\n",
      "[timestep: 42] [epoch: 3121] loss: 0.0033608524\n",
      "[timestep: 42] [epoch: 3151] loss: 0.0015388882\n",
      "[timestep: 42] [epoch: 3181] loss: 0.0020473008\n",
      "[timestep: 42] [epoch: 3211] loss: 0.0149686728\n",
      "[timestep: 42] [epoch: 3241] loss: 0.0048010675\n",
      "[timestep: 42] [epoch: 3271] loss: 0.0216036066\n",
      "[timestep: 42] [epoch: 3301] loss: 0.0062875072\n",
      "[timestep: 42] [epoch: 3331] loss: 0.0020704537\n",
      "[timestep: 42] [epoch: 3361] loss: 0.0024493402\n",
      "[timestep: 42] [epoch: 3391] loss: 0.0217274930\n",
      "[timestep: 42] [epoch: 3421] loss: 0.0028944828\n",
      "[timestep: 42] [epoch: 3451] loss: 0.0026082033\n",
      "[timestep: 42] [epoch: 3481] loss: 0.0021312200\n",
      "[timestep: 42] [epoch: 3511] loss: 0.0019078588\n",
      "[timestep: 42] [epoch: 3541] loss: 0.0048711551\n",
      "[timestep: 42] [epoch: 3571] loss: 0.0026720595\n",
      "[timestep: 42] [epoch: 3601] loss: 0.0098692207\n",
      "[timestep: 42] [epoch: 3631] loss: 0.0023328592\n",
      "[timestep: 42] [epoch: 3661] loss: 0.0019480051\n",
      "[timestep: 42] [epoch: 3691] loss: 0.0032525607\n",
      "[timestep: 42] [epoch: 3721] loss: 0.0068699308\n",
      "[timestep: 42] [epoch: 3751] loss: 0.0192588288\n",
      "[timestep: 42] [epoch: 3781] loss: 0.0026857040\n",
      "[timestep: 42] [epoch: 3811] loss: 0.0025337997\n",
      "[timestep: 42] [epoch: 3841] loss: 0.0092371404\n",
      "[timestep: 42] [epoch: 3871] loss: 0.0026991800\n",
      "[timestep: 42] [epoch: 3901] loss: 0.0043188464\n",
      "[timestep: 42] [epoch: 3931] loss: 0.0028959829\n",
      "[timestep: 42] [epoch: 3961] loss: 0.0043212823\n",
      "[timestep: 42] [epoch: 3991] loss: 0.0048300680\n",
      "[timestep: 42] [epoch: 4021] loss: 0.0014539040\n",
      "[timestep: 42] [epoch: 4051] loss: 0.0019496239\n",
      "[timestep: 42] [epoch: 4081] loss: 0.0056382534\n",
      "[timestep: 42] [epoch: 4111] loss: 0.0035162121\n",
      "[timestep: 42] [epoch: 4141] loss: 0.0020437478\n",
      "[timestep: 42] [epoch: 4171] loss: 0.0032644519\n",
      "[timestep: 42] [epoch: 4201] loss: 0.0031260843\n",
      "0.01\n",
      "[timestep: 43] [epoch: 1] loss: 0.7636965513\n",
      "[timestep: 43] [epoch: 31] loss: 0.0540923849\n",
      "[timestep: 43] [epoch: 61] loss: 0.0038874042\n",
      "0.01\n",
      "[timestep: 44] [epoch: 1] loss: 0.7476691008\n",
      "[timestep: 44] [epoch: 31] loss: 0.0635627508\n",
      "[timestep: 44] [epoch: 61] loss: 0.0033136753\n",
      "0.01\n",
      "[timestep: 45] [epoch: 1] loss: 0.7605637312\n",
      "[timestep: 45] [epoch: 31] loss: 0.0713405237\n",
      "[timestep: 45] [epoch: 61] loss: 0.0036806725\n",
      "0.01\n",
      "[timestep: 46] [epoch: 1] loss: 0.7504819632\n",
      "[timestep: 46] [epoch: 31] loss: 0.0744815916\n",
      "[timestep: 46] [epoch: 61] loss: 0.0043535503\n",
      "0.01\n",
      "[timestep: 47] [epoch: 1] loss: 0.7494959831\n",
      "[timestep: 47] [epoch: 31] loss: 0.0600163713\n",
      "[timestep: 47] [epoch: 61] loss: 0.0060507925\n",
      "0.01\n",
      "[timestep: 48] [epoch: 1] loss: 0.7416260242\n",
      "[timestep: 48] [epoch: 31] loss: 0.1279399842\n",
      "[timestep: 48] [epoch: 61] loss: 0.0062739216\n",
      "[timestep: 48] [epoch: 91] loss: 0.0020729108\n",
      "[timestep: 48] [epoch: 121] loss: 0.0072686537\n",
      "0.01\n",
      "[timestep: 49] [epoch: 1] loss: 0.7497850657\n",
      "[timestep: 49] [epoch: 31] loss: 0.1082137376\n",
      "[timestep: 49] [epoch: 61] loss: 0.0060856184\n",
      "[timestep: 49] [epoch: 91] loss: 0.0019973367\n",
      "[timestep: 49] [epoch: 121] loss: 0.0120590245\n",
      "[timestep: 49] [epoch: 151] loss: 0.0071575218\n",
      "0.01\n",
      "[timestep: 50] [epoch: 1] loss: 0.7451423407\n",
      "[timestep: 50] [epoch: 31] loss: 0.1115503907\n",
      "[timestep: 50] [epoch: 61] loss: 0.0071980003\n",
      "[timestep: 50] [epoch: 91] loss: 0.0038004625\n",
      "[timestep: 50] [epoch: 121] loss: 0.0019236120\n",
      "[timestep: 50] [epoch: 151] loss: 0.0170637779\n",
      "[timestep: 50] [epoch: 181] loss: 0.0054549035\n",
      "[timestep: 50] [epoch: 211] loss: 0.0057492540\n",
      "[timestep: 50] [epoch: 241] loss: 0.0019328231\n",
      "[timestep: 50] [epoch: 271] loss: 0.0193615872\n",
      "[timestep: 50] [epoch: 301] loss: 0.0044068894\n",
      "[timestep: 50] [epoch: 331] loss: 0.0082411263\n",
      "[timestep: 50] [epoch: 361] loss: 0.0021022984\n",
      "[timestep: 50] [epoch: 391] loss: 0.0046463725\n",
      "[timestep: 50] [epoch: 421] loss: 0.0049533397\n",
      "[timestep: 50] [epoch: 451] loss: 0.0126534747\n",
      "[timestep: 50] [epoch: 481] loss: 0.0579088591\n",
      "[timestep: 50] [epoch: 511] loss: 0.0027286408\n",
      "[timestep: 50] [epoch: 541] loss: 0.0131184794\n",
      "[timestep: 50] [epoch: 571] loss: 0.0158056132\n",
      "[timestep: 50] [epoch: 601] loss: 0.0342670940\n",
      "[timestep: 50] [epoch: 631] loss: 0.0234472398\n",
      "[timestep: 50] [epoch: 661] loss: 0.0180192888\n",
      "[timestep: 50] [epoch: 691] loss: 0.0307541750\n",
      "[timestep: 50] [epoch: 721] loss: 0.0080715194\n",
      "[timestep: 50] [epoch: 751] loss: 0.0459545031\n",
      "[timestep: 50] [epoch: 781] loss: 0.0292525385\n",
      "[timestep: 50] [epoch: 811] loss: 0.0062358556\n",
      "[timestep: 50] [epoch: 841] loss: 0.0101721035\n",
      "[timestep: 50] [epoch: 871] loss: 0.0085931420\n",
      "[timestep: 50] [epoch: 901] loss: 0.0183766577\n",
      "[timestep: 50] [epoch: 931] loss: 0.0200742632\n",
      "[timestep: 50] [epoch: 961] loss: 0.0091466131\n",
      "[timestep: 50] [epoch: 991] loss: 0.0082506444\n",
      "[timestep: 50] [epoch: 1021] loss: 0.0018791261\n",
      "[timestep: 50] [epoch: 1051] loss: 0.0019532656\n",
      "[timestep: 50] [epoch: 1081] loss: 0.0108256079\n",
      "[timestep: 50] [epoch: 1111] loss: 0.0072275647\n",
      "[timestep: 50] [epoch: 1141] loss: 0.0029857312\n",
      "[timestep: 50] [epoch: 1171] loss: 0.0103711877\n",
      "[timestep: 50] [epoch: 1201] loss: 0.0108420011\n",
      "[timestep: 50] [epoch: 1231] loss: 0.0291687511\n",
      "[timestep: 50] [epoch: 1261] loss: 0.0029829787\n",
      "[timestep: 50] [epoch: 1291] loss: 0.0227628723\n",
      "[timestep: 50] [epoch: 1321] loss: 0.0074888598\n",
      "[timestep: 50] [epoch: 1351] loss: 0.0137933586\n",
      "[timestep: 50] [epoch: 1381] loss: 0.0047710137\n",
      "[timestep: 50] [epoch: 1411] loss: 0.0011756634\n",
      "The training time is:  10768.841036558151\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4cad4-f1a2-4c25-9f19-1489b910bb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
